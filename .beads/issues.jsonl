{"id":"bd-10c","title":"[10.9] Build trust economics dashboard with attacker-ROI deltas.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.9 — Moonshot Disruption Track\n\nWhy This Exists:\nMoonshot disruption track for public benchmark leadership, adversarial campaigns, verifier economy, and category-shift reporting.\n\nTask Objective:\nBuild trust economics dashboard with attacker-ROI deltas.\n\nAcceptance Criteria:\n- Implement with explicit success/failure invariants and deterministic behavior under normal, edge, and fault scenarios.\n- Ensure outcomes are verifiable via automated tests and reproducible artifact outputs.\n\nExpected Artifacts:\n- Section-owned design/spec artifact at `docs/specs/section_10_9/bd-10c_contract.md`, capturing decision rationale, invariants, and interface boundaries.\n- Machine-readable verification artifact at `artifacts/section_10_9/bd-10c/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_9/bd-10c/verification_summary.md` linking implementation intent to measured outcomes.\n\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.9] Build trust economics dashboard with attacker-ROI deltas.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.9] Build trust economics dashboard with attacker-ROI deltas.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.9] Build trust economics dashboard with attacker-ROI deltas.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.9] Build trust economics dashboard with attacker-ROI deltas.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.9] Build trust economics dashboard with attacker-ROI deltas.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"1. Dashboard displays attacker-ROI deltas: estimated cost-to-compromise franken_node vs. Node.js across at least 5 attack categories (supply-chain, privilege escalation, resource exhaustion, data exfiltration, denial of service).\n2. Per Section 3 category targets: dashboard highlights where franken_node achieves >= 10x compromise reduction (cost increase for attacker).\n3. Metrics are computed from empirical data: adversarial campaign results (bd-9is), fuzz findings, CVE analysis, and audit results.\n4. Dashboard includes time-series views showing how attacker-ROI evolves across releases.\n5. Data sources are documented and each metric includes a methodology note explaining how the ROI delta was calculated.\n6. Dashboard is generated as a static HTML report (no external runtime dependencies) from a structured JSON data source under artifacts/.\n7. Per Section 9F moonshot bets: dashboard includes a 'trust economics summary' section quantifying the aggregate security value proposition with reproducible calculations.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:36:48.602750013Z","created_by":"ubuntu","updated_at":"2026-02-20T15:20:30.712203367Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-9","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-10c","depends_on_id":"bd-m8p","type":"blocks","created_at":"2026-02-20T07:43:24.181062201Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-10ee","title":"[16] Contribution: transparent technical reports","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 16\n\nTask Objective:\nPublish transparent reports including failures and corrective actions.\n\nExecution Requirements:\n- Make this requirement machine-verifiable and release-gated where applicable.\n- Keep behavior self-documenting so future contributors do not need to re-open the master plan.\n\nTesting & Logging Requirements:\n- Unit tests for rule/contract logic and error conditions.\n- Integration/E2E tests for workflow-level enforcement.\n- Structured logs with stable codes and trace IDs.\n- Reproducible artifacts that prove contract satisfaction.\n\nAcceptance Criteria:\n- Success and failure invariants for [16] Contribution: transparent technical reports are explicitly quantified and machine-verifiable.\n- Determinism requirements for [16] Contribution: transparent technical reports are validated across repeated runs and adversarial perturbations.\n\n\nExpected Artifacts:\n- Machine-readable verification artifact with explicit canonical path under artifacts/section_16/bd-10ee/verification_evidence.json, suitable for CI/release gating.\n- Human-readable verification summary with explicit canonical path under artifacts/section_16/bd-10ee/verification_summary.md, linking implementation intent to measured validation outcomes.\n\nTask-Specific Clarification:\n- The implementation must deliver the exact capability named in the title, with no scope dilution and no silent feature omission.\n- Validation artifacts must include capability-specific thresholds, pass/fail criteria, and reproducible evidence bundles tied to this bead ID.\n- Program/section verification gates must be able to consume this bead's outputs without manual interpretation.\n\nWhy This Improves User Outcomes:\n- \"[16] Contribution: transparent technical reports\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[16] Contribution: transparent technical reports\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"1. Transparent technical reports are published for all major project milestones, including both successes and failures.\n2. Each report includes: (a) objective and hypothesis, (b) methodology, (c) results (quantitative where possible), (d) failures and what was learned, (e) corrective actions taken, (f) open questions and future work.\n3. Failure transparency: at least 30% of published reports include documentation of approaches that did not work and why.\n4. Reports are published on a regular cadence: at least quarterly, with ad-hoc reports for significant incidents or discoveries.\n5. Reports are written for a technical audience but include an executive summary accessible to non-specialists.\n6. Reports are versioned and hosted in a public, searchable archive with consistent formatting.\n7. Community feedback mechanism: each report has a discussion thread or comment section for external feedback.\n8. Evidence: technical_report_registry.json with per-report: title, date, category (success/failure/mixed), publication URL, and feedback count.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:39:37.131441436Z","created_by":"ubuntu","updated_at":"2026-02-20T15:28:44.620275194Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-16","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-10ee","depends_on_id":"bd-3id1","type":"blocks","created_at":"2026-02-20T07:43:26.724779215Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-10g0","title":"[10.16] Section-wide verification gate: comprehensive unit+e2e+logging","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.16\n\nTask Objective:\nCreate a hard section completion gate that verifies all implemented behavior in this section with comprehensive unit tests, integration/e2e scripts, and detailed structured logging evidence.\n\nAcceptance Criteria:\n- Section test matrix covers happy-path, edge-case, and adversarial/error-path scenarios for all section deliverables.\n- E2E scripts execute representative end-user workflows and policy/control-plane transitions for this section.\n- Structured logs include stable event/error codes, trace correlation IDs, and enough context for deterministic replay triage.\n- Verification report is deterministic and machine-readable for CI/release gating.\n\nExpected Artifacts:\n- Section-level test matrix and coverage summary artifact.\n- E2E script suite with pass/fail outputs and reproducible fixtures/seeds.\n- Structured log validation report and traceability bundle.\n- Gate verdict artifact consumable by release automation.\n\n- Machine-readable verification artifact at `artifacts/section_10_16/bd-10g0/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_16/bd-10g0/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests must validate contracts, invariants, and failure semantics.\n- E2E tests must validate cross-component behavior from user/operator entrypoints to persisted effects.\n- Logging must support root-cause analysis without hidden context requirements.\n\nTask-Specific Clarification:\n- For \"[10.16] Section-wide verification gate: comprehensive unit+e2e+logging\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.16] Section-wide verification gate: comprehensive unit+e2e+logging\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.16] Section-wide verification gate: comprehensive unit+e2e+logging\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.16] Section-wide verification gate: comprehensive unit+e2e+logging\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.16] Section-wide verification gate: comprehensive unit+e2e+logging\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:48:15.835934792Z","created_by":"ubuntu","updated_at":"2026-02-20T08:43:51.657945440Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-16","test-obligations","verification-gate"],"dependencies":[{"issue_id":"bd-10g0","depends_on_id":"bd-159q","type":"blocks","created_at":"2026-02-20T07:48:16.036471071Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-10g0","depends_on_id":"bd-1719","type":"blocks","created_at":"2026-02-20T07:48:16.519026205Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-10g0","depends_on_id":"bd-1a1j","type":"blocks","created_at":"2026-02-20T07:48:16.472312389Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-10g0","depends_on_id":"bd-1dpd","type":"blocks","created_at":"2026-02-20T08:24:26.286693849Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-10g0","depends_on_id":"bd-1v65","type":"blocks","created_at":"2026-02-20T07:48:16.283543557Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-10g0","depends_on_id":"bd-1xtf","type":"blocks","created_at":"2026-02-20T07:48:16.567260334Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-10g0","depends_on_id":"bd-26ux","type":"blocks","created_at":"2026-02-20T07:48:16.378661078Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-10g0","depends_on_id":"bd-28ld","type":"blocks","created_at":"2026-02-20T07:48:16.668054368Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-10g0","depends_on_id":"bd-2f5l","type":"blocks","created_at":"2026-02-20T07:48:16.186051413Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-10g0","depends_on_id":"bd-2ji2","type":"blocks","created_at":"2026-02-20T07:48:15.938293521Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-10g0","depends_on_id":"bd-2owx","type":"blocks","created_at":"2026-02-20T07:48:16.716714059Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-10g0","depends_on_id":"bd-2tua","type":"blocks","created_at":"2026-02-20T07:48:16.425842997Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-10g0","depends_on_id":"bd-2twu","type":"blocks","created_at":"2026-02-20T08:20:52.107783222Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-10g0","depends_on_id":"bd-34ll","type":"blocks","created_at":"2026-02-20T07:48:16.619989725Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-10g0","depends_on_id":"bd-35l5","type":"blocks","created_at":"2026-02-20T07:48:15.986272173Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-10g0","depends_on_id":"bd-3ndj","type":"blocks","created_at":"2026-02-20T07:48:16.236183937Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-10g0","depends_on_id":"bd-3u2o","type":"blocks","created_at":"2026-02-20T07:48:16.089917108Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-10g0","depends_on_id":"bd-8l9k","type":"blocks","created_at":"2026-02-20T07:48:16.137776518Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-10g0","depends_on_id":"bd-bt82","type":"blocks","created_at":"2026-02-20T07:48:16.331555341Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-10zx","title":"[BOOTSTRAP] Foundation integration and legacy-bead convergence","description":"Context:\nThis epic integrates active pre-master-plan beads (charter/doc/bootstrap/transplant/check tasks) into the canonical execution graph so no critical foundation work remains structurally orphaned.\n\nObjective:\n- Preserve all existing active work without duplication or scope loss.\n- Provide a single dependency anchor for bootstrap and migration-prep obligations before full plan closure.\n- Keep this bridge explicit so future agents can reason about why these tasks exist and how they relate to the master roadmap.\n\nIn-Scope Bead Families:\n- Product charter and governance baseline (docs surface).\n- CLI/bootstrap readiness beads currently in progress.\n- Transplant integrity chain (snapshot, lockfile, drift workflow).\n- Baseline verification pass executed via rch-only offload.\n\nExecution Notes:\n- This epic is dependency-only orchestration: it does not replace implementation beads.\n- Existing assignees and ownership remain unchanged.\n- Canonical plan epics stay authoritative for feature scope; this epic ensures bootstrap readiness is not forgotten.\n\nAcceptance Criteria:\n- All mapped bootstrap beads are explicitly linked into this epic via dependencies.\n- No mapped bead loses scope, status history, or ownership metadata.\n- Master execution closure (bd-33v) is gated on this integration epic to prevent silent omission.\n\nExpected Artifacts:\n- Dependency map proving each bootstrap bead is attached to this epic.\n- Rationale note that explains why bootstrap beads are retained and how they map to canonical execution.\n- Machine-readable verification artifact at `artifacts/section_bootstrap/bd-10zx/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_bootstrap/bd-10zx/verification_summary.md` linking dependency orchestration intent to measured outcomes.\n\nTesting & Logging Requirements:\n- Unit tests and unit-level validation for any scripts/helpers used to enforce dependency-map integrity.\n- E2E verification that br ready --json and bv --robot-plan reflect this integration deterministically.\n- Detailed structured logs or command artifacts showing before/after graph state and gating behavior.\n\n## Success Criteria\n- Bootstrap and legacy readiness work is fully represented in the canonical dependency graph with no orphan critical tasks.\n- Graph diagnostics remain healthy (no cycles, lint clean) after integration.\n- Agents can select work without ambiguity about bootstrap prerequisites or ownership boundaries.\n\n## Optimization Notes\n- User-Outcome Lens: \"[BOOTSTRAP] Foundation integration and legacy-bead convergence\" must improve operator confidence, safety posture, and deterministic recovery behavior under both normal and adversarial conditions.\n- Cross-Section Coordination: child beads must encode integration assumptions explicitly to avoid local optimizations that degrade system-wide correctness.\n- Verification Non-Negotiable: completion requires reproducible unit/integration/E2E evidence and structured logs suitable for independent replay.\n- Scope Protection: any simplification must preserve canonical-plan feature intent and be justified with explicit tradeoff documentation.","notes":"Verification spine added in this pass: matrix=bd-jvzc, e2e=bd-3k9t, gate=bd-3ohj. This preserves full scope while forcing deterministic quality evidence before bd-10zx closure.","status":"open","priority":1,"issue_type":"epic","created_at":"2026-02-20T07:55:44.537988268Z","created_by":"ubuntu","updated_at":"2026-02-20T16:06:18.316945720Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["bootstrap","plan-integration","quality-gate"],"dependencies":[{"issue_id":"bd-10zx","depends_on_id":"bd-1pk","type":"blocks","created_at":"2026-02-20T07:56:11.516898289Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-10zx","depends_on_id":"bd-1qz","type":"blocks","created_at":"2026-02-20T07:56:10.429288401Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-10zx","depends_on_id":"bd-29q","type":"blocks","created_at":"2026-02-20T07:56:10.754427901Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-10zx","depends_on_id":"bd-2a3","type":"blocks","created_at":"2026-02-20T07:56:10.262899213Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-10zx","depends_on_id":"bd-2lb","type":"blocks","created_at":"2026-02-20T07:56:10.901576221Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-10zx","depends_on_id":"bd-2nd","type":"blocks","created_at":"2026-02-20T07:56:10.100987764Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-10zx","depends_on_id":"bd-32e","type":"blocks","created_at":"2026-02-20T07:56:11.368787246Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-10zx","depends_on_id":"bd-3ohj","type":"blocks","created_at":"2026-02-20T08:03:12.206594381Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-10zx","depends_on_id":"bd-3vk","type":"blocks","created_at":"2026-02-20T07:56:11.051936044Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-10zx","depends_on_id":"bd-7rt","type":"blocks","created_at":"2026-02-20T07:56:10.597375332Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-10zx","depends_on_id":"bd-n9r","type":"blocks","created_at":"2026-02-20T07:56:11.208335195Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-11j7","title":"Epic: Proof-Carrying + Deterministic Operations [10.14d]","description":"- type: epic","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-20T07:47:58.072163029Z","updated_at":"2026-02-20T07:49:21.215295937Z","closed_at":"2026-02-20T07:49:21.215278134Z","close_reason":"Superseded by canonical detailed master-plan graph (bd-33v) with full 10.N-10.21 and 11-16 coverage, explicit dependencies, and per-section verification gates.","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-11oz","title":"Epic: FrankenSQLite-Inspired Runtime Systems [10.11]","description":"- type: epic","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-20T07:47:58.072163029Z","updated_at":"2026-02-20T07:49:21.147604066Z","closed_at":"2026-02-20T07:49:21.147582055Z","close_reason":"Superseded by canonical detailed master-plan graph (bd-33v) with full 10.N-10.21 and 11-16 coverage, explicit dependencies, and per-section verification gates.","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-11rz","title":"[10.19] Add release gate requiring ATC-backed evidence for designated ecosystem-level trust claims.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.19 — Adversarial Trust Commons Execution Track (9M)\n\nWhy This Exists:\nATC federated intelligence track for privacy-preserving cross-deployment threat learning, robust aggregation, and verifier-backed trust metrics.\n\nTask Objective:\nAdd release gate requiring ATC-backed evidence for designated ecosystem-level trust claims.\n\nAcceptance Criteria:\n- Release and public claims about collective intelligence are blocked without required ATC coverage/provenance artifacts; gate output is signed and machine-readable.\n\nExpected Artifacts:\n- `.github/workflows/atc-claim-gate.yml`, `docs/conformance/atc_release_claim_gate.md`, `artifacts/10.19/atc_release_gate_report.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_19/bd-11rz/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_19/bd-11rz/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.19] Add release gate requiring ATC-backed evidence for designated ecosystem-level trust claims.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.19] Add release gate requiring ATC-backed evidence for designated ecosystem-level trust claims.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.19] Add release gate requiring ATC-backed evidence for designated ecosystem-level trust claims.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.19] Add release gate requiring ATC-backed evidence for designated ecosystem-level trust claims.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.19] Add release gate requiring ATC-backed evidence for designated ecosystem-level trust claims.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- Release and public claims about collective intelligence are blocked without required ATC coverage/provenance artifacts; gate output is signed and machine-readable.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:37:06.336242Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:14.991889097Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-19","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-11rz","depends_on_id":"bd-24du","type":"blocks","created_at":"2026-02-20T07:43:19.998855942Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-126h","title":"[10.14] Implement append-only marker stream for high-impact control events with dense sequence invariant checks.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.14 — FrankenSQLite Deep-Mined Expansion Execution Track (9J)\n\nWhy This Exists:\nFrankenSQLite deep-mined control integrity track: evidence ledgers, proofs, epochs, remote effects, markers/MMR, and deterministic fault labs.\n\nTask Objective:\nImplement append-only marker stream for high-impact control events with dense sequence invariant checks.\n\nAcceptance Criteria:\n- Marker stream is append-only with dense sequence and hash-chain invariants; torn-tail recovery is deterministic; invariant breaks trigger hard alert.\n\nExpected Artifacts:\n- `src/control_plane/marker_stream.rs`, `tests/conformance/marker_stream_invariants.rs`, `artifacts/10.14/marker_stream_integrity_report.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_14/bd-126h/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_14/bd-126h/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.14] Implement append-only marker stream for high-impact control events with dense sequence invariant checks.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.14] Implement append-only marker stream for high-impact control events with dense sequence invariant checks.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.14] Implement append-only marker stream for high-impact control events with dense sequence invariant checks.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.14] Implement append-only marker stream for high-impact control events with dense sequence invariant checks.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.14] Implement append-only marker stream for high-impact control events with dense sequence invariant checks.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"Marker stream is append-only with dense sequence and hash-chain invariants; torn-tail recovery is deterministic; invariant breaks trigger hard alert.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:36:58.546917975Z","created_by":"ubuntu","updated_at":"2026-02-20T15:44:03.904341145Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-14","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-126h","depends_on_id":"bd-1vsr","type":"blocks","created_at":"2026-02-20T07:43:15.977112385Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-129f","title":"[10.14] Implement O(1) marker lookup by sequence and O(log N) timestamp-to-sequence search.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.14 — FrankenSQLite Deep-Mined Expansion Execution Track (9J)\n\nWhy This Exists:\nFrankenSQLite deep-mined control integrity track: evidence ledgers, proofs, epochs, remote effects, markers/MMR, and deterministic fault labs.\n\nTask Objective:\nImplement O(1) marker lookup by sequence and O(log N) timestamp-to-sequence search.\n\nAcceptance Criteria:\n- Sequence lookup performs O(1) slot math; timestamp lookup uses bounded O(log N) search; performance targets are met on large history sets.\n\nExpected Artifacts:\n- `tests/perf/marker_lookup_complexity.rs`, `docs/specs/marker_lookup_algorithms.md`, `artifacts/10.14/marker_lookup_benchmarks.csv`.\n\n- Machine-readable verification artifact at `artifacts/section_10_14/bd-129f/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_14/bd-129f/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.14] Implement O(1) marker lookup by sequence and O(log N) timestamp-to-sequence search.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.14] Implement O(1) marker lookup by sequence and O(log N) timestamp-to-sequence search.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.14] Implement O(1) marker lookup by sequence and O(log N) timestamp-to-sequence search.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.14] Implement O(1) marker lookup by sequence and O(log N) timestamp-to-sequence search.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.14] Implement O(1) marker lookup by sequence and O(log N) timestamp-to-sequence search.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"Sequence lookup performs O(1) slot math; timestamp lookup uses bounded O(log N) search; performance targets are met on large history sets.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:36:58.627411278Z","created_by":"ubuntu","updated_at":"2026-02-20T15:44:03.694246146Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-14","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-129f","depends_on_id":"bd-126h","type":"blocks","created_at":"2026-02-20T07:43:16.019535697Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-12f","title":"[10.3] Build migration confidence report with uncertainty bands.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.3 — Migration System\n\nWhy This Exists:\nMigration autopilot pipeline from audit to rollout, designed to collapse migration friction with deterministic confidence and replayability.\n\nTask Objective:\nBuild migration confidence report with uncertainty bands.\n\nAcceptance Criteria:\n- Implement with explicit success/failure invariants and deterministic behavior under normal, edge, and fault scenarios.\n- Ensure outcomes are verifiable via automated tests and reproducible artifact outputs.\n\nExpected Artifacts:\n- Section-owned design/spec artifact at `docs/specs/section_10_3/bd-12f_contract.md`, capturing decision rationale, invariants, and interface boundaries.\n- Machine-readable verification artifact at `artifacts/section_10_3/bd-12f/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_3/bd-12f/verification_summary.md` linking implementation intent to measured outcomes.\n\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.3] Build migration confidence report with uncertainty bands.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.3] Build migration confidence report with uncertainty bands.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.3] Build migration confidence report with uncertainty bands.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.3] Build migration confidence report with uncertainty bands.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.3] Build migration confidence report with uncertainty bands.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","status":"closed","priority":1,"issue_type":"task","assignee":"CrimsonCrane","created_at":"2026-02-20T07:36:45.191082355Z","created_by":"ubuntu","updated_at":"2026-02-20T10:18:27.341029979Z","closed_at":"2026-02-20T10:18:27.341003880Z","close_reason":"done","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-3","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-12f","depends_on_id":"bd-3dn","type":"blocks","created_at":"2026-02-20T07:43:22.233582034Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-12h8","title":"[10.13] Persist required artifacts (`invoke/response/receipt/approval/revocation/audit`) with deterministic replay hooks.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.13 — FCP Deep-Mined Expansion Execution Track (9I)\n\nWhy This Exists:\nDeep connector/provider contract track: lifecycle FSMs, conformance harnesses, fencing, sandboxing, revocation freshness, and protocol hardening.\n\nTask Objective:\nPersist required artifacts (`invoke/response/receipt/approval/revocation/audit`) with deterministic replay hooks.\n\nAcceptance Criteria:\n- Required artifact families are persisted and indexable; replay hook reconstructs high-impact event sequence deterministically; missing required artifacts fail integrity checks.\n\nExpected Artifacts:\n- `tests/integration/required_artifact_replay.rs`, `docs/specs/replay_hook_contract.md`, `artifacts/10.13/replay_integrity_report.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_13/bd-12h8/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_13/bd-12h8/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.13] Persist required artifacts (`invoke/response/receipt/approval/revocation/audit`) with deterministic replay hooks.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.13] Persist required artifacts (`invoke/response/receipt/approval/revocation/audit`) with deterministic replay hooks.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.13] Persist required artifacts (`invoke/response/receipt/approval/revocation/audit`) with deterministic replay hooks.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.13] Persist required artifacts (`invoke/response/receipt/approval/revocation/audit`) with deterministic replay hooks.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.13] Persist required artifacts (`invoke/response/receipt/approval/revocation/audit`) with deterministic replay hooks.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","status":"closed","priority":1,"issue_type":"task","assignee":"CrimsonCrane","created_at":"2026-02-20T07:36:54.331753829Z","created_by":"ubuntu","updated_at":"2026-02-20T13:00:34.420339433Z","closed_at":"2026-02-20T13:00:34.420311151Z","close_reason":"done","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-13","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-12h8","depends_on_id":"bd-1p2b","type":"blocks","created_at":"2026-02-20T07:43:13.769445404Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-12n3","title":"[10.14] Implement idempotency key derivation from request bytes with epoch binding.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.14 — FrankenSQLite Deep-Mined Expansion Execution Track (9J)\n\nWhy This Exists:\nFrankenSQLite deep-mined control integrity track: evidence ledgers, proofs, epochs, remote effects, markers/MMR, and deterministic fault labs.\n\nTask Objective:\nImplement idempotency key derivation from request bytes with epoch binding.\n\nAcceptance Criteria:\n- Key derivation is deterministic, domain-separated, and epoch-bound; collisions on distinct requests are empirically negligible; derivation vectors are published.\n\nExpected Artifacts:\n- `src/remote/idempotency.rs`, `tests/conformance/idempotency_key_derivation.rs`, `artifacts/10.14/idempotency_vectors.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_14/bd-12n3/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_14/bd-12n3/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.14] Implement idempotency key derivation from request bytes with epoch binding.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.14] Implement idempotency key derivation from request bytes with epoch binding.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.14] Implement idempotency key derivation from request bytes with epoch binding.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.14] Implement idempotency key derivation from request bytes with epoch binding.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.14] Implement idempotency key derivation from request bytes with epoch binding.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"Key derivation is deterministic, domain-separated, and epoch-bound; collisions on distinct requests are empirically negligible; derivation vectors are published.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:36:57.812183569Z","created_by":"ubuntu","updated_at":"2026-02-20T15:44:05.824918237Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-14","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-12n3","depends_on_id":"bd-ac83","type":"blocks","created_at":"2026-02-20T07:43:15.570763894Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-12q","title":"[10.4] Integrate revocation propagation with canonical freshness checks (from `10.13`) in extension workflows.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.4 — Extension Ecosystem + Registry\n\nWhy This Exists:\nExtension ecosystem and registry trust foundation: signed artifacts, provenance, trust cards, revocation, and quarantine flows.\n\nTask Objective:\nIntegrate revocation propagation with canonical freshness checks (from `10.13`) in extension workflows.\n\nAcceptance Criteria:\n(See structured acceptance_criteria field for domain-specific criteria.)\n\nExpected Artifacts:\n- Section-owned design/spec artifact at `docs/specs/section_10_4/bd-12q_contract.md`, capturing decision rationale, invariants, and interface boundaries.\n- Machine-readable verification artifact at `artifacts/section_10_4/bd-12q/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_4/bd-12q/verification_summary.md` linking implementation intent to measured outcomes.\n\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.4] Integrate revocation propagation with canonical freshness checks (from `10.13`) in extension workflows.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.4] Integrate revocation propagation with canonical freshness checks (from `10.13`) in extension workflows.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.4] Integrate revocation propagation with canonical freshness checks (from `10.13`) in extension workflows.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.4] Integrate revocation propagation with canonical freshness checks (from `10.13`) in extension workflows.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.4] Integrate revocation propagation with canonical freshness checks (from `10.13`) in extension workflows.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"1. Extension install/update/load workflows query the 10.13 revocation registry (bd-y7lu) for current revocation-head checkpoint before proceeding; stale checks (older than the safety-tier-specific freshness threshold from bd-1m8r) block the operation. 2. Freshness tiers map to extension operations: 'dangerous' tier (real-time check) for install/enable of new extensions, 'risky' tier (<=60s staleness) for extension updates, 'routine' tier (<=300s staleness) for extension capability re-evaluation at runtime. 3. Revocation propagation is push-based where available (webhook/SSE from registry) with pull-based fallback; local cache stores last-known-good revocation-head with monotonic sequence number. 4. When a revocation event arrives mid-operation (e.g., during a staged rollout of an extension update), the operation is atomically aborted and the extension is moved to quarantine state. 5. Offline/partitioned nodes enforce a maximum grace period (configurable, default 24h) before all non-cached extensions are suspended; grace period is per-safety-tier. 6. Revocation status is embedded in the extension trust card (bd-2yh) as a real-time field, not a cached snapshot. 7. Integration tests simulate: (a) revocation arriving during install, (b) freshness check timeout, (c) network partition exceeding grace period, (d) revocation of a key in the attestation chain (not just the extension itself). 8. Structured log events: REVOCATION_CHECK_STARTED, REVOCATION_CHECK_PASSED, REVOCATION_CHECK_STALE, REVOCATION_PROPAGATED, EXTENSION_SUSPENDED_OFFLINE_GRACE, each with extension_id, revocation_head_seq, freshness_age_ms, and safety_tier fields.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:36:45.585688440Z","created_by":"ubuntu","updated_at":"2026-02-20T15:18:40.946420033Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-4","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-12q","depends_on_id":"bd-1ah","type":"blocks","created_at":"2026-02-20T07:43:22.463856173Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-12q","depends_on_id":"bd-1m8r","type":"blocks","created_at":"2026-02-20T15:00:22.931690858Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-12q","depends_on_id":"bd-y7lu","type":"blocks","created_at":"2026-02-20T15:00:22.748441618Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-137","title":"[10.5] Implement policy-visible compatibility gate APIs.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.5 — Security + Policy Product Surfaces\n\nWhy This Exists:\nSecurity and policy product surfaces: decision receipts, incident replay, expected-loss policying, and auditable degraded-mode behavior.\n\nTask Objective:\nImplement policy-visible compatibility gate APIs.\n\nAcceptance Criteria:\n- Implement with explicit success/failure invariants and deterministic behavior under normal, edge, and fault scenarios.\n- Ensure outcomes are verifiable via automated tests and reproducible artifact outputs.\n\nExpected Artifacts:\n- Section-owned design/spec artifact at `docs/specs/section_10_5/bd-137_contract.md`, capturing decision rationale, invariants, and interface boundaries.\n- Machine-readable verification artifact at `artifacts/section_10_5/bd-137/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_5/bd-137/verification_summary.md` linking implementation intent to measured outcomes.\n\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.5] Implement policy-visible compatibility gate APIs.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.5] Implement policy-visible compatibility gate APIs.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.5] Implement policy-visible compatibility gate APIs.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.5] Implement policy-visible compatibility gate APIs.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.5] Implement policy-visible compatibility gate APIs.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"1. Expose a PolicyGateStatus struct containing: gate_name (string), pass (bool), evaluated_at (RFC-3339 timestamp), evidence_hash (SHA-256 hex), policy_version (semver string), and detail (human-readable summary).\n2. Implement at least three concrete gate checks: CompatibilityMatrixGate (validates current capability matrix against minimum compatibility floor), RevocationPrecheckGate (confirms no active revocation entries block the requested action), and VersionFenceGate (ensures target version satisfies the fencing predicate from state_model.rs).\n3. Each gate check must complete within 50 ms on a single core; add a benchmark test that asserts this.\n4. Provide a query_gates(action: &str) -> Vec<PolicyGateStatus> API that evaluates all registered gates for a given action name and returns their statuses.\n5. Gates must be composable: a CompositeGate can combine N child gates with AND/OR/THRESHOLD(k-of-n) logic and itself returns a PolicyGateStatus.\n6. All gate evaluations must emit a structured log event (tracing span) containing the gate name, result, and wall-clock duration.\n7. Verification: scripts/check_policy_gate.py --json produces a JSON report; unit tests in tests/test_check_policy_gate.py cover pass, fail, and composite scenarios; evidence artifact lands in artifacts/section_10_5/bd-137/.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:36:46.061122822Z","created_by":"ubuntu","updated_at":"2026-02-20T15:15:02.149265962Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-5","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-137","depends_on_id":"bd-1ta","type":"blocks","created_at":"2026-02-20T07:46:36.343558606Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-137","depends_on_id":"bd-1xg","type":"blocks","created_at":"2026-02-20T07:46:36.388237131Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-137","depends_on_id":"bd-3il","type":"blocks","created_at":"2026-02-20T07:46:36.433708903Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-137","depends_on_id":"bd-cda","type":"blocks","created_at":"2026-02-20T07:46:36.480340506Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-13q","title":"[10.10] Adopt canonical stable error namespace and compatibility policy (from `10.13`) across product surfaces.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.10 — FCP-Inspired Hardening + Interop Integration Track\n\nWhy This Exists:\nFCP-inspired hardening/interop contract for IDs, serialization, control-channel auth, revocation freshness, and publication gating.\n\nTask Objective:\nAdopt canonical stable error namespace and compatibility policy (from `10.13`) across product surfaces.\n\nAcceptance Criteria:\n- Implement with explicit success/failure invariants and deterministic behavior under normal, edge, and fault scenarios.\n- Ensure outcomes are verifiable via automated tests and reproducible artifact outputs.\n\nExpected Artifacts:\n- Section-owned design/spec artifact at `docs/specs/section_10_10/bd-13q_contract.md`, capturing decision rationale, invariants, and interface boundaries.\n- Machine-readable verification artifact at `artifacts/section_10_10/bd-13q/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_10/bd-13q/verification_summary.md` linking implementation intent to measured outcomes.\n\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.10] Adopt canonical stable error namespace and compatibility policy (from `10.13`) across product surfaces.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.10] Adopt canonical stable error namespace and compatibility policy (from `10.13`) across product surfaces.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.10] Adopt canonical stable error namespace and compatibility policy (from `10.13`) across product surfaces.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.10] Adopt canonical stable error namespace and compatibility policy (from `10.13`) across product surfaces.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.10] Adopt canonical stable error namespace and compatibility policy (from `10.13`) across product surfaces.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"1. Adopt the canonical error code registry from 10.13 (error_code_registry.rs) as the single source of truth for all product-surface error codes. Every error returned to users or operators MUST reference a registered error code from this registry.\n2. Define product-surface error namespace prefixes: FN-CTRL-* (control plane), FN-MIG-* (migration), FN-AUTH-* (authentication/authorization), FN-POL-* (policy), FN-ZON-* (zone/tenant), FN-TOK-* (token). Each prefix MUST be registered in the canonical registry.\n3. Implement an ErrorCompatibilityPolicy with rules: (a) error codes are append-only (existing codes MUST NOT be removed or renumbered), (b) error message text may be refined but the code and category (TRANSIENT, PERMANENT, CONFIGURATION) MUST NOT change, (c) new error codes MUST include a human-readable description and a machine-readable severity tag.\n4. Implement a compatibility check: given two versions of the error registry (old and new), verify no codes were removed, no categories changed, and all new codes have required metadata. Return a CompatibilityReport with added/unchanged/violated lists.\n5. Provide a product_error! macro or builder that constructs errors with: (a) registered code, (b) message, (c) trace correlation ID, (d) optional structured context map. Reject construction with unregistered codes at compile time or test time.\n6. Integrate with the telemetry_namespace module from 10.13: error metrics MUST use the registered code as a dimension, not free-form strings.\n7. Unit tests: (a) all existing product errors map to registered codes, (b) compatibility check passes for additive changes, (c) compatibility check fails for removal, (d) compatibility check fails for category change, (e) product_error! with valid code succeeds, (f) product_error! with unknown code fails.\n8. CI gate: run the compatibility check between the previous release registry and the current one; fail the build on violations.\n9. Verification: scripts/check_error_namespace.py --json, artifacts at artifacts/section_10_10/bd-13q/.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:36:49.504860647Z","created_by":"ubuntu","updated_at":"2026-02-20T15:38:35.004837550Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-10","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-13q","depends_on_id":"bd-1vp","type":"blocks","created_at":"2026-02-20T07:43:11.212397454Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-13q","depends_on_id":"bd-novi","type":"blocks","created_at":"2026-02-20T14:59:52.298263711Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-13yn","title":"[12] Risk control: signal poisoning and Sybil","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 12\n\nTask Objective:\nImplement robust aggregation plus attestation/stake weighting and adversarial federation gates.\n\nExecution Requirements:\n- Make this requirement machine-verifiable and release-gated where applicable.\n- Keep behavior self-documenting so future contributors do not need to re-open the master plan.\n\nTesting & Logging Requirements:\n- Unit tests for rule/contract logic and error conditions.\n- Integration/E2E tests for workflow-level enforcement.\n- Structured logs with stable codes and trace IDs.\n- Reproducible artifacts that prove contract satisfaction.\n\nAcceptance Criteria:\n- Success and failure invariants for [12] Risk control: signal poisoning and Sybil are explicitly quantified and machine-verifiable.\n- Determinism requirements for [12] Risk control: signal poisoning and Sybil are validated across repeated runs and adversarial perturbations.\n\n\nExpected Artifacts:\n- Machine-readable verification artifact with explicit canonical path under artifacts/section_12/bd-13yn/verification_evidence.json, suitable for CI/release gating.\n- Human-readable verification summary with explicit canonical path under artifacts/section_12/bd-13yn/verification_summary.md, linking implementation intent to measured validation outcomes.\n\nTask-Specific Clarification:\n- The implementation must deliver the exact capability named in the title, with no scope dilution and no silent feature omission.\n- Validation artifacts must include capability-specific thresholds, pass/fail criteria, and reproducible evidence bundles tied to this bead ID.\n- Program/section verification gates must be able to consume this bead's outputs without manual interpretation.\n\nWhy This Improves User Outcomes:\n- \"[12] Risk control: signal poisoning and Sybil\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[12] Risk control: signal poisoning and Sybil\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"RISK: Signal poisoning and Sybil attacks — malicious nodes inject false reputation/trust signals or create multiple fake identities to manipulate the trust graph.\nIMPACT: Corrupted trust decisions, malicious extensions gaining undeserved trust, legitimate extensions being suppressed.\nCOUNTERMEASURES:\n  (a) Robust aggregation: trust signal aggregation uses trimmed-mean or median (not simple average) to resist outlier injection.\n  (b) Stake weighting: trust signals are weighted by the contributor's own stake/reputation, making Sybil attacks expensive.\n  (c) Adversarial gates: CI includes adversarial test suites that simulate poisoning and Sybil scenarios; trust system must maintain correct rankings.\nVERIFICATION:\n  1. Robust aggregation: injecting 20% poisoned signals shifts the aggregate by <= 5% from the true value.\n  2. Stake weighting: a newly-created node's signal has <= 1% weight vs an established node's signal.\n  3. Sybil resistance: creating 100 fake identities has less influence than 5 established honest nodes.\n  4. Adversarial test suite with >= 10 attack scenarios passes in CI.\nTEST SCENARIOS:\n  - Scenario A: Inject 20% maximally-adversarial signals; verify trust ranking of honest nodes changes by <= 1 position.\n  - Scenario B: Create 100 Sybil identities all endorsing a malicious extension; verify it does not enter the top-50% trust tier.\n  - Scenario C: Simulate a coordinated signal poisoning campaign over 10 rounds; verify trust system converges back to correct rankings within 3 rounds after attack stops.\n  - Scenario D: Verify that stake-weighting function is monotonically increasing with verified history length.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:39:33.765954329Z","created_by":"ubuntu","updated_at":"2026-02-20T15:19:23.743706916Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-12","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-13yn","depends_on_id":"bd-1nab","type":"blocks","created_at":"2026-02-20T07:43:24.997723150Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-145n","title":"[10.15] Integrate deterministic lab runtime scenarios for all high-impact control protocols.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.15 — Asupersync-First Integration Execution Track (8.4-8.6)\n\nWhy This Exists:\nAsupersync-first control-plane migration track enforcing Cx-first, region ownership, cancellation correctness, and protocol-grade verification gates.\n\nTask Objective:\nIntegrate deterministic lab runtime scenarios for all high-impact control protocols.\n\nAcceptance Criteria:\n- Canonical control scenarios replay identically by seed; protocol invariants are asserted with deterministic failure artifacts.\n\nExpected Artifacts:\n- `tests/lab/control_protocol_scenarios.rs`, `docs/testing/control_lab_scenarios.md`, `artifacts/10.15/control_lab_seed_matrix.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_15/bd-145n/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_15/bd-145n/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.15] Integrate deterministic lab runtime scenarios for all high-impact control protocols.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.15] Integrate deterministic lab runtime scenarios for all high-impact control protocols.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.15] Integrate deterministic lab runtime scenarios for all high-impact control protocols.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.15] Integrate deterministic lab runtime scenarios for all high-impact control protocols.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.15] Integrate deterministic lab runtime scenarios for all high-impact control protocols.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- Canonical control scenarios replay identically by seed; protocol invariants are asserted with deterministic failure artifacts.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:37:00.709371105Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:50.798295743Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-15","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-145n","depends_on_id":"bd-2qqu","type":"blocks","created_at":"2026-02-20T14:59:37.557871351Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-145n","depends_on_id":"bd-876n","type":"blocks","created_at":"2026-02-20T14:59:37.729448838Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-145n","depends_on_id":"bd-tyr2","type":"blocks","created_at":"2026-02-20T07:43:17.096073446Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-159q","title":"[10.16] Add waiver workflow for justified substrate exceptions.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.16 — Adjacent Substrate Integration Execution Track (8.7)\n\nWhy This Exists:\nAdjacent substrate integration track to enforce deep composition with frankentui, frankensqlite, sqlmodel_rust, and fastapi_rust.\n\nTask Objective:\nAdd waiver workflow for justified substrate exceptions.\n\nAcceptance Criteria:\n- Waivers require risk analysis, bounded scope, owner signoff, and expiry date; expired waivers fail compliance gate.\n\nExpected Artifacts:\n- `docs/policy/adjacent_substrate_waiver_process.md`, `artifacts/10.16/waiver_registry.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_16/bd-159q/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_16/bd-159q/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.16] Add waiver workflow for justified substrate exceptions.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.16] Add waiver workflow for justified substrate exceptions.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.16] Add waiver workflow for justified substrate exceptions.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.16] Add waiver workflow for justified substrate exceptions.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.16] Add waiver workflow for justified substrate exceptions.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- Waivers require risk analysis, bounded scope, owner signoff, and expiry date; expired waivers fail compliance gate.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:37:02.682442447Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:45.388336087Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-16","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-159q","depends_on_id":"bd-3u2o","type":"blocks","created_at":"2026-02-20T07:43:18.128420150Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-15j6","title":"[10.15] Make canonical evidence-ledger emission (from `10.14`) mandatory for policy-influenced control decisions.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.15 — Asupersync-First Integration Execution Track (8.4-8.6)\n\nWhy This Exists:\nAsupersync-first control-plane migration track enforcing Cx-first, region ownership, cancellation correctness, and protocol-grade verification gates.\n\nTask Objective:\nMake canonical evidence-ledger emission (from `10.14`) mandatory for policy-influenced control decisions.\n\nAcceptance Criteria:\n- Missing evidence entry for policy-influenced decision is a conformance failure; control-plane entries align with canonical schema and ordering.\n\nExpected Artifacts:\n- `tests/conformance/control_policy_evidence_required.rs`, `docs/integration/control_evidence_contract.md`, `artifacts/10.15/control_evidence_samples.jsonl`.\n\n- Machine-readable verification artifact at `artifacts/section_10_15/bd-15j6/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_15/bd-15j6/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.15] Make canonical evidence-ledger emission (from `10.14`) mandatory for policy-influenced control decisions.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.15] Make canonical evidence-ledger emission (from `10.14`) mandatory for policy-influenced control decisions.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.15] Make canonical evidence-ledger emission (from `10.14`) mandatory for policy-influenced control decisions.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.15] Make canonical evidence-ledger emission (from `10.14`) mandatory for policy-influenced control decisions.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.15] Make canonical evidence-ledger emission (from `10.14`) mandatory for policy-influenced control decisions.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- Missing evidence entry for policy-influenced decision is a conformance failure; control-plane entries align with canonical schema and ordering.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:37:00.547863408Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:51.244741187Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-15","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-15j6","depends_on_id":"bd-1hbw","type":"blocks","created_at":"2026-02-20T07:43:17.007329393Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-15j6","depends_on_id":"bd-2e73","type":"blocks","created_at":"2026-02-20T14:59:36.873265306Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-15j6","depends_on_id":"bd-nupr","type":"blocks","created_at":"2026-02-20T14:59:36.696941218Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-15j6","depends_on_id":"bd-oolt","type":"blocks","created_at":"2026-02-20T14:59:37.043876343Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-15t","title":"[10.9] Build category-shift reporting pipeline with reproducible artifacts.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.9 — Moonshot Disruption Track\n\nWhy This Exists:\nMoonshot disruption track for public benchmark leadership, adversarial campaigns, verifier economy, and category-shift reporting.\n\nTask Objective:\nBuild category-shift reporting pipeline with reproducible artifacts.\n\nAcceptance Criteria:\n- Implement with explicit success/failure invariants and deterministic behavior under normal, edge, and fault scenarios.\n- Ensure outcomes are verifiable via automated tests and reproducible artifact outputs.\n\nExpected Artifacts:\n- Section-owned design/spec artifact at `docs/specs/section_10_9/bd-15t_contract.md`, capturing decision rationale, invariants, and interface boundaries.\n- Machine-readable verification artifact at `artifacts/section_10_9/bd-15t/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_9/bd-15t/verification_summary.md` linking implementation intent to measured outcomes.\n\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.9] Build category-shift reporting pipeline with reproducible artifacts.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.9] Build category-shift reporting pipeline with reproducible artifacts.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.9] Build category-shift reporting pipeline with reproducible artifacts.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.9] Build category-shift reporting pipeline with reproducible artifacts.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.9] Build category-shift reporting pipeline with reproducible artifacts.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"1. Reporting pipeline aggregates data from all moonshot beads (benchmark campaigns, adversarial runner, migration demos, verifier portal, trust economics) into a unified category-shift report.\n2. Report includes reproducible artifacts: every claim is backed by a specific evidence file under artifacts/ with a hash and a command to regenerate it.\n3. Per Section 3 category-defining targets: report explicitly scores franken_node against the three category thresholds (>= 95% compat, >= 3x migration velocity, >= 10x compromise reduction) with supporting data.\n4. Pipeline produces both human-readable (Markdown/HTML) and machine-readable (JSON) report formats.\n5. Report is versioned and diffable: each release produces a new report, and a diff tool highlights changes from the previous release.\n6. Per Section 9F moonshot bets: report includes a 'bet status' section for each moonshot initiative showing progress, blockers, and projected timeline.\n7. Pipeline is automated: scripts/generate_category_report.sh produces the full report from current artifacts with no manual data entry.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:36:48.681544863Z","created_by":"ubuntu","updated_at":"2026-02-20T15:20:42.768313640Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-9","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-15t","depends_on_id":"bd-10c","type":"blocks","created_at":"2026-02-20T07:43:24.226429146Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-15u3","title":"[10.14] Enforce guardrail precedence: anytime-valid bounds override Bayesian recommendations.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.14 — FrankenSQLite Deep-Mined Expansion Execution Track (9J)\n\nWhy This Exists:\nFrankenSQLite deep-mined control integrity track: evidence ledgers, proofs, epochs, remote effects, markers/MMR, and deterministic fault labs.\n\nTask Objective:\nEnforce guardrail precedence: anytime-valid bounds override Bayesian recommendations.\n\nAcceptance Criteria:\n- Decision engine always checks guardrail before recommendation apply; blocked recommendations emit explicit reason; precedence covered by conformance tests.\n\nExpected Artifacts:\n- `tests/conformance/guardrail_precedence.rs`, `docs/specs/decision_precedence_rules.md`, `artifacts/10.14/guardrail_override_events.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_14/bd-15u3/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_14/bd-15u3/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.14] Enforce guardrail precedence: anytime-valid bounds override Bayesian recommendations.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.14] Enforce guardrail precedence: anytime-valid bounds override Bayesian recommendations.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.14] Enforce guardrail precedence: anytime-valid bounds override Bayesian recommendations.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.14] Enforce guardrail precedence: anytime-valid bounds override Bayesian recommendations.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.14] Enforce guardrail precedence: anytime-valid bounds override Bayesian recommendations.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"Decision engine always checks guardrail before recommendation apply; blocked recommendations emit explicit reason; precedence covered by conformance tests.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:36:55.873233584Z","created_by":"ubuntu","updated_at":"2026-02-20T15:44:10.796733264Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-14","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-15u3","depends_on_id":"bd-2igi","type":"blocks","created_at":"2026-02-20T07:43:14.596796369Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-16fq","title":"[10.18] Define VEF policy-constraint language and compiler contract for high-risk action classes.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.18 — Verifiable Execution Fabric Execution Track (9L)\n\nWhy This Exists:\nVEF track for proof-carrying runtime compliance: receipt chains, commitment checkpoints, proof generation/verification, and claim gating.\n\nTask Objective:\nDefine VEF policy-constraint language and compiler contract for high-risk action classes.\n\nAcceptance Criteria:\n- Constraint language maps runtime policy to proof-checkable predicates for required action classes; compiler outputs are deterministic and versioned.\n\nExpected Artifacts:\n- `docs/specs/vef_policy_constraint_language.md`, `spec/vef_policy_constraints_v1.json`, `artifacts/10.18/vef_constraint_compiler_report.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_18/bd-16fq/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_18/bd-16fq/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.18] Define VEF policy-constraint language and compiler contract for high-risk action classes.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.18] Define VEF policy-constraint language and compiler contract for high-risk action classes.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.18] Define VEF policy-constraint language and compiler contract for high-risk action classes.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.18] Define VEF policy-constraint language and compiler contract for high-risk action classes.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.18] Define VEF policy-constraint language and compiler contract for high-risk action classes.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- Constraint language maps runtime policy to proof-checkable predicates for required action classes; compiler outputs are deterministic and versioned.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:37:04.172496302Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:57.604181565Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-18","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-16fq","depends_on_id":"bd-1wz","type":"blocks","created_at":"2026-02-20T07:46:34.267565808Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-16fq","depends_on_id":"bd-3qo","type":"blocks","created_at":"2026-02-20T07:46:34.315268576Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-16fq","depends_on_id":"bd-5rh","type":"blocks","created_at":"2026-02-20T07:46:34.359792293Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-16fq","depends_on_id":"bd-cda","type":"blocks","created_at":"2026-02-20T07:46:34.404808737Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-16sk","title":"[10.1] Section-wide verification gate: comprehensive unit+e2e+logging","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.1\n\nTask Objective:\nCreate a hard section completion gate that verifies all implemented behavior in this section with comprehensive unit tests, integration/e2e scripts, and detailed structured logging evidence.\n\nAcceptance Criteria:\n- Section test matrix covers happy-path, edge-case, and adversarial/error-path scenarios for all section deliverables.\n- E2E scripts execute representative end-user workflows and policy/control-plane transitions for this section.\n- Structured logs include stable event/error codes, trace correlation IDs, and enough context for deterministic replay triage.\n- Verification report is deterministic and machine-readable for CI/release gating.\n\nExpected Artifacts:\n- Section-level test matrix and coverage summary artifact.\n- E2E script suite with pass/fail outputs and reproducible fixtures/seeds.\n- Structured log validation report and traceability bundle.\n- Gate verdict artifact consumable by release automation.\n\n- Machine-readable verification artifact at `artifacts/section_10_1/bd-16sk/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_1/bd-16sk/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests must validate contracts, invariants, and failure semantics.\n- E2E tests must validate cross-component behavior from user/operator entrypoints to persisted effects.\n- Logging must support root-cause analysis without hidden context requirements.\n\nTask-Specific Clarification:\n- For \"[10.1] Section-wide verification gate: comprehensive unit+e2e+logging\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.1] Section-wide verification gate: comprehensive unit+e2e+logging\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.1] Section-wide verification gate: comprehensive unit+e2e+logging\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.1] Section-wide verification gate: comprehensive unit+e2e+logging\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.1] Section-wide verification gate: comprehensive unit+e2e+logging\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","status":"closed","priority":1,"issue_type":"task","assignee":"CrimsonCrane","created_at":"2026-02-20T07:48:06.068063125Z","created_by":"ubuntu","updated_at":"2026-02-20T09:28:00.706957898Z","closed_at":"2026-02-20T09:28:00.706931408Z","close_reason":"done","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-1","test-obligations","verification-gate"],"dependencies":[{"issue_id":"bd-16sk","depends_on_id":"bd-1dpd","type":"blocks","created_at":"2026-02-20T08:24:27.234048787Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-16sk","depends_on_id":"bd-1j2","type":"blocks","created_at":"2026-02-20T07:48:06.406663715Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-16sk","depends_on_id":"bd-1mj","type":"blocks","created_at":"2026-02-20T07:48:06.267590054Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-16sk","depends_on_id":"bd-1pc","type":"blocks","created_at":"2026-02-20T07:48:06.172035118Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-16sk","depends_on_id":"bd-20l","type":"blocks","created_at":"2026-02-20T07:48:06.217196934Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-16sk","depends_on_id":"bd-2twu","type":"blocks","created_at":"2026-02-20T08:20:53.255202556Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-16sk","depends_on_id":"bd-2zz","type":"blocks","created_at":"2026-02-20T07:48:06.360111910Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-16sk","depends_on_id":"bd-4yv","type":"blocks","created_at":"2026-02-20T07:48:06.314127252Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-16sk","depends_on_id":"bd-vjq","type":"blocks","created_at":"2026-02-20T07:48:06.453547368Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-1719","title":"[10.16] Add deterministic visual/snapshot and interaction tests for `frankentui`-backed surfaces.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.16 — Adjacent Substrate Integration Execution Track (8.7)\n\nWhy This Exists:\nAdjacent substrate integration track to enforce deep composition with frankentui, frankensqlite, sqlmodel_rust, and fastapi_rust.\n\nTask Objective:\nAdd deterministic visual/snapshot and interaction tests for `frankentui`-backed surfaces.\n\nAcceptance Criteria:\n- Snapshot suite runs in CI and catches visual regressions; keyboard-interaction paths are replayable and stable.\n\nExpected Artifacts:\n- `tests/tui/frankentui_snapshots.rs`, `artifacts/10.16/frankentui_snapshot_report.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_16/bd-1719/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_16/bd-1719/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.16] Add deterministic visual/snapshot and interaction tests for `frankentui`-backed surfaces.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.16] Add deterministic visual/snapshot and interaction tests for `frankentui`-backed surfaces.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.16] Add deterministic visual/snapshot and interaction tests for `frankentui`-backed surfaces.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.16] Add deterministic visual/snapshot and interaction tests for `frankentui`-backed surfaces.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.16] Add deterministic visual/snapshot and interaction tests for `frankentui`-backed surfaces.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- Snapshot suite runs in CI and catches visual regressions; keyboard-interaction paths are replayable and stable.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:37:01.854475439Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:47.648220996Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-16","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-1719","depends_on_id":"bd-1xtf","type":"blocks","created_at":"2026-02-20T07:43:17.706326223Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-174","title":"[10.10] Implement policy checkpoint chain for product release channels.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.10 — FCP-Inspired Hardening + Interop Integration Track\n\nWhy This Exists:\nFCP-inspired hardening/interop contract for IDs, serialization, control-channel auth, revocation freshness, and publication gating.\n\nTask Objective:\nImplement policy checkpoint chain for product release channels.\n\nAcceptance Criteria:\n- Implement with explicit success/failure invariants and deterministic behavior under normal, edge, and fault scenarios.\n- Ensure outcomes are verifiable via automated tests and reproducible artifact outputs.\n\nExpected Artifacts:\n- Section-owned design/spec artifact at `docs/specs/section_10_10/bd-174_contract.md`, capturing decision rationale, invariants, and interface boundaries.\n- Machine-readable verification artifact at `artifacts/section_10_10/bd-174/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_10/bd-174/verification_summary.md` linking implementation intent to measured outcomes.\n\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.10] Implement policy checkpoint chain for product release channels.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.10] Implement policy checkpoint chain for product release channels.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.10] Implement policy checkpoint chain for product release channels.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.10] Implement policy checkpoint chain for product release channels.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.10] Implement policy checkpoint chain for product release channels.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"1. Define a PolicyCheckpoint struct containing: (a) checkpoint_id (TrustObjectId with POLICY domain), (b) parent_checkpoint_id (Option, None only for genesis), (c) channel enum (CANARY, BETA, STABLE, LTS), (d) policy_hash (SHA-256 of the canonical-serialized policy document), (e) sequence_number (u64, strictly monotonic per channel), (f) timestamp (UTC, second precision), (g) signer_key_id (TrustObjectId with KEY domain).\n2. Implement a PolicyCheckpointChain that maintains an append-only ordered list of checkpoints per channel. Enforce: (a) each new checkpoint's parent_checkpoint_id equals the previous checkpoint's id, (b) sequence_number == previous + 1, (c) timestamp >= previous timestamp.\n3. Reject any checkpoint whose parent_checkpoint_id does not match the chain tip (fork prevention). Return a typed error PolicyForkDetected with both the expected and received parent IDs.\n4. Implement chain validation: given a full chain, verify the parent linkage, monotonic sequence, and monotonic timestamps from genesis to tip. Return first violation index on failure.\n5. Implement channel promotion: a checkpoint may reference a checkpoint from a less-stable channel (CANARY -> BETA -> STABLE -> LTS) via a promotion_source_id field. Validate that the source checkpoint exists and belongs to a strictly less-stable channel.\n6. Provide a genesis checkpoint constructor that enforces parent=None, sequence=0.\n7. Unit tests: (a) valid chain append, (b) fork rejection, (c) sequence gap rejection, (d) timestamp regression rejection, (e) cross-channel promotion valid/invalid, (f) genesis invariants.\n8. Golden fixture: a 5-checkpoint chain across CANARY->BETA promotion in vectors/policy_checkpoint_chain.json.\n9. Verification script scripts/check_policy_checkpoint.py with --json, artifacts at artifacts/section_10_10/bd-174/.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:36:48.919772635Z","created_by":"ubuntu","updated_at":"2026-02-20T15:36:32.761685766Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-10","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-174","depends_on_id":"bd-jjm","type":"blocks","created_at":"2026-02-20T07:43:10.921812810Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-17mb","title":"[10.13] Implement fail-closed manifest negotiation (SemVer-aware version checks, required-feature resolution, transport cap checks).","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.13 — FCP Deep-Mined Expansion Execution Track (9I)\n\nWhy This Exists:\nDeep connector/provider contract track: lifecycle FSMs, conformance harnesses, fencing, sandboxing, revocation freshness, and protocol hardening.\n\nTask Objective:\nImplement fail-closed manifest negotiation (SemVer-aware version checks, required-feature resolution, transport cap checks).\n\nAcceptance Criteria:\n- Unsupported major versions and missing required features hard-fail activation; version comparisons are semantic, not lexical; negotiation decisions are logged.\n\nExpected Artifacts:\n- `docs/specs/manifest_negotiation.md`, `tests/conformance/manifest_negotiation_fail_closed.rs`, `artifacts/10.13/manifest_negotiation_trace.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_13/bd-17mb/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_13/bd-17mb/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.13] Implement fail-closed manifest negotiation (SemVer-aware version checks, required-feature resolution, transport cap checks).\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.13] Implement fail-closed manifest negotiation (SemVer-aware version checks, required-feature resolution, transport cap checks).\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.13] Implement fail-closed manifest negotiation (SemVer-aware version checks, required-feature resolution, transport cap checks).\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.13] Implement fail-closed manifest negotiation (SemVer-aware version checks, required-feature resolution, transport cap checks).\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.13] Implement fail-closed manifest negotiation (SemVer-aware version checks, required-feature resolution, transport cap checks).\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","status":"closed","priority":1,"issue_type":"task","assignee":"CrimsonCrane","created_at":"2026-02-20T07:36:52.450176581Z","created_by":"ubuntu","updated_at":"2026-02-20T11:32:31.228575187Z","closed_at":"2026-02-20T11:32:31.228546493Z","close_reason":"done","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-13","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-17mb","depends_on_id":"bd-1nk5","type":"blocks","created_at":"2026-02-20T07:43:12.801157459Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-181w","title":"[10.15] Integrate canonical epoch-scoped validity windows (from `10.14`) for control artifacts and remote contracts.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.15 — Asupersync-First Integration Execution Track (8.4-8.6)\n\nWhy This Exists:\nAsupersync-first control-plane migration track enforcing Cx-first, region ownership, cancellation correctness, and protocol-grade verification gates.\n\nTask Objective:\nIntegrate canonical epoch-scoped validity windows (from `10.14`) for control artifacts and remote contracts.\n\nAcceptance Criteria:\n- Control-plane operations use canonical epoch-validity semantics; future-epoch artifacts are rejected fail-closed; epoch scope is logged for accepted high-impact operations.\n\nExpected Artifacts:\n- `tests/security/control_epoch_validity.rs`, `docs/integration/control_epoch_validity_adoption.md`, `artifacts/10.15/epoch_validity_decisions.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_15/bd-181w/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_15/bd-181w/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.15] Integrate canonical epoch-scoped validity windows (from `10.14`) for control artifacts and remote contracts.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.15] Integrate canonical epoch-scoped validity windows (from `10.14`) for control artifacts and remote contracts.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.15] Integrate canonical epoch-scoped validity windows (from `10.14`) for control artifacts and remote contracts.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.15] Integrate canonical epoch-scoped validity windows (from `10.14`) for control artifacts and remote contracts.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.15] Integrate canonical epoch-scoped validity windows (from `10.14`) for control artifacts and remote contracts.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- Control-plane operations use canonical epoch-validity semantics; future-epoch artifacts are rejected fail-closed; epoch scope is logged for accepted high-impact operations.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:37:00.383685717Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:51.688848360Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-15","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-181w","depends_on_id":"bd-2xv8","type":"blocks","created_at":"2026-02-20T14:59:36.467655154Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-181w","depends_on_id":"bd-3h63","type":"blocks","created_at":"2026-02-20T07:43:16.923335657Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-181w","depends_on_id":"bd-3hdv","type":"blocks","created_at":"2026-02-20T14:59:36.299215652Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-18ie","title":"[14] Metric family: compatibility correctness by API/risk band","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 14\n\nTask Objective:\nInstrument compatibility correctness metric family by API family and risk band.\n\nExecution Requirements:\n- Make this requirement machine-verifiable and release-gated where applicable.\n- Keep behavior self-documenting so future contributors do not need to re-open the master plan.\n\nTesting & Logging Requirements:\n- Unit tests for rule/contract logic and error conditions.\n- Integration/E2E tests for workflow-level enforcement.\n- Structured logs with stable codes and trace IDs.\n- Reproducible artifacts that prove contract satisfaction.\n\nAcceptance Criteria:\n- Success and failure invariants for [14] Metric family: compatibility correctness by API/risk band are explicitly quantified and machine-verifiable.\n- Determinism requirements for [14] Metric family: compatibility correctness by API/risk band are validated across repeated runs and adversarial perturbations.\n\n\nExpected Artifacts:\n- Machine-readable verification artifact with explicit canonical path under artifacts/section_14/bd-18ie/verification_evidence.json, suitable for CI/release gating.\n- Human-readable verification summary with explicit canonical path under artifacts/section_14/bd-18ie/verification_summary.md, linking implementation intent to measured validation outcomes.\n\nTask-Specific Clarification:\n- The implementation must deliver the exact capability named in the title, with no scope dilution and no silent feature omission.\n- Validation artifacts must include capability-specific thresholds, pass/fail criteria, and reproducible evidence bundles tied to this bead ID.\n- Program/section verification gates must be able to consume this bead's outputs without manual interpretation.\n\nWhy This Improves User Outcomes:\n- \"[14] Metric family: compatibility correctness by API/risk band\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[14] Metric family: compatibility correctness by API/risk band\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"METRIC FAMILY: Compatibility correctness by API family and risk band.\n1. Metrics measured: pass rate, failure rate, skip rate, flaky rate — each broken down by API family (fs, http, net, crypto, stream, buffer, path, child_process, cluster, events, timers, url, zlib, tls, os, querystring).\n2. Risk band classification: critical (security-sensitive APIs: crypto, tls, child_process), high (I/O APIs: fs, net, http), medium (data APIs: stream, buffer, zlib), low (utility APIs: path, url, os, querystring, events, timers).\n3. Reporting format: matrix of API family x risk band with pass/fail counts and percentages.\n4. Threshold gates: critical-band APIs must have >= 99% pass rate; high-band >= 95%; medium-band >= 90%; low-band >= 85%.\n5. Trend tracking: compatibility metrics are tracked over time with automated regression detection (> 2% drop triggers alert).\n6. Publication: metric results are included in every benchmark report with methodology description.\n7. Evidence: compatibility_by_family.json with per-family, per-band metrics and threshold compliance.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:39:35.642921950Z","created_by":"ubuntu","updated_at":"2026-02-20T15:24:28.383154417Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-14","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-18ie","depends_on_id":"bd-3v8g","type":"blocks","created_at":"2026-02-20T07:43:25.936571189Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-18o","title":"[10.13] Implement canonical connector state root/object model with explicit state model tagging.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.13 — FCP Deep-Mined Expansion Execution Track (9I)\n\nWhy This Exists:\nDeep connector/provider contract track: lifecycle FSMs, conformance harnesses, fencing, sandboxing, revocation freshness, and protocol hardening.\n\nTask Objective:\nImplement canonical connector state root/object model with explicit state model tagging.\n\nAcceptance Criteria:\n- All connectors declare state model type; canonical root/head objects are persisted; local cache divergence is detectable and repairable.\n\nExpected Artifacts:\n- `docs/specs/connector_state_model.md`, `tests/integration/connector_state_persistence.rs`, `artifacts/10.13/state_model_samples.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_13/bd-18o/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_13/bd-18o/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.13] Implement canonical connector state root/object model with explicit state model tagging.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.13] Implement canonical connector state root/object model with explicit state model tagging.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.13] Implement canonical connector state root/object model with explicit state model tagging.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.13] Implement canonical connector state root/object model with explicit state model tagging.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.13] Implement canonical connector state root/object model with explicit state model tagging.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","status":"closed","priority":1,"issue_type":"task","assignee":"CrimsonCrane","created_at":"2026-02-20T07:36:51.717873925Z","created_by":"ubuntu","updated_at":"2026-02-20T10:48:39.930887680Z","closed_at":"2026-02-20T10:48:39.930861190Z","close_reason":"done","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-13","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-18o","depends_on_id":"bd-3en","type":"blocks","created_at":"2026-02-20T07:43:12.398935263Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-18ud","title":"[10.14] Implement `durability=local` and `durability=quorum(M)` semantics for control/trust artifacts.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.14 — FrankenSQLite Deep-Mined Expansion Execution Track (9J)\n\nWhy This Exists:\nFrankenSQLite deep-mined control integrity track: evidence ledgers, proofs, epochs, remote effects, markers/MMR, and deterministic fault labs.\n\nTask Objective:\nImplement `durability=local` and `durability=quorum(M)` semantics for control/trust artifacts.\n\nAcceptance Criteria:\n- Mode semantics are enforced end-to-end; mode switches are auditable and policy-gated; claim language mapping is deterministic.\n\nExpected Artifacts:\n- `docs/specs/durability_modes.md`, `tests/conformance/durability_mode_semantics.rs`, `artifacts/10.14/durability_mode_claim_matrix.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_14/bd-18ud/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_14/bd-18ud/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.14] Implement `durability=local` and `durability=quorum(M)` semantics for control/trust artifacts.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.14] Implement `durability=local` and `durability=quorum(M)` semantics for control/trust artifacts.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.14] Implement `durability=local` and `durability=quorum(M)` semantics for control/trust artifacts.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.14] Implement `durability=local` and `durability=quorum(M)` semantics for control/trust artifacts.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.14] Implement `durability=local` and `durability=quorum(M)` semantics for control/trust artifacts.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"Mode semantics are enforced end-to-end; mode switches are auditable and policy-gated; claim language mapping is deterministic.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:36:57.406100907Z","created_by":"ubuntu","updated_at":"2026-02-20T15:44:06.885747541Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-14","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-18ud","depends_on_id":"bd-okqy","type":"blocks","created_at":"2026-02-20T07:43:15.358560932Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-1961","title":"[15] Pillar: reputation graph APIs","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 15\n\nTask Objective:\nImplement reputation graph API pillar for ecosystem trust and incident response.\n\nExecution Requirements:\n- Make this requirement machine-verifiable and release-gated where applicable.\n- Keep behavior self-documenting so future contributors do not need to re-open the master plan.\n\nTesting & Logging Requirements:\n- Unit tests for rule/contract logic and error conditions.\n- Integration/E2E tests for workflow-level enforcement.\n- Structured logs with stable codes and trace IDs.\n- Reproducible artifacts that prove contract satisfaction.\n\nAcceptance Criteria:\n- Success and failure invariants for [15] Pillar: reputation graph APIs are explicitly quantified and machine-verifiable.\n- Determinism requirements for [15] Pillar: reputation graph APIs are validated across repeated runs and adversarial perturbations.\n\n\nExpected Artifacts:\n- Machine-readable verification artifact with explicit canonical path under artifacts/section_15/bd-1961/verification_evidence.json, suitable for CI/release gating.\n- Human-readable verification summary with explicit canonical path under artifacts/section_15/bd-1961/verification_summary.md, linking implementation intent to measured validation outcomes.\n\nTask-Specific Clarification:\n- The implementation must deliver the exact capability named in the title, with no scope dilution and no silent feature omission.\n- Validation artifacts must include capability-specific thresholds, pass/fail criteria, and reproducible evidence bundles tied to this bead ID.\n- Program/section verification gates must be able to consume this bead's outputs without manual interpretation.\n\nWhy This Improves User Outcomes:\n- \"[15] Pillar: reputation graph APIs\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[15] Pillar: reputation graph APIs\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"1. Reputation graph API is published with OpenAPI/Swagger specification.\n2. API endpoints include: (a) query node reputation score, (b) query extension trust level, (c) query trust graph neighborhood (1-hop and 2-hop), (d) submit trust signal (authenticated), (e) query reputation history for a node/extension.\n3. API enforces rate limiting: <= 100 requests/minute per API key for free tier.\n4. API responses include: reputation score (0-100), confidence level (low/medium/high), contributing signal count, last-updated timestamp.\n5. Privacy: API never exposes individual trust signals, only aggregates. Minimum cohort size >= 5 for any aggregation.\n6. API authentication via API key with role-based access (read-only, contributor, admin).\n7. API has >= 95% uptime SLA (measured over 30-day window) and p99 latency <= 200ms.\n8. SDK clients available for >= 2 languages (JavaScript, Python).\n9. Evidence: reputation_api_spec.json (OpenAPI) and api_health_report.json with uptime and latency metrics.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:39:36.442226068Z","created_by":"ubuntu","updated_at":"2026-02-20T15:26:40.061464657Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-15","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-1961","depends_on_id":"bd-3mj9","type":"blocks","created_at":"2026-02-20T07:43:26.342166549Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-19j5","title":"Epic: Operational Readiness [10.8]","description":"- type: epic","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-20T07:47:58.072163029Z","updated_at":"2026-02-20T07:49:21.129961907Z","closed_at":"2026-02-20T07:49:21.129941899Z","close_reason":"Superseded by canonical detailed master-plan graph (bd-33v) with full 10.N-10.21 and 11-16 coverage, explicit dependencies, and per-section verification gates.","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-19k2","title":"[10.20] Implement expected-loss cascade economics and ROI-aware mitigation ranking.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.20 — Dependency Graph Immune System Execution Track (9N)\n\nWhy This Exists:\nDGIS topological immune system track for dependency contagion modeling, choke-point immunization, and graph-aware containment economics.\n\nTask Objective:\nImplement expected-loss cascade economics and ROI-aware mitigation ranking.\n\nAcceptance Criteria:\n- Each candidate mitigation includes expected-loss delta, residual risk, and operational cost estimates; rankings are stable under fixed assumptions and sensitivity-tested.\n\nExpected Artifacts:\n- `src/security/dgis/cascade_economics.rs`, `docs/specs/dgis_expected_loss_model.md`, `artifacts/10.20/dgis_economic_rankings.csv`.\n\n- Machine-readable verification artifact at `artifacts/section_10_20/bd-19k2/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_20/bd-19k2/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.20] Implement expected-loss cascade economics and ROI-aware mitigation ranking.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.20] Implement expected-loss cascade economics and ROI-aware mitigation ranking.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.20] Implement expected-loss cascade economics and ROI-aware mitigation ranking.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.20] Implement expected-loss cascade economics and ROI-aware mitigation ranking.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.20] Implement expected-loss cascade economics and ROI-aware mitigation ranking.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- Each candidate mitigation includes expected-loss delta, residual risk, and operational cost estimates; rankings are stable under fixed assumptions and sensitivity-tested.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:37:07.247484594Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:15.263085866Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-20","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-19k2","depends_on_id":"bd-351r","type":"blocks","created_at":"2026-02-20T07:43:21.019090749Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-19u","title":"[10.13] Add CRDT state mode scaffolding (lww-map/or-set/gcounter/pncounter) with merge conformance fixtures.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.13 — FCP Deep-Mined Expansion Execution Track (9I)\n\nWhy This Exists:\nDeep connector/provider contract track: lifecycle FSMs, conformance harnesses, fencing, sandboxing, revocation freshness, and protocol hardening.\n\nTask Objective:\nAdd CRDT state mode scaffolding (lww-map/or-set/gcounter/pncounter) with merge conformance fixtures.\n\nAcceptance Criteria:\n- Each CRDT type has merge laws covered by fixtures; merge output is deterministic across replicas; schema tags prevent type confusion.\n\nExpected Artifacts:\n- `tests/conformance/crdt_merge_fixtures.rs`, `fixtures/crdt/*.json`, `docs/specs/crdt_state_mode.md`.\n\n- Machine-readable verification artifact at `artifacts/section_10_13/bd-19u/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_13/bd-19u/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.13] Add CRDT state mode scaffolding (lww-map/or-set/gcounter/pncounter) with merge conformance fixtures.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.13] Add CRDT state mode scaffolding (lww-map/or-set/gcounter/pncounter) with merge conformance fixtures.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.13] Add CRDT state mode scaffolding (lww-map/or-set/gcounter/pncounter) with merge conformance fixtures.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.13] Add CRDT state mode scaffolding (lww-map/or-set/gcounter/pncounter) with merge conformance fixtures.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.13] Add CRDT state mode scaffolding (lww-map/or-set/gcounter/pncounter) with merge conformance fixtures.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","status":"closed","priority":1,"issue_type":"task","assignee":"CrimsonCrane","created_at":"2026-02-20T07:36:51.880209184Z","created_by":"ubuntu","updated_at":"2026-02-20T10:59:51.381242793Z","closed_at":"2026-02-20T10:59:51.381215272Z","close_reason":"done","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-13","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-19u","depends_on_id":"bd-1cm","type":"blocks","created_at":"2026-02-20T07:43:12.482525717Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-1a1j","title":"[10.16] Define `frankensqlite` persistence integration contract for control/audit/replay state.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.16 — Adjacent Substrate Integration Execution Track (8.7)\n\nWhy This Exists:\nAdjacent substrate integration track to enforce deep composition with frankentui, frankensqlite, sqlmodel_rust, and fastapi_rust.\n\nTask Objective:\nDefine `frankensqlite` persistence integration contract for control/audit/replay state.\n\nAcceptance Criteria:\n- Contract enumerates required persistence classes and durability modes; storage semantics map to product safety tiers.\n\nExpected Artifacts:\n- `docs/specs/frankensqlite_persistence_contract.md`, `artifacts/10.16/frankensqlite_persistence_matrix.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_16/bd-1a1j/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_16/bd-1a1j/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.16] Define `frankensqlite` persistence integration contract for control/audit/replay state.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.16] Define `frankensqlite` persistence integration contract for control/audit/replay state.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.16] Define `frankensqlite` persistence integration contract for control/audit/replay state.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.16] Define `frankensqlite` persistence integration contract for control/audit/replay state.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.16] Define `frankensqlite` persistence integration contract for control/audit/replay state.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- Contract enumerates required persistence classes and durability modes; storage semantics map to product safety tiers.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:37:01.935868538Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:47.425565314Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-16","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-1a1j","depends_on_id":"bd-1719","type":"blocks","created_at":"2026-02-20T07:43:17.749842241Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-1a4a","title":"Epic: Correctness + Policy Boundaries [10.14b]","description":"- type: epic","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-20T07:47:58.072163029Z","updated_at":"2026-02-20T07:49:21.204056603Z","closed_at":"2026-02-20T07:49:21.204038810Z","close_reason":"Superseded by canonical detailed master-plan graph (bd-33v) with full 10.N-10.21 and 11-16 coverage, explicit dependencies, and per-section verification gates.","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-1ah","title":"[10.4] Define provenance attestation requirements and verification chain.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.4 — Extension Ecosystem + Registry\n\nWhy This Exists:\nExtension ecosystem and registry trust foundation: signed artifacts, provenance, trust cards, revocation, and quarantine flows.\n\nTask Objective:\nDefine provenance attestation requirements and verification chain.\n\nAcceptance Criteria:\n(See structured acceptance_criteria field for domain-specific criteria.)\n\nExpected Artifacts:\n- Section-owned design/spec artifact at `docs/specs/section_10_4/bd-1ah_contract.md`, capturing decision rationale, invariants, and interface boundaries.\n- Machine-readable verification artifact at `artifacts/section_10_4/bd-1ah/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_4/bd-1ah/verification_summary.md` linking implementation intent to measured outcomes.\n\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.4] Define provenance attestation requirements and verification chain.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.4] Define provenance attestation requirements and verification chain.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.4] Define provenance attestation requirements and verification chain.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.4] Define provenance attestation requirements and verification chain.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.4] Define provenance attestation requirements and verification chain.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"1. Define attestation document format using in-toto or SLSA v1.0 provenance predicate schema, specifying required fields: builder_id, build_type, source_uri, source_digest (SHA-256 minimum), build_config, materials[], and invocation parameters. 2. Verification chain requires at minimum two attestation layers: (a) source-to-build attestation linking git commit to build artifact, and (b) build-to-publish attestation linking build artifact to registry entry. 3. Each attestation is signed using the publisher's registered key from the key-transparency log; signatures use domain-separated signing (context string: 'franken-ext-provenance-v1'). 4. Verification logic validates the full chain from source commit through to published artifact, rejecting any chain with gaps, expired signatures, or revoked keys. 5. Reproducibility markers are required for certification levels >= 'verified': build must produce identical artifact hash from same source+config inputs. 6. Attestation documents reference the manifest schema from bd-1gx via provenance_attestation_refs[] field. 7. Key rotation is supported: old attestations remain valid if the signing key was valid at attestation time (verified against key-transparency log timestamps). 8. Verification errors produce structured rejection codes: CHAIN_GAP, SIGNATURE_EXPIRED, KEY_REVOKED, DIGEST_MISMATCH, MISSING_ATTESTATION_LAYER, REPRODUCIBILITY_FAILED. 9. CLI command 'franken-node ext verify-provenance <artifact>' performs full chain verification and outputs pass/fail with detailed chain trace. 10. Attestation storage format supports both embedded (in manifest) and detached (separate .attestation.json sidecar) modes.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:36:45.507060902Z","created_by":"ubuntu","updated_at":"2026-02-20T15:18:40.758181550Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-4","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-1ah","depends_on_id":"bd-1gx","type":"blocks","created_at":"2026-02-20T07:43:22.420428491Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-1ayu","title":"[10.14] Implement overhead/rate clamp policy for hardening escalations with configured ceilings.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.14 — FrankenSQLite Deep-Mined Expansion Execution Track (9J)\n\nWhy This Exists:\nFrankenSQLite deep-mined control integrity track: evidence ledgers, proofs, epochs, remote effects, markers/MMR, and deterministic fault labs.\n\nTask Objective:\nImplement overhead/rate clamp policy for hardening escalations with configured ceilings.\n\nAcceptance Criteria:\n- Escalation clamps respect min/max bounds and policy budget; clamp calculations are deterministic; clamp hits are visible in telemetry.\n\nExpected Artifacts:\n- `src/policy/hardening_clamps.rs`, `tests/conformance/hardening_clamp_bounds.rs`, `artifacts/10.14/hardening_clamp_metrics.csv`.\n\n- Machine-readable verification artifact at `artifacts/section_10_14/bd-1ayu/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_14/bd-1ayu/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.14] Implement overhead/rate clamp policy for hardening escalations with configured ceilings.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.14] Implement overhead/rate clamp policy for hardening escalations with configured ceilings.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.14] Implement overhead/rate clamp policy for hardening escalations with configured ceilings.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.14] Implement overhead/rate clamp policy for hardening escalations with configured ceilings.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.14] Implement overhead/rate clamp policy for hardening escalations with configured ceilings.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"Escalation clamps respect min/max bounds and policy budget; clamp calculations are deterministic; clamp hits are visible in telemetry.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:36:56.219100534Z","created_by":"ubuntu","updated_at":"2026-02-20T15:44:09.942703342Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-14","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-1ayu","depends_on_id":"bd-1zym","type":"blocks","created_at":"2026-02-20T07:43:14.767444757Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-1b0g","title":"Epic: Remote Effects + Distributed Control [10.14f]","description":"- type: epic","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-20T07:47:58.072163029Z","updated_at":"2026-02-20T07:49:21.239212854Z","closed_at":"2026-02-20T07:49:21.239195321Z","close_reason":"Superseded by canonical detailed master-plan graph (bd-33v) with full 10.N-10.21 and 11-16 coverage, explicit dependencies, and per-section verification gates.","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-1b9x","title":"[10.21] Implement survival/hazard model for compromise-propensity progression under observed trajectory patterns.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.21 — Behavioral Phenotype Evolution Tracker Execution Track (9O)\n\nWhy This Exists:\nBPET longitudinal phenotype intelligence track for pre-compromise trajectory detection and integration with DGIS/ATC/migration/economic policy.\n\nTask Objective:\nImplement survival/hazard model for compromise-propensity progression under observed trajectory patterns.\n\nAcceptance Criteria:\n- Hazard outputs are calibrated and monotonic under defined risk assumptions; censoring handling and covariate drift strategy are explicit and test-covered.\n\nExpected Artifacts:\n- `src/security/bpet/hazard_model.rs`, `docs/specs/bpet_time_to_compromise_model.md`, `artifacts/10.21/bpet_hazard_calibration_report.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_21/bd-1b9x/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_21/bd-1b9x/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.21] Implement survival/hazard model for compromise-propensity progression under observed trajectory patterns.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.21] Implement survival/hazard model for compromise-propensity progression under observed trajectory patterns.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.21] Implement survival/hazard model for compromise-propensity progression under observed trajectory patterns.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.21] Implement survival/hazard model for compromise-propensity progression under observed trajectory patterns.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.21] Implement survival/hazard model for compromise-propensity progression under observed trajectory patterns.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- Hazard outputs are calibrated and monotonic under defined risk assumptions; censoring handling and covariate drift strategy are explicit and test-covered.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:37:08.207596236Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:17.337924763Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-21","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-1b9x","depends_on_id":"bd-2lll","type":"blocks","created_at":"2026-02-20T07:43:21.519986904Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-1ck","title":"[10.2] Implement L2 engine-boundary semantic oracle integration policy and release gate linkage.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.2 — Compatibility Core\n\nWhy This Exists:\nCompatibility core as strategic wedge: policy-visible behavior, divergence receipts, L1/L2 lockstep, and spec-first fixture governance.\n\nTask Objective:\nImplement L2 engine-boundary semantic oracle integration policy and release gate linkage.\n\nAcceptance Criteria:\n- Implement with explicit success/failure invariants and deterministic behavior under normal, edge, and fault scenarios.\n- Ensure outcomes are verifiable via automated tests and reproducible artifact outputs.\n\nExpected Artifacts:\n- Section-owned design/spec artifact at `docs/specs/section_10_2/bd-1ck_contract.md`, capturing decision rationale, invariants, and interface boundaries.\n- Machine-readable verification artifact at `artifacts/section_10_2/bd-1ck/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_2/bd-1ck/verification_summary.md` linking implementation intent to measured outcomes.\n\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.2] Implement L2 engine-boundary semantic oracle integration policy and release gate linkage.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.2] Implement L2 engine-boundary semantic oracle integration policy and release gate linkage.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.2] Implement L2 engine-boundary semantic oracle integration policy and release gate linkage.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.2] Implement L2 engine-boundary semantic oracle integration policy and release gate linkage.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.2] Implement L2 engine-boundary semantic oracle integration policy and release gate linkage.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","status":"closed","priority":1,"issue_type":"task","assignee":"CrimsonCrane","created_at":"2026-02-20T07:36:44.401871436Z","created_by":"ubuntu","updated_at":"2026-02-20T09:46:37.698578291Z","closed_at":"2026-02-20T09:46:37.698550399Z","close_reason":"done","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-2","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-1ck","depends_on_id":"bd-32v","type":"blocks","created_at":"2026-02-20T07:43:20.349163419Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-1clg","title":"Epic: Sandbox + Network Security [10.13b]","description":"- type: epic","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-20T07:47:58.072163029Z","updated_at":"2026-02-20T07:49:21.164744401Z","closed_at":"2026-02-20T07:49:21.164724294Z","close_reason":"Superseded by canonical detailed master-plan graph (bd-33v) with full 10.N-10.21 and 11-16 coverage, explicit dependencies, and per-section verification gates.","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-1cm","title":"[10.13] Add singleton-writer fencing validation using `lease_seq` + lease-object linkage.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.13 — FCP Deep-Mined Expansion Execution Track (9I)\n\nWhy This Exists:\nDeep connector/provider contract track: lifecycle FSMs, conformance harnesses, fencing, sandboxing, revocation freshness, and protocol hardening.\n\nTask Objective:\nAdd singleton-writer fencing validation using `lease_seq` + lease-object linkage.\n\nAcceptance Criteria:\n- Unfenced or stale-fenced writes are rejected; fence checks are monotonic; stale writer test cases fail deterministically.\n\nExpected Artifacts:\n- `tests/conformance/singleton_writer_fencing.rs`, `docs/specs/fencing_rules.md`, `artifacts/10.13/fencing_rejection_receipts.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_13/bd-1cm/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_13/bd-1cm/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.13] Add singleton-writer fencing validation using `lease_seq` + lease-object linkage.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.13] Add singleton-writer fencing validation using `lease_seq` + lease-object linkage.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.13] Add singleton-writer fencing validation using `lease_seq` + lease-object linkage.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.13] Add singleton-writer fencing validation using `lease_seq` + lease-object linkage.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.13] Add singleton-writer fencing validation using `lease_seq` + lease-object linkage.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","status":"closed","priority":1,"issue_type":"task","assignee":"CrimsonCrane","created_at":"2026-02-20T07:36:51.799537829Z","created_by":"ubuntu","updated_at":"2026-02-20T10:52:03.912554166Z","closed_at":"2026-02-20T10:52:03.912492521Z","close_reason":"done","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-13","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-1cm","depends_on_id":"bd-18o","type":"blocks","created_at":"2026-02-20T07:43:12.440631511Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-1cs7","title":"[10.15] Implement request -> drain -> finalize cancellation protocol across high-impact workflows.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.15 — Asupersync-First Integration Execution Track (8.4-8.6)\n\nWhy This Exists:\nAsupersync-first control-plane migration track enforcing Cx-first, region ownership, cancellation correctness, and protocol-grade verification gates.\n\nTask Objective:\nImplement request -> drain -> finalize cancellation protocol across high-impact workflows.\n\nAcceptance Criteria:\n- Cancellation transitions are explicit and deterministic; cleanup budget bounds are documented and tested.\n\nExpected Artifacts:\n- `docs/specs/cancellation_protocol_contract.md`, `tests/conformance/cancel_drain_finalize.rs`, `artifacts/10.15/cancel_protocol_timing.csv`.\n\n- Machine-readable verification artifact at `artifacts/section_10_15/bd-1cs7/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_15/bd-1cs7/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.15] Implement request -> drain -> finalize cancellation protocol across high-impact workflows.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.15] Implement request -> drain -> finalize cancellation protocol across high-impact workflows.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.15] Implement request -> drain -> finalize cancellation protocol across high-impact workflows.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.15] Implement request -> drain -> finalize cancellation protocol across high-impact workflows.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.15] Implement request -> drain -> finalize cancellation protocol across high-impact workflows.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- Cancellation transitions are explicit and deterministic; cleanup budget bounds are documented and tested.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:36:59.890626565Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:53.206185491Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-15","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-1cs7","depends_on_id":"bd-2tdi","type":"blocks","created_at":"2026-02-20T07:43:16.669253747Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-1cwp","title":"[10.15] Enforce canonical idempotency-key contracts (from `10.14`) on all retryable remote control requests.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.15 — Asupersync-First Integration Execution Track (8.4-8.6)\n\nWhy This Exists:\nAsupersync-first control-plane migration track enforcing Cx-first, region ownership, cancellation correctness, and protocol-grade verification gates.\n\nTask Objective:\nEnforce canonical idempotency-key contracts (from `10.14`) on all retryable remote control requests.\n\nAcceptance Criteria:\n- Control-plane requests inherit canonical idempotency semantics; duplicate same-payload requests dedupe safely; same-key/payload-mismatch hard-fails.\n\nExpected Artifacts:\n- `tests/integration/control_remote_idempotency.rs`, `docs/integration/control_idempotency_adoption.md`, `artifacts/10.15/control_idempotency_report.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_15/bd-1cwp/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_15/bd-1cwp/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.15] Enforce canonical idempotency-key contracts (from `10.14`) on all retryable remote control requests.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.15] Enforce canonical idempotency-key contracts (from `10.14`) on all retryable remote control requests.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.15] Enforce canonical idempotency-key contracts (from `10.14`) on all retryable remote control requests.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.15] Enforce canonical idempotency-key contracts (from `10.14`) on all retryable remote control requests.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.15] Enforce canonical idempotency-key contracts (from `10.14`) on all retryable remote control requests.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- Control-plane requests inherit canonical idempotency semantics; duplicate same-payload requests dedupe safely; same-key/payload-mismatch hard-fails.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:37:00.220597315Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:52.140780935Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-15","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-1cwp","depends_on_id":"bd-12n3","type":"blocks","created_at":"2026-02-20T14:59:47.718915217Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1cwp","depends_on_id":"bd-206h","type":"blocks","created_at":"2026-02-20T14:59:47.851186754Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1cwp","depends_on_id":"bd-3014","type":"blocks","created_at":"2026-02-20T07:43:16.839210356Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-1d6x","title":"[10.12] Section-wide verification gate: comprehensive unit+e2e+logging","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.12\n\nTask Objective:\nCreate a hard section completion gate that verifies all implemented behavior in this section with comprehensive unit tests, integration/e2e scripts, and detailed structured logging evidence.\n\nAcceptance Criteria:\n- Section test matrix covers happy-path, edge-case, and adversarial/error-path scenarios for all section deliverables.\n- E2E scripts execute representative end-user workflows and policy/control-plane transitions for this section.\n- Structured logs include stable event/error codes, trace correlation IDs, and enough context for deterministic replay triage.\n- Verification report is deterministic and machine-readable for CI/release gating.\n\nExpected Artifacts:\n- Section-level test matrix and coverage summary artifact.\n- E2E script suite with pass/fail outputs and reproducible fixtures/seeds.\n- Structured log validation report and traceability bundle.\n- Gate verdict artifact consumable by release automation.\n\n- Machine-readable verification artifact at `artifacts/section_10_12/bd-1d6x/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_12/bd-1d6x/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests must validate contracts, invariants, and failure semantics.\n- E2E tests must validate cross-component behavior from user/operator entrypoints to persisted effects.\n- Logging must support root-cause analysis without hidden context requirements.\n\nTask-Specific Clarification:\n- For \"[10.12] Section-wide verification gate: comprehensive unit+e2e+logging\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.12] Section-wide verification gate: comprehensive unit+e2e+logging\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.12] Section-wide verification gate: comprehensive unit+e2e+logging\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.12] Section-wide verification gate: comprehensive unit+e2e+logging\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.12] Section-wide verification gate: comprehensive unit+e2e+logging\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:48:08.411696239Z","created_by":"ubuntu","updated_at":"2026-02-20T08:43:52.618878648Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-12","test-obligations","verification-gate"],"dependencies":[{"issue_id":"bd-1d6x","depends_on_id":"bd-1dpd","type":"blocks","created_at":"2026-02-20T08:24:26.820714360Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1d6x","depends_on_id":"bd-2aj","type":"blocks","created_at":"2026-02-20T07:48:08.584401751Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1d6x","depends_on_id":"bd-2twu","type":"blocks","created_at":"2026-02-20T08:20:52.757269754Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1d6x","depends_on_id":"bd-3c2","type":"blocks","created_at":"2026-02-20T07:48:08.704933979Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1d6x","depends_on_id":"bd-3hm","type":"blocks","created_at":"2026-02-20T07:48:08.846372575Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1d6x","depends_on_id":"bd-3j4","type":"blocks","created_at":"2026-02-20T07:48:08.797919960Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1d6x","depends_on_id":"bd-5si","type":"blocks","created_at":"2026-02-20T07:48:08.751513606Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1d6x","depends_on_id":"bd-n1w","type":"blocks","created_at":"2026-02-20T07:48:08.535912979Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1d6x","depends_on_id":"bd-y0v","type":"blocks","created_at":"2026-02-20T07:48:08.654357157Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-1d7n","title":"[10.13] Implement deterministic activation pipeline: sandbox -> ephemeral secret mount -> capability issue -> health-ready transition.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.13 — FCP Deep-Mined Expansion Execution Track (9I)\n\nWhy This Exists:\nDeep connector/provider contract track: lifecycle FSMs, conformance harnesses, fencing, sandboxing, revocation freshness, and protocol hardening.\n\nTask Objective:\nImplement deterministic activation pipeline: sandbox -> ephemeral secret mount -> capability issue -> health-ready transition.\n\nAcceptance Criteria:\n- Stage order is fixed and enforced; partial activation cannot leak persistent secrets; restart replay reproduces identical activation transcript.\n\nExpected Artifacts:\n- `docs/specs/activation_pipeline.md`, `tests/integration/activation_pipeline_determinism.rs`, `artifacts/10.13/activation_stage_transcript.jsonl`.\n\n- Machine-readable verification artifact at `artifacts/section_10_13/bd-1d7n/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_13/bd-1d7n/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.13] Implement deterministic activation pipeline: sandbox -> ephemeral secret mount -> capability issue -> health-ready transition.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.13] Implement deterministic activation pipeline: sandbox -> ephemeral secret mount -> capability issue -> health-ready transition.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.13] Implement deterministic activation pipeline: sandbox -> ephemeral secret mount -> capability issue -> health-ready transition.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.13] Implement deterministic activation pipeline: sandbox -> ephemeral secret mount -> capability issue -> health-ready transition.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.13] Implement deterministic activation pipeline: sandbox -> ephemeral secret mount -> capability issue -> health-ready transition.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","status":"closed","priority":1,"issue_type":"task","assignee":"CrimsonCrane","created_at":"2026-02-20T07:36:52.865799544Z","created_by":"ubuntu","updated_at":"2026-02-20T11:52:50.417718334Z","closed_at":"2026-02-20T11:52:50.417692176Z","close_reason":"done","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-13","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-1d7n","depends_on_id":"bd-3i9o","type":"blocks","created_at":"2026-02-20T07:43:13.012177086Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-1dar","title":"[10.14] Implement optional MMR checkpoints and inclusion/prefix proof APIs for external verifiers.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.14 — FrankenSQLite Deep-Mined Expansion Execution Track (9J)\n\nWhy This Exists:\nFrankenSQLite deep-mined control integrity track: evidence ledgers, proofs, epochs, remote effects, markers/MMR, and deterministic fault labs.\n\nTask Objective:\nImplement optional MMR checkpoints and inclusion/prefix proof APIs for external verifiers.\n\nAcceptance Criteria:\n- MMR checkpoints can be enabled/disabled without corrupting marker truth; proof APIs verify inclusion and prefix claims; verifier examples pass.\n\nExpected Artifacts:\n- `src/control_plane/mmr_proofs.rs`, `tests/conformance/mmr_proof_verification.rs`, `artifacts/10.14/mmr_proof_vectors.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_14/bd-1dar/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_14/bd-1dar/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.14] Implement optional MMR checkpoints and inclusion/prefix proof APIs for external verifiers.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.14] Implement optional MMR checkpoints and inclusion/prefix proof APIs for external verifiers.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.14] Implement optional MMR checkpoints and inclusion/prefix proof APIs for external verifiers.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.14] Implement optional MMR checkpoints and inclusion/prefix proof APIs for external verifiers.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.14] Implement optional MMR checkpoints and inclusion/prefix proof APIs for external verifiers.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"MMR checkpoints can be enabled/disabled without corrupting marker truth; proof APIs verify inclusion and prefix claims; verifier examples pass.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:36:58.792991832Z","created_by":"ubuntu","updated_at":"2026-02-20T15:44:03.272685342Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-14","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-1dar","depends_on_id":"bd-xwk5","type":"blocks","created_at":"2026-02-20T07:43:16.104026960Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-1daz","title":"[10.14] Implement retroactive hardening pipeline that appends additional protection artifacts without rewriting canonical objects.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.14 — FrankenSQLite Deep-Mined Expansion Execution Track (9J)\n\nWhy This Exists:\nFrankenSQLite deep-mined control integrity track: evidence ledgers, proofs, epochs, remote effects, markers/MMR, and deterministic fault labs.\n\nTask Objective:\nImplement retroactive hardening pipeline that appends additional protection artifacts without rewriting canonical objects.\n\nAcceptance Criteria:\n- Retroactive hardening adds union-only artifacts; canonical object identity remains stable; repairability improvement is measurable on target corpus.\n\nExpected Artifacts:\n- `docs/specs/retroactive_hardening.md`, `tests/integration/retroactive_hardening_union_only.rs`, `artifacts/10.14/retroactive_hardening_report.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_14/bd-1daz/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_14/bd-1daz/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.14] Implement retroactive hardening pipeline that appends additional protection artifacts without rewriting canonical objects.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.14] Implement retroactive hardening pipeline that appends additional protection artifacts without rewriting canonical objects.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.14] Implement retroactive hardening pipeline that appends additional protection artifacts without rewriting canonical objects.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.14] Implement retroactive hardening pipeline that appends additional protection artifacts without rewriting canonical objects.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.14] Implement retroactive hardening pipeline that appends additional protection artifacts without rewriting canonical objects.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"Retroactive hardening adds union-only artifacts; canonical object identity remains stable; repairability improvement is measurable on target corpus.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:36:56.299367956Z","created_by":"ubuntu","updated_at":"2026-02-20T15:44:09.728628365Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-14","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-1daz","depends_on_id":"bd-1ayu","type":"blocks","created_at":"2026-02-20T07:43:14.809328864Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-1dpd","title":"[PROGRAM] Enforce rch-only offload contract for CPU-intensive build/test/benchmark workflows","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md (Cross-cutting execution policy across Sections 10.0–10.21 and 11–16)\n\nTask Objective:\nDefine and enforce a fail-closed execution policy requiring rch offload for CPU-intensive build/test/benchmark/coverage/e2e workloads so verification remains reproducible, resource-safe, and audit-traceable under parallel multi-agent execution.\n\nWhy This Exists:\nThe project explicitly requires CPU-intensive operations to run via rch. Without a dedicated policy bead and automated gate, agents may accidentally run heavy local cargo jobs, causing noisy contention, nondeterministic timing artifacts, and verification drift.\n\nAcceptance Criteria:\n- Publish canonical command-class policy that marks CPU-intensive workloads as rch-required (for example: cargo check, cargo clippy, cargo test, cargo nextest, cargo llvm-cov, benchmark suites, broad E2E sweeps).\n- Define and enforce allowlist/exception process for commands that may run locally without violating policy.\n- Implement fail-closed detector that flags local execution of rch-required workloads in CI/local verification gates.\n- Emit machine-readable evidence proving each heavy verification run used rch and include worker provenance (worker id/host/queue/wait/run durations).\n- Integrate policy checks into bootstrap, section, and program-wide verification gates.\n\nExpected Artifacts:\n- docs/verification/RCH_EXECUTION_POLICY.md\n- schemas/rch_execution_provenance.schema.json\n- scripts/verify_rch_required_workloads.sh\n- artifacts/program/rch_execution_policy_report.json\n\nTesting & Logging Requirements:\n- Unit tests for command classification logic, exception resolution, and policy parser behavior.\n- E2E tests that run representative heavy workflows and assert fail-closed behavior when rch is bypassed.\n- Detailed structured logs with stable event codes for classification decisions, policy violations, worker provenance, and remediation hints.\n- Deterministic replay artifacts capturing command input, policy decision, and provenance bundle.\n\nTask-Specific Clarification:\n- Preserve full feature scope: this bead strengthens execution discipline only and must not weaken any existing verification/test requirements.\n- This policy is additive to section/program gates and must be consumable without manual interpretation.\n- Any bypass path must be explicit, logged, and policy-approved; silent bypass is forbidden.\n\nWhy This Improves User Outcomes:\n- Prevents flaky or misleading verification results caused by uncontrolled local resource contention.\n- Improves trust by making heavy verification runs auditable, reproducible, and attributable to specific offload workers.\n- Reduces incident MTTR by pairing failures with deterministic provenance and clear policy-violation diagnostics.","status":"closed","priority":1,"issue_type":"task","assignee":"ubuntu","created_at":"2026-02-20T08:23:55.611747103Z","created_by":"ubuntu","updated_at":"2026-02-20T08:32:49.126193776Z","closed_at":"2026-02-20T08:32:49.126102376Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","program-integration","test-obligations","verification"]}
{"id":"bd-1e0","title":"[10.9] Build migration singularity demo pipeline for flagship repositories.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.9 — Moonshot Disruption Track\n\nWhy This Exists:\nMoonshot disruption track for public benchmark leadership, adversarial campaigns, verifier economy, and category-shift reporting.\n\nTask Objective:\nBuild migration singularity demo pipeline for flagship repositories.\n\nAcceptance Criteria:\n- Implement with explicit success/failure invariants and deterministic behavior under normal, edge, and fault scenarios.\n- Ensure outcomes are verifiable via automated tests and reproducible artifact outputs.\n\nExpected Artifacts:\n- Section-owned design/spec artifact at `docs/specs/section_10_9/bd-1e0_contract.md`, capturing decision rationale, invariants, and interface boundaries.\n- Machine-readable verification artifact at `artifacts/section_10_9/bd-1e0/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_9/bd-1e0/verification_summary.md` linking implementation intent to measured outcomes.\n\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.9] Build migration singularity demo pipeline for flagship repositories.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.9] Build migration singularity demo pipeline for flagship repositories.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.9] Build migration singularity demo pipeline for flagship repositories.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.9] Build migration singularity demo pipeline for flagship repositories.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.9] Build migration singularity demo pipeline for flagship repositories.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"1. Demo pipeline migrates at least 3 flagship open-source repositories (e.g., Express, Fastify, Next.js-like projects) from Node.js to franken_node with zero manual intervention.\n2. Pipeline produces a migration singularity report: complete migration log, before/after test results, compatibility coverage percentage, and time-to-migrate.\n3. Per Section 3 category targets: demo achieves >= 3x migration velocity compared to manual migration baseline for each flagship repo.\n4. Pipeline is fully scripted and reproducible: scripts/run_singularity_demo.sh <repo-url> executes the entire migration and validation cycle.\n5. Each demo includes a compatibility proof: full test suite of the migrated project passes under franken_node with results compared against Node.js baseline.\n6. Pipeline handles failure gracefully: partial migrations produce a diagnostic report listing blocked modules, unsupported APIs, and suggested workarounds.\n7. Demo artifacts (migration logs, test results, compatibility reports) are published under artifacts/ with a summary suitable for external stakeholders.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:36:48.445017898Z","created_by":"ubuntu","updated_at":"2026-02-20T15:20:07.577060995Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-9","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-1e0","depends_on_id":"bd-9is","type":"blocks","created_at":"2026-02-20T07:43:24.090629263Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-1eot","title":"[10.19] Integrate privacy-preserving urgent routing for revocation/quarantine signals.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.19 — Adversarial Trust Commons Execution Track (9M)\n\nWhy This Exists:\nATC federated intelligence track for privacy-preserving cross-deployment threat learning, robust aggregation, and verifier-backed trust metrics.\n\nTask Objective:\nIntegrate privacy-preserving urgent routing for revocation/quarantine signals.\n\nAcceptance Criteria:\n- High-severity signals propagate within policy SLO while preserving privacy envelopes; urgent route decisions are signed and replayable.\n\nExpected Artifacts:\n- `docs/specs/atc_urgent_signal_routing.md`, `tests/integration/atc_urgent_routing_latency.rs`, `artifacts/10.19/atc_urgent_routing_telemetry.csv`.\n\n- Machine-readable verification artifact at `artifacts/section_10_19/bd-1eot/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_19/bd-1eot/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.19] Integrate privacy-preserving urgent routing for revocation/quarantine signals.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.19] Integrate privacy-preserving urgent routing for revocation/quarantine signals.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.19] Integrate privacy-preserving urgent routing for revocation/quarantine signals.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.19] Integrate privacy-preserving urgent routing for revocation/quarantine signals.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.19] Integrate privacy-preserving urgent routing for revocation/quarantine signals.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- High-severity signals propagate within policy SLO while preserving privacy envelopes; urgent route decisions are signed and replayable.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:37:06.087676863Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:17.575638814Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-19","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-1eot","depends_on_id":"bd-253o","type":"blocks","created_at":"2026-02-20T07:43:19.873242560Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-1f8m","title":"[10.15] Add invariant-breach runbooks for region-quiescence failure, obligation leak, and cancel-timeout incidents.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.15 — Asupersync-First Integration Execution Track (8.4-8.6)\n\nWhy This Exists:\nAsupersync-first control-plane migration track enforcing Cx-first, region ownership, cancellation correctness, and protocol-grade verification gates.\n\nTask Objective:\nAdd invariant-breach runbooks for region-quiescence failure, obligation leak, and cancel-timeout incidents.\n\nAcceptance Criteria:\n- Runbooks include detection signature, immediate containment steps, replay procedure, and rollback procedure.\n\nExpected Artifacts:\n- `docs/runbooks/region_quiescence_breach.md`, `docs/runbooks/obligation_leak_incident.md`, `docs/runbooks/cancel_timeout_incident.md`.\n\n- Machine-readable verification artifact at `artifacts/section_10_15/bd-1f8m/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_15/bd-1f8m/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.15] Add invariant-breach runbooks for region-quiescence failure, obligation leak, and cancel-timeout incidents.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.15] Add invariant-breach runbooks for region-quiescence failure, obligation leak, and cancel-timeout incidents.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.15] Add invariant-breach runbooks for region-quiescence failure, obligation leak, and cancel-timeout incidents.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.15] Add invariant-breach runbooks for region-quiescence failure, obligation leak, and cancel-timeout incidents.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.15] Add invariant-breach runbooks for region-quiescence failure, obligation leak, and cancel-timeout incidents.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- Runbooks include detection signature, immediate containment steps, replay procedure, and rollback procedure.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:37:01.200576053Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:49.439203120Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-15","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-1f8m","depends_on_id":"bd-3gnh","type":"blocks","created_at":"2026-02-20T07:43:17.350655628Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-1f8v","title":"[10.20] Add operator copilot guidance for dependency updates with topology-aware risk deltas and mitigation playbooks.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.20 — Dependency Graph Immune System Execution Track (9N)\n\nWhy This Exists:\nDGIS topological immune system track for dependency contagion modeling, choke-point immunization, and graph-aware containment economics.\n\nTask Objective:\nAdd operator copilot guidance for dependency updates with topology-aware risk deltas and mitigation playbooks.\n\nAcceptance Criteria:\n- Update proposals include pre/post topology risk scores, containment recommendations, and verifier-backed confidence outputs; high-risk updates require explicit policy acknowledgements.\n\nExpected Artifacts:\n- `src/ops/dgis_update_copilot.rs`, `tests/integration/dgis_update_recommendations.rs`, `artifacts/10.20/dgis_operator_recommendation_log.jsonl`.\n\n- Machine-readable verification artifact at `artifacts/section_10_20/bd-1f8v/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_20/bd-1f8v/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.20] Add operator copilot guidance for dependency updates with topology-aware risk deltas and mitigation playbooks.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.20] Add operator copilot guidance for dependency updates with topology-aware risk deltas and mitigation playbooks.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.20] Add operator copilot guidance for dependency updates with topology-aware risk deltas and mitigation playbooks.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.20] Add operator copilot guidance for dependency updates with topology-aware risk deltas and mitigation playbooks.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.20] Add operator copilot guidance for dependency updates with topology-aware risk deltas and mitigation playbooks.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- Update proposals include pre/post topology risk scores, containment recommendations, and verifier-backed confidence outputs; high-risk updates require explicit policy acknowledgements.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:37:07.359001655Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:17.818311862Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-20","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-1f8v","depends_on_id":"bd-19k2","type":"blocks","created_at":"2026-02-20T07:43:21.062794316Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-1fck","title":"[10.14] Implement retrievability-before-eviction proofs for L2->L3 lifecycle transitions.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.14 — FrankenSQLite Deep-Mined Expansion Execution Track (9J)\n\nWhy This Exists:\nFrankenSQLite deep-mined control integrity track: evidence ledgers, proofs, epochs, remote effects, markers/MMR, and deterministic fault labs.\n\nTask Objective:\nImplement retrievability-before-eviction proofs for L2->L3 lifecycle transitions.\n\nAcceptance Criteria:\n- Eviction requires successful retrievability proof check; failed proofs block eviction; proof records tie to retired segment IDs.\n\nExpected Artifacts:\n- `src/storage/retrievability_gate.rs`, `tests/integration/retrievability_before_eviction.rs`, `artifacts/10.14/retrievability_proof_receipts.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_14/bd-1fck/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_14/bd-1fck/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.14] Implement retrievability-before-eviction proofs for L2->L3 lifecycle transitions.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.14] Implement retrievability-before-eviction proofs for L2->L3 lifecycle transitions.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.14] Implement retrievability-before-eviction proofs for L2->L3 lifecycle transitions.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.14] Implement retrievability-before-eviction proofs for L2->L3 lifecycle transitions.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.14] Implement retrievability-before-eviction proofs for L2->L3 lifecycle transitions.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"Eviction requires successful retrievability proof check; failed proofs block eviction; proof records tie to retired segment IDs.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:36:57.487589775Z","created_by":"ubuntu","updated_at":"2026-02-20T15:44:06.671002723Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-14","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-1fck","depends_on_id":"bd-18ud","type":"blocks","created_at":"2026-02-20T07:43:15.400576234Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-1fi2","title":"[10.8] Section-wide verification gate: comprehensive unit+e2e+logging","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.8\n\nTask Objective:\nCreate a hard section completion gate that verifies all implemented behavior in this section with comprehensive unit tests, integration/e2e scripts, and detailed structured logging evidence.\n\nAcceptance Criteria:\n- Section test matrix covers happy-path, edge-case, and adversarial/error-path scenarios for all section deliverables.\n- E2E scripts execute representative end-user workflows and policy/control-plane transitions for this section.\n- Structured logs include stable event/error codes, trace correlation IDs, and enough context for deterministic replay triage.\n- Verification report is deterministic and machine-readable for CI/release gating.\n\nExpected Artifacts:\n- Section-level test matrix and coverage summary artifact.\n- E2E script suite with pass/fail outputs and reproducible fixtures/seeds.\n- Structured log validation report and traceability bundle.\n- Gate verdict artifact consumable by release automation.\n\n- Machine-readable verification artifact at `artifacts/section_10_8/bd-1fi2/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_8/bd-1fi2/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests must validate contracts, invariants, and failure semantics.\n- E2E tests must validate cross-component behavior from user/operator entrypoints to persisted effects.\n- Logging must support root-cause analysis without hidden context requirements.\n\nTask-Specific Clarification:\n- For \"[10.8] Section-wide verification gate: comprehensive unit+e2e+logging\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.8] Section-wide verification gate: comprehensive unit+e2e+logging\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.8] Section-wide verification gate: comprehensive unit+e2e+logging\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.8] Section-wide verification gate: comprehensive unit+e2e+logging\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.8] Section-wide verification gate: comprehensive unit+e2e+logging\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"1. Section 10.8 gate aggregates pass/fail status from all sibling beads (bd-tg2, bd-3o6, bd-k6o, bd-f2y, bd-nr4, bd-3m6).\n2. Gate script (scripts/check_section_10_8_gate.py) runs all section verification scripts and produces a unified JSON report.\n3. Gate fails if any sibling bead's verification evidence is missing or shows a failure.\n4. Unit tests cover gate logic: all-pass, single-fail, and missing-evidence scenarios.\n5. Gate produces a section-level summary under artifacts/ with per-bead status, timestamps, and links to individual evidence files.\n6. E2E logging: gate execution emits structured log lines for each sub-check with bead ID, result, and duration.\n7. Gate is idempotent: running it twice in succession with no changes produces identical output.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:48:26.005618085Z","created_by":"ubuntu","updated_at":"2026-02-20T15:19:26.061592607Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-8","test-obligations","verification-gate"],"dependencies":[{"issue_id":"bd-1fi2","depends_on_id":"bd-1dpd","type":"blocks","created_at":"2026-02-20T08:24:24.596033499Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1fi2","depends_on_id":"bd-2twu","type":"blocks","created_at":"2026-02-20T08:20:50.133799070Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1fi2","depends_on_id":"bd-3m6","type":"blocks","created_at":"2026-02-20T07:48:26.101845374Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1fi2","depends_on_id":"bd-3o6","type":"blocks","created_at":"2026-02-20T07:48:26.310271429Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1fi2","depends_on_id":"bd-f2y","type":"blocks","created_at":"2026-02-20T07:48:26.195563990Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1fi2","depends_on_id":"bd-k6o","type":"blocks","created_at":"2026-02-20T07:48:26.255849585Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1fi2","depends_on_id":"bd-nr4","type":"blocks","created_at":"2026-02-20T07:48:26.148262809Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1fi2","depends_on_id":"bd-tg2","type":"blocks","created_at":"2026-02-20T07:48:26.360765476Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-1fp4","title":"[10.14] Implement integrity sweep escalation/de-escalation policy driven by evidence trajectories.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.14 — FrankenSQLite Deep-Mined Expansion Execution Track (9J)\n\nWhy This Exists:\nFrankenSQLite deep-mined control integrity track: evidence ledgers, proofs, epochs, remote effects, markers/MMR, and deterministic fault labs.\n\nTask Objective:\nImplement integrity sweep escalation/de-escalation policy driven by evidence trajectories.\n\nAcceptance Criteria:\n- Sweep cadence adjusts according to policy evidence bands; escalation/de-escalation hysteresis prevents oscillation; decisions are ledgered.\n\nExpected Artifacts:\n- `src/policy/integrity_sweep_scheduler.rs`, `tests/perf/integrity_sweep_adaptation.rs`, `artifacts/10.14/sweep_policy_trajectory.csv`.\n\n- Machine-readable verification artifact at `artifacts/section_10_14/bd-1fp4/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_14/bd-1fp4/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.14] Implement integrity sweep escalation/de-escalation policy driven by evidence trajectories.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.14] Implement integrity sweep escalation/de-escalation policy driven by evidence trajectories.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.14] Implement integrity sweep escalation/de-escalation policy driven by evidence trajectories.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.14] Implement integrity sweep escalation/de-escalation policy driven by evidence trajectories.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.14] Implement integrity sweep escalation/de-escalation policy driven by evidence trajectories.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"Sweep cadence adjusts according to policy evidence bands; escalation/de-escalation hysteresis prevents oscillation; decisions are ledgered.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:36:56.380775372Z","created_by":"ubuntu","updated_at":"2026-02-20T15:44:09.482293485Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-14","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-1fp4","depends_on_id":"bd-1daz","type":"blocks","created_at":"2026-02-20T07:43:14.852197185Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-1fr7","title":"Epic: FCP-Inspired Hardening + Interop [10.10]","description":"- type: epic","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-20T07:47:58.072163029Z","updated_at":"2026-02-20T07:49:21.141916313Z","closed_at":"2026-02-20T07:49:21.141894963Z","close_reason":"Superseded by canonical detailed master-plan graph (bd-33v) with full 10.N-10.21 and 11-16 coverage, explicit dependencies, and per-section verification gates.","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-1ga5","title":"[10.21] Implement cohort-aware baseline modeling for expected phenotype evolution patterns.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.21 — Behavioral Phenotype Evolution Tracker Execution Track (9O)\n\nWhy This Exists:\nBPET longitudinal phenotype intelligence track for pre-compromise trajectory detection and integration with DGIS/ATC/migration/economic policy.\n\nTask Objective:\nImplement cohort-aware baseline modeling for expected phenotype evolution patterns.\n\nAcceptance Criteria:\n- Baselines are generated for comparable extension cohorts (domain, maturity, release cadence, dependency class) and include confidence envelopes; model recalibration is deterministic and versioned.\n\nExpected Artifacts:\n- `src/security/bpet/cohort_baselines.rs`, `tests/security/bpet_baseline_calibration.rs`, `artifacts/10.21/bpet_cohort_baseline_report.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_21/bd-1ga5/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_21/bd-1ga5/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.21] Implement cohort-aware baseline modeling for expected phenotype evolution patterns.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.21] Implement cohort-aware baseline modeling for expected phenotype evolution patterns.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.21] Implement cohort-aware baseline modeling for expected phenotype evolution patterns.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.21] Implement cohort-aware baseline modeling for expected phenotype evolution patterns.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.21] Implement cohort-aware baseline modeling for expected phenotype evolution patterns.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- Baselines are generated for comparable extension cohorts (domain, maturity, release cadence, dependency class) and include confidence envelopes; model recalibration is deterministic and versioned.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:37:07.941121959Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:18.057678464Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-21","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-1ga5","depends_on_id":"bd-3rai","type":"blocks","created_at":"2026-02-20T07:43:21.387370820Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-1gnb","title":"[10.13] Require distributed trace correlation IDs across connector execution and control-plane artifacts.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.13 — FCP Deep-Mined Expansion Execution Track (9I)\n\nWhy This Exists:\nDeep connector/provider contract track: lifecycle FSMs, conformance harnesses, fencing, sandboxing, revocation freshness, and protocol hardening.\n\nTask Objective:\nRequire distributed trace correlation IDs across connector execution and control-plane artifacts.\n\nAcceptance Criteria:\n- All high-impact flows carry trace correlation fields end-to-end; missing trace context is surfaced as conformance failure; traces can be stitched across services.\n\nExpected Artifacts:\n- `tests/integration/trace_correlation_end_to_end.rs`, `docs/specs/trace_context_contract.md`, `artifacts/10.13/distributed_trace_sample.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_13/bd-1gnb/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_13/bd-1gnb/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.13] Require distributed trace correlation IDs across connector execution and control-plane artifacts.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.13] Require distributed trace correlation IDs across connector execution and control-plane artifacts.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.13] Require distributed trace correlation IDs across connector execution and control-plane artifacts.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.13] Require distributed trace correlation IDs across connector execution and control-plane artifacts.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.13] Require distributed trace correlation IDs across connector execution and control-plane artifacts.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","status":"closed","priority":1,"issue_type":"task","assignee":"CrimsonCrane","created_at":"2026-02-20T07:36:54.738650207Z","created_by":"ubuntu","updated_at":"2026-02-20T13:26:06.415136147Z","closed_at":"2026-02-20T13:26:06.415109107Z","close_reason":"done","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-13","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-1gnb","depends_on_id":"bd-novi","type":"blocks","created_at":"2026-02-20T07:43:13.978818786Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-1gx","title":"[10.4] Define signed extension package manifest schema.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.4 — Extension Ecosystem + Registry (Item 1 of 8)\n\nWhy This Exists:\nThe signed extension package manifest schema is the foundation for the entire extension trust ecosystem. Every extension must have a machine-readable, cryptographically signed manifest that declares its capabilities, provenance, and behavioral profile. This is the first step in building the trust-native extension distribution network.\n\nTask Objective:\nDefine the canonical schema for signed extension package manifests that will be used across the registry, trust card system, and policy evaluation pipeline.\n\nDetailed Acceptance Criteria:\n1. Schema defines required fields: package identity, version, author/publisher, capability declarations (FsRead, FsWrite, NetworkEgress, ProcessSpawn, EnvRead per franken_engine ExtensionManifest), behavioral profile, minimum runtime version.\n2. Schema includes provenance fields: build system, source repository, reproducibility markers, attestation chain.\n3. Schema includes trust metadata: certification level, revocation status pointer, trust card reference.\n4. Manifest is cryptographically signed with publisher key; signature scheme supports threshold signing for high-impact operations (9B.7).\n5. Schema versioning strategy with backward-compatible evolution path.\n6. Schema is published as both human-readable spec and JSON Schema/machine-readable format.\n7. Integration with franken_engine ExtensionManifest validation (from frankenengine-extension-host crate).\n\nKey Dependencies:\n- Depends on 10.1 (Charter) for governance boundaries on what extensions can declare.\n- Depends on 10.N (Normalization) for canonical ownership rules.\n- Consumed by 10.4 remaining items (provenance, trust cards, registry).\n- Consumed by 10.13 (FCP) for manifest negotiation and admission.\n\nExpected Artifacts:\n- Schema definition document at docs/specs/section_10_4/extension_manifest_schema.md\n- JSON Schema at schemas/extension_manifest.schema.json\n- Rust types in src/supply_chain/manifest.rs implementing the schema\n- artifacts/section_10_4/bd-1gx/verification_evidence.json\n\nTesting and Logging Requirements:\n- Unit tests: schema validation (valid manifests, invalid manifests, missing required fields, malformed signatures).\n- Integration tests: manifest creation -> signing -> validation -> registry admission pipeline.\n- Fuzz tests: malformed manifest payloads.\n- Structured logs: MANIFEST_CREATED, MANIFEST_SIGNED, MANIFEST_VALIDATED, MANIFEST_REJECTED with rejection reason codes.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:36:45.428676958Z","created_by":"ubuntu","updated_at":"2026-02-20T13:09:26.543605354Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-4","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-1gx","depends_on_id":"bd-1ta","type":"blocks","created_at":"2026-02-20T07:46:36.052669446Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1gx","depends_on_id":"bd-3il","type":"blocks","created_at":"2026-02-20T07:46:36.098543578Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1gx","depends_on_id":"bd-cda","type":"blocks","created_at":"2026-02-20T07:46:36.144056928Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-1h6","title":"[10.13] Implement standard connector method contract validator (`handshake/describe/introspect/capabilities/configure/simulate/invoke/health/shutdown`).","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.13 — FCP Deep-Mined Expansion Execution Track (9I)\n\nWhy This Exists:\nDeep connector/provider contract track: lifecycle FSMs, conformance harnesses, fencing, sandboxing, revocation freshness, and protocol hardening.\n\nTask Objective:\nImplement standard connector method contract validator (`handshake/describe/introspect/capabilities/configure/simulate/invoke/health/shutdown`).\n\nAcceptance Criteria:\n- Validator rejects missing or schema-invalid methods; method schemas are versioned and pinned; contract report is machine-readable.\n\nExpected Artifacts:\n- `src/conformance/connector_method_validator.rs`, `docs/specs/connector_method_contract.md`, `artifacts/10.13/connector_method_contract_report.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_13/bd-1h6/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_13/bd-1h6/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.13] Implement standard connector method contract validator (`handshake/describe/introspect/capabilities/configure/simulate/invoke/health/shutdown`).\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.13] Implement standard connector method contract validator (`handshake/describe/introspect/capabilities/configure/simulate/invoke/health/shutdown`).\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.13] Implement standard connector method contract validator (`handshake/describe/introspect/capabilities/configure/simulate/invoke/health/shutdown`).\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.13] Implement standard connector method contract validator (`handshake/describe/introspect/capabilities/configure/simulate/invoke/health/shutdown`).\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.13] Implement standard connector method contract validator (`handshake/describe/introspect/capabilities/configure/simulate/invoke/health/shutdown`).\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","status":"closed","priority":1,"issue_type":"task","assignee":"CrimsonCrane","created_at":"2026-02-20T07:36:51.557602070Z","created_by":"ubuntu","updated_at":"2026-02-20T10:40:22.765101588Z","closed_at":"2026-02-20T10:40:22.765075921Z","close_reason":"done","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-13","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-1h6","depends_on_id":"bd-1rk","type":"blocks","created_at":"2026-02-20T07:43:12.315822708Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-1h64","title":"Epic: Radical Expansion - Speculative Execution + Security [10.17a]","description":"- type: epic","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-20T07:47:58.072163029Z","updated_at":"2026-02-20T07:49:21.283695075Z","closed_at":"2026-02-20T07:49:21.283675228Z","close_reason":"Superseded by canonical detailed master-plan graph (bd-33v) with full 10.N-10.21 and 11-16 coverage, explicit dependencies, and per-section verification gates.","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-1hbw","title":"[10.15] Integrate canonical epoch transition barriers (from `10.14`) across control services with explicit abort semantics.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.15 — Asupersync-First Integration Execution Track (8.4-8.6)\n\nWhy This Exists:\nAsupersync-first control-plane migration track enforcing Cx-first, region ownership, cancellation correctness, and protocol-grade verification gates.\n\nTask Objective:\nIntegrate canonical epoch transition barriers (from `10.14`) across control services with explicit abort semantics.\n\nAcceptance Criteria:\n- Control transitions use canonical barrier protocol; transition commits only with full participant arrival/drain; timeout/cancel abort behavior remains deterministic.\n\nExpected Artifacts:\n- `docs/integration/control_epoch_barrier_adoption.md`, `tests/integration/control_epoch_barrier.rs`, `artifacts/10.15/control_epoch_barrier_transcript.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_15/bd-1hbw/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_15/bd-1hbw/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.15] Integrate canonical epoch transition barriers (from `10.14`) across control services with explicit abort semantics.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.15] Integrate canonical epoch transition barriers (from `10.14`) across control services with explicit abort semantics.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.15] Integrate canonical epoch transition barriers (from `10.14`) across control services with explicit abort semantics.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.15] Integrate canonical epoch transition barriers (from `10.14`) across control services with explicit abort semantics.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.15] Integrate canonical epoch transition barriers (from `10.14`) across control services with explicit abort semantics.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- Control transitions use canonical barrier protocol; transition commits only with full participant arrival/drain; timeout/cancel abort behavior remains deterministic.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:37:00.465325967Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:51.467494989Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-15","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-1hbw","depends_on_id":"bd-181w","type":"blocks","created_at":"2026-02-20T07:43:16.965417844Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1hbw","depends_on_id":"bd-2wsm","type":"blocks","created_at":"2026-02-20T14:59:37.214208972Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-1hd","title":"[10.10] Adopt canonical trust protocol vectors/golden fixtures (from `10.13` + `10.14`) as product publication and release gates.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.10 — FCP-Inspired Hardening + Interop Integration Track\n\nWhy This Exists:\nFCP-inspired hardening/interop contract for IDs, serialization, control-channel auth, revocation freshness, and publication gating.\n\nTask Objective:\nAdopt canonical trust protocol vectors/golden fixtures (from `10.13` + `10.14`) as product publication and release gates.\n\nAcceptance Criteria:\n- Implement with explicit success/failure invariants and deterministic behavior under normal, edge, and fault scenarios.\n- Ensure outcomes are verifiable via automated tests and reproducible artifact outputs.\n\nExpected Artifacts:\n- Section-owned design/spec artifact at `docs/specs/section_10_10/bd-1hd_contract.md`, capturing decision rationale, invariants, and interface boundaries.\n- Machine-readable verification artifact at `artifacts/section_10_10/bd-1hd/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_10/bd-1hd/verification_summary.md` linking implementation intent to measured outcomes.\n\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.10] Adopt canonical trust protocol vectors/golden fixtures (from `10.13` + `10.14`) as product publication and release gates.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.10] Adopt canonical trust protocol vectors/golden fixtures (from `10.13` + `10.14`) as product publication and release gates.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.10] Adopt canonical trust protocol vectors/golden fixtures (from `10.13` + `10.14`) as product publication and release gates.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.10] Adopt canonical trust protocol vectors/golden fixtures (from `10.13` + `10.14`) as product publication and release gates.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.10] Adopt canonical trust protocol vectors/golden fixtures (from `10.13` + `10.14`) as product publication and release gates.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"1. Integrate the canonical golden vector suite from 10.13 (golden_vectors.rs) and the conformance suite from 10.14 as mandatory release gates. No product build may be published to any release channel (CANARY, BETA, STABLE, LTS) without passing all golden vector tests.\n2. Define a ReleaseGateManifest struct containing: (a) release_id (TrustObjectId with RELEASE domain), (b) channel (release channel enum), (c) golden_vector_suite_version (semver string), (d) golden_vector_results (list of {vector_name, pass/fail, actual_hash, expected_hash}), (e) conformance_profile_results (from 10.13 conformance_profile.rs), (f) gate_timestamp, (g) gate_signer_key_id.\n3. Enforce pass/fail logic: (a) ALL golden vectors must pass for any channel, (b) conformance profile coverage must be >= 100% for STABLE and LTS, >= 90% for BETA, >= 80% for CANARY, (c) any single golden vector failure blocks the release with a GateFailure error listing all failing vectors.\n4. Implement a gate evaluation function: evaluate_release_gate(release_id, channel, vector_results, conformance_results) -> Result<ReleaseGateManifest, GateFailure>.\n5. Implement vector freshness check: the golden vector suite version used in the gate MUST be within 1 minor version of the latest published suite. Reject stale suites with VectorSuiteOutdated error.\n6. Implement a publication receipt: on successful gate evaluation, produce a signed receipt (using an ATTESTATION-role key from bd-364) containing the ReleaseGateManifest. This receipt is the artifact that authorizes publication.\n7. Store the gate manifest and receipt as machine-readable JSON artifacts alongside the release.\n8. Unit tests: (a) all vectors pass => gate passes, (b) one vector fails => gate fails with details, (c) conformance below threshold => gate fails, (d) stale vector suite => rejected, (e) receipt signature verification round-trip.\n9. Integration test: build a mock release pipeline, run full gate evaluation, verify receipt is produced and verifiable.\n10. Verification: scripts/check_release_gates.py --json, artifacts at artifacts/section_10_10/bd-1hd/.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:36:49.585429852Z","created_by":"ubuntu","updated_at":"2026-02-20T15:38:54.664657628Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-10","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-1hd","depends_on_id":"bd-13q","type":"blocks","created_at":"2026-02-20T07:43:11.266544061Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1hd","depends_on_id":"bd-3n2u","type":"blocks","created_at":"2026-02-20T14:59:52.490667600Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-1hf","title":"[PLAN 10.10] FCP-Inspired Hardening + Interop Integration Track","description":"Section: 10.10 — FCP-Inspired Hardening + Interop Integration Track\n\nStrategic Context:\nFCP-inspired hardening/interop contract for IDs, serialization, control-channel auth, revocation freshness, and publication gating.\n\nExecution Requirements:\n- Preserve all scoped capabilities from the canonical plan.\n- Keep contracts self-contained so future contributors can execute without reopening the master plan.\n- Require explicit testing strategy (unit + integration/e2e) and structured logging/telemetry for every child bead.\n- Require artifact-backed validation for performance, security, and correctness claims.\n\nDependency Semantics:\n- This epic is blocked by its child implementation beads.\n- Cross-epic dependencies encode strategic sequencing and canonical ownership boundaries.\n\n## Success Criteria\n- All child beads for this section are completed with acceptance artifacts attached and no unresolved blockers.\n- Section-level verification gate for comprehensive unit tests, integration/e2e workflows, and detailed structured logging evidence is green.\n- Scope-to-plan traceability is explicit, with no feature loss versus the canonical plan section.\n\n## Optimization Notes\n- User-Outcome Lens: \"[PLAN 10.10] FCP-Inspired Hardening + Interop Integration Track\" must improve operator confidence, safety posture, and deterministic recovery behavior under both normal and adversarial conditions.\n- Cross-Section Coordination: child beads must encode integration assumptions explicitly to avoid local optimizations that degrade system-wide correctness.\n- Verification Non-Negotiable: completion requires reproducible unit/integration/E2E evidence and structured logs suitable for independent replay.\n- Scope Protection: any simplification must preserve canonical-plan feature intent and be justified with explicit tradeoff documentation.","status":"open","priority":2,"issue_type":"epic","created_at":"2026-02-20T07:36:41.031586341Z","created_by":"ubuntu","updated_at":"2026-02-20T08:16:47.555101501Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-10"],"dependencies":[{"issue_id":"bd-1hf","depends_on_id":"bd-13q","type":"blocks","created_at":"2026-02-20T07:36:49.542162178Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1hf","depends_on_id":"bd-174","type":"blocks","created_at":"2026-02-20T07:36:48.957857014Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1hf","depends_on_id":"bd-1hd","type":"blocks","created_at":"2026-02-20T07:36:49.621886409Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1hf","depends_on_id":"bd-1jjq","type":"blocks","created_at":"2026-02-20T07:48:07.288639479Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1hf","depends_on_id":"bd-1l5","type":"blocks","created_at":"2026-02-20T07:36:48.795731716Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1hf","depends_on_id":"bd-1r2","type":"blocks","created_at":"2026-02-20T07:36:49.124527458Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1hf","depends_on_id":"bd-1ta","type":"blocks","created_at":"2026-02-20T07:37:10.706149914Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1hf","depends_on_id":"bd-1vp","type":"blocks","created_at":"2026-02-20T07:36:49.462726845Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1hf","depends_on_id":"bd-2ms","type":"blocks","created_at":"2026-02-20T07:36:49.038641299Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1hf","depends_on_id":"bd-2sx","type":"blocks","created_at":"2026-02-20T07:36:49.365138059Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1hf","depends_on_id":"bd-364","type":"blocks","created_at":"2026-02-20T07:36:49.204073066Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1hf","depends_on_id":"bd-5rh","type":"blocks","created_at":"2026-02-20T07:37:10.744067643Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1hf","depends_on_id":"bd-cda","type":"blocks","created_at":"2026-02-20T07:37:09.427896947Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1hf","depends_on_id":"bd-jjm","type":"blocks","created_at":"2026-02-20T07:36:48.874439003Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1hf","depends_on_id":"bd-oty","type":"blocks","created_at":"2026-02-20T07:36:49.284219864Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-1hj3","title":"[10.19] Implement local signal extraction pipeline from trust cards, adversary graph, and control-plane events.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.19 — Adversarial Trust Commons Execution Track (9M)\n\nWhy This Exists:\nATC federated intelligence track for privacy-preserving cross-deployment threat learning, robust aggregation, and verifier-backed trust metrics.\n\nTask Objective:\nImplement local signal extraction pipeline from trust cards, adversary graph, and control-plane events.\n\nAcceptance Criteria:\n- Extraction is deterministic for identical inputs; sensitive raw payloads are excluded by policy; extraction outputs are replay-auditable.\n\nExpected Artifacts:\n- `src/federation/atc_signal_extractor.rs`, `tests/conformance/atc_signal_extraction.rs`, `artifacts/10.19/atc_local_signal_samples.jsonl`.\n\n- Machine-readable verification artifact at `artifacts/section_10_19/bd-1hj3/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_19/bd-1hj3/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.19] Implement local signal extraction pipeline from trust cards, adversary graph, and control-plane events.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.19] Implement local signal extraction pipeline from trust cards, adversary graph, and control-plane events.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.19] Implement local signal extraction pipeline from trust cards, adversary graph, and control-plane events.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.19] Implement local signal extraction pipeline from trust cards, adversary graph, and control-plane events.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.19] Implement local signal extraction pipeline from trust cards, adversary graph, and control-plane events.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- Extraction is deterministic for identical inputs; sensitive raw payloads are excluded by policy; extraction outputs are replay-auditable.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:37:05.501718880Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:18.296127956Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-19","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-1hj3","depends_on_id":"bd-3aqy","type":"blocks","created_at":"2026-02-20T07:43:19.575455982Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-1id0","title":"[10.15] Publish tri-kernel ownership contract (`franken_engine`, `asupersync`, `franken_node`) with explicit interface boundaries.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.15 — Asupersync-First Integration Execution Track (8.4-8.6)\n\nWhy This Exists:\nAsupersync-first control-plane migration track enforcing Cx-first, region ownership, cancellation correctness, and protocol-grade verification gates.\n\nTask Objective:\nPublish tri-kernel ownership contract (`franken_engine`, `asupersync`, `franken_node`) with explicit interface boundaries.\n\nAcceptance Criteria:\n- Contract names owners for execution, correctness, and product planes; boundary violations have deterministic CI failures; exceptions require signed waiver artifact.\n\nExpected Artifacts:\n- `docs/architecture/tri_kernel_ownership_contract.md`, `tests/conformance/ownership_boundary_checks.rs`, `artifacts/10.15/ownership_boundary_report.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_15/bd-1id0/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_15/bd-1id0/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.15] Publish tri-kernel ownership contract (`franken_engine`, `asupersync`, `franken_node`) with explicit interface boundaries.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.15] Publish tri-kernel ownership contract (`franken_engine`, `asupersync`, `franken_node`) with explicit interface boundaries.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.15] Publish tri-kernel ownership contract (`franken_engine`, `asupersync`, `franken_node`) with explicit interface boundaries.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.15] Publish tri-kernel ownership contract (`franken_engine`, `asupersync`, `franken_node`) with explicit interface boundaries.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.15] Publish tri-kernel ownership contract (`franken_engine`, `asupersync`, `franken_node`) with explicit interface boundaries.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- Contract names owners for execution, correctness, and product planes; boundary violations have deterministic CI failures; exceptions require signed waiver artifact.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:36:59.474000123Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:54.414589132Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-15","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-1id0","depends_on_id":"bd-1ow","type":"blocks","created_at":"2026-02-20T07:46:33.223681854Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1id0","depends_on_id":"bd-5rh","type":"blocks","created_at":"2026-02-20T07:46:33.274270988Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1id0","depends_on_id":"bd-cda","type":"blocks","created_at":"2026-02-20T07:46:33.319097779Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-1iyx","title":"[10.14] Add determinism conformance tests ensuring identical artifacts across replicas for identical content/config.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.14 — FrankenSQLite Deep-Mined Expansion Execution Track (9J)\n\nWhy This Exists:\nFrankenSQLite deep-mined control integrity track: evidence ledgers, proofs, epochs, remote effects, markers/MMR, and deterministic fault labs.\n\nTask Objective:\nAdd determinism conformance tests ensuring identical artifacts across replicas for identical content/config.\n\nAcceptance Criteria:\n- Multi-replica fixture run yields byte-identical artifact sets; divergence test reports first mismatch and root cause; tests run in CI.\n\nExpected Artifacts:\n- `tests/conformance/replica_artifact_determinism.rs`, `fixtures/determinism/*`, `artifacts/10.14/determinism_conformance_results.csv`.\n\n- Machine-readable verification artifact at `artifacts/section_10_14/bd-1iyx/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_14/bd-1iyx/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.14] Add determinism conformance tests ensuring identical artifacts across replicas for identical content/config.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.14] Add determinism conformance tests ensuring identical artifacts across replicas for identical content/config.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.14] Add determinism conformance tests ensuring identical artifacts across replicas for identical content/config.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.14] Add determinism conformance tests ensuring identical artifacts across replicas for identical content/config.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.14] Add determinism conformance tests ensuring identical artifacts across replicas for identical content/config.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"Multi-replica fixture run yields byte-identical artifact sets; divergence test reports first mismatch and root cause; tests run in CI.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:36:56.970468633Z","created_by":"ubuntu","updated_at":"2026-02-20T15:44:07.992451145Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-14","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-1iyx","depends_on_id":"bd-29r6","type":"blocks","created_at":"2026-02-20T07:43:15.147930610Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-1j2","title":"[10.1] Enforce repository split contract checks in CI.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.1 — Charter + Split Governance\n\nWhy This Exists:\nProgram charter and governance baseline: split contracts, reproducibility, and anti-regression rules for strategic integrity.\n\nTask Objective:\nEnforce repository split contract checks in CI.\n\nAcceptance Criteria:\n- Implement with explicit success/failure invariants and deterministic behavior under normal, edge, and fault scenarios.\n- Ensure outcomes are verifiable via automated tests and reproducible artifact outputs.\n\nExpected Artifacts:\n- Section-owned design/spec artifact at `docs/specs/section_10_1/bd-1j2_contract.md`, capturing decision rationale, invariants, and interface boundaries.\n- Machine-readable verification artifact at `artifacts/section_10_1/bd-1j2/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_1/bd-1j2/verification_summary.md` linking implementation intent to measured outcomes.\n\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.1] Enforce repository split contract checks in CI.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.1] Enforce repository split contract checks in CI.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.1] Enforce repository split contract checks in CI.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.1] Enforce repository split contract checks in CI.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.1] Enforce repository split contract checks in CI.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","status":"closed","priority":1,"issue_type":"task","assignee":"CrimsonCrane","created_at":"2026-02-20T07:36:43.368738359Z","created_by":"ubuntu","updated_at":"2026-02-20T09:06:34.403407547Z","closed_at":"2026-02-20T09:06:34.403381529Z","close_reason":"Split contract CI enforcement implemented. 4 checks (no-local-crates, path-deps, no-internals, governance-docs) all PASS. 8 unit tests all pass. Spec document, enforcement script, and verification artifacts created.","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-1","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-1j2","depends_on_id":"bd-vjq","type":"blocks","created_at":"2026-02-20T07:43:10.574942355Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-1jjq","title":"[10.10] Section-wide verification gate: comprehensive unit+e2e+logging","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.10\n\nTask Objective:\nCreate a hard section completion gate that verifies all implemented behavior in this section with comprehensive unit tests, integration/e2e scripts, and detailed structured logging evidence.\n\nAcceptance Criteria:\n- Section test matrix covers happy-path, edge-case, and adversarial/error-path scenarios for all section deliverables.\n- E2E scripts execute representative end-user workflows and policy/control-plane transitions for this section.\n- Structured logs include stable event/error codes, trace correlation IDs, and enough context for deterministic replay triage.\n- Verification report is deterministic and machine-readable for CI/release gating.\n\nExpected Artifacts:\n- Section-level test matrix and coverage summary artifact.\n- E2E script suite with pass/fail outputs and reproducible fixtures/seeds.\n- Structured log validation report and traceability bundle.\n- Gate verdict artifact consumable by release automation.\n\n- Machine-readable verification artifact at `artifacts/section_10_10/bd-1jjq/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_10/bd-1jjq/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests must validate contracts, invariants, and failure semantics.\n- E2E tests must validate cross-component behavior from user/operator entrypoints to persisted effects.\n- Logging must support root-cause analysis without hidden context requirements.\n\nTask-Specific Clarification:\n- For \"[10.10] Section-wide verification gate: comprehensive unit+e2e+logging\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.10] Section-wide verification gate: comprehensive unit+e2e+logging\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.10] Section-wide verification gate: comprehensive unit+e2e+logging\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.10] Section-wide verification gate: comprehensive unit+e2e+logging\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.10] Section-wide verification gate: comprehensive unit+e2e+logging\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:48:06.665766167Z","created_by":"ubuntu","updated_at":"2026-02-20T08:43:53.090758918Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-10","test-obligations","verification-gate"],"dependencies":[{"issue_id":"bd-1jjq","depends_on_id":"bd-13q","type":"blocks","created_at":"2026-02-20T07:48:06.812416049Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1jjq","depends_on_id":"bd-174","type":"blocks","created_at":"2026-02-20T07:48:07.147997446Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1jjq","depends_on_id":"bd-1dpd","type":"blocks","created_at":"2026-02-20T08:24:27.097219827Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1jjq","depends_on_id":"bd-1hd","type":"blocks","created_at":"2026-02-20T07:48:06.764993302Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1jjq","depends_on_id":"bd-1l5","type":"blocks","created_at":"2026-02-20T07:48:07.242258071Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1jjq","depends_on_id":"bd-1r2","type":"blocks","created_at":"2026-02-20T07:48:07.050557169Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1jjq","depends_on_id":"bd-1vp","type":"blocks","created_at":"2026-02-20T07:48:06.859933272Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1jjq","depends_on_id":"bd-2ms","type":"blocks","created_at":"2026-02-20T07:48:07.098143731Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1jjq","depends_on_id":"bd-2sx","type":"blocks","created_at":"2026-02-20T07:48:06.906505546Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1jjq","depends_on_id":"bd-2twu","type":"blocks","created_at":"2026-02-20T08:20:53.088912456Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1jjq","depends_on_id":"bd-364","type":"blocks","created_at":"2026-02-20T07:48:07.002927075Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1jjq","depends_on_id":"bd-jjm","type":"blocks","created_at":"2026-02-20T07:48:07.195302414Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1jjq","depends_on_id":"bd-oty","type":"blocks","created_at":"2026-02-20T07:48:06.954404720Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-1jmq","title":"[11] Contract field: EV score and tier","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 11\n\nTask Objective:\nRequire EV scoring metadata and tier classification for each major subsystem change.\n\nExecution Requirements:\n- Make this requirement machine-verifiable and release-gated where applicable.\n- Keep behavior self-documenting so future contributors do not need to re-open the master plan.\n\nTesting & Logging Requirements:\n- Unit tests for rule/contract logic and error conditions.\n- Integration/E2E tests for workflow-level enforcement.\n- Structured logs with stable codes and trace IDs.\n- Reproducible artifacts that prove contract satisfaction.\n\nAcceptance Criteria:\n- Success and failure invariants for [11] Contract field: EV score and tier are explicitly quantified and machine-verifiable.\n- Determinism requirements for [11] Contract field: EV score and tier are validated across repeated runs and adversarial perturbations.\n\n\nExpected Artifacts:\n- Machine-readable verification artifact with explicit canonical path under artifacts/section_11/bd-1jmq/verification_evidence.json, suitable for CI/release gating.\n- Human-readable verification summary with explicit canonical path under artifacts/section_11/bd-1jmq/verification_summary.md, linking implementation intent to measured validation outcomes.\n\nTask-Specific Clarification:\n- The implementation must deliver the exact capability named in the title, with no scope dilution and no silent feature omission.\n- Validation artifacts must include capability-specific thresholds, pass/fail criteria, and reproducible evidence bundles tied to this bead ID.\n- Program/section verification gates must be able to consume this bead's outputs without manual interpretation.\n\nWhy This Improves User Outcomes:\n- \"[11] Contract field: EV score and tier\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[11] Contract field: EV score and tier\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"1. Every evidence contract includes an EV-score field computed as: EV = P(success) * benefit - P(failure) * cost, with explicit numeric values for each term.\n2. Tier classification follows: Tier-1 (EV >= 10, critical path), Tier-2 (EV >= 1, important), Tier-3 (EV < 1, nice-to-have).\n3. The EV calculation references concrete data: measured test pass rates, estimated blast radius, historical incident cost.\n4. CI rejects contracts where EV score is missing, non-numeric, or tier is inconsistent with the computed EV value.\n5. Unit test: contracts with correct EV and tier pass; contracts with mismatched tier/EV or missing fields fail validation.\n6. A helper script or library function exists to compute EV from input parameters and assign tier automatically.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:39:32.649250887Z","created_by":"ubuntu","updated_at":"2026-02-20T15:16:05.695603050Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-11","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-1jmq","depends_on_id":"bd-36wa","type":"blocks","created_at":"2026-02-20T07:43:24.372861472Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-1jpc","title":"[10.21] Implement unified evolution-risk scorer with explainability contract and confidence decomposition.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.21 — Behavioral Phenotype Evolution Tracker Execution Track (9O)\n\nWhy This Exists:\nBPET longitudinal phenotype intelligence track for pre-compromise trajectory detection and integration with DGIS/ATC/migration/economic policy.\n\nTask Objective:\nImplement unified evolution-risk scorer with explainability contract and confidence decomposition.\n\nAcceptance Criteria:\n- Scorer combines drift, regime, hazard, and provenance features under a documented weighting policy; output includes stable explanation vectors and confidence intervals.\n\nExpected Artifacts:\n- `src/security/bpet/evolution_risk_scorer.rs`, `tests/conformance/bpet_risk_score_explainability.rs`, `artifacts/10.21/bpet_risk_score_catalog.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_21/bd-1jpc/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_21/bd-1jpc/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.21] Implement unified evolution-risk scorer with explainability contract and confidence decomposition.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.21] Implement unified evolution-risk scorer with explainability contract and confidence decomposition.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.21] Implement unified evolution-risk scorer with explainability contract and confidence decomposition.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.21] Implement unified evolution-risk scorer with explainability contract and confidence decomposition.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.21] Implement unified evolution-risk scorer with explainability contract and confidence decomposition.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- Scorer combines drift, regime, hazard, and provenance features under a documented weighting policy; output includes stable explanation vectors and confidence intervals.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:37:08.291306712Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:18.535436469Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-21","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-1jpc","depends_on_id":"bd-1b9x","type":"blocks","created_at":"2026-02-20T07:43:21.563993846Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-1jpo","title":"[10.11] Section-wide verification gate: comprehensive unit+e2e+logging","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.11\n\nTask Objective:\nCreate a hard section completion gate that verifies all implemented behavior in this section with comprehensive unit tests, integration/e2e scripts, and detailed structured logging evidence.\n\nAcceptance Criteria:\n- Section test matrix covers happy-path, edge-case, and adversarial/error-path scenarios for all section deliverables.\n- E2E scripts execute representative end-user workflows and policy/control-plane transitions for this section.\n- Structured logs include stable event/error codes, trace correlation IDs, and enough context for deterministic replay triage.\n- Verification report is deterministic and machine-readable for CI/release gating.\n\nExpected Artifacts:\n- Section-level test matrix and coverage summary artifact.\n- E2E script suite with pass/fail outputs and reproducible fixtures/seeds.\n- Structured log validation report and traceability bundle.\n- Gate verdict artifact consumable by release automation.\n\n- Machine-readable verification artifact at `artifacts/section_10_11/bd-1jpo/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_11/bd-1jpo/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests must validate contracts, invariants, and failure semantics.\n- E2E tests must validate cross-component behavior from user/operator entrypoints to persisted effects.\n- Logging must support root-cause analysis without hidden context requirements.\n\nTask-Specific Clarification:\n- For \"[10.11] Section-wide verification gate: comprehensive unit+e2e+logging\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.11] Section-wide verification gate: comprehensive unit+e2e+logging\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.11] Section-wide verification gate: comprehensive unit+e2e+logging\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.11] Section-wide verification gate: comprehensive unit+e2e+logging\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.11] Section-wide verification gate: comprehensive unit+e2e+logging\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"AC for bd-1jpo (Section 10.11 Verification Gate):\n1. A section-level test matrix covers every 10.11 deliverable (bd-cvt through bd-390) with happy-path, edge-case, and adversarial/error-path scenarios; the matrix is encoded as a machine-readable JSON mapping bead_id -> [test_ids].\n2. E2E scripts exercise representative cross-cutting workflows: (a) full lifecycle from capability profile definition through anti-entropy convergence, (b) cancellation cascade through supervision tree with epoch transition mid-drain, (c) saga compensation under regime-change budget boost.\n3. The test suite runs under the DeterministicRuntime (bd-2ko) with fixed seeds; CI runs each scenario twice and diffs outputs to verify bit-for-bit reproducibility.\n4. Structured log validation: a log-schema checker verifies that every stable event code defined across all 10.11 beads (CAPABILITY_*, AMBIENT_*, CHECKPOINT_*, CANCEL_*, MASK_*, OBLIGATION_*, CHILD_*, SCENARIO_*, BOCPD_*, VOI_*, EPOCH_*, IDEMPOTENCY_*, SAGA_*, LANE_*, BULKHEAD_*, RECONCILIATION_*) appears in at least one test trace and conforms to the declared schema.\n5. Coverage report: all Rust modules under the 10.11 scope achieve >= 80% line coverage; any module below threshold blocks the gate with COVERAGE_BELOW_THRESHOLD.\n6. Gate verdict artifact at artifacts/section_10_11/bd-1jpo/verification_evidence.json encodes: per-bead pass/fail, coverage percentages, reproducibility check result, and log-schema conformance result.\n7. The gate returns exit code 0 only when all sub-checks pass; any failure returns exit code 1 with a structured summary of which checks failed and why.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:48:07.460302460Z","created_by":"ubuntu","updated_at":"2026-02-20T15:19:56.354902072Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-11","test-obligations","verification-gate"],"dependencies":[{"issue_id":"bd-1jpo","depends_on_id":"bd-1dpd","type":"blocks","created_at":"2026-02-20T08:24:26.954868176Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1jpo","depends_on_id":"bd-24k","type":"blocks","created_at":"2026-02-20T07:48:08.001172427Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1jpo","depends_on_id":"bd-2ah","type":"blocks","created_at":"2026-02-20T07:48:07.946131581Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1jpo","depends_on_id":"bd-2gr","type":"blocks","created_at":"2026-02-20T07:48:07.702066458Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1jpo","depends_on_id":"bd-2ko","type":"blocks","created_at":"2026-02-20T07:48:07.847142629Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1jpo","depends_on_id":"bd-2nt","type":"blocks","created_at":"2026-02-20T07:48:07.752435112Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1jpo","depends_on_id":"bd-2twu","type":"blocks","created_at":"2026-02-20T08:20:52.923905878Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1jpo","depends_on_id":"bd-390","type":"blocks","created_at":"2026-02-20T07:48:07.561848996Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1jpo","depends_on_id":"bd-3he","type":"blocks","created_at":"2026-02-20T07:48:07.894550930Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1jpo","depends_on_id":"bd-3hw","type":"blocks","created_at":"2026-02-20T07:48:07.655763125Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1jpo","depends_on_id":"bd-3u4","type":"blocks","created_at":"2026-02-20T07:48:07.799758374Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1jpo","depends_on_id":"bd-3vm","type":"blocks","created_at":"2026-02-20T07:48:08.145815102Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1jpo","depends_on_id":"bd-7om","type":"blocks","created_at":"2026-02-20T07:48:08.051212930Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1jpo","depends_on_id":"bd-93k","type":"blocks","created_at":"2026-02-20T07:48:08.097099947Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1jpo","depends_on_id":"bd-cvt","type":"blocks","created_at":"2026-02-20T07:48:08.193048396Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1jpo","depends_on_id":"bd-lus","type":"blocks","created_at":"2026-02-20T07:48:07.609422944Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-1kfq","title":"[10.9] Section-wide verification gate: comprehensive unit+e2e+logging","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.9\n\nTask Objective:\nCreate a hard section completion gate that verifies all implemented behavior in this section with comprehensive unit tests, integration/e2e scripts, and detailed structured logging evidence.\n\nAcceptance Criteria:\n- Section test matrix covers happy-path, edge-case, and adversarial/error-path scenarios for all section deliverables.\n- E2E scripts execute representative end-user workflows and policy/control-plane transitions for this section.\n- Structured logs include stable event/error codes, trace correlation IDs, and enough context for deterministic replay triage.\n- Verification report is deterministic and machine-readable for CI/release gating.\n\nExpected Artifacts:\n- Section-level test matrix and coverage summary artifact.\n- E2E script suite with pass/fail outputs and reproducible fixtures/seeds.\n- Structured log validation report and traceability bundle.\n- Gate verdict artifact consumable by release automation.\n\n- Machine-readable verification artifact at `artifacts/section_10_9/bd-1kfq/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_9/bd-1kfq/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests must validate contracts, invariants, and failure semantics.\n- E2E tests must validate cross-component behavior from user/operator entrypoints to persisted effects.\n- Logging must support root-cause analysis without hidden context requirements.\n\nTask-Specific Clarification:\n- For \"[10.9] Section-wide verification gate: comprehensive unit+e2e+logging\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.9] Section-wide verification gate: comprehensive unit+e2e+logging\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.9] Section-wide verification gate: comprehensive unit+e2e+logging\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.9] Section-wide verification gate: comprehensive unit+e2e+logging\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.9] Section-wide verification gate: comprehensive unit+e2e+logging\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"1. Section 10.9 gate aggregates pass/fail status from all sibling beads (bd-f5d, bd-9is, bd-1e0, bd-m8p, bd-10c, bd-15t).\n2. Gate script (scripts/check_section_10_9_gate.py) runs all section verification scripts and produces a unified JSON report.\n3. Gate fails if any sibling bead's verification evidence is missing or shows a failure.\n4. Unit tests cover gate logic: all-pass, single-fail, and missing-evidence scenarios.\n5. Gate produces a section-level summary under artifacts/ with per-bead status, timestamps, and links to individual evidence files.\n6. E2E logging: gate execution emits structured log lines for each sub-check with bead ID, result, and duration.\n7. Gate is idempotent: running it twice in succession with no changes produces identical output.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:48:26.577180281Z","created_by":"ubuntu","updated_at":"2026-02-20T15:20:50.794139233Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-9","test-obligations","verification-gate"],"dependencies":[{"issue_id":"bd-1kfq","depends_on_id":"bd-10c","type":"blocks","created_at":"2026-02-20T07:48:26.722244440Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1kfq","depends_on_id":"bd-15t","type":"blocks","created_at":"2026-02-20T07:48:26.674981871Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1kfq","depends_on_id":"bd-1dpd","type":"blocks","created_at":"2026-02-20T08:24:24.451624955Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1kfq","depends_on_id":"bd-1e0","type":"blocks","created_at":"2026-02-20T07:48:26.816221738Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1kfq","depends_on_id":"bd-2twu","type":"blocks","created_at":"2026-02-20T08:20:49.965117653Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1kfq","depends_on_id":"bd-9is","type":"blocks","created_at":"2026-02-20T07:48:26.862838044Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1kfq","depends_on_id":"bd-f5d","type":"blocks","created_at":"2026-02-20T07:48:26.909731235Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1kfq","depends_on_id":"bd-m8p","type":"blocks","created_at":"2026-02-20T07:48:26.769135107Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-1koz","title":"[10.5] Section-wide verification gate: comprehensive unit+e2e+logging","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.5\n\nTask Objective:\nCreate a hard section completion gate that verifies all implemented behavior in this section with comprehensive unit tests, integration/e2e scripts, and detailed structured logging evidence.\n\nAcceptance Criteria:\n- Section test matrix covers happy-path, edge-case, and adversarial/error-path scenarios for all section deliverables.\n- E2E scripts execute representative end-user workflows and policy/control-plane transitions for this section.\n- Structured logs include stable event/error codes, trace correlation IDs, and enough context for deterministic replay triage.\n- Verification report is deterministic and machine-readable for CI/release gating.\n\nExpected Artifacts:\n- Section-level test matrix and coverage summary artifact.\n- E2E script suite with pass/fail outputs and reproducible fixtures/seeds.\n- Structured log validation report and traceability bundle.\n- Gate verdict artifact consumable by release automation.\n\n- Machine-readable verification artifact at `artifacts/section_10_5/bd-1koz/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_5/bd-1koz/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests must validate contracts, invariants, and failure semantics.\n- E2E tests must validate cross-component behavior from user/operator entrypoints to persisted effects.\n- Logging must support root-cause analysis without hidden context requirements.\n\nTask-Specific Clarification:\n- For \"[10.5] Section-wide verification gate: comprehensive unit+e2e+logging\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.5] Section-wide verification gate: comprehensive unit+e2e+logging\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.5] Section-wide verification gate: comprehensive unit+e2e+logging\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.5] Section-wide verification gate: comprehensive unit+e2e+logging\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.5] Section-wide verification gate: comprehensive unit+e2e+logging\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"1. All eight 10.5 implementation beads (bd-137, bd-21z, bd-vll, bd-2fa, bd-2yc, bd-33b, bd-3nr, bd-sh3) must be closed with passing verification evidence before this gate can close.\n2. Every verification script (check_policy_gate, check_signed_receipt, check_replay_bundle, check_counterfactual, check_copilot_api, check_loss_scoring, check_degraded_mode, check_policy_approval) must pass with --json flag and produce valid JSON output with no failures.\n3. All unit test files (tests/test_check_*.py for each of the eight beads) must pass under pytest with zero failures and zero errors.\n4. Integration coverage: at least one end-to-end scenario must chain policy gate evaluation (bd-137) -> signed receipt generation (bd-21z) -> replay bundle inclusion (bd-vll) -> counterfactual replay (bd-2fa), proving the four components compose correctly.\n5. All structured log events (tracing spans) from gate evaluations, receipt signing, degraded mode, and policy approvals must conform to a shared LogEventSchema with required fields: timestamp, event_type, component, and correlation_id.\n6. Evidence artifacts for all eight beads must exist under artifacts/section_10_5/ with both verification_evidence.json and verification_summary.md files present and non-empty.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:48:24.123275190Z","created_by":"ubuntu","updated_at":"2026-02-20T15:16:35.649350840Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-5","test-obligations","verification-gate"],"dependencies":[{"issue_id":"bd-1koz","depends_on_id":"bd-137","type":"blocks","created_at":"2026-02-20T07:48:24.565477706Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1koz","depends_on_id":"bd-1dpd","type":"blocks","created_at":"2026-02-20T08:24:25.016750352Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1koz","depends_on_id":"bd-21z","type":"blocks","created_at":"2026-02-20T07:48:24.518405732Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1koz","depends_on_id":"bd-2fa","type":"blocks","created_at":"2026-02-20T07:48:24.419370113Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1koz","depends_on_id":"bd-2twu","type":"blocks","created_at":"2026-02-20T08:20:50.628953105Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1koz","depends_on_id":"bd-2yc","type":"blocks","created_at":"2026-02-20T07:48:24.371651485Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1koz","depends_on_id":"bd-33b","type":"blocks","created_at":"2026-02-20T07:48:24.320815871Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1koz","depends_on_id":"bd-3nr","type":"blocks","created_at":"2026-02-20T07:48:24.271693007Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1koz","depends_on_id":"bd-sh3","type":"blocks","created_at":"2026-02-20T07:48:24.223879361Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1koz","depends_on_id":"bd-vll","type":"blocks","created_at":"2026-02-20T07:48:24.467720098Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-1l5","title":"[10.10] Define canonical product trust object IDs with domain separation.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.10 — FCP-Inspired Hardening + Interop Integration Track\n\nWhy This Exists:\nFCP-inspired hardening/interop contract for IDs, serialization, control-channel auth, revocation freshness, and publication gating.\n\nTask Objective:\nDefine canonical product trust object IDs with domain separation.\n\nAcceptance Criteria:\n- Implement with explicit success/failure invariants and deterministic behavior under normal, edge, and fault scenarios.\n- Ensure outcomes are verifiable via automated tests and reproducible artifact outputs.\n\nExpected Artifacts:\n- Section-owned design/spec artifact at `docs/specs/section_10_10/bd-1l5_contract.md`, capturing decision rationale, invariants, and interface boundaries.\n- Machine-readable verification artifact at `artifacts/section_10_10/bd-1l5/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_10/bd-1l5/verification_summary.md` linking implementation intent to measured outcomes.\n\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.10] Define canonical product trust object IDs with domain separation.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.10] Define canonical product trust object IDs with domain separation.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.10] Define canonical product trust object IDs with domain separation.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.10] Define canonical product trust object IDs with domain separation.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.10] Define canonical product trust object IDs with domain separation.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"1. Define a TrustObjectId type containing: (a) a 4-byte domain tag drawn from an enum of canonical domains (POLICY, TOKEN, KEY, SESSION, ZONE, RELEASE, REVOCATION, MARKER), (b) a 16-byte random component, (c) a 4-byte version field. Total fixed size = 24 bytes.\n2. Implement TrustObjectId::new(domain) that generates a cryptographically random ID with the correct domain tag and version=1.\n3. Implement TrustObjectId::parse(bytes) that validates the domain tag against the canonical enum and rejects unknown domains with a typed error (UnknownDomain).\n4. Enforce domain separation: two IDs with identical random bytes but different domain tags MUST NOT compare as equal. Equality requires all three fields to match.\n5. Implement Display and FromStr for a human-readable form: `{DOMAIN}-{hex(random)}-v{version}` (e.g., `POLICY-a1b2c3...f0-v1`).\n6. Provide a `domain()` accessor returning the enum variant, and a `is_domain(expected)` predicate.\n7. Reject construction or parsing of zero-filled random components (all zeros) as invalid.\n8. Unit tests: (a) round-trip serialize/parse for every domain tag, (b) cross-domain inequality, (c) zero-rejection, (d) unknown-domain rejection, (e) Display/FromStr round-trip.\n9. Golden fixture: generate one canonical ID per domain, store as JSON in vectors/trust_object_ids.json, and verify parse stability across builds.\n10. Verification script scripts/check_trust_object_ids.py emits pass/fail JSON to artifacts/section_10_10/bd-1l5/verification_evidence.json.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:36:48.759819874Z","created_by":"ubuntu","updated_at":"2026-02-20T15:35:57.081601253Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-10","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-1l5","depends_on_id":"bd-1ta","type":"blocks","created_at":"2026-02-20T07:46:31.225935104Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1l5","depends_on_id":"bd-5rh","type":"blocks","created_at":"2026-02-20T07:46:31.287396287Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1l5","depends_on_id":"bd-cda","type":"blocks","created_at":"2026-02-20T07:46:31.342269640Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-1l62","title":"[10.14] Gate durable-claiming operations on verifiable marker/proof availability.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.14 — FrankenSQLite Deep-Mined Expansion Execution Track (9J)\n\nWhy This Exists:\nFrankenSQLite deep-mined control integrity track: evidence ledgers, proofs, epochs, remote effects, markers/MMR, and deterministic fault labs.\n\nTask Objective:\nGate durable-claiming operations on verifiable marker/proof availability.\n\nAcceptance Criteria:\n- Durable claims fail closed when marker/proof verification is incomplete; claim API exposes reason codes; false-claim path is blocked in tests.\n\nExpected Artifacts:\n- `tests/security/durable_claim_gate.rs`, `docs/specs/durable_claim_requirements.md`, `artifacts/10.14/durable_claim_gate_results.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_14/bd-1l62/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_14/bd-1l62/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.14] Gate durable-claiming operations on verifiable marker/proof availability.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.14] Gate durable-claiming operations on verifiable marker/proof availability.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.14] Gate durable-claiming operations on verifiable marker/proof availability.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.14] Gate durable-claiming operations on verifiable marker/proof availability.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.14] Gate durable-claiming operations on verifiable marker/proof availability.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"Durable claims fail closed when marker/proof verification is incomplete; claim API exposes reason codes; false-claim path is blocked in tests.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:36:56.544196093Z","created_by":"ubuntu","updated_at":"2026-02-20T15:44:09.057126625Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-14","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-1l62","depends_on_id":"bd-b9b6","type":"blocks","created_at":"2026-02-20T07:43:14.936213934Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-1m7","title":"Add transplant re-sync and drift detection workflow","description":"Add repeatable process/script/docs to re-sync from pi_agent_rust and detect inventory/hash drift.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-20T07:26:05.443350039Z","created_by":"ubuntu","updated_at":"2026-02-20T07:27:13.152239970Z","closed_at":"2026-02-20T07:27:13.152217177Z","close_reason":"Duplicate scope; superseded by bd-29q","source_repo":".","compaction_level":0,"original_size":0,"dependencies":[{"issue_id":"bd-1m7","depends_on_id":"bd-1qz","type":"blocks","created_at":"2026-02-20T07:26:09.673595026Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1m7","depends_on_id":"bd-2zl","type":"blocks","created_at":"2026-02-20T07:26:09.739001938Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-1m8r","title":"[10.13] Enforce revocation freshness per safety tier before risky and dangerous actions.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.13 — FCP Deep-Mined Expansion Execution Track (9I)\n\nWhy This Exists:\nDeep connector/provider contract track: lifecycle FSMs, conformance harnesses, fencing, sandboxing, revocation freshness, and protocol hardening.\n\nTask Objective:\nEnforce revocation freshness per safety tier before risky and dangerous actions.\n\nAcceptance Criteria:\n- Safety-tier gate denies stale-frontier risky/dangerous actions; override behavior follows policy and is receipt-backed; gate latency meets SLO.\n\nExpected Artifacts:\n- `tests/security/revocation_freshness_gate.rs`, `docs/specs/safety_tier_freshness.md`, `artifacts/10.13/revocation_freshness_decisions.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_13/bd-1m8r/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_13/bd-1m8r/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.13] Enforce revocation freshness per safety tier before risky and dangerous actions.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.13] Enforce revocation freshness per safety tier before risky and dangerous actions.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.13] Enforce revocation freshness per safety tier before risky and dangerous actions.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.13] Enforce revocation freshness per safety tier before risky and dangerous actions.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.13] Enforce revocation freshness per safety tier before risky and dangerous actions.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","status":"closed","priority":1,"issue_type":"task","assignee":"CrimsonCrane","created_at":"2026-02-20T07:36:53.111923915Z","created_by":"ubuntu","updated_at":"2026-02-20T12:03:50.587386394Z","closed_at":"2026-02-20T12:03:50.587354675Z","close_reason":"done","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-13","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-1m8r","depends_on_id":"bd-y7lu","type":"blocks","created_at":"2026-02-20T07:43:13.137488665Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-1mj","title":"[10.1] Add claim-language policy requiring verifier artifacts for external claims.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.1 — Charter + Split Governance\n\nWhy This Exists:\nProgram charter and governance baseline: split contracts, reproducibility, and anti-regression rules for strategic integrity.\n\nTask Objective:\nAdd claim-language policy requiring verifier artifacts for external claims.\n\nAcceptance Criteria:\n- Implement with explicit success/failure invariants and deterministic behavior under normal, edge, and fault scenarios.\n- Ensure outcomes are verifiable via automated tests and reproducible artifact outputs.\n\nExpected Artifacts:\n- Section-owned design/spec artifact at `docs/specs/section_10_1/bd-1mj_contract.md`, capturing decision rationale, invariants, and interface boundaries.\n- Machine-readable verification artifact at `artifacts/section_10_1/bd-1mj/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_1/bd-1mj/verification_summary.md` linking implementation intent to measured outcomes.\n\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.1] Add claim-language policy requiring verifier artifacts for external claims.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.1] Add claim-language policy requiring verifier artifacts for external claims.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.1] Add claim-language policy requiring verifier artifacts for external claims.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.1] Add claim-language policy requiring verifier artifacts for external claims.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.1] Add claim-language policy requiring verifier artifacts for external claims.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","status":"closed","priority":1,"issue_type":"task","assignee":"CrimsonCrane","created_at":"2026-02-20T07:36:43.603346339Z","created_by":"ubuntu","updated_at":"2026-02-20T09:20:59.077852855Z","closed_at":"2026-02-20T09:20:59.077814303Z","close_reason":"done","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-1","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-1mj","depends_on_id":"bd-4yv","type":"blocks","created_at":"2026-02-20T07:43:10.702211510Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-1n1t","title":"[12] Risk control: topology blind spots","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 12\n\nTask Objective:\nEnforce mandatory graph coverage, topology baselines, and unresolved-edge escalation.\n\nExecution Requirements:\n- Make this requirement machine-verifiable and release-gated where applicable.\n- Keep behavior self-documenting so future contributors do not need to re-open the master plan.\n\nTesting & Logging Requirements:\n- Unit tests for rule/contract logic and error conditions.\n- Integration/E2E tests for workflow-level enforcement.\n- Structured logs with stable codes and trace IDs.\n- Reproducible artifacts that prove contract satisfaction.\n\nAcceptance Criteria:\n- Success and failure invariants for [12] Risk control: topology blind spots are explicitly quantified and machine-verifiable.\n- Determinism requirements for [12] Risk control: topology blind spots are validated across repeated runs and adversarial perturbations.\n\n\nExpected Artifacts:\n- Machine-readable verification artifact with explicit canonical path under artifacts/section_12/bd-1n1t/verification_evidence.json, suitable for CI/release gating.\n- Human-readable verification summary with explicit canonical path under artifacts/section_12/bd-1n1t/verification_summary.md, linking implementation intent to measured validation outcomes.\n\nTask-Specific Clarification:\n- The implementation must deliver the exact capability named in the title, with no scope dilution and no silent feature omission.\n- Validation artifacts must include capability-specific thresholds, pass/fail criteria, and reproducible evidence bundles tied to this bead ID.\n- Program/section verification gates must be able to consume this bead's outputs without manual interpretation.\n\nWhy This Improves User Outcomes:\n- \"[12] Risk control: topology blind spots\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[12] Risk control: topology blind spots\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"RISK: Dependency topology blind spots — unknown or untracked dependency relationships create hidden attack surfaces and cascading failure paths.\nIMPACT: Supply-chain attacks via unmonitored transitive dependencies, cascading failures from topology choke-points, inability to assess blast radius.\nCOUNTERMEASURES:\n  (a) Mandatory graph ingestion: every build ingests the full dependency graph (direct + transitive) into a queryable data structure.\n  (b) Topology-metric baselines: key topology metrics (max depth, fan-out, centrality of critical nodes) are baselined and monitored for drift.\n  (c) Choke-point alerts: dependencies that appear in > 50% of dependency paths are flagged as choke-points with heightened review.\nVERIFICATION:\n  1. Dependency graph is generated on every build and includes all transitive dependencies (verified against cargo metadata or equivalent).\n  2. Topology metrics are computed: max depth, average fan-out, betweenness centrality of top-10 nodes.\n  3. Baselines exist for all topology metrics; drift > 20% from baseline triggers a review alert.\n  4. Choke-point detection correctly identifies dependencies used by > 50% of paths.\nTEST SCENARIOS:\n  - Scenario A: Add a new deep transitive dependency; verify graph ingestion captures it and depth metric increases.\n  - Scenario B: Introduce a dependency that becomes a choke-point (used by > 50% of paths); verify alert is triggered.\n  - Scenario C: Remove a choke-point dependency; verify topology metrics improve and alert clears.\n  - Scenario D: Verify graph ingestion handles cyclic dependencies gracefully (detects and reports them).","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:39:33.852996881Z","created_by":"ubuntu","updated_at":"2026-02-20T15:19:38.990028973Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-12","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-1n1t","depends_on_id":"bd-13yn","type":"blocks","created_at":"2026-02-20T07:43:25.041118773Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-1n5p","title":"[10.15] Replace critical ad hoc messaging with obligation-tracked two-phase channels.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.15 — Asupersync-First Integration Execution Track (8.4-8.6)\n\nWhy This Exists:\nAsupersync-first control-plane migration track enforcing Cx-first, region ownership, cancellation correctness, and protocol-grade verification gates.\n\nTask Objective:\nReplace critical ad hoc messaging with obligation-tracked two-phase channels.\n\nAcceptance Criteria:\n- Publish/revoke/quarantine/migration critical paths use reserve/commit semantics; leak oracle remains green under cancellation injection.\n\nExpected Artifacts:\n- `tests/security/obligation_tracked_channels.rs`, `docs/specs/two_phase_effects.md`, `artifacts/10.15/obligation_leak_oracle_report.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_15/bd-1n5p/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_15/bd-1n5p/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.15] Replace critical ad hoc messaging with obligation-tracked two-phase channels.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.15] Replace critical ad hoc messaging with obligation-tracked two-phase channels.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.15] Replace critical ad hoc messaging with obligation-tracked two-phase channels.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.15] Replace critical ad hoc messaging with obligation-tracked two-phase channels.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.15] Replace critical ad hoc messaging with obligation-tracked two-phase channels.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- Publish/revoke/quarantine/migration critical paths use reserve/commit semantics; leak oracle remains green under cancellation injection.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:36:59.972242209Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:52.833147166Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-15","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-1n5p","depends_on_id":"bd-1cs7","type":"blocks","created_at":"2026-02-20T07:43:16.712093174Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-1nab","title":"[12] Risk control: federated privacy leakage","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 12\n\nTask Objective:\nEnforce strict privacy budgets, secure aggregation, and verifier checks for federation outputs.\n\nExecution Requirements:\n- Make this requirement machine-verifiable and release-gated where applicable.\n- Keep behavior self-documenting so future contributors do not need to re-open the master plan.\n\nTesting & Logging Requirements:\n- Unit tests for rule/contract logic and error conditions.\n- Integration/E2E tests for workflow-level enforcement.\n- Structured logs with stable codes and trace IDs.\n- Reproducible artifacts that prove contract satisfaction.\n\nAcceptance Criteria:\n- Success and failure invariants for [12] Risk control: federated privacy leakage are explicitly quantified and machine-verifiable.\n- Determinism requirements for [12] Risk control: federated privacy leakage are validated across repeated runs and adversarial perturbations.\n\n\nExpected Artifacts:\n- Machine-readable verification artifact with explicit canonical path under artifacts/section_12/bd-1nab/verification_evidence.json, suitable for CI/release gating.\n- Human-readable verification summary with explicit canonical path under artifacts/section_12/bd-1nab/verification_summary.md, linking implementation intent to measured validation outcomes.\n\nTask-Specific Clarification:\n- The implementation must deliver the exact capability named in the title, with no scope dilution and no silent feature omission.\n- Validation artifacts must include capability-specific thresholds, pass/fail criteria, and reproducible evidence bundles tied to this bead ID.\n- Program/section verification gates must be able to consume this bead's outputs without manual interpretation.\n\nWhy This Improves User Outcomes:\n- \"[12] Risk control: federated privacy leakage\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[12] Risk control: federated privacy leakage\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"RISK: Federated privacy leakage — aggregated telemetry or federated learning signals inadvertently reveal individual node/user information.\nIMPACT: Privacy violations, regulatory non-compliance (GDPR/CCPA), loss of user trust, potential legal liability.\nCOUNTERMEASURES:\n  (a) Strict privacy budgets: each telemetry channel has a defined epsilon (differential privacy) budget; once exhausted, no more data is emitted.\n  (b) Secure aggregation: individual contributions are encrypted; only the aggregate is visible to the coordinator.\n  (c) External verifier checks: an independent verifier can audit that privacy budgets are respected without seeing raw data.\nVERIFICATION:\n  1. Every telemetry channel has a configured epsilon budget; default epsilon <= 1.0.\n  2. Privacy budget accounting is tested: after N emissions that exhaust the budget, the (N+1)th emission is blocked.\n  3. Secure aggregation protocol passes: individual contributions are not recoverable from aggregated output (tested with >= 10 participants).\n  4. External verifier API exists and can confirm budget compliance given only aggregate data and budget parameters.\nTEST SCENARIOS:\n  - Scenario A: Emit telemetry until epsilon budget is exhausted; verify subsequent emissions are blocked with clear error.\n  - Scenario B: Run secure aggregation with 10 participants; attempt to recover individual contribution from aggregate; verify failure.\n  - Scenario C: External verifier audits a fully-consumed budget; verify it correctly reports budget exhausted.\n  - Scenario D: Attempt to reset privacy budget without authorization; verify it is denied and logged.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:39:33.672761330Z","created_by":"ubuntu","updated_at":"2026-02-20T15:19:05.872443066Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-12","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-1nab","depends_on_id":"bd-2w4u","type":"blocks","created_at":"2026-02-20T07:43:24.951040084Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-1naf","title":"[10.21] Define BPET governance policy for thresholding, appeals, and evidence-backed override workflows.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.21 — Behavioral Phenotype Evolution Tracker Execution Track (9O)\n\nWhy This Exists:\nBPET longitudinal phenotype intelligence track for pre-compromise trajectory detection and integration with DGIS/ATC/migration/economic policy.\n\nTask Objective:\nDefine BPET governance policy for thresholding, appeals, and evidence-backed override workflows.\n\nAcceptance Criteria:\n- False-positive handling, human override, and appeal lifecycle are explicit, auditable, and bounded by safety constraints; every override emits signed rationale.\n\nExpected Artifacts:\n- `docs/policy/bpet_governance_policy.md`, `tests/policy/bpet_override_audit.rs`, `artifacts/10.21/bpet_governance_audit_log.jsonl`.\n\n- Machine-readable verification artifact at `artifacts/section_10_21/bd-1naf/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_21/bd-1naf/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.21] Define BPET governance policy for thresholding, appeals, and evidence-backed override workflows.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.21] Define BPET governance policy for thresholding, appeals, and evidence-backed override workflows.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.21] Define BPET governance policy for thresholding, appeals, and evidence-backed override workflows.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.21] Define BPET governance policy for thresholding, appeals, and evidence-backed override workflows.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.21] Define BPET governance policy for thresholding, appeals, and evidence-backed override workflows.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- False-positive handling, human override, and appeal lifecycle are explicit, auditable, and bounded by safety constraints; every override emits signed rationale.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:37:08.878626130Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:18.759758707Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-21","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-1naf","depends_on_id":"bd-ye4m","type":"blocks","created_at":"2026-02-20T07:43:21.907221026Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-1neb","title":"[10.N] Section-wide verification gate: comprehensive unit+e2e+logging","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.N\n\nTask Objective:\nCreate a hard section completion gate that verifies all implemented behavior in this section with comprehensive unit tests, integration/e2e scripts, and detailed structured logging evidence.\n\nAcceptance Criteria:\n- Section test matrix covers happy-path, edge-case, and adversarial/error-path scenarios for all section deliverables.\n- E2E scripts execute representative end-user workflows and policy/control-plane transitions for this section.\n- Structured logs include stable event/error codes, trace correlation IDs, and enough context for deterministic replay triage.\n- Verification report is deterministic and machine-readable for CI/release gating.\n\nExpected Artifacts:\n- Section-level test matrix and coverage summary artifact.\n- E2E script suite with pass/fail outputs and reproducible fixtures/seeds.\n- Structured log validation report and traceability bundle.\n- Gate verdict artifact consumable by release automation.\n\nTesting & Logging Requirements:\n- Unit tests must validate contracts, invariants, and failure semantics.\n- E2E tests must validate cross-component behavior from user/operator entrypoints to persisted effects.\n- Logging must support root-cause analysis without hidden context requirements.\n\nTask-Specific Clarification:\n- For \"[10.N] Section-wide verification gate: comprehensive unit+e2e+logging\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.N] Section-wide verification gate: comprehensive unit+e2e+logging\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.N] Section-wide verification gate: comprehensive unit+e2e+logging\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.N] Section-wide verification gate: comprehensive unit+e2e+logging\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.N] Section-wide verification gate: comprehensive unit+e2e+logging\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","status":"closed","priority":1,"issue_type":"task","assignee":"ubuntu","created_at":"2026-02-20T07:48:27.123913150Z","created_by":"ubuntu","updated_at":"2026-02-20T08:41:08.718496708Z","closed_at":"2026-02-20T08:41:08.718407452Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-N","test-obligations","verification-gate"],"dependencies":[{"issue_id":"bd-1neb","depends_on_id":"bd-1dpd","type":"blocks","created_at":"2026-02-20T08:24:24.312939926Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1neb","depends_on_id":"bd-1oyt","type":"blocks","created_at":"2026-02-20T07:50:04.617165933Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1neb","depends_on_id":"bd-1v2c","type":"blocks","created_at":"2026-02-20T07:50:04.711756785Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1neb","depends_on_id":"bd-2twu","type":"blocks","created_at":"2026-02-20T08:20:49.800136753Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1neb","depends_on_id":"bd-2yhs","type":"blocks","created_at":"2026-02-20T07:50:04.495179795Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1neb","depends_on_id":"bd-zxk8","type":"blocks","created_at":"2026-02-20T07:50:04.399857520Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-1nf","title":"[10.0] Implement operator safety copilot.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.0 — Top 10 Initiative Tracking (Initiative #8)\nCross-references: 9A.8, 9B.8, 9C.8, 9D.8\n\nWhy This Exists:\nOperator safety copilot is the #8 strategic initiative. It offers live recommended actions with expected-loss rationale, confidence context, and deterministic rollback commands. This transforms security incident response from reactive guesswork into informed, evidence-backed decision-making.\n\nTask Objective:\nBuild the operator safety copilot that recommends actions during security incidents, trust decisions, and policy changes — each recommendation backed by expected-loss scoring, confidence intervals, and pre-computed rollback commands.\n\nDetailed Acceptance Criteria:\n1. Action recommendation API: given current state + incident context, returns ranked action list with expected-loss vectors.\n2. Each recommendation includes: action description, expected loss (quantified), confidence interval, uncertainty bands (9C.8), and deterministic rollback command.\n3. VOI-based ranking for recommendations so operator attention goes to highest expected impact actions (9B.8).\n4. Counterfactual replay mode: simulate what-if scenarios for policy changes before committing (10.5).\n5. Recommendation latency optimized for interactive operation budgets — sub-second response (9D.8).\n6. CLI surface: franken-node doctor with copilot recommendations, franken-node incident commands.\n7. Copilot integrates with trust cards (10.0.3), fleet quarantine (10.0.6), and economic trust layer (10.0.9).\n8. All copilot recommendations logged with signed decision receipts for audit trail.\n\nKey Dependencies:\n- Depends on 10.5 (Security + Policy) for expected-loss action scoring and decision receipt export.\n- Depends on trust cards (10.0.3) for extension risk context.\n- Depends on fleet quarantine (10.0.6) for containment action options.\n- Consumed by 10.8 (Operational Readiness) for operator runbooks.\n\nExpected Artifacts:\n- src/copilot/ module with recommendation_engine.rs, expected_loss.rs, rollback_commands.rs.\n- CLI integration for doctor and incident commands.\n- docs/specs/section_10_0/bd-1nf_contract.md\n- artifacts/section_10_0/bd-1nf/verification_evidence.json\n\nTesting and Logging Requirements:\n- Unit tests: action scoring, VOI ranking, rollback command generation, confidence interval computation.\n- Integration tests: copilot recommendation generation from mock incident + trust state.\n- E2E tests: franken-node doctor producing ranked recommendations, franken-node incident counterfactual simulating policy changes.\n- Performance tests: recommendation latency under various state sizes.\n- Structured logs: COPILOT_RECOMMENDATION_GENERATED, ACTION_SCORED, VOI_RANKED, ROLLBACK_COMPUTED, DECISION_RECEIPT_SIGNED with trace IDs.","acceptance_criteria":"1. Live recommended actions: copilot surfaces top-3 recommended actions ranked by expected-loss reduction; updates within <= 10 seconds of state change.\n2. Each recommendation includes: action description, expected-loss rationale (quantified in risk-units), confidence level (high/medium/low with percentage), deterministic rollback command.\n3. Rollback commands are executable: `franken-node copilot execute <recommendation-id>` runs the recommended action; `franken-node copilot rollback <recommendation-id>` deterministically reverses it.\n4. Expected-loss model: recommendations grounded in quantitative risk model considering: blast radius (affected nodes/workloads), severity (critical/high/medium/low), time-to-impact, and historical incident data.\n5. Confidence calibration: copilot confidence predictions are calibrated — actions labeled \"high confidence (>= 90%)\" succeed >= 90% of the time in validation suite.\n6. Safety guardrails: copilot never auto-executes actions above \"medium\" blast radius without operator confirmation; all actions logged before execution.\n7. Integration with quarantine system (bd-yqz): copilot recommends quarantine actions when anomaly detected; pre-computes blast-radius view for operator.\n8. Integration with economic trust layer (bd-2g0): recommendations incorporate privilege-risk pricing signals for cost-aware decision support.\n9. Audit trail: every recommendation (accepted/rejected/deferred), execution, and rollback logged with timestamp, operator identity, and outcome; append-only.\n10. Verification evidence includes: recommendation accuracy test (>= 80% of high-confidence recommendations validated as correct), rollback determinism test, latency measurement for recommendation generation.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:36:43.042426134Z","created_by":"ubuntu","updated_at":"2026-02-20T15:36:24.221629995Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-0","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-1nf","depends_on_id":"bd-2ac","type":"blocks","created_at":"2026-02-20T07:43:10.394615492Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-1nfu","title":"[10.14] Require `RemoteCap` (or equivalent) for all network-bound trust/control operations.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.14 — FrankenSQLite Deep-Mined Expansion Execution Track (9J)\n\nWhy This Exists:\nFrankenSQLite deep-mined control integrity track: evidence ledgers, proofs, epochs, remote effects, markers/MMR, and deterministic fault labs.\n\nTask Objective:\nRequire `RemoteCap` (or equivalent) for all network-bound trust/control operations.\n\nAcceptance Criteria:\n- Network-bound operations fail without capability token; capability checks are centralized and auditable; local-only mode remains functional.\n\nExpected Artifacts:\n- `tests/security/remote_cap_enforcement.rs`, `docs/specs/remote_cap_contract.md`, `artifacts/10.14/remote_cap_denials.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_14/bd-1nfu/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_14/bd-1nfu/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.14] Require `RemoteCap` (or equivalent) for all network-bound trust/control operations.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.14] Require `RemoteCap` (or equivalent) for all network-bound trust/control operations.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.14] Require `RemoteCap` (or equivalent) for all network-bound trust/control operations.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.14] Require `RemoteCap` (or equivalent) for all network-bound trust/control operations.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.14] Require `RemoteCap` (or equivalent) for all network-bound trust/control operations.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"Network-bound operations fail without capability token; capability checks are centralized and auditable; local-only mode remains functional.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:36:57.650595572Z","created_by":"ubuntu","updated_at":"2026-02-20T15:44:06.252914860Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-14","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-1nfu","depends_on_id":"bd-1ru2","type":"blocks","created_at":"2026-02-20T07:43:15.483964082Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-1nk5","title":"[10.13] Add SSRF-deny default policy template (localhost/tailnet/private CIDR denied unless explicitly allowed).","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.13 — FCP Deep-Mined Expansion Execution Track (9I)\n\nWhy This Exists:\nDeep connector/provider contract track: lifecycle FSMs, conformance harnesses, fencing, sandboxing, revocation freshness, and protocol hardening.\n\nTask Objective:\nAdd SSRF-deny default policy template (localhost/tailnet/private CIDR denied unless explicitly allowed).\n\nAcceptance Criteria:\n- Default templates block unsafe internal destinations; explicit allowlist exceptions require policy receipts; regression tests cover common SSRF patterns.\n\nExpected Artifacts:\n- `config/policies/network_guard_default.toml`, `tests/security/ssrf_default_deny.rs`, `artifacts/10.13/ssrf_policy_test_report.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_13/bd-1nk5/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_13/bd-1nk5/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.13] Add SSRF-deny default policy template (localhost/tailnet/private CIDR denied unless explicitly allowed).\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.13] Add SSRF-deny default policy template (localhost/tailnet/private CIDR denied unless explicitly allowed).\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.13] Add SSRF-deny default policy template (localhost/tailnet/private CIDR denied unless explicitly allowed).\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.13] Add SSRF-deny default policy template (localhost/tailnet/private CIDR denied unless explicitly allowed).\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.13] Add SSRF-deny default policy template (localhost/tailnet/private CIDR denied unless explicitly allowed).\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","status":"closed","priority":1,"issue_type":"task","assignee":"CrimsonCrane","created_at":"2026-02-20T07:36:52.366422143Z","created_by":"ubuntu","updated_at":"2026-02-20T11:28:37.880582192Z","closed_at":"2026-02-20T11:28:37.880556835Z","close_reason":"done","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-13","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-1nk5","depends_on_id":"bd-2m2b","type":"blocks","created_at":"2026-02-20T07:43:12.756576197Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-1nl1","title":"[10.17] Build proof-carrying speculative execution governance framework for extension-host hot paths.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.17 — Radical Expansion Execution Track (9K)\n\nWhy This Exists:\nRadical expansion track for proof-carrying speculation, Bayesian adversary control, time-travel replay, ZK attestations, and claim compiler systems.\n\nTask Objective:\nBuild proof-carrying speculative execution governance framework for extension-host hot paths.\n\nAcceptance Criteria:\n- Speculative transforms cannot activate without proof receipts and guard checks; guard failure always degrades to deterministic safe baseline with no correctness regression; activation occurs only via approved franken_engine interfaces.\n\nExpected Artifacts:\n- `docs/specs/proof_carrying_speculation.md`, `src/runtime/speculation/proof_executor.rs`, `tests/conformance/proof_speculation_guards.rs`, `artifacts/10.17/speculation_proof_report.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_17/bd-1nl1/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_17/bd-1nl1/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.17] Build proof-carrying speculative execution governance framework for extension-host hot paths.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.17] Build proof-carrying speculative execution governance framework for extension-host hot paths.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.17] Build proof-carrying speculative execution governance framework for extension-host hot paths.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.17] Build proof-carrying speculative execution governance framework for extension-host hot paths.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.17] Build proof-carrying speculative execution governance framework for extension-host hot paths.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- Speculative transforms cannot activate without proof receipts and guard checks; guard failure always degrades to deterministic safe baseline with no correctness regression; activation occurs only via approved franken_engine interfaces.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:37:02.927493339Z","created_by":"ubuntu","updated_at":"2026-02-20T15:46:01.006955147Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-17","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-1nl1","depends_on_id":"bd-1ta","type":"blocks","created_at":"2026-02-20T07:46:33.798018723Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1nl1","depends_on_id":"bd-229","type":"blocks","created_at":"2026-02-20T07:46:33.843240390Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1nl1","depends_on_id":"bd-3il","type":"blocks","created_at":"2026-02-20T07:46:33.888249500Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1nl1","depends_on_id":"bd-3qo","type":"blocks","created_at":"2026-02-20T07:46:33.933893504Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1nl1","depends_on_id":"bd-5rh","type":"blocks","created_at":"2026-02-20T07:46:33.978872949Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1nl1","depends_on_id":"bd-cda","type":"blocks","created_at":"2026-02-20T07:46:34.023526217Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1nl1","depends_on_id":"bd-n71","type":"blocks","created_at":"2026-02-20T07:46:34.070551974Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-1nmg","title":"Epic: CI/CD Pipeline Setup","description":"- type: task","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-20T07:47:58.072163029Z","updated_at":"2026-02-20T07:49:21.083126433Z","closed_at":"2026-02-20T07:49:21.083109191Z","close_reason":"Superseded by canonical detailed master-plan graph (bd-33v) with full 10.N-10.21 and 11-16 coverage, explicit dependencies, and per-section verification gates.","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-1o4v","title":"[10.18] Implement proof-verification gate API for control-plane trust decisions.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.18 — Verifiable Execution Fabric Execution Track (9L)\n\nWhy This Exists:\nVEF track for proof-carrying runtime compliance: receipt chains, commitment checkpoints, proof generation/verification, and claim gating.\n\nTask Objective:\nImplement proof-verification gate API for control-plane trust decisions.\n\nAcceptance Criteria:\n- Verification gate validates proof, receipt-window commitment, and policy hash binding; invalid/missing proofs return stable fail-closed verdict classes.\n\nExpected Artifacts:\n- `src/trust/vef_verification_gate.rs`, `tests/security/vef_verification_gate.rs`, `artifacts/10.18/vef_verification_gate_report.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_18/bd-1o4v/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_18/bd-1o4v/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.18] Implement proof-verification gate API for control-plane trust decisions.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.18] Implement proof-verification gate API for control-plane trust decisions.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.18] Implement proof-verification gate API for control-plane trust decisions.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.18] Implement proof-verification gate API for control-plane trust decisions.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.18] Implement proof-verification gate API for control-plane trust decisions.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- Verification gate validates proof, receipt-window commitment, and policy hash binding; invalid/missing proofs return stable fail-closed verdict classes.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:37:04.625740872Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:56.287192645Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-18","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-1o4v","depends_on_id":"bd-1u8m","type":"blocks","created_at":"2026-02-20T07:43:19.133719851Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-1oof","title":"[10.14] Attach trace-witness references to every high-impact ledger entry.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.14 — FrankenSQLite Deep-Mined Expansion Execution Track (9J)\n\nWhy This Exists:\nFrankenSQLite deep-mined control integrity track: evidence ledgers, proofs, epochs, remote effects, markers/MMR, and deterministic fault labs.\n\nTask Objective:\nAttach trace-witness references to every high-impact ledger entry.\n\nAcceptance Criteria:\n- High-impact evidence entries include stable trace witness IDs; witness references resolve in replay bundles; broken references fail integrity check.\n\nExpected Artifacts:\n- `tests/integration/evidence_trace_witness_linking.rs`, `docs/specs/witness_reference_contract.md`, `artifacts/10.14/witness_link_audit.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_14/bd-1oof/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_14/bd-1oof/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.14] Attach trace-witness references to every high-impact ledger entry.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.14] Attach trace-witness references to every high-impact ledger entry.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.14] Attach trace-witness references to every high-impact ledger entry.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.14] Attach trace-witness references to every high-impact ledger entry.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.14] Attach trace-witness references to every high-impact ledger entry.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"High-impact evidence entries include stable trace witness IDs; witness references resolve in replay bundles; broken references fail integrity check.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:36:55.386366656Z","created_by":"ubuntu","updated_at":"2026-02-20T15:44:12.103719246Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-14","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-1oof","depends_on_id":"bd-oolt","type":"blocks","created_at":"2026-02-20T07:43:14.345863254Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-1ow","title":"[PLAN 10.1] Charter + Split Governance","description":"Section: 10.1 — Charter + Split Governance\n\nStrategic Context:\nProgram charter and governance baseline: split contracts, reproducibility, and anti-regression rules for strategic integrity.\n\nExecution Requirements:\n- Preserve all scoped capabilities from the canonical plan.\n- Keep contracts self-contained so future contributors can execute without reopening the master plan.\n- Require explicit testing strategy (unit + integration/e2e) and structured logging/telemetry for every child bead.\n- Require artifact-backed validation for performance, security, and correctness claims.\n\nDependency Semantics:\n- This epic is blocked by its child implementation beads.\n- Cross-epic dependencies encode strategic sequencing and canonical ownership boundaries.\n\n## Success Criteria\n- All child beads for this section are completed with acceptance artifacts attached and no unresolved blockers.\n- Section-level verification gate for comprehensive unit tests, integration/e2e workflows, and detailed structured logging evidence is green.\n- Scope-to-plan traceability is explicit, with no feature loss versus the canonical plan section.\n\n## Optimization Notes\n- User-Outcome Lens: \"[PLAN 10.1] Charter + Split Governance\" must improve operator confidence, safety posture, and deterministic recovery behavior under both normal and adversarial conditions.\n- Cross-Section Coordination: child beads must encode integration assumptions explicitly to avoid local optimizations that degrade system-wide correctness.\n- Verification Non-Negotiable: completion requires reproducible unit/integration/E2E evidence and structured logs suitable for independent replay.\n- Scope Protection: any simplification must preserve canonical-plan feature intent and be justified with explicit tradeoff documentation.","status":"closed","priority":2,"issue_type":"epic","assignee":"CrimsonCrane","created_at":"2026-02-20T07:36:40.297308976Z","created_by":"ubuntu","updated_at":"2026-02-20T09:28:23.626442305Z","closed_at":"2026-02-20T09:28:23.626404394Z","close_reason":"done","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-1"],"dependencies":[{"issue_id":"bd-1ow","depends_on_id":"bd-16sk","type":"blocks","created_at":"2026-02-20T07:48:06.500281934Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1ow","depends_on_id":"bd-1j2","type":"blocks","created_at":"2026-02-20T07:36:43.404919513Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1ow","depends_on_id":"bd-1mj","type":"blocks","created_at":"2026-02-20T07:36:43.639150210Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1ow","depends_on_id":"bd-1pc","type":"blocks","created_at":"2026-02-20T07:36:43.794691404Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1ow","depends_on_id":"bd-20l","type":"blocks","created_at":"2026-02-20T07:36:43.716039320Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1ow","depends_on_id":"bd-2nd","type":"blocks","created_at":"2026-02-20T07:56:25.059990167Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1ow","depends_on_id":"bd-2zz","type":"blocks","created_at":"2026-02-20T07:36:43.484114548Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1ow","depends_on_id":"bd-4yv","type":"blocks","created_at":"2026-02-20T07:36:43.561726795Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1ow","depends_on_id":"bd-cda","type":"blocks","created_at":"2026-02-20T07:37:09.075949892Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1ow","depends_on_id":"bd-vjq","type":"blocks","created_at":"2026-02-20T07:36:43.325531699Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-1oyt","title":"[10.N] Implement dual-oracle completion close-condition gate","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.N — Execution Normalization Contract\n\nTask Objective:\nEncode the dual-oracle completion close condition as a machine-enforced gate: L1 product oracle (10.2), L2 engine-boundary oracle (10.17), and release-policy linkage must all be green.\n\nAcceptance Criteria:\n- Gate consumes L1, L2, and release-policy verdict artifacts.\n- Section/program close condition fails if any required oracle dimension is missing or red.\n- Gate output is deterministic and machine-readable for release automation.\n\nExpected Artifacts:\n- Dual-oracle close-condition policy contract.\n- Gate verdict artifact samples for pass/fail conditions.\n\nTesting & Logging Requirements:\n- Unit tests for gate logic and edge-state handling.\n- E2E tests simulating partial oracle success/failure combinations.\n- Structured gate logs with explicit failing dimension tags.\n\nTask-Specific Clarification:\n- For \"[10.N] Implement dual-oracle completion close-condition gate\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.N] Implement dual-oracle completion close-condition gate\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.N] Implement dual-oracle completion close-condition gate\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.N] Implement dual-oracle completion close-condition gate\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.N] Implement dual-oracle completion close-condition gate\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","status":"closed","priority":1,"issue_type":"task","assignee":"ubuntu","created_at":"2026-02-20T07:50:04.174660975Z","created_by":"ubuntu","updated_at":"2026-02-20T08:20:29.847950311Z","closed_at":"2026-02-20T08:20:29.847853451Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-N","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-1oyt","depends_on_id":"bd-2yhs","type":"blocks","created_at":"2026-02-20T07:50:04.306017356Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-1p2b","title":"[10.13] Implement control-plane retention policy (`required` vs `ephemeral`) and storage enforcement.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.13 — FCP Deep-Mined Expansion Execution Track (9I)\n\nWhy This Exists:\nDeep connector/provider contract track: lifecycle FSMs, conformance harnesses, fencing, sandboxing, revocation freshness, and protocol hardening.\n\nTask Objective:\nImplement control-plane retention policy (`required` vs `ephemeral`) and storage enforcement.\n\nAcceptance Criteria:\n- Retention class is mandatory per control-plane message type; required objects are durably stored; ephemeral objects can be dropped only under policy.\n\nExpected Artifacts:\n- `docs/specs/control_plane_retention.md`, `tests/conformance/retention_class_enforcement.rs`, `artifacts/10.13/retention_policy_matrix.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_13/bd-1p2b/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_13/bd-1p2b/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.13] Implement control-plane retention policy (`required` vs `ephemeral`) and storage enforcement.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.13] Implement control-plane retention policy (`required` vs `ephemeral`) and storage enforcement.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.13] Implement control-plane retention policy (`required` vs `ephemeral`) and storage enforcement.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.13] Implement control-plane retention policy (`required` vs `ephemeral`) and storage enforcement.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.13] Implement control-plane retention policy (`required` vs `ephemeral`) and storage enforcement.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","status":"closed","priority":1,"issue_type":"task","assignee":"CrimsonCrane","created_at":"2026-02-20T07:36:54.252038585Z","created_by":"ubuntu","updated_at":"2026-02-20T12:57:47.283310215Z","closed_at":"2026-02-20T12:57:47.283272364Z","close_reason":"done","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-13","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-1p2b","depends_on_id":"bd-3cm3","type":"blocks","created_at":"2026-02-20T07:43:13.725180262Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-1pc","title":"[10.1] Add implementation-governance policy that forbids line-by-line legacy translation and requires spec+fixture references in compatibility PRs.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.1 — Charter + Split Governance\n\nWhy This Exists:\nProgram charter and governance baseline: split contracts, reproducibility, and anti-regression rules for strategic integrity.\n\nTask Objective:\nAdd implementation-governance policy that forbids line-by-line legacy translation and requires spec+fixture references in compatibility PRs.\n\nAcceptance Criteria:\n- Implement with explicit success/failure invariants and deterministic behavior under normal, edge, and fault scenarios.\n- Ensure outcomes are verifiable via automated tests and reproducible artifact outputs.\n\nExpected Artifacts:\n- Section-owned design/spec artifact at `docs/specs/section_10_1/bd-1pc_contract.md`, capturing decision rationale, invariants, and interface boundaries.\n- Machine-readable verification artifact at `artifacts/section_10_1/bd-1pc/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_1/bd-1pc/verification_summary.md` linking implementation intent to measured outcomes.\n\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.1] Add implementation-governance policy that forbids line-by-line legacy translation and requires spec+fixture references in compatibility PRs.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.1] Add implementation-governance policy that forbids line-by-line legacy translation and requires spec+fixture references in compatibility PRs.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.1] Add implementation-governance policy that forbids line-by-line legacy translation and requires spec+fixture references in compatibility PRs.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.1] Add implementation-governance policy that forbids line-by-line legacy translation and requires spec+fixture references in compatibility PRs.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.1] Add implementation-governance policy that forbids line-by-line legacy translation and requires spec+fixture references in compatibility PRs.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","status":"closed","priority":1,"issue_type":"task","assignee":"CrimsonCrane","created_at":"2026-02-20T07:36:43.758632999Z","created_by":"ubuntu","updated_at":"2026-02-20T09:26:08.444045199Z","closed_at":"2026-02-20T09:26:08.444018219Z","close_reason":"done","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-1","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-1pc","depends_on_id":"bd-20l","type":"blocks","created_at":"2026-02-20T07:43:10.784299165Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-1pe0","title":"Epic: Dependency Graph Immune System (DGIS) [10.20]","description":"- type: epic","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-20T07:47:58.072163029Z","updated_at":"2026-02-20T07:49:21.316891385Z","closed_at":"2026-02-20T07:49:21.316873822Z","close_reason":"Superseded by canonical detailed master-plan graph (bd-33v) with full 10.N-10.21 and 11-16 coverage, explicit dependencies, and per-section verification gates.","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-1pk","title":"Implement doctor command for environment diagnostics","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md (Bootstrap bridge for Sections 10.0, 10.8 operational readiness)\nSection: BOOTSTRAP (Operational readiness diagnostics bridge)\n\nTask Objective:\nImplement `franken-node doctor` as a deterministic environment diagnostics command that surfaces readiness/blockers across runtime, config, and extension-host prerequisites.\n\nIn Scope:\n- Environment/system prerequisite checks relevant to current bootstrap scope.\n- Snapshot/config/path integrity checks with actionable remediation hints.\n- Deterministic machine-readable doctor report output for CI and support workflows.\n\nAcceptance Criteria:\n- Doctor output clearly distinguishes pass/warn/fail states with stable codes.\n- Failure diagnostics include actionable remediation guidance and affected scope.\n- Command behavior is deterministic for equivalent environment/config states.\n\nExpected Artifacts:\n- Doctor checks matrix mapping each check to status codes and remediation text.\n- Sample doctor reports for healthy/degraded/failure environments.\n- CI-consumable diagnostic artifact format documentation.\n\n- Machine-readable verification artifact at `artifacts/section_bootstrap/bd-1pk/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_bootstrap/bd-1pk/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for each check module and status-code mapping.\n- Integration tests validating full report assembly and deterministic ordering.\n- E2E tests for representative degraded-environment scenarios.\n- Structured logs with check IDs, durations, verdicts, and trace correlation IDs.\n\nTask-Specific Clarification:\n- For \"Implement doctor command for environment diagnostics\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"Implement doctor command for environment diagnostics\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"Implement doctor command for environment diagnostics\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"Implement doctor command for environment diagnostics\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"Implement doctor command for environment diagnostics\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:29:22.294182970Z","created_by":"ubuntu","updated_at":"2026-02-20T08:46:43.632159515Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["cli","diagnostics"],"dependencies":[{"issue_id":"bd-1pk","depends_on_id":"bd-2lb","type":"blocks","created_at":"2026-02-20T08:04:16.423814955Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1pk","depends_on_id":"bd-3rp","type":"blocks","created_at":"2026-02-20T07:29:36.464286329Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1pk","depends_on_id":"bd-n9r","type":"blocks","created_at":"2026-02-20T07:29:36.528606668Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-1ps","title":"[PLAN 13] Program Success Criteria Instrumentation","description":"Section 13 success-metrics epic. Implement KPI instrumentation and claim gating for compatibility>=95%, migration>=3x, compromise reduction>=10x, replay coverage=100%, and external replication goals.\n\n## Success Criteria\n- All child beads for this section are completed with acceptance artifacts attached and no unresolved blockers.\n- Section-level verification gate for comprehensive unit tests, integration/e2e workflows, and detailed structured logging evidence is green.\n- Scope-to-plan traceability is explicit, with no feature loss versus the canonical plan section.\n\n## Optimization Notes\n- User-Outcome Lens: \"[PLAN 13] Program Success Criteria Instrumentation\" must improve real operator and end-user reliability, explainability, and time-to-safe-outcome under both normal and degraded conditions.\n- Cross-Section Coordination: this epic's child beads must explicitly encode integration expectations with neighboring sections to prevent local optimizations that break global behavior.\n- Verification Non-Negotiable: completion requires deterministic unit coverage, integration/E2E replay evidence, and structured logs sufficient for independent third-party reproduction and triage.\n- Scope Protection: any proposed simplification must prove feature parity against plan intent and document tradeoffs explicitly; silent scope reduction is forbidden.","status":"open","priority":1,"issue_type":"epic","created_at":"2026-02-20T07:36:42.164001900Z","created_by":"ubuntu","updated_at":"2026-02-20T08:12:47.234822646Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-13"],"dependencies":[{"issue_id":"bd-1ps","depends_on_id":"bd-1w78","type":"blocks","created_at":"2026-02-20T07:39:34.452259797Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1ps","depends_on_id":"bd-1xao","type":"blocks","created_at":"2026-02-20T07:39:34.707834911Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1ps","depends_on_id":"bd-20a","type":"blocks","created_at":"2026-02-20T07:38:35.593712559Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1ps","depends_on_id":"bd-229","type":"blocks","created_at":"2026-02-20T07:38:35.541405788Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1ps","depends_on_id":"bd-26k","type":"blocks","created_at":"2026-02-20T07:38:35.727766589Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1ps","depends_on_id":"bd-28sz","type":"blocks","created_at":"2026-02-20T07:39:34.911708132Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1ps","depends_on_id":"bd-2a4l","type":"blocks","created_at":"2026-02-20T07:39:34.540256587Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1ps","depends_on_id":"bd-2f43","type":"blocks","created_at":"2026-02-20T07:39:34.343763322Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1ps","depends_on_id":"bd-2l1k","type":"blocks","created_at":"2026-02-20T07:39:35.168572649Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1ps","depends_on_id":"bd-32p","type":"blocks","created_at":"2026-02-20T07:38:35.772665862Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1ps","depends_on_id":"bd-34d5","type":"blocks","created_at":"2026-02-20T08:02:26.065583281Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1ps","depends_on_id":"bd-37i","type":"blocks","created_at":"2026-02-20T07:38:35.900694378Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1ps","depends_on_id":"bd-39a","type":"blocks","created_at":"2026-02-20T07:38:35.816400385Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1ps","depends_on_id":"bd-3agp","type":"blocks","created_at":"2026-02-20T07:39:34.998996192Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1ps","depends_on_id":"bd-3cpa","type":"blocks","created_at":"2026-02-20T07:39:35.083603108Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1ps","depends_on_id":"bd-3e74","type":"blocks","created_at":"2026-02-20T07:39:34.816794629Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1ps","depends_on_id":"bd-3fo","type":"blocks","created_at":"2026-02-20T07:38:35.445801167Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1ps","depends_on_id":"bd-3il","type":"blocks","created_at":"2026-02-20T07:38:35.493770228Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1ps","depends_on_id":"bd-3rc","type":"blocks","created_at":"2026-02-20T07:38:35.642745913Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1ps","depends_on_id":"bd-c4f","type":"blocks","created_at":"2026-02-20T07:38:35.684597479Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1ps","depends_on_id":"bd-pga7","type":"blocks","created_at":"2026-02-20T07:39:34.624056279Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1ps","depends_on_id":"bd-whxp","type":"blocks","created_at":"2026-02-20T07:39:35.253274261Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1ps","depends_on_id":"bd-ybe","type":"blocks","created_at":"2026-02-20T07:38:35.858599369Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1ps","depends_on_id":"bd-z7bt","type":"blocks","created_at":"2026-02-20T07:48:29.681207780Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-1q38","title":"[10.20] Implement adversarial contagion simulator for xz-style and multi-stage supply-chain campaigns.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.20 — Dependency Graph Immune System Execution Track (9N)\n\nWhy This Exists:\nDGIS topological immune system track for dependency contagion modeling, choke-point immunization, and graph-aware containment economics.\n\nTask Objective:\nImplement adversarial contagion simulator for xz-style and multi-stage supply-chain campaigns.\n\nAcceptance Criteria:\n- Simulator supports campaign templates, probabilistic branching, and policy-conditioned propagation; runs are reproducible via fixed seeds and canonical scenario descriptors.\n\nExpected Artifacts:\n- `src/security/dgis/contagion_simulator.rs`, `tests/security/dgis_contagion_scenarios.rs`, `artifacts/10.20/dgis_contagion_simulation_report.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_20/bd-1q38/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_20/bd-1q38/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.20] Implement adversarial contagion simulator for xz-style and multi-stage supply-chain campaigns.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.20] Implement adversarial contagion simulator for xz-style and multi-stage supply-chain campaigns.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.20] Implement adversarial contagion simulator for xz-style and multi-stage supply-chain campaigns.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.20] Implement adversarial contagion simulator for xz-style and multi-stage supply-chain campaigns.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.20] Implement adversarial contagion simulator for xz-style and multi-stage supply-chain campaigns.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- Simulator supports campaign templates, probabilistic branching, and policy-conditioned propagation; runs are reproducible via fixed seeds and canonical scenario descriptors.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:37:06.748790626Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:19.027615715Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-20","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-1q38","depends_on_id":"bd-2jns","type":"blocks","created_at":"2026-02-20T07:43:20.756675258Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-1qag","title":"Comprehensive Unit Test Suite","description":"- type: task","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-20T07:47:58.072163029Z","updated_at":"2026-02-20T07:49:21.327992592Z","closed_at":"2026-02-20T07:49:21.327971542Z","close_reason":"Superseded by canonical detailed master-plan graph (bd-33v) with full 10.N-10.21 and 11-16 coverage, explicit dependencies, and per-section verification gates.","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-1qp","title":"[10.0] Implement compatibility envelope + divergence ledger.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.0 — Top 10 Initiative Tracking (Initiative #1, highest priority)\nCross-references: 9A.1, 9B.1, 9C.1, 9D.1\n\nWhy This Exists:\nThe compatibility envelope is the #1 strategic initiative. It creates a deterministic compatibility layer covering high-value Node/Bun behavior while making intentional divergences first-class, policy-visible, and signed. Without this, users cannot trust that franken_node faithfully reproduces expected behavior or understand where/why it intentionally differs.\n\nTask Objective:\nImplement the compatibility envelope (the boundary defining which Node/Bun APIs are covered and at what fidelity) together with the divergence ledger (an append-only, signed record of intentional behavioral differences with rationale).\n\nDetailed Acceptance Criteria:\n1. Compatibility envelope covers the four bands defined in 10.2: core, high-value, edge, unsafe, each with explicit policy defaults.\n2. Divergence ledger stores signed rationale entries for every intentional behavioral difference, with author, timestamp, affected API, severity, and justification fields.\n3. Each divergence entry is append-only and tamper-evident (hash-chained or Merkle-backed).\n4. Policy-visible: operators can query the ledger to understand all divergences for a given API surface, risk band, or profile.\n5. Integration with compatibility modes (strict, balanced, legacy-risky) — divergence handling varies by mode.\n6. Shim dispatch overhead profiled and reduced with precompiled decision DAGs where safe (9D.1).\n7. Typed-state transition primitives and session-type protocol checks applied to compatibility pathways (9B.1).\n8. Proof-carrying compatibility claims: each shim publishes invariance evidence and explicit divergence rationale (9C.1).\n\nKey Dependencies:\n- Depends on 10.2 (Compatibility Core) for band definitions and fixture runners.\n- Depends on 10.1 (Charter) for split-governance boundaries.\n- Depends on 10.N (Normalization) for canonical ownership rules.\n- Consumed by 10.3 (Migration) for risk assessment and 10.7 (Verification) for golden corpus.\n\nExpected Artifacts:\n- src/conformance/compatibility_envelope.rs — envelope definition and query API.\n- src/conformance/divergence_ledger.rs — signed divergence entry storage.\n- docs/specs/section_10_0/bd-1qp_contract.md — design rationale, invariants, interface boundaries.\n- artifacts/section_10_0/bd-1qp/verification_evidence.json — machine-readable CI gate.\n- artifacts/section_10_0/bd-1qp/verification_summary.md — human-readable summary.\n\nTesting and Logging Requirements:\n- Unit tests: envelope boundary queries, divergence entry creation/validation, hash chain integrity, mode-dependent divergence handling, band membership queries.\n- Integration tests: full workflow from API call -> envelope check -> divergence recording -> ledger query -> policy-visible output.\n- E2E tests: operator scenario exercising franken-node verify lockstep with divergence report generation.\n- Fuzz tests: malformed divergence entries, hash chain corruption detection.\n- Structured logs: stable event codes for COMPAT_ENVELOPE_QUERY, DIVERGENCE_RECORDED, DIVERGENCE_QUERIED, HASH_CHAIN_VERIFIED with trace correlation IDs.\n\nWhy This Improves User Outcomes:\n- Operators get deterministic, explainable answers about what behavior they can expect from franken_node vs Node/Bun.\n- Signed divergence rationale prevents silent behavior drift — every difference is intentional and auditable.\n- Policy-visible divergence data enables informed risk decisions during migration and rollout.\n- Proof-carrying claims (9C.1) enable external verification of compatibility assertions.","acceptance_criteria":"1. Envelope definition covers >= 95% of high-value Node.js API surface (fs, net, http, crypto, stream, child_process, path, os, events, buffer, url, util, assert, timers) measured by weighted API call frequency in npm-top-1000.\n2. Divergence ledger schema captures: API name, divergence type (semantic/signature/missing), severity (breaking/degraded/cosmetic), policy disposition (accepted/mitigated/blocked), signature of approver.\n3. Every intentional divergence has a signed entry with rationale, linked mitigation shim (if any), and policy-gate flag.\n4. Compatibility score computation is deterministic: same input manifest produces identical score across runs (no floating-point drift, no ordering sensitivity).\n5. Ledger entries are cryptographically signed and append-only; tampering detection via hash chain verification.\n6. CI gate rejects PRs that reduce overall compatibility score below the 95% category target threshold (Section 3).\n7. Divergence ledger is queryable via CLI (`franken-node compat divergences --format json`) and produces machine-readable output for downstream tooling.\n8. Replay coverage for envelope validation reaches 100% of catalogued divergences (Section 3 target).\n9. Cross-references to enhancement maps 9A.1, 9B.1, 9C.1, 9D.1 verified: each sub-deliverable traceable.\n10. Verification evidence artifact contains: compatibility score, divergence count by severity, ledger integrity hash, timestamp.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:36:42.485738572Z","created_by":"ubuntu","updated_at":"2026-02-20T15:35:17.412591453Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-0","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-1qp","depends_on_id":"bd-1hf","type":"blocks","created_at":"2026-02-20T07:46:29.385108753Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1qp","depends_on_id":"bd-1ow","type":"blocks","created_at":"2026-02-20T07:46:29.445817264Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1qp","depends_on_id":"bd-1ta","type":"blocks","created_at":"2026-02-20T07:46:29.507098101Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1qp","depends_on_id":"bd-1u9","type":"blocks","created_at":"2026-02-20T07:46:29.575562889Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1qp","depends_on_id":"bd-1wz","type":"blocks","created_at":"2026-02-20T07:46:29.631360965Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1qp","depends_on_id":"bd-1xg","type":"blocks","created_at":"2026-02-20T07:46:29.699988185Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1qp","depends_on_id":"bd-20a","type":"blocks","created_at":"2026-02-20T07:46:29.759040892Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1qp","depends_on_id":"bd-20z","type":"blocks","created_at":"2026-02-20T07:46:29.814011967Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1qp","depends_on_id":"bd-229","type":"blocks","created_at":"2026-02-20T07:46:29.882495770Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1qp","depends_on_id":"bd-26k","type":"blocks","created_at":"2026-02-20T07:46:29.948869653Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1qp","depends_on_id":"bd-32p","type":"blocks","created_at":"2026-02-20T07:46:30.005348757Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1qp","depends_on_id":"bd-37i","type":"blocks","created_at":"2026-02-20T07:46:30.076732061Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1qp","depends_on_id":"bd-39a","type":"blocks","created_at":"2026-02-20T07:46:30.142011806Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1qp","depends_on_id":"bd-3il","type":"blocks","created_at":"2026-02-20T07:46:30.207349830Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1qp","depends_on_id":"bd-3qo","type":"blocks","created_at":"2026-02-20T07:46:30.267897552Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1qp","depends_on_id":"bd-3rc","type":"blocks","created_at":"2026-02-20T07:46:30.337547547Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1qp","depends_on_id":"bd-5rh","type":"blocks","created_at":"2026-02-20T07:46:30.396154233Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1qp","depends_on_id":"bd-c4f","type":"blocks","created_at":"2026-02-20T07:46:30.456287573Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1qp","depends_on_id":"bd-cda","type":"blocks","created_at":"2026-02-20T07:46:30.521352479Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1qp","depends_on_id":"bd-go4","type":"blocks","created_at":"2026-02-20T07:46:30.584715574Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1qp","depends_on_id":"bd-n71","type":"blocks","created_at":"2026-02-20T07:46:30.640613455Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1qp","depends_on_id":"bd-ybe","type":"blocks","created_at":"2026-02-20T07:46:30.696473096Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-1qz","title":"Restore transplant snapshot files under transplant/pi_agent_rust","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md (Bootstrap bridge for migration/transplant integrity readiness)\n\nTask Objective:\nRestore the documented transplant snapshot under `transplant/pi_agent_rust` as the canonical input set for lockfile generation, drift detection, and provenance audits.\n\nIn Scope:\n- Rehydrate required snapshot files/directories exactly per documented inventory.\n- Validate inventory completeness and deterministic file layout.\n- Establish provenance notes (source revision/reference) for auditability.\n\nAcceptance Criteria:\n- Snapshot inventory is complete and matches documented expectations.\n- File layout and metadata are deterministic and reproducible across environments.\n- Downstream integrity beads (`bd-7rt`, `bd-29q`) can run without manual patching.\n\nExpected Artifacts:\n- Restored snapshot inventory report with counts and source references.\n- Canonical manifest of restored paths used by downstream integrity tooling.\n- Reproducibility note describing restoration procedure.\n\nTesting & Logging Requirements:\n- Unit tests (or deterministic validators) for inventory completeness checks.\n- Integration tests that validate downstream lockfile generation and drift detection consume restored snapshot correctly.\n- E2E test path that exercises restore -> lockfile -> drift workflow.\n- Structured logs recording restored path IDs, provenance refs, and validation outcomes.","notes":"Legacy transplant integrity prerequisite retained for continuity; upstream/master-plan workstreams should reference this when touching transplant provenance.","status":"closed","priority":1,"issue_type":"task","assignee":"ubuntu","created_at":"2026-02-20T07:26:05.311794442Z","created_by":"ubuntu","updated_at":"2026-02-20T08:08:46.889348412Z","closed_at":"2026-02-20T08:08:46.889259687Z","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-1r2","title":"[10.10] Implement audience-bound token chains for control actions.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.10 — FCP-Inspired Hardening + Interop Integration Track\n\nWhy This Exists:\nFCP-inspired hardening/interop contract for IDs, serialization, control-channel auth, revocation freshness, and publication gating.\n\nTask Objective:\nImplement audience-bound token chains for control actions.\n\nAcceptance Criteria:\n- Implement with explicit success/failure invariants and deterministic behavior under normal, edge, and fault scenarios.\n- Ensure outcomes are verifiable via automated tests and reproducible artifact outputs.\n\nExpected Artifacts:\n- Section-owned design/spec artifact at `docs/specs/section_10_10/bd-1r2_contract.md`, capturing decision rationale, invariants, and interface boundaries.\n- Machine-readable verification artifact at `artifacts/section_10_10/bd-1r2/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_10/bd-1r2/verification_summary.md` linking implementation intent to measured outcomes.\n\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.10] Implement audience-bound token chains for control actions.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.10] Implement audience-bound token chains for control actions.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.10] Implement audience-bound token chains for control actions.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.10] Implement audience-bound token chains for control actions.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.10] Implement audience-bound token chains for control actions.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"1. Define an AudienceBoundToken struct containing: (a) token_id (TrustObjectId with TOKEN domain), (b) issuer_key_id (TrustObjectId with KEY domain), (c) audience (a list of 1+ TrustObjectId values identifying the intended recipients/zones), (d) action_scope (enum: MIGRATE, ROLLBACK, PROMOTE, REVOKE, CONFIGURE), (e) issued_at (UTC timestamp), (f) expires_at (UTC timestamp), (g) delegation_parent (Option<token_id> for chained delegation, None for root tokens), (h) max_delegation_depth (u8, default 0 = no further delegation).\n2. Implement token chain validation: given a chain of tokens [root, delegate1, delegate2, ...], verify: (a) each delegate's delegation_parent matches the previous token_id, (b) chain length <= root's max_delegation_depth + 1, (c) each delegate's audience is a subset of its parent's audience (no audience escalation), (d) each delegate's action_scope is a subset of its parent's action_scope, (e) no token in the chain is expired at the evaluation timestamp.\n3. Implement audience binding check: given a token and a requester identity (TrustObjectId), verify the requester appears in the token's audience list. Reject with AudienceMismatch error.\n4. Implement scope narrowing: a delegated token MUST NOT grant action_scopes not present in the parent. Return ScopeEscalation error on violation.\n5. Reject tokens where issued_at >= expires_at (zero or negative validity window).\n6. Reject delegation chains where any intermediate token is expired even if the leaf is not.\n7. Unit tests: (a) valid root token creation, (b) valid single-hop delegation, (c) valid multi-hop delegation, (d) audience escalation rejection, (e) scope escalation rejection, (f) depth limit exceeded, (g) expired intermediate rejection, (h) zero-validity rejection, (i) audience mismatch.\n8. Golden fixture: a 3-level delegation chain in vectors/audience_bound_tokens.json with known pass/fail cases.\n9. Verification: scripts/check_token_chains.py --json, artifacts at artifacts/section_10_10/bd-1r2/.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:36:49.081452553Z","created_by":"ubuntu","updated_at":"2026-02-20T15:37:05.586217944Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-10","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-1r2","depends_on_id":"bd-2ms","type":"blocks","created_at":"2026-02-20T07:43:11.005025972Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-1rbl","title":"Epic: Asupersync Ownership + Boundaries [10.15a]","description":"- type: epic","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-20T07:47:58.072163029Z","updated_at":"2026-02-20T07:49:21.256050204Z","closed_at":"2026-02-20T07:49:21.256031920Z","close_reason":"Superseded by canonical detailed master-plan graph (bd-33v) with full 10.N-10.21 and 11-16 coverage, explicit dependencies, and per-section verification gates.","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-1rff","title":"[12] Risk control: longitudinal privacy/re-identification","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 12\n\nTask Objective:\nImplement privacy-preserving trajectory sketching and cohort-size publication thresholds with federated temporal checks.\n\nExecution Requirements:\n- Make this requirement machine-verifiable and release-gated where applicable.\n- Keep behavior self-documenting so future contributors do not need to re-open the master plan.\n\nTesting & Logging Requirements:\n- Unit tests for rule/contract logic and error conditions.\n- Integration/E2E tests for workflow-level enforcement.\n- Structured logs with stable codes and trace IDs.\n- Reproducible artifacts that prove contract satisfaction.\n\nAcceptance Criteria:\n- Success and failure invariants for [12] Risk control: longitudinal privacy/re-identification are explicitly quantified and machine-verifiable.\n- Determinism requirements for [12] Risk control: longitudinal privacy/re-identification are validated across repeated runs and adversarial perturbations.\n\n\nExpected Artifacts:\n- Machine-readable verification artifact with explicit canonical path under artifacts/section_12/bd-1rff/verification_evidence.json, suitable for CI/release gating.\n- Human-readable verification summary with explicit canonical path under artifacts/section_12/bd-1rff/verification_summary.md, linking implementation intent to measured validation outcomes.\n\nTask-Specific Clarification:\n- The implementation must deliver the exact capability named in the title, with no scope dilution and no silent feature omission.\n- Validation artifacts must include capability-specific thresholds, pass/fail criteria, and reproducible evidence bundles tied to this bead ID.\n- Program/section verification gates must be able to consume this bead's outputs without manual interpretation.\n\nWhy This Improves User Outcomes:\n- \"[12] Risk control: longitudinal privacy/re-identification\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[12] Risk control: longitudinal privacy/re-identification\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"RISK: Longitudinal trajectory privacy/re-identification — accumulated behavioral data over time enables re-identification of individual nodes or users.\nIMPACT: Privacy violation through trajectory analysis, de-anonymization of supposedly anonymous participants, regulatory exposure.\nCOUNTERMEASURES:\n  (a) Privacy-preserving sketching: behavioral trajectories are represented as lossy sketches (e.g., count-min sketch, HyperLogLog) that prevent exact reconstruction.\n  (b) Minimum cohort-size thresholds: no query or aggregation is served if the underlying cohort has fewer than k participants (k >= 50).\n  (c) Temporal aggregation: individual time-series data is aggregated into epoch buckets (minimum 1-hour granularity) to prevent fine-grained tracking.\nVERIFICATION:\n  1. Sketch-based representation: raw trajectories are not stored; only sketches are persisted. Verified by attempting to reconstruct exact trajectory from sketch and confirming failure.\n  2. k-anonymity: all query results are filtered by cohort size >= 50; queries on smaller cohorts return empty/error.\n  3. Temporal granularity: no stored data has resolution finer than 1-hour epochs.\n  4. Re-identification test: given 1000 sketches, an adversary with auxiliary data cannot link > 1% of sketches to individuals.\nTEST SCENARIOS:\n  - Scenario A: Store 100 trajectories as sketches; attempt to reconstruct any single trajectory; verify failure.\n  - Scenario B: Query a cohort of 30 participants; verify response is blocked with 'insufficient cohort size' error.\n  - Scenario C: Attempt to store sub-hour-granularity data; verify it is automatically bucketed to 1-hour epochs.\n  - Scenario D: Run linkage attack with full auxiliary data on 1000 sketches; verify success rate < 1%.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:39:34.126779671Z","created_by":"ubuntu","updated_at":"2026-02-20T15:20:24.510712927Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-12","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-1rff","depends_on_id":"bd-v4ps","type":"blocks","created_at":"2026-02-20T07:43:25.171374050Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-1rk","title":"[10.13] Add lifecycle-aware health gating and rollout-state persistence for every connector instance.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.13 — FCP Deep-Mined Expansion Execution Track (9I)\n\nWhy This Exists:\nDeep connector/provider contract track: lifecycle FSMs, conformance harnesses, fencing, sandboxing, revocation freshness, and protocol hardening.\n\nTask Objective:\nAdd lifecycle-aware health gating and rollout-state persistence for every connector instance.\n\nAcceptance Criteria:\n- Activation requires lifecycle + health gate satisfaction; rollout state survives restart and failover; recovery replay reproduces same state.\n\nExpected Artifacts:\n- `docs/specs/rollout_state_machine.md`, `tests/integration/lifecycle_health_gate.rs`, `artifacts/10.13/rollout_state_replay.log`.\n\n- Machine-readable verification artifact at `artifacts/section_10_13/bd-1rk/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_13/bd-1rk/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.13] Add lifecycle-aware health gating and rollout-state persistence for every connector instance.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.13] Add lifecycle-aware health gating and rollout-state persistence for every connector instance.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.13] Add lifecycle-aware health gating and rollout-state persistence for every connector instance.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.13] Add lifecycle-aware health gating and rollout-state persistence for every connector instance.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.13] Add lifecycle-aware health gating and rollout-state persistence for every connector instance.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","status":"closed","priority":1,"issue_type":"task","assignee":"CrimsonCrane","created_at":"2026-02-20T07:36:51.474592690Z","created_by":"ubuntu","updated_at":"2026-02-20T10:36:52.823494220Z","closed_at":"2026-02-20T10:36:52.823465837Z","close_reason":"done","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-13","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-1rk","depends_on_id":"bd-2gh","type":"blocks","created_at":"2026-02-20T07:43:12.274386354Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-1ru2","title":"[10.14] Implement cancel-safe eviction saga (upload -> verify -> retire) with deterministic compensations.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.14 — FrankenSQLite Deep-Mined Expansion Execution Track (9J)\n\nWhy This Exists:\nFrankenSQLite deep-mined control integrity track: evidence ledgers, proofs, epochs, remote effects, markers/MMR, and deterministic fault labs.\n\nTask Objective:\nImplement cancel-safe eviction saga (upload -> verify -> retire) with deterministic compensations.\n\nAcceptance Criteria:\n- Saga guarantees no partial retire on cancellation/crash; compensation path is deterministic; leak tests confirm zero orphan states.\n\nExpected Artifacts:\n- `docs/specs/eviction_saga.md`, `tests/integration/eviction_saga_cancel_safety.rs`, `artifacts/10.14/eviction_saga_trace.jsonl`.\n\n- Machine-readable verification artifact at `artifacts/section_10_14/bd-1ru2/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_14/bd-1ru2/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.14] Implement cancel-safe eviction saga (upload -> verify -> retire) with deterministic compensations.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.14] Implement cancel-safe eviction saga (upload -> verify -> retire) with deterministic compensations.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.14] Implement cancel-safe eviction saga (upload -> verify -> retire) with deterministic compensations.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.14] Implement cancel-safe eviction saga (upload -> verify -> retire) with deterministic compensations.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.14] Implement cancel-safe eviction saga (upload -> verify -> retire) with deterministic compensations.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"Saga guarantees no partial retire on cancellation/crash; compensation path is deterministic; leak tests confirm zero orphan states.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:36:57.569198947Z","created_by":"ubuntu","updated_at":"2026-02-20T15:44:06.462457256Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-14","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-1ru2","depends_on_id":"bd-1fck","type":"blocks","created_at":"2026-02-20T07:43:15.442435676Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-1rwq","title":"[10.7] Section-wide verification gate: comprehensive unit+e2e+logging","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.7\n\nTask Objective:\nCreate a hard section completion gate that verifies all implemented behavior in this section with comprehensive unit tests, integration/e2e scripts, and detailed structured logging evidence.\n\nAcceptance Criteria:\n- Section test matrix covers happy-path, edge-case, and adversarial/error-path scenarios for all section deliverables.\n- E2E scripts execute representative end-user workflows and policy/control-plane transitions for this section.\n- Structured logs include stable event/error codes, trace correlation IDs, and enough context for deterministic replay triage.\n- Verification report is deterministic and machine-readable for CI/release gating.\n\nExpected Artifacts:\n- Section-level test matrix and coverage summary artifact.\n- E2E script suite with pass/fail outputs and reproducible fixtures/seeds.\n- Structured log validation report and traceability bundle.\n- Gate verdict artifact consumable by release automation.\n\n- Machine-readable verification artifact at `artifacts/section_10_7/bd-1rwq/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_7/bd-1rwq/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests must validate contracts, invariants, and failure semantics.\n- E2E tests must validate cross-component behavior from user/operator entrypoints to persisted effects.\n- Logging must support root-cause analysis without hidden context requirements.\n\nTask-Specific Clarification:\n- For \"[10.7] Section-wide verification gate: comprehensive unit+e2e+logging\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.7] Section-wide verification gate: comprehensive unit+e2e+logging\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.7] Section-wide verification gate: comprehensive unit+e2e+logging\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.7] Section-wide verification gate: comprehensive unit+e2e+logging\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.7] Section-wide verification gate: comprehensive unit+e2e+logging\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"1. Section 10.7 gate aggregates pass/fail status from all sibling beads (bd-2ja, bd-s6y, bd-1ul, bd-1u4, bd-3ex, bd-2pu).\n2. Gate script (scripts/check_section_10_7_gate.py) runs all section verification scripts and produces a unified JSON report.\n3. Gate fails if any sibling bead's verification evidence is missing or shows a failure.\n4. Unit tests cover gate logic: all-pass, single-fail, and missing-evidence scenarios.\n5. Gate produces a section-level summary under artifacts/ with per-bead status, timestamps, and links to individual evidence files.\n6. E2E logging: gate execution emits structured log lines for each sub-check with bead ID, result, and duration.\n7. Gate is idempotent: running it twice in succession with no changes produces identical output.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:48:25.395020464Z","created_by":"ubuntu","updated_at":"2026-02-20T15:17:48.141256904Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-7","test-obligations","verification-gate"],"dependencies":[{"issue_id":"bd-1rwq","depends_on_id":"bd-1dpd","type":"blocks","created_at":"2026-02-20T08:24:24.738723630Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1rwq","depends_on_id":"bd-1u4","type":"blocks","created_at":"2026-02-20T07:48:25.600772869Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1rwq","depends_on_id":"bd-1ul","type":"blocks","created_at":"2026-02-20T07:48:25.666133146Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1rwq","depends_on_id":"bd-2ja","type":"blocks","created_at":"2026-02-20T07:48:25.766621101Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1rwq","depends_on_id":"bd-2pu","type":"blocks","created_at":"2026-02-20T07:48:25.495331970Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1rwq","depends_on_id":"bd-2twu","type":"blocks","created_at":"2026-02-20T08:20:50.298599714Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1rwq","depends_on_id":"bd-3ex","type":"blocks","created_at":"2026-02-20T07:48:25.545846777Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1rwq","depends_on_id":"bd-s6y","type":"blocks","created_at":"2026-02-20T07:48:25.718349612Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-1sgr","title":"[16] Output contract: multiple reproducible technical reports","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 16\n\nTask Objective:\nDeliver multiple publishable reports with reproducible artifact bundles.\n\nExecution Requirements:\n- Make this requirement machine-verifiable and release-gated where applicable.\n- Keep behavior self-documenting so future contributors do not need to re-open the master plan.\n\nTesting & Logging Requirements:\n- Unit tests for rule/contract logic and error conditions.\n- Integration/E2E tests for workflow-level enforcement.\n- Structured logs with stable codes and trace IDs.\n- Reproducible artifacts that prove contract satisfaction.\n\nAcceptance Criteria:\n- Success and failure invariants for [16] Output contract: multiple reproducible technical reports are explicitly quantified and machine-verifiable.\n- Determinism requirements for [16] Output contract: multiple reproducible technical reports are validated across repeated runs and adversarial perturbations.\n\n\nExpected Artifacts:\n- Machine-readable verification artifact with explicit canonical path under artifacts/section_16/bd-1sgr/verification_evidence.json, suitable for CI/release gating.\n- Human-readable verification summary with explicit canonical path under artifacts/section_16/bd-1sgr/verification_summary.md, linking implementation intent to measured validation outcomes.\n\nTask-Specific Clarification:\n- The implementation must deliver the exact capability named in the title, with no scope dilution and no silent feature omission.\n- Validation artifacts must include capability-specific thresholds, pass/fail criteria, and reproducible evidence bundles tied to this bead ID.\n- Program/section verification gates must be able to consume this bead's outputs without manual interpretation.\n\nWhy This Improves User Outcomes:\n- \"[16] Output contract: multiple reproducible technical reports\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[16] Output contract: multiple reproducible technical reports\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"1. At least 3 reproducible technical reports published covering distinct aspects: (a) compatibility/migration system, (b) trust/security system, (c) benchmark/verification methodology.\n2. Each report includes: (a) complete methodology section enabling independent replication, (b) all data and scripts required to reproduce results (published alongside report), (c) reproduction instructions tested on a clean environment, (d) expected results with tolerance bounds.\n3. Reproducibility verified: at least 1 report has been independently reproduced by an external party with results within 10% of original.\n4. Reports are formatted for academic/industry publication: abstract, introduction, related work, methodology, results, discussion, conclusion, references.\n5. Reports are submitted to at least 1 venue: academic conference, industry journal, or technical blog with peer review.\n6. All reports carry a reproducibility badge or statement indicating level of reproducibility achieved.\n7. Evidence: reproducible_report_registry.json with per-report: title, topic, reproduction status, venue, and external reproduction results.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:39:37.216637449Z","created_by":"ubuntu","updated_at":"2026-02-20T15:28:57.921783116Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-16","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-1sgr","depends_on_id":"bd-10ee","type":"blocks","created_at":"2026-02-20T07:43:26.769758348Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-1ta","title":"[PLAN 10.13] FCP Deep-Mined Expansion Execution Track (9I)","description":"Section: 10.13 — FCP Deep-Mined Expansion Execution Track (9I)\n\nStrategic Context:\nDeep connector/provider contract track: lifecycle FSMs, conformance harnesses, fencing, sandboxing, revocation freshness, and protocol hardening.\n\nExecution Requirements:\n- Preserve all scoped capabilities from the canonical plan.\n- Keep contracts self-contained so future contributors can execute without reopening the master plan.\n- Require explicit testing strategy (unit + integration/e2e) and structured logging/telemetry for every child bead.\n- Require artifact-backed validation for performance, security, and correctness claims.\n\nDependency Semantics:\n- This epic is blocked by its child implementation beads.\n- Cross-epic dependencies encode strategic sequencing and canonical ownership boundaries.\n\n## Success Criteria\n- All child beads for this section are completed with acceptance artifacts attached and no unresolved blockers.\n- Section-level verification gate for comprehensive unit tests, integration/e2e workflows, and detailed structured logging evidence is green.\n- Scope-to-plan traceability is explicit, with no feature loss versus the canonical plan section.\n\n## Optimization Notes\n- User-Outcome Lens: \"[PLAN 10.13] FCP Deep-Mined Expansion Execution Track (9I)\" must improve operator confidence, safety posture, and deterministic recovery behavior under both normal and adversarial conditions.\n- Cross-Section Coordination: child beads must encode integration assumptions explicitly to avoid local optimizations that degrade system-wide correctness.\n- Verification Non-Negotiable: completion requires reproducible unit/integration/E2E evidence and structured logs suitable for independent replay.\n- Scope Protection: any simplification must preserve canonical-plan feature intent and be justified with explicit tradeoff documentation.","status":"closed","priority":1,"issue_type":"epic","created_at":"2026-02-20T07:36:41.285268229Z","created_by":"ubuntu","updated_at":"2026-02-20T14:58:29.693108668Z","closed_at":"2026-02-20T14:58:29.693081257Z","close_reason":"done","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-13"],"dependencies":[{"issue_id":"bd-1ta","depends_on_id":"bd-12h8","type":"blocks","created_at":"2026-02-20T07:36:54.368428342Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1ta","depends_on_id":"bd-17mb","type":"blocks","created_at":"2026-02-20T07:36:52.489455475Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1ta","depends_on_id":"bd-18o","type":"blocks","created_at":"2026-02-20T07:36:51.755584378Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1ta","depends_on_id":"bd-19u","type":"blocks","created_at":"2026-02-20T07:36:51.917227447Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1ta","depends_on_id":"bd-1cm","type":"blocks","created_at":"2026-02-20T07:36:51.836601837Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1ta","depends_on_id":"bd-1d7n","type":"blocks","created_at":"2026-02-20T07:36:52.906227178Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1ta","depends_on_id":"bd-1gnb","type":"blocks","created_at":"2026-02-20T07:36:54.775278144Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1ta","depends_on_id":"bd-1h6","type":"blocks","created_at":"2026-02-20T07:36:51.594085677Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1ta","depends_on_id":"bd-1m8r","type":"blocks","created_at":"2026-02-20T07:36:53.149339088Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1ta","depends_on_id":"bd-1nk5","type":"blocks","created_at":"2026-02-20T07:36:52.405095099Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1ta","depends_on_id":"bd-1ow","type":"blocks","created_at":"2026-02-20T07:37:11.011553523Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1ta","depends_on_id":"bd-1p2b","type":"blocks","created_at":"2026-02-20T07:36:54.288673444Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1ta","depends_on_id":"bd-1rk","type":"blocks","created_at":"2026-02-20T07:36:51.514993544Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1ta","depends_on_id":"bd-1ugy","type":"blocks","created_at":"2026-02-20T07:36:54.614852151Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1ta","depends_on_id":"bd-1vvs","type":"blocks","created_at":"2026-02-20T07:36:52.240693691Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1ta","depends_on_id":"bd-1z9s","type":"blocks","created_at":"2026-02-20T07:36:52.736543932Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1ta","depends_on_id":"bd-24s","type":"blocks","created_at":"2026-02-20T07:36:51.997880568Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1ta","depends_on_id":"bd-29ct","type":"blocks","created_at":"2026-02-20T07:36:55.016580493Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1ta","depends_on_id":"bd-29w6","type":"blocks","created_at":"2026-02-20T07:36:53.799851866Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1ta","depends_on_id":"bd-2eun","type":"blocks","created_at":"2026-02-20T07:36:54.124335315Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1ta","depends_on_id":"bd-2gh","type":"blocks","created_at":"2026-02-20T07:36:51.430546205Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1ta","depends_on_id":"bd-2k74","type":"blocks","created_at":"2026-02-20T07:36:53.960331227Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1ta","depends_on_id":"bd-2m2b","type":"blocks","created_at":"2026-02-20T07:36:52.322919772Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1ta","depends_on_id":"bd-2t5u","type":"blocks","created_at":"2026-02-20T07:36:53.716832437Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1ta","depends_on_id":"bd-2vs4","type":"blocks","created_at":"2026-02-20T07:36:53.392506551Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1ta","depends_on_id":"bd-2yc4","type":"blocks","created_at":"2026-02-20T07:36:52.987816072Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1ta","depends_on_id":"bd-35by","type":"blocks","created_at":"2026-02-20T07:36:54.935988516Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1ta","depends_on_id":"bd-35q1","type":"blocks","created_at":"2026-02-20T07:36:52.655405537Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1ta","depends_on_id":"bd-3b8m","type":"blocks","created_at":"2026-02-20T07:36:54.040955064Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1ta","depends_on_id":"bd-3cm3","type":"blocks","created_at":"2026-02-20T07:36:54.208054036Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1ta","depends_on_id":"bd-3en","type":"blocks","created_at":"2026-02-20T07:36:51.674458095Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1ta","depends_on_id":"bd-3i9o","type":"blocks","created_at":"2026-02-20T07:36:52.820856339Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1ta","depends_on_id":"bd-3n2u","type":"blocks","created_at":"2026-02-20T07:36:55.096274577Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1ta","depends_on_id":"bd-3n58","type":"blocks","created_at":"2026-02-20T07:36:52.573199233Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1ta","depends_on_id":"bd-3tzl","type":"blocks","created_at":"2026-02-20T07:36:54.534100497Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1ta","depends_on_id":"bd-3ua7","type":"blocks","created_at":"2026-02-20T07:36:52.160058995Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1ta","depends_on_id":"bd-3uoo","type":"blocks","created_at":"2026-02-20T07:48:11.356690640Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1ta","depends_on_id":"bd-8uvb","type":"blocks","created_at":"2026-02-20T07:36:53.472587026Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1ta","depends_on_id":"bd-8vby","type":"blocks","created_at":"2026-02-20T07:36:53.554148338Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1ta","depends_on_id":"bd-91gg","type":"blocks","created_at":"2026-02-20T07:36:53.879952197Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1ta","depends_on_id":"bd-b44","type":"blocks","created_at":"2026-02-20T07:36:52.077621159Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1ta","depends_on_id":"bd-bq6y","type":"blocks","created_at":"2026-02-20T07:36:53.312328605Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1ta","depends_on_id":"bd-cda","type":"blocks","created_at":"2026-02-20T07:37:09.546802079Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1ta","depends_on_id":"bd-ck2h","type":"blocks","created_at":"2026-02-20T07:36:54.855586673Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1ta","depends_on_id":"bd-jxgt","type":"blocks","created_at":"2026-02-20T07:36:53.637535011Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1ta","depends_on_id":"bd-novi","type":"blocks","created_at":"2026-02-20T07:36:54.695090870Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1ta","depends_on_id":"bd-v97o","type":"blocks","created_at":"2026-02-20T07:36:54.453073599Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1ta","depends_on_id":"bd-w0jq","type":"blocks","created_at":"2026-02-20T07:36:53.231142371Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1ta","depends_on_id":"bd-y7lu","type":"blocks","created_at":"2026-02-20T07:36:53.068068396Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-1tnu","title":"[10.20] Implement trust barrier primitives and policy wiring (behavioral sandbox escalation, composition firewall, verified-fork pinning, staged rollout fences).","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.20 — Dependency Graph Immune System Execution Track (9N)\n\nWhy This Exists:\nDGIS topological immune system track for dependency contagion modeling, choke-point immunization, and graph-aware containment economics.\n\nTask Objective:\nImplement trust barrier primitives and policy wiring (behavioral sandbox escalation, composition firewall, verified-fork pinning, staged rollout fences).\n\nAcceptance Criteria:\n- Barrier primitives are independently testable and composable; policy engine can enforce barrier sets at designated choke points with deterministic overrides and audit receipts.\n\nExpected Artifacts:\n- `src/security/dgis/barrier_primitives.rs`, `tests/integration/dgis_barrier_enforcement.rs`, `artifacts/10.20/dgis_barrier_enforcement_trace.jsonl`.\n\n- Machine-readable verification artifact at `artifacts/section_10_20/bd-1tnu/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_20/bd-1tnu/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.20] Implement trust barrier primitives and policy wiring (behavioral sandbox escalation, composition firewall, verified-fork pinning, staged rollout fences).\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.20] Implement trust barrier primitives and policy wiring (behavioral sandbox escalation, composition firewall, verified-fork pinning, staged rollout fences).\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.20] Implement trust barrier primitives and policy wiring (behavioral sandbox escalation, composition firewall, verified-fork pinning, staged rollout fences).\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.20] Implement trust barrier primitives and policy wiring (behavioral sandbox escalation, composition firewall, verified-fork pinning, staged rollout fences).\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.20] Implement trust barrier primitives and policy wiring (behavioral sandbox escalation, composition firewall, verified-fork pinning, staged rollout fences).\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- Barrier primitives are independently testable and composable; policy engine can enforce barrier sets at designated choke points with deterministic overrides and audit receipts.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:37:06.914671199Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:19.273157441Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-20","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-1tnu","depends_on_id":"bd-2fid","type":"blocks","created_at":"2026-02-20T07:43:20.843618247Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-1u4","title":"[10.7] Add metamorphic tests for compatibility invariants.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.7 — Conformance + Verification\n\nWhy This Exists:\nConformance and verification evidence stack for compatibility, trust protocols, fuzzing, and external reproducibility.\n\nTask Objective:\nAdd metamorphic tests for compatibility invariants.\n\nAcceptance Criteria:\n- Implement with explicit success/failure invariants and deterministic behavior under normal, edge, and fault scenarios.\n- Ensure outcomes are verifiable via automated tests and reproducible artifact outputs.\n\nExpected Artifacts:\n- Section-owned design/spec artifact at `docs/specs/section_10_7/bd-1u4_contract.md`, capturing decision rationale, invariants, and interface boundaries.\n- Machine-readable verification artifact at `artifacts/section_10_7/bd-1u4/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_7/bd-1u4/verification_summary.md` linking implementation intent to measured outcomes.\n\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.7] Add metamorphic tests for compatibility invariants.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.7] Add metamorphic tests for compatibility invariants.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.7] Add metamorphic tests for compatibility invariants.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.7] Add metamorphic tests for compatibility invariants.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.7] Add metamorphic tests for compatibility invariants.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"1. At least 5 metamorphic relations are defined and documented (e.g., 'if module M loads successfully, then M with an added no-op wrapper must also load with identical exports').\n2. Each metamorphic relation is encoded as a test generator that produces input pairs (A, f(A)) and asserts output relation (X, f(X)).\n3. Relations cover: module loading invariants, migration plan idempotency, shim composition commutativity, and compatibility-set closure properties.\n4. Tests run against both the Rust implementation and the lockstep oracle to detect divergence.\n5. Metamorphic test suite is integrated into CI and produces a structured JSON report with per-relation pass/fail status.\n6. At least one relation validates the extraction-and-proof discipline from Section 5.4: porting a fixture through the migration pipeline and back yields equivalent output.\n7. False-positive rate is documented: each relation includes a rationale explaining why the invariant must hold and under what conditions it could legitimately break.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:36:47.507200223Z","created_by":"ubuntu","updated_at":"2026-02-20T15:17:12.730032620Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-7","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-1u4","depends_on_id":"bd-1ul","type":"blocks","created_at":"2026-02-20T07:43:23.573176351Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-1u8m","title":"[10.18] Implement proof-generation service interface (backend-agnostic) for receipt-window compliance proofs.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.18 — Verifiable Execution Fabric Execution Track (9L)\n\nWhy This Exists:\nVEF track for proof-carrying runtime compliance: receipt chains, commitment checkpoints, proof generation/verification, and claim gating.\n\nTask Objective:\nImplement proof-generation service interface (backend-agnostic) for receipt-window compliance proofs.\n\nAcceptance Criteria:\n- Proof service supports deterministic input envelope and output proof envelope; backend selection is pluggable without semantic drift.\n\nExpected Artifacts:\n- `docs/specs/vef_proof_service_contract.md`, `src/trust/vef_proof_service.rs`, `artifacts/10.18/vef_proof_service_matrix.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_18/bd-1u8m/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_18/bd-1u8m/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.18] Implement proof-generation service interface (backend-agnostic) for receipt-window compliance proofs.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.18] Implement proof-generation service interface (backend-agnostic) for receipt-window compliance proofs.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.18] Implement proof-generation service interface (backend-agnostic) for receipt-window compliance proofs.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.18] Implement proof-generation service interface (backend-agnostic) for receipt-window compliance proofs.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.18] Implement proof-generation service interface (backend-agnostic) for receipt-window compliance proofs.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- Proof service supports deterministic input envelope and output proof envelope; backend selection is pluggable without semantic drift.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:37:04.544729684Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:56.522629322Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-18","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-1u8m","depends_on_id":"bd-28u0","type":"blocks","created_at":"2026-02-20T07:43:19.092037319Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-1u9","title":"[PLAN 10.6] Performance + Packaging","description":"\n\n## Success Criteria\n- All child beads for this section are completed with acceptance artifacts attached and no unresolved blockers.\n- Section-level verification gate for comprehensive unit tests, integration/e2e workflows, and detailed structured logging evidence is green.\n- Scope-to-plan traceability is explicit, with no feature loss versus the canonical plan section.\n\n## Optimization Notes\n- User-Outcome Lens: \"[PLAN 10.6] Performance + Packaging\" must improve real operator and end-user reliability, explainability, and time-to-safe-outcome under both normal and degraded conditions.\n- Cross-Section Coordination: this epic's child beads must explicitly encode integration expectations with neighboring sections to prevent local optimizations that break global behavior.\n- Verification Non-Negotiable: completion requires deterministic unit coverage, integration/E2E replay evidence, and structured logs sufficient for independent third-party reproduction and triage.\n- Scope Protection: any proposed simplification must prove feature parity against plan intent and document tradeoffs explicitly; silent scope reduction is forbidden.","status":"open","priority":2,"issue_type":"epic","created_at":"2026-02-20T07:36:40.705483806Z","created_by":"ubuntu","updated_at":"2026-02-20T08:12:49.767293632Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-6"],"dependencies":[{"issue_id":"bd-1u9","depends_on_id":"bd-20a","type":"blocks","created_at":"2026-02-20T07:37:10.241891429Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1u9","depends_on_id":"bd-229","type":"blocks","created_at":"2026-02-20T07:37:10.203432742Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1u9","depends_on_id":"bd-2pw","type":"blocks","created_at":"2026-02-20T07:36:47.138295371Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1u9","depends_on_id":"bd-2q5","type":"blocks","created_at":"2026-02-20T07:36:46.973090247Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1u9","depends_on_id":"bd-38m","type":"blocks","created_at":"2026-02-20T07:36:46.894386777Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1u9","depends_on_id":"bd-3il","type":"blocks","created_at":"2026-02-20T07:37:10.162896506Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1u9","depends_on_id":"bd-3kn","type":"blocks","created_at":"2026-02-20T07:36:47.055417847Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1u9","depends_on_id":"bd-3lh","type":"blocks","created_at":"2026-02-20T07:36:46.815299473Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1u9","depends_on_id":"bd-3p9n","type":"blocks","created_at":"2026-02-20T07:48:25.223542477Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1u9","depends_on_id":"bd-3q9","type":"blocks","created_at":"2026-02-20T07:36:47.220923231Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1u9","depends_on_id":"bd-cda","type":"blocks","created_at":"2026-02-20T07:37:09.271148865Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1u9","depends_on_id":"bd-k4s","type":"blocks","created_at":"2026-02-20T07:36:46.737278545Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-1ugy","title":"[10.13] Define stable telemetry namespace for protocol/capability/egress/security planes.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.13 — FCP Deep-Mined Expansion Execution Track (9I)\n\nWhy This Exists:\nDeep connector/provider contract track: lifecycle FSMs, conformance harnesses, fencing, sandboxing, revocation freshness, and protocol hardening.\n\nTask Objective:\nDefine stable telemetry namespace for protocol/capability/egress/security planes.\n\nAcceptance Criteria:\n- Metric names and labels are versioned and frozen by contract; deprecations follow compatibility policy; schema validator enforces namespace rules.\n\nExpected Artifacts:\n- `docs/observability/telemetry_namespace.md`, `tests/conformance/metric_schema_stability.rs`, `artifacts/10.13/telemetry_schema_catalog.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_13/bd-1ugy/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_13/bd-1ugy/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.13] Define stable telemetry namespace for protocol/capability/egress/security planes.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.13] Define stable telemetry namespace for protocol/capability/egress/security planes.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.13] Define stable telemetry namespace for protocol/capability/egress/security planes.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.13] Define stable telemetry namespace for protocol/capability/egress/security planes.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.13] Define stable telemetry namespace for protocol/capability/egress/security planes.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","status":"closed","priority":1,"issue_type":"task","assignee":"CrimsonCrane","created_at":"2026-02-20T07:36:54.577751044Z","created_by":"ubuntu","updated_at":"2026-02-20T13:17:20.021892265Z","closed_at":"2026-02-20T13:17:20.021867379Z","close_reason":"done","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-13","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-1ugy","depends_on_id":"bd-3tzl","type":"blocks","created_at":"2026-02-20T07:43:13.895487393Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-1ul","title":"[10.7] Add fuzz/adversarial tests for migration and shim logic.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.7 — Conformance + Verification\n\nWhy This Exists:\nConformance and verification evidence stack for compatibility, trust protocols, fuzzing, and external reproducibility.\n\nTask Objective:\nAdd fuzz/adversarial tests for migration and shim logic.\n\nAcceptance Criteria:\n- Implement with explicit success/failure invariants and deterministic behavior under normal, edge, and fault scenarios.\n- Ensure outcomes are verifiable via automated tests and reproducible artifact outputs.\n\nExpected Artifacts:\n- Section-owned design/spec artifact at `docs/specs/section_10_7/bd-1ul_contract.md`, capturing decision rationale, invariants, and interface boundaries.\n- Machine-readable verification artifact at `artifacts/section_10_7/bd-1ul/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_7/bd-1ul/verification_summary.md` linking implementation intent to measured outcomes.\n\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.7] Add fuzz/adversarial tests for migration and shim logic.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.7] Add fuzz/adversarial tests for migration and shim logic.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.7] Add fuzz/adversarial tests for migration and shim logic.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.7] Add fuzz/adversarial tests for migration and shim logic.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.7] Add fuzz/adversarial tests for migration and shim logic.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"1. Fuzz tests target at minimum: migration plan parser, shim dispatch logic, compatibility mapping engine, and configuration loader.\n2. Fuzz harnesses use cargo-fuzz (libfuzzer) or equivalent and are runnable with a single command.\n3. Each fuzz target runs for at least 10 minutes in CI without panics, hangs, or memory safety violations.\n4. Adversarial tests include: malformed migration manifests, circular dependency graphs, oversized inputs, and type-confused shim arguments.\n5. Any crash or violation found by fuzzing is captured as a regression test in the corpus and added to the golden test suite.\n6. Fuzz corpus seeds are stored under fixtures/fuzz/ and are version-controlled.\n7. Coverage report shows fuzz targets exercise at least 70% of branches in the targeted modules.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:36:47.424296620Z","created_by":"ubuntu","updated_at":"2026-02-20T15:16:59.568822514Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-7","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-1ul","depends_on_id":"bd-s6y","type":"blocks","created_at":"2026-02-20T07:43:23.527153084Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-1v2c","title":"[10.N] Implement cross-track canonical-reference linting","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.N — Execution Normalization Contract\n\nTask Objective:\nAdd a cross-track reference lint gate requiring integration/policy/adoption tasks to reference canonical owner IDs and artifact contracts, preventing silent semantic drift.\n\nAcceptance Criteria:\n- Lint rejects missing or invalid canonical-owner references.\n- Lint enforces artifact-contract linkage for cross-track integration tasks.\n- Findings include precise remediation pointers to canonical owner beads/contracts.\n\nExpected Artifacts:\n- Cross-track lint rules and mapping config.\n- Lint conformance report across current bead graph/tasks.\n\nTesting & Logging Requirements:\n- Unit tests for lint parsing and reference validation behavior.\n- E2E tests for CI enforcement on valid/invalid cross-track references.\n- Structured lint logs with stable finding categories.\n\nTask-Specific Clarification:\n- For \"[10.N] Implement cross-track canonical-reference linting\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.N] Implement cross-track canonical-reference linting\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.N] Implement cross-track canonical-reference linting\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.N] Implement cross-track canonical-reference linting\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.N] Implement cross-track canonical-reference linting\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","status":"closed","priority":1,"issue_type":"task","assignee":"ubuntu","created_at":"2026-02-20T07:50:04.216769836Z","created_by":"ubuntu","updated_at":"2026-02-20T08:26:52.206405612Z","closed_at":"2026-02-20T08:26:52.206316045Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-N","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-1v2c","depends_on_id":"bd-1oyt","type":"blocks","created_at":"2026-02-20T07:50:04.353037955Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-1v65","title":"[10.16] Integrate `sqlmodel_rust` in domains where typed schema/query safety is high-EV.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.16 — Adjacent Substrate Integration Execution Track (8.7)\n\nWhy This Exists:\nAdjacent substrate integration track to enforce deep composition with frankentui, frankensqlite, sqlmodel_rust, and fastapi_rust.\n\nTask Objective:\nIntegrate `sqlmodel_rust` in domains where typed schema/query safety is high-EV.\n\nAcceptance Criteria:\n- Selected domains use typed models and query contracts; schema drift is caught by conformance checks.\n\nExpected Artifacts:\n- `tests/conformance/sqlmodel_contracts.rs`, `artifacts/10.16/sqlmodel_integration_domains.csv`.\n\n- Machine-readable verification artifact at `artifacts/section_10_16/bd-1v65/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_16/bd-1v65/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.16] Integrate `sqlmodel_rust` in domains where typed schema/query safety is high-EV.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.16] Integrate `sqlmodel_rust` in domains where typed schema/query safety is high-EV.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.16] Integrate `sqlmodel_rust` in domains where typed schema/query safety is high-EV.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.16] Integrate `sqlmodel_rust` in domains where typed schema/query safety is high-EV.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.16] Integrate `sqlmodel_rust` in domains where typed schema/query safety is high-EV.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- Selected domains use typed models and query contracts; schema drift is caught by conformance checks.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:37:02.267781296Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:46.501688810Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-16","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-1v65","depends_on_id":"bd-bt82","type":"blocks","created_at":"2026-02-20T07:43:17.920728070Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-1vc4","title":"Epic: Admission + Quarantine Controls [10.13f]","description":"- type: epic","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-20T07:47:58.072163029Z","updated_at":"2026-02-20T07:49:21.187290094Z","closed_at":"2026-02-20T07:49:21.187272261Z","close_reason":"Superseded by canonical detailed master-plan graph (bd-33v) with full 10.N-10.21 and 11-16 coverage, explicit dependencies, and per-section verification gates.","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-1vm","title":"[10.4] Implement fast quarantine/recall workflow for compromised artifacts.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.4 — Extension Ecosystem + Registry\n\nWhy This Exists:\nExtension ecosystem and registry trust foundation: signed artifacts, provenance, trust cards, revocation, and quarantine flows.\n\nTask Objective:\nImplement fast quarantine/recall workflow for compromised artifacts.\n\nAcceptance Criteria:\n(See structured acceptance_criteria field for domain-specific criteria.)\n\nExpected Artifacts:\n- Section-owned design/spec artifact at `docs/specs/section_10_4/bd-1vm_contract.md`, capturing decision rationale, invariants, and interface boundaries.\n- Machine-readable verification artifact at `artifacts/section_10_4/bd-1vm/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_4/bd-1vm/verification_summary.md` linking implementation intent to measured outcomes.\n\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.4] Implement fast quarantine/recall workflow for compromised artifacts.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.4] Implement fast quarantine/recall workflow for compromised artifacts.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.4] Implement fast quarantine/recall workflow for compromised artifacts.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.4] Implement fast quarantine/recall workflow for compromised artifacts.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.4] Implement fast quarantine/recall workflow for compromised artifacts.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"1. Quarantine workflow has three trigger modes: (a) automated — triggered by revocation event from 10.13 registry, (b) operator-initiated — via CLI 'franken-node ext quarantine <ext-id> --reason <code>', (c) publisher-initiated — publisher issues recall via registry API with signed recall notice. 2. Quarantine is enacted within 30 seconds of trigger on the local node: extension is disabled (no new invocations), in-flight operations are drained with configurable timeout (default 10s), and extension state is preserved for forensic analysis. 3. Recall workflow extends quarantine to fleet-wide: recall notice is propagated to all nodes via the revocation registry (10.13); each node independently enacts quarantine upon receiving the notice. 4. Quarantine state machine: Active -> Quarantined -> {Recalled, Reinstated}. Reinstated requires explicit operator approval plus passing a re-verification check (full provenance chain re-validation). 5. Compromised artifact forensics: upon quarantine, the system captures and preserves extension binary hash, last-known behavioral telemetry snapshot, capability exercise log (last 1000 events), and active session count at quarantine time. Forensic bundle is stored at artifacts/quarantine/<ext-id>/<timestamp>/. 6. Fleet recall progress tracking: operator can query 'franken-node ext recall status <ext-id>' to see per-node quarantine confirmation status (confirmed/pending/unreachable). 7. Rollback support: if the quarantined extension was an update, automatic rollback to the last known-good version is attempted; if no known-good version exists, the extension remains disabled. 8. Quarantine does not cascade to other extensions unless they declare a hard dependency on the quarantined extension; soft-dependency extensions receive a degraded-mode signal. 9. Time budget: full quarantine-to-disabled path must complete in <30s on a single node, and fleet-wide recall propagation must reach 99% of connected nodes within 5 minutes. 10. Structured log events: QUARANTINE_TRIGGERED (trigger_mode, ext_id, reason_code), QUARANTINE_DRAIN_STARTED, QUARANTINE_DRAIN_COMPLETE (drained_sessions_count), RECALL_PROPAGATED, RECALL_NODE_CONFIRMED, EXTENSION_REINSTATED (operator_id, re_verification_result).","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:36:45.825278520Z","created_by":"ubuntu","updated_at":"2026-02-20T15:18:41.678463829Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-4","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-1vm","depends_on_id":"bd-ml1","type":"blocks","created_at":"2026-02-20T07:43:22.598597856Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-1vp","title":"[10.10] Implement zone/tenant trust segmentation policies.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.10 — FCP-Inspired Hardening + Interop Integration Track\n\nWhy This Exists:\nFCP-inspired hardening/interop contract for IDs, serialization, control-channel auth, revocation freshness, and publication gating.\n\nTask Objective:\nImplement zone/tenant trust segmentation policies.\n\nAcceptance Criteria:\n- Implement with explicit success/failure invariants and deterministic behavior under normal, edge, and fault scenarios.\n- Ensure outcomes are verifiable via automated tests and reproducible artifact outputs.\n\nExpected Artifacts:\n- Section-owned design/spec artifact at `docs/specs/section_10_10/bd-1vp_contract.md`, capturing decision rationale, invariants, and interface boundaries.\n- Machine-readable verification artifact at `artifacts/section_10_10/bd-1vp/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_10/bd-1vp/verification_summary.md` linking implementation intent to measured outcomes.\n\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.10] Implement zone/tenant trust segmentation policies.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.10] Implement zone/tenant trust segmentation policies.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.10] Implement zone/tenant trust segmentation policies.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.10] Implement zone/tenant trust segmentation policies.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.10] Implement zone/tenant trust segmentation policies.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"1. Define a TrustZone struct containing: (a) zone_id (TrustObjectId with ZONE domain), (b) zone_name (human-readable, max 128 chars, alphanumeric + hyphens), (c) parent_zone_id (Option, None for root zone), (d) trust_boundary_policy (enum: STRICT_ISOLATION, CONTROLLED_BRIDGE, OPEN), (e) created_at, (f) owner_key_id (TrustObjectId with KEY domain).\n2. Define a TenantBinding struct: (a) tenant_id (string, max 64 chars), (b) zone_id, (c) role (enum: OWNER, OPERATOR, READER), (d) bound_at, (e) bound_by (authority key_id).\n3. Implement zone hierarchy: zones form a tree rooted at a single root zone. Enforce that parent_zone_id references an existing zone. Reject cycles (a zone cannot be its own ancestor).\n4. Implement trust boundary enforcement: (a) STRICT_ISOLATION: no cross-zone token delegation or key sharing; tokens with audience in zone A are rejected in zone B. (b) CONTROLLED_BRIDGE: cross-zone access requires an explicit bridge policy listing source_zone, target_zone, and allowed action_scopes. (c) OPEN: no cross-zone restrictions (for development/test only, must be flagged in logs).\n5. Implement a ZonePolicyEngine with: (a) create_zone(name, parent, policy, owner_key) -> Result, (b) bind_tenant(tenant_id, zone_id, role, authority) -> Result, (c) check_access(requester_tenant, target_zone, action) -> Result<Allow/Deny>, (d) create_bridge(source_zone, target_zone, scopes, authority) -> Result.\n6. Enforce that bridge creation requires the authority key to be an OWNER in both the source and target zones.\n7. Emit structured log events for: zone creation, tenant binding, access check (with allow/deny result), bridge creation, and cross-zone violation attempts.\n8. Unit tests: (a) root zone creation, (b) child zone creation, (c) cycle rejection, (d) STRICT_ISOLATION cross-zone rejection, (e) CONTROLLED_BRIDGE with valid bridge, (f) CONTROLLED_BRIDGE without bridge (rejected), (g) tenant binding and role check, (h) bridge authority validation.\n9. Integration test: create a 3-level zone hierarchy, bind tenants, attempt cross-zone actions, verify isolation.\n10. Verification: scripts/check_zone_segmentation.py --json, artifacts at artifacts/section_10_10/bd-1vp/.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:36:49.426354415Z","created_by":"ubuntu","updated_at":"2026-02-20T15:38:18.285265535Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-10","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-1vp","depends_on_id":"bd-2sx","type":"blocks","created_at":"2026-02-20T07:43:11.171653450Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-1vsr","title":"[10.14] Implement transition abort semantics on timeout/cancellation unless explicit force policy is provided.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.14 — FrankenSQLite Deep-Mined Expansion Execution Track (9J)\n\nWhy This Exists:\nFrankenSQLite deep-mined control integrity track: evidence ledgers, proofs, epochs, remote effects, markers/MMR, and deterministic fault labs.\n\nTask Objective:\nImplement transition abort semantics on timeout/cancellation unless explicit force policy is provided.\n\nAcceptance Criteria:\n- Default behavior aborts transition on timeout/cancel; force policy is explicit, scoped, and audited; partial transition state is impossible.\n\nExpected Artifacts:\n- `tests/security/epoch_transition_abort_semantics.rs`, `docs/specs/force_transition_policy.md`, `artifacts/10.14/transition_abort_events.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_14/bd-1vsr/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_14/bd-1vsr/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.14] Implement transition abort semantics on timeout/cancellation unless explicit force policy is provided.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.14] Implement transition abort semantics on timeout/cancellation unless explicit force policy is provided.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.14] Implement transition abort semantics on timeout/cancellation unless explicit force policy is provided.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.14] Implement transition abort semantics on timeout/cancellation unless explicit force policy is provided.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.14] Implement transition abort semantics on timeout/cancellation unless explicit force policy is provided.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"Default behavior aborts transition on timeout/cancel; force policy is explicit, scoped, and audited; partial transition state is impossible.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:36:58.465729166Z","created_by":"ubuntu","updated_at":"2026-02-20T15:44:04.117458069Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-14","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-1vsr","depends_on_id":"bd-2wsm","type":"blocks","created_at":"2026-02-20T07:43:15.934925123Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-1vvs","title":"[10.13] Add strict-plus isolation backend (microVM when available, hardened fallback otherwise).","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.13 — FCP Deep-Mined Expansion Execution Track (9I)\n\nWhy This Exists:\nDeep connector/provider contract track: lifecycle FSMs, conformance harnesses, fencing, sandboxing, revocation freshness, and protocol hardening.\n\nTask Objective:\nAdd strict-plus isolation backend (microVM when available, hardened fallback otherwise).\n\nAcceptance Criteria:\n- `strict_plus` maps to microVM isolation where supported; unsupported platforms use hardened fallback with equivalent policy guarantees; compatibility tests pass across OS targets.\n\nExpected Artifacts:\n- `docs/specs/strict_plus_backend_matrix.md`, `tests/integration/strict_plus_isolation.rs`, `artifacts/10.13/strict_plus_runtime_matrix.csv`.\n\n- Machine-readable verification artifact at `artifacts/section_10_13/bd-1vvs/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_13/bd-1vvs/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.13] Add strict-plus isolation backend (microVM when available, hardened fallback otherwise).\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.13] Add strict-plus isolation backend (microVM when available, hardened fallback otherwise).\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.13] Add strict-plus isolation backend (microVM when available, hardened fallback otherwise).\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.13] Add strict-plus isolation backend (microVM when available, hardened fallback otherwise).\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.13] Add strict-plus isolation backend (microVM when available, hardened fallback otherwise).\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","status":"closed","priority":1,"issue_type":"task","assignee":"CrimsonCrane","created_at":"2026-02-20T07:36:52.204383297Z","created_by":"ubuntu","updated_at":"2026-02-20T11:15:35.550490307Z","closed_at":"2026-02-20T11:15:35.550465711Z","close_reason":"done","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-13","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-1vvs","depends_on_id":"bd-3ua7","type":"blocks","created_at":"2026-02-20T07:43:12.651901464Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-1w78","title":"[13] Success criterion: continuous lockstep validation","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 13\n\nTask Objective:\nInstrument and enforce continuous lockstep validation for compatibility claims.\n\nExecution Requirements:\n- Make this requirement machine-verifiable and release-gated where applicable.\n- Keep behavior self-documenting so future contributors do not need to re-open the master plan.\n\nTesting & Logging Requirements:\n- Unit tests for rule/contract logic and error conditions.\n- Integration/E2E tests for workflow-level enforcement.\n- Structured logs with stable codes and trace IDs.\n- Reproducible artifacts that prove contract satisfaction.\n\nAcceptance Criteria:\n- Success and failure invariants for [13] Success criterion: continuous lockstep validation are explicitly quantified and machine-verifiable.\n- Determinism requirements for [13] Success criterion: continuous lockstep validation are validated across repeated runs and adversarial perturbations.\n\n\nExpected Artifacts:\n- Machine-readable verification artifact with explicit canonical path under artifacts/section_13/bd-1w78/verification_evidence.json, suitable for CI/release gating.\n- Human-readable verification summary with explicit canonical path under artifacts/section_13/bd-1w78/verification_summary.md, linking implementation intent to measured validation outcomes.\n\nTask-Specific Clarification:\n- The implementation must deliver the exact capability named in the title, with no scope dilution and no silent feature omission.\n- Validation artifacts must include capability-specific thresholds, pass/fail criteria, and reproducible evidence bundles tied to this bead ID.\n- Program/section verification gates must be able to consume this bead's outputs without manual interpretation.\n\nWhy This Improves User Outcomes:\n- \"[13] Success criterion: continuous lockstep validation\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[13] Success criterion: continuous lockstep validation\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"1. Lockstep validation runs continuously: every CI pipeline execution includes a lockstep comparison against reference Node.js on a representative test subset.\n2. The representative subset covers >= 100 API calls across critical API families (fs, http, crypto, stream, net).\n3. Any lockstep divergence fails CI and produces a divergence receipt with: input, expected output, actual output, API family, severity.\n4. Lockstep validation history is tracked: a dashboard or report shows pass/fail trend over the last 30 days.\n5. Divergence receipts are immutable once created (append-only storage).\n6. Lockstep validation can be triggered on-demand for a specific API family (not just full suite).\n7. Evidence: lockstep_validation_status.json with latest run date, pass rate, and list of any open divergences.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:39:34.389711289Z","created_by":"ubuntu","updated_at":"2026-02-20T15:22:28.124905491Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-13","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-1w78","depends_on_id":"bd-2f43","type":"blocks","created_at":"2026-02-20T07:43:25.313179869Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-1wz","title":"[PLAN 10.17] Radical Expansion Execution Track (9K)","description":"Section: 10.17 — Radical Expansion Execution Track (9K)\n\nStrategic Context:\nRadical expansion track for proof-carrying speculation, Bayesian adversary control, time-travel replay, ZK attestations, and claim compiler systems.\n\nExecution Requirements:\n- Preserve all scoped capabilities from the canonical plan.\n- Keep contracts self-contained so future contributors can execute without reopening the master plan.\n- Require explicit testing strategy (unit + integration/e2e) and structured logging/telemetry for every child bead.\n- Require artifact-backed validation for performance, security, and correctness claims.\n\nDependency Semantics:\n- This epic is blocked by its child implementation beads.\n- Cross-epic dependencies encode strategic sequencing and canonical ownership boundaries.\n\n## Success Criteria\n- All child beads for this section are completed with acceptance artifacts attached and no unresolved blockers.\n- Section-level verification gate for comprehensive unit tests, integration/e2e workflows, and detailed structured logging evidence is green.\n- Scope-to-plan traceability is explicit, with no feature loss versus the canonical plan section.\n\n## Optimization Notes\n- User-Outcome Lens: \"[PLAN 10.17] Radical Expansion Execution Track (9K)\" must improve operator confidence, safety posture, and deterministic recovery behavior under both normal and adversarial conditions.\n- Cross-Section Coordination: child beads must encode integration assumptions explicitly to avoid local optimizations that degrade system-wide correctness.\n- Verification Non-Negotiable: completion requires reproducible unit/integration/E2E evidence and structured logs suitable for independent replay.\n- Scope Protection: any simplification must preserve canonical-plan feature intent and be justified with explicit tradeoff documentation.","status":"open","priority":1,"issue_type":"epic","created_at":"2026-02-20T07:36:41.623984119Z","created_by":"ubuntu","updated_at":"2026-02-20T08:41:05.804997206Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-17"],"dependencies":[{"issue_id":"bd-1wz","depends_on_id":"bd-1nl1","type":"blocks","created_at":"2026-02-20T07:37:02.964405495Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1wz","depends_on_id":"bd-1ta","type":"blocks","created_at":"2026-02-20T07:37:11.319185203Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1wz","depends_on_id":"bd-1xbc","type":"blocks","created_at":"2026-02-20T07:37:03.136967152Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1wz","depends_on_id":"bd-21fo","type":"blocks","created_at":"2026-02-20T07:37:03.635743433Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1wz","depends_on_id":"bd-229","type":"blocks","created_at":"2026-02-20T07:37:11.280821353Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1wz","depends_on_id":"bd-26mk","type":"blocks","created_at":"2026-02-20T07:37:03.553966348Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1wz","depends_on_id":"bd-274s","type":"blocks","created_at":"2026-02-20T07:37:03.047856227Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1wz","depends_on_id":"bd-2iyk","type":"blocks","created_at":"2026-02-20T07:37:03.798361148Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1wz","depends_on_id":"bd-2kd9","type":"blocks","created_at":"2026-02-20T07:37:04.127277755Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1wz","depends_on_id":"bd-2o8b","type":"blocks","created_at":"2026-02-20T07:37:03.963175925Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1wz","depends_on_id":"bd-383z","type":"blocks","created_at":"2026-02-20T07:37:04.044673980Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1wz","depends_on_id":"bd-3il","type":"blocks","created_at":"2026-02-20T07:37:11.242903474Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1wz","depends_on_id":"bd-3ku8","type":"blocks","created_at":"2026-02-20T07:37:03.222341417Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1wz","depends_on_id":"bd-3l2p","type":"blocks","created_at":"2026-02-20T07:37:03.717250324Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1wz","depends_on_id":"bd-3qo","type":"blocks","created_at":"2026-02-20T07:37:11.397069457Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1wz","depends_on_id":"bd-3t08","type":"blocks","created_at":"2026-02-20T07:48:17.789556785Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1wz","depends_on_id":"bd-5rh","type":"blocks","created_at":"2026-02-20T07:37:11.358150353Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1wz","depends_on_id":"bd-al8i","type":"blocks","created_at":"2026-02-20T07:37:03.471219888Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1wz","depends_on_id":"bd-cda","type":"blocks","created_at":"2026-02-20T07:37:09.702995447Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1wz","depends_on_id":"bd-gad3","type":"blocks","created_at":"2026-02-20T07:37:03.304005170Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1wz","depends_on_id":"bd-kcg9","type":"blocks","created_at":"2026-02-20T07:37:03.389259753Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1wz","depends_on_id":"bd-n71","type":"blocks","created_at":"2026-02-20T07:37:11.436332251Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1wz","depends_on_id":"bd-nbwo","type":"blocks","created_at":"2026-02-20T07:37:03.879067618Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-1xao","title":"[13] Success criterion: impossible-by-default adoption","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 13\n\nTask Objective:\nTrack and gate production-grade adoption of impossible-by-default capabilities.\n\nExecution Requirements:\n- Make this requirement machine-verifiable and release-gated where applicable.\n- Keep behavior self-documenting so future contributors do not need to re-open the master plan.\n\nTesting & Logging Requirements:\n- Unit tests for rule/contract logic and error conditions.\n- Integration/E2E tests for workflow-level enforcement.\n- Structured logs with stable codes and trace IDs.\n- Reproducible artifacts that prove contract satisfaction.\n\nAcceptance Criteria:\n- Success and failure invariants for [13] Success criterion: impossible-by-default adoption are explicitly quantified and machine-verifiable.\n- Determinism requirements for [13] Success criterion: impossible-by-default adoption are validated across repeated runs and adversarial perturbations.\n\n\nExpected Artifacts:\n- Machine-readable verification artifact with explicit canonical path under artifacts/section_13/bd-1xao/verification_evidence.json, suitable for CI/release gating.\n- Human-readable verification summary with explicit canonical path under artifacts/section_13/bd-1xao/verification_summary.md, linking implementation intent to measured validation outcomes.\n\nTask-Specific Clarification:\n- The implementation must deliver the exact capability named in the title, with no scope dilution and no silent feature omission.\n- Validation artifacts must include capability-specific thresholds, pass/fail criteria, and reproducible evidence bundles tied to this bead ID.\n- Program/section verification gates must be able to consume this bead's outputs without manual interpretation.\n\nWhy This Improves User Outcomes:\n- \"[13] Success criterion: impossible-by-default adoption\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[13] Success criterion: impossible-by-default adoption\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"1. 'Impossible-by-default' capabilities are defined: operations that are blocked unless explicitly enabled with cryptographic authorization.\n2. At minimum, these capabilities are impossible-by-default: (a) arbitrary file system access outside project root, (b) outbound network to non-allowlisted hosts, (c) spawning child processes without sandbox, (d) loading unsigned extensions, (e) disabling hardening profiles.\n3. Each impossible-by-default capability requires explicit opt-in via signed capability token with expiry.\n4. Attempting a blocked operation produces a clear, actionable error message (not a generic permission denied).\n5. Adoption metric: >= 90% of production deployments run with all impossible-by-default capabilities enforced (measured via telemetry).\n6. No impossible-by-default capability can be silently disabled; any disabling is logged and alerted.\n7. Evidence: capability_enforcement_report.json listing each capability, enforcement status, and opt-in rate.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:39:34.668279352Z","created_by":"ubuntu","updated_at":"2026-02-20T15:23:06.909308202Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-13","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-1xao","depends_on_id":"bd-pga7","type":"blocks","created_at":"2026-02-20T07:43:25.443838167Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-1xbc","title":"[10.17] Add deterministic time-travel runtime capture/replay for extension-host workflows.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.17 — Radical Expansion Execution Track (9K)\n\nWhy This Exists:\nRadical expansion track for proof-carrying speculation, Bayesian adversary control, time-travel replay, ZK attestations, and claim compiler systems.\n\nTask Objective:\nAdd deterministic time-travel runtime capture/replay for extension-host workflows.\n\nAcceptance Criteria:\n- Captured executions replay byte-for-byte equivalent control decisions under same seed/input; incident replay includes stepwise state navigation and divergence explanation.\n\nExpected Artifacts:\n- `docs/specs/time_travel_runtime.md`, `src/replay/time_travel_engine.rs`, `tests/lab/time_travel_replay_equivalence.rs`, `artifacts/10.17/time_travel_replay_report.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_17/bd-1xbc/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_17/bd-1xbc/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.17] Add deterministic time-travel runtime capture/replay for extension-host workflows.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.17] Add deterministic time-travel runtime capture/replay for extension-host workflows.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.17] Add deterministic time-travel runtime capture/replay for extension-host workflows.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.17] Add deterministic time-travel runtime capture/replay for extension-host workflows.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.17] Add deterministic time-travel runtime capture/replay for extension-host workflows.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- Captured executions replay byte-for-byte equivalent control decisions under same seed/input; incident replay includes stepwise state navigation and divergence explanation.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:37:03.099102362Z","created_by":"ubuntu","updated_at":"2026-02-20T15:46:00.589726222Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-17","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-1xbc","depends_on_id":"bd-274s","type":"blocks","created_at":"2026-02-20T07:43:18.349690460Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-1xg","title":"[PLAN 10.4] Extension Ecosystem + Registry","description":"Section: 10.4 — Extension Ecosystem + Registry\n\nStrategic Context:\nExtension ecosystem and registry trust foundation: signed artifacts, provenance, trust cards, revocation, and quarantine flows.\n\nExecution Requirements:\n- Preserve all scoped capabilities from the canonical plan.\n- Keep contracts self-contained so future contributors can execute without reopening the master plan.\n- Require explicit testing strategy (unit + integration/e2e) and structured logging/telemetry for every child bead.\n- Require artifact-backed validation for performance, security, and correctness claims.\n\nDependency Semantics:\n- This epic is blocked by its child implementation beads.\n- Cross-epic dependencies encode strategic sequencing and canonical ownership boundaries.\n\n## Success Criteria\n- All child beads for this section are completed with acceptance artifacts attached and no unresolved blockers.\n- Section-level verification gate for comprehensive unit tests, integration/e2e workflows, and detailed structured logging evidence is green.\n- Scope-to-plan traceability is explicit, with no feature loss versus the canonical plan section.\n\n## Optimization Notes\n- User-Outcome Lens: \"[PLAN 10.4] Extension Ecosystem + Registry\" must improve operator confidence, safety posture, and deterministic recovery behavior under both normal and adversarial conditions.\n- Cross-Section Coordination: child beads must encode integration assumptions explicitly to avoid local optimizations that degrade system-wide correctness.\n- Verification Non-Negotiable: completion requires reproducible unit/integration/E2E evidence and structured logs suitable for independent replay.\n- Scope Protection: any simplification must preserve canonical-plan feature intent and be justified with explicit tradeoff documentation.","status":"open","priority":1,"issue_type":"epic","created_at":"2026-02-20T07:36:40.545082850Z","created_by":"ubuntu","updated_at":"2026-02-20T08:16:41.824377207Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-4"],"dependencies":[{"issue_id":"bd-1xg","depends_on_id":"bd-12q","type":"blocks","created_at":"2026-02-20T07:36:45.622421462Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1xg","depends_on_id":"bd-1ah","type":"blocks","created_at":"2026-02-20T07:36:45.543343715Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1xg","depends_on_id":"bd-1gx","type":"blocks","created_at":"2026-02-20T07:36:45.464548314Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1xg","depends_on_id":"bd-1ta","type":"blocks","created_at":"2026-02-20T07:37:10.009028359Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1xg","depends_on_id":"bd-1vm","type":"blocks","created_at":"2026-02-20T07:36:45.861491603Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1xg","depends_on_id":"bd-261k","type":"blocks","created_at":"2026-02-20T07:48:23.958545463Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1xg","depends_on_id":"bd-273","type":"blocks","created_at":"2026-02-20T07:36:45.940576082Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1xg","depends_on_id":"bd-2yh","type":"blocks","created_at":"2026-02-20T07:36:45.701292433Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1xg","depends_on_id":"bd-3il","type":"blocks","created_at":"2026-02-20T07:37:09.970879510Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1xg","depends_on_id":"bd-cda","type":"blocks","created_at":"2026-02-20T07:37:09.193972901Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1xg","depends_on_id":"bd-ml1","type":"blocks","created_at":"2026-02-20T07:36:45.782176575Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-1xg","depends_on_id":"bd-phf","type":"blocks","created_at":"2026-02-20T07:36:46.018692649Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-1xtf","title":"[10.16] Migrate existing or planned relevant TUI workflows to `frankentui` primitives.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.16 — Adjacent Substrate Integration Execution Track (8.7)\n\nWhy This Exists:\nAdjacent substrate integration track to enforce deep composition with frankentui, frankensqlite, sqlmodel_rust, and fastapi_rust.\n\nTask Objective:\nMigrate existing or planned relevant TUI workflows to `frankentui` primitives.\n\nAcceptance Criteria:\n- Relevant workflows use `frankentui` abstraction points; no duplicate homegrown TUI stack remains in migrated surfaces.\n\nExpected Artifacts:\n- `tests/integration/frankentui_surface_migration.rs`, `artifacts/10.16/frankentui_surface_inventory.csv`.\n\n- Machine-readable verification artifact at `artifacts/section_10_16/bd-1xtf/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_16/bd-1xtf/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.16] Migrate existing or planned relevant TUI workflows to `frankentui` primitives.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.16] Migrate existing or planned relevant TUI workflows to `frankentui` primitives.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.16] Migrate existing or planned relevant TUI workflows to `frankentui` primitives.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.16] Migrate existing or planned relevant TUI workflows to `frankentui` primitives.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.16] Migrate existing or planned relevant TUI workflows to `frankentui` primitives.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- Relevant workflows use `frankentui` abstraction points; no duplicate homegrown TUI stack remains in migrated surfaces.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:37:01.770888002Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:47.870213020Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-16","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-1xtf","depends_on_id":"bd-34ll","type":"blocks","created_at":"2026-02-20T07:43:17.663002725Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-1xwz","title":"[10.15] Add performance budget guard for asupersync integration overhead in control-plane hot paths.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.15 — Asupersync-First Integration Execution Track (8.4-8.6)\n\nWhy This Exists:\nAsupersync-first control-plane migration track enforcing Cx-first, region ownership, cancellation correctness, and protocol-grade verification gates.\n\nTask Objective:\nAdd performance budget guard for asupersync integration overhead in control-plane hot paths.\n\nAcceptance Criteria:\n- Integration overhead remains within agreed p95/p99/cold-start budgets; regressions fail CI and include flamegraph evidence.\n\nExpected Artifacts:\n- `benchmarks/asupersync_integration_overhead/*`, `tests/perf/control_plane_overhead_gate.rs`, `artifacts/10.15/integration_overhead_report.csv`.\n\n- Machine-readable verification artifact at `artifacts/section_10_15/bd-1xwz/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_15/bd-1xwz/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.15] Add performance budget guard for asupersync integration overhead in control-plane hot paths.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.15] Add performance budget guard for asupersync integration overhead in control-plane hot paths.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.15] Add performance budget guard for asupersync integration overhead in control-plane hot paths.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.15] Add performance budget guard for asupersync integration overhead in control-plane hot paths.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.15] Add performance budget guard for asupersync integration overhead in control-plane hot paths.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- Integration overhead remains within agreed p95/p99/cold-start budgets; regressions fail CI and include flamegraph evidence.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:37:01.363671779Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:48.991560643Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-15","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-1xwz","depends_on_id":"bd-2h2s","type":"blocks","created_at":"2026-02-20T07:43:17.435735867Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-1z3","title":"[10.2] Implement deterministic compatibility fixture runner and result canonicalizer.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.2 — Compatibility Core\n\nWhy This Exists:\nCompatibility core as strategic wedge: policy-visible behavior, divergence receipts, L1/L2 lockstep, and spec-first fixture governance.\n\nTask Objective:\nImplement deterministic compatibility fixture runner and result canonicalizer.\n\nAcceptance Criteria:\n- Implement with explicit success/failure invariants and deterministic behavior under normal, edge, and fault scenarios.\n- Ensure outcomes are verifiable via automated tests and reproducible artifact outputs.\n\nExpected Artifacts:\n- Section-owned design/spec artifact at `docs/specs/section_10_2/bd-1z3_contract.md`, capturing decision rationale, invariants, and interface boundaries.\n- Machine-readable verification artifact at `artifacts/section_10_2/bd-1z3/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_2/bd-1z3/verification_summary.md` linking implementation intent to measured outcomes.\n\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.2] Implement deterministic compatibility fixture runner and result canonicalizer.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.2] Implement deterministic compatibility fixture runner and result canonicalizer.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.2] Implement deterministic compatibility fixture runner and result canonicalizer.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.2] Implement deterministic compatibility fixture runner and result canonicalizer.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.2] Implement deterministic compatibility fixture runner and result canonicalizer.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","status":"closed","priority":1,"issue_type":"task","assignee":"CrimsonCrane","created_at":"2026-02-20T07:36:44.163128134Z","created_by":"ubuntu","updated_at":"2026-02-20T09:40:35.689847016Z","closed_at":"2026-02-20T09:40:35.689820326Z","close_reason":"done","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-2","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-1z3","depends_on_id":"bd-2kf","type":"blocks","created_at":"2026-02-20T07:43:20.220218653Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-1z9s","title":"[10.13] Implement transparency-log inclusion proof checks in install/update pipelines.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.13 — FCP Deep-Mined Expansion Execution Track (9I)\n\nWhy This Exists:\nDeep connector/provider contract track: lifecycle FSMs, conformance harnesses, fencing, sandboxing, revocation freshness, and protocol hardening.\n\nTask Objective:\nImplement transparency-log inclusion proof checks in install/update pipelines.\n\nAcceptance Criteria:\n- Install/update fails if required inclusion proof is missing/invalid; log roots are pinned per policy; verification path is replayable.\n\nExpected Artifacts:\n- `src/supply_chain/transparency_verifier.rs`, `tests/security/transparency_inclusion.rs`, `artifacts/10.13/transparency_proof_receipts.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_13/bd-1z9s/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_13/bd-1z9s/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.13] Implement transparency-log inclusion proof checks in install/update pipelines.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.13] Implement transparency-log inclusion proof checks in install/update pipelines.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.13] Implement transparency-log inclusion proof checks in install/update pipelines.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.13] Implement transparency-log inclusion proof checks in install/update pipelines.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.13] Implement transparency-log inclusion proof checks in install/update pipelines.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","status":"closed","priority":1,"issue_type":"task","assignee":"CrimsonCrane","created_at":"2026-02-20T07:36:52.699603053Z","created_by":"ubuntu","updated_at":"2026-02-20T11:43:23.636373487Z","closed_at":"2026-02-20T11:43:23.636346347Z","close_reason":"done","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-13","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-1z9s","depends_on_id":"bd-35q1","type":"blocks","created_at":"2026-02-20T07:43:12.928750837Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-1zym","title":"[10.14] Implement automatic hardening trigger on guardrail rejection evidence.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.14 — FrankenSQLite Deep-Mined Expansion Execution Track (9J)\n\nWhy This Exists:\nFrankenSQLite deep-mined control integrity track: evidence ledgers, proofs, epochs, remote effects, markers/MMR, and deterministic fault labs.\n\nTask Objective:\nImplement automatic hardening trigger on guardrail rejection evidence.\n\nAcceptance Criteria:\n- Guardrail rejection triggers hardening within configured latency bound; trigger path is idempotent; trigger events include causal evidence pointer.\n\nExpected Artifacts:\n- `tests/integration/hardening_auto_trigger.rs`, `docs/specs/hardening_trigger_policy.md`, `artifacts/10.14/hardening_trigger_events.jsonl`.\n\n- Machine-readable verification artifact at `artifacts/section_10_14/bd-1zym/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_14/bd-1zym/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.14] Implement automatic hardening trigger on guardrail rejection evidence.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.14] Implement automatic hardening trigger on guardrail rejection evidence.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.14] Implement automatic hardening trigger on guardrail rejection evidence.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.14] Implement automatic hardening trigger on guardrail rejection evidence.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.14] Implement automatic hardening trigger on guardrail rejection evidence.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"Guardrail rejection triggers hardening within configured latency bound; trigger path is idempotent; trigger events include causal evidence pointer.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:36:56.138256697Z","created_by":"ubuntu","updated_at":"2026-02-20T15:44:10.158265693Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-14","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-1zym","depends_on_id":"bd-3rya","type":"blocks","created_at":"2026-02-20T07:43:14.725796218Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-206h","title":"[10.14] Implement idempotency dedupe store semantics (same key/same payload returns cached outcome; mismatch conflicts).","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.14 — FrankenSQLite Deep-Mined Expansion Execution Track (9J)\n\nWhy This Exists:\nFrankenSQLite deep-mined control integrity track: evidence ledgers, proofs, epochs, remote effects, markers/MMR, and deterministic fault labs.\n\nTask Objective:\nImplement idempotency dedupe store semantics (same key/same payload returns cached outcome; mismatch conflicts).\n\nAcceptance Criteria:\n- Duplicate same-payload requests are safely deduped; same-key different-payload conflicts hard-fail; dedupe state handles restart recovery.\n\nExpected Artifacts:\n- `tests/integration/idempotency_dedupe_store.rs`, `docs/specs/idempotency_store_semantics.md`, `artifacts/10.14/idempotency_conflict_report.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_14/bd-206h/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_14/bd-206h/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.14] Implement idempotency dedupe store semantics (same key/same payload returns cached outcome; mismatch conflicts).\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.14] Implement idempotency dedupe store semantics (same key/same payload returns cached outcome; mismatch conflicts).\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.14] Implement idempotency dedupe store semantics (same key/same payload returns cached outcome; mismatch conflicts).\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.14] Implement idempotency dedupe store semantics (same key/same payload returns cached outcome; mismatch conflicts).\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.14] Implement idempotency dedupe store semantics (same key/same payload returns cached outcome; mismatch conflicts).\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"Duplicate same-payload requests are safely deduped; same-key different-payload conflicts hard-fail; dedupe state handles restart recovery.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:36:57.892308276Z","created_by":"ubuntu","updated_at":"2026-02-20T15:44:05.616764950Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-14","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-206h","depends_on_id":"bd-12n3","type":"blocks","created_at":"2026-02-20T07:43:15.613060159Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-209w","title":"[15] Pillar: signed extension registry with provenance and revocation","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 15\n\nTask Objective:\nImplement signed extension registry pillar with strict provenance and revocation controls.\n\nExecution Requirements:\n- Make this requirement machine-verifiable and release-gated where applicable.\n- Keep behavior self-documenting so future contributors do not need to re-open the master plan.\n\nTesting & Logging Requirements:\n- Unit tests for rule/contract logic and error conditions.\n- Integration/E2E tests for workflow-level enforcement.\n- Structured logs with stable codes and trace IDs.\n- Reproducible artifacts that prove contract satisfaction.\n\nAcceptance Criteria:\n- Success and failure invariants for [15] Pillar: signed extension registry with provenance and revocation are explicitly quantified and machine-verifiable.\n- Determinism requirements for [15] Pillar: signed extension registry with provenance and revocation are validated across repeated runs and adversarial perturbations.\n\n\nExpected Artifacts:\n- Machine-readable verification artifact with explicit canonical path under artifacts/section_15/bd-209w/verification_evidence.json, suitable for CI/release gating.\n- Human-readable verification summary with explicit canonical path under artifacts/section_15/bd-209w/verification_summary.md, linking implementation intent to measured validation outcomes.\n\nTask-Specific Clarification:\n- The implementation must deliver the exact capability named in the title, with no scope dilution and no silent feature omission.\n- Validation artifacts must include capability-specific thresholds, pass/fail criteria, and reproducible evidence bundles tied to this bead ID.\n- Program/section verification gates must be able to consume this bead's outputs without manual interpretation.\n\nWhy This Improves User Outcomes:\n- \"[15] Pillar: signed extension registry with provenance and revocation\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[15] Pillar: signed extension registry with provenance and revocation\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"1. Extension registry exists and enforces cryptographic signing: all published extensions must be signed with a verified identity key.\n2. Provenance tracking: each extension version records build provenance (source repo, commit hash, build environment hash, builder identity).\n3. Revocation support: compromised extensions can be revoked in <= 5 minutes; revocation propagates to all consumers within 1 hour.\n4. Revocation is irrevocable (cannot be undone without re-signing with a new key and new review).\n5. Registry rejects unsigned extensions with clear error message.\n6. Provenance is queryable: users can verify any extension's build chain before installation.\n7. Signing key rotation is supported without breaking existing installations (grace period for old signatures).\n8. CI test: publish an unsigned extension; verify rejection. Publish a signed extension; verify acceptance. Revoke it; verify consumers are notified.\n9. Evidence: extension_registry_status.json with total extensions, signed %, revocation count, and average revocation propagation time.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:39:36.160912260Z","created_by":"ubuntu","updated_at":"2026-02-20T16:09:26.661730374Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-15","self-contained","test-obligations"]}
{"id":"bd-20a","title":"[PLAN 10.5] Security + Policy Product Surfaces","description":"Section: 10.5 — Security + Policy Product Surfaces\n\nStrategic Context:\nSecurity and policy product surfaces: decision receipts, incident replay, expected-loss policying, and auditable degraded-mode behavior.\n\nExecution Requirements:\n- Preserve all scoped capabilities from the canonical plan.\n- Keep contracts self-contained so future contributors can execute without reopening the master plan.\n- Require explicit testing strategy (unit + integration/e2e) and structured logging/telemetry for every child bead.\n- Require artifact-backed validation for performance, security, and correctness claims.\n\nDependency Semantics:\n- This epic is blocked by its child implementation beads.\n- Cross-epic dependencies encode strategic sequencing and canonical ownership boundaries.\n\n## Success Criteria\n- All child beads for this section are completed with acceptance artifacts attached and no unresolved blockers.\n- Section-level verification gate for comprehensive unit tests, integration/e2e workflows, and detailed structured logging evidence is green.\n- Scope-to-plan traceability is explicit, with no feature loss versus the canonical plan section.\n\n## Optimization Notes\n- User-Outcome Lens: \"[PLAN 10.5] Security + Policy Product Surfaces\" must improve operator confidence, safety posture, and deterministic recovery behavior under both normal and adversarial conditions.\n- Cross-Section Coordination: child beads must encode integration assumptions explicitly to avoid local optimizations that degrade system-wide correctness.\n- Verification Non-Negotiable: completion requires reproducible unit/integration/E2E evidence and structured logs suitable for independent replay.\n- Scope Protection: any simplification must preserve canonical-plan feature intent and be justified with explicit tradeoff documentation.","status":"open","priority":1,"issue_type":"epic","created_at":"2026-02-20T07:36:40.625682742Z","created_by":"ubuntu","updated_at":"2026-02-20T08:16:41.436986643Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-5"],"dependencies":[{"issue_id":"bd-20a","depends_on_id":"bd-137","type":"blocks","created_at":"2026-02-20T07:36:46.096981716Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-20a","depends_on_id":"bd-1koz","type":"blocks","created_at":"2026-02-20T07:48:24.613964616Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-20a","depends_on_id":"bd-1ta","type":"blocks","created_at":"2026-02-20T07:37:10.124940476Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-20a","depends_on_id":"bd-1xg","type":"blocks","created_at":"2026-02-20T07:37:10.085765636Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-20a","depends_on_id":"bd-21z","type":"blocks","created_at":"2026-02-20T07:36:46.176895270Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-20a","depends_on_id":"bd-2fa","type":"blocks","created_at":"2026-02-20T07:36:46.337388607Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-20a","depends_on_id":"bd-2yc","type":"blocks","created_at":"2026-02-20T07:36:46.420485430Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-20a","depends_on_id":"bd-33b","type":"blocks","created_at":"2026-02-20T07:36:46.500080260Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-20a","depends_on_id":"bd-3il","type":"blocks","created_at":"2026-02-20T07:37:10.047461638Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-20a","depends_on_id":"bd-3nr","type":"blocks","created_at":"2026-02-20T07:36:46.580197663Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-20a","depends_on_id":"bd-cda","type":"blocks","created_at":"2026-02-20T07:37:09.233010936Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-20a","depends_on_id":"bd-sh3","type":"blocks","created_at":"2026-02-20T07:36:46.658462145Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-20a","depends_on_id":"bd-vll","type":"blocks","created_at":"2026-02-20T07:36:46.258189635Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-20eg","title":"[10.15] Section-wide verification gate: comprehensive unit+e2e+logging","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.15\n\nTask Objective:\nCreate a hard section completion gate that verifies all implemented behavior in this section with comprehensive unit tests, integration/e2e scripts, and detailed structured logging evidence.\n\nAcceptance Criteria:\n- Section test matrix covers happy-path, edge-case, and adversarial/error-path scenarios for all section deliverables.\n- E2E scripts execute representative end-user workflows and policy/control-plane transitions for this section.\n- Structured logs include stable event/error codes, trace correlation IDs, and enough context for deterministic replay triage.\n- Verification report is deterministic and machine-readable for CI/release gating.\n\nExpected Artifacts:\n- Section-level test matrix and coverage summary artifact.\n- E2E script suite with pass/fail outputs and reproducible fixtures/seeds.\n- Structured log validation report and traceability bundle.\n- Gate verdict artifact consumable by release automation.\n\n- Machine-readable verification artifact at `artifacts/section_10_15/bd-20eg/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_15/bd-20eg/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests must validate contracts, invariants, and failure semantics.\n- E2E tests must validate cross-component behavior from user/operator entrypoints to persisted effects.\n- Logging must support root-cause analysis without hidden context requirements.\n\nTask-Specific Clarification:\n- For \"[10.15] Section-wide verification gate: comprehensive unit+e2e+logging\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.15] Section-wide verification gate: comprehensive unit+e2e+logging\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.15] Section-wide verification gate: comprehensive unit+e2e+logging\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.15] Section-wide verification gate: comprehensive unit+e2e+logging\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.15] Section-wide verification gate: comprehensive unit+e2e+logging\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:48:14.380295860Z","created_by":"ubuntu","updated_at":"2026-02-20T15:02:21.806383192Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-15","test-obligations","verification-gate"],"dependencies":[{"issue_id":"bd-20eg","depends_on_id":"bd-145n","type":"blocks","created_at":"2026-02-20T07:48:14.902052648Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-20eg","depends_on_id":"bd-15j6","type":"blocks","created_at":"2026-02-20T07:48:15.000448235Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-20eg","depends_on_id":"bd-181w","type":"blocks","created_at":"2026-02-20T07:48:15.096091826Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-20eg","depends_on_id":"bd-1cs7","type":"blocks","created_at":"2026-02-20T07:48:15.383228093Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-20eg","depends_on_id":"bd-1cwp","type":"blocks","created_at":"2026-02-20T07:48:15.191345371Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-20eg","depends_on_id":"bd-1dpd","type":"blocks","created_at":"2026-02-20T08:24:26.419698294Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-20eg","depends_on_id":"bd-1f8m","type":"blocks","created_at":"2026-02-20T07:48:14.620636757Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-20eg","depends_on_id":"bd-1hbw","type":"blocks","created_at":"2026-02-20T07:48:15.047427006Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-20eg","depends_on_id":"bd-1id0","type":"blocks","created_at":"2026-02-20T07:48:15.622846444Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-20eg","depends_on_id":"bd-1n5p","type":"blocks","created_at":"2026-02-20T07:48:15.334337551Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-20eg","depends_on_id":"bd-1xwz","type":"blocks","created_at":"2026-02-20T07:48:14.525913169Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-20eg","depends_on_id":"bd-2177","type":"blocks","created_at":"2026-02-20T07:48:15.570039929Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-20eg","depends_on_id":"bd-25oa","type":"blocks","created_at":"2026-02-20T07:48:14.765281165Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-20eg","depends_on_id":"bd-2g6r","type":"blocks","created_at":"2026-02-20T07:48:15.523039990Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-20eg","depends_on_id":"bd-2h2s","type":"blocks","created_at":"2026-02-20T07:48:14.573322111Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-20eg","depends_on_id":"bd-2tdi","type":"blocks","created_at":"2026-02-20T07:48:15.430358876Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-20eg","depends_on_id":"bd-2twu","type":"blocks","created_at":"2026-02-20T08:20:52.268307086Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-20eg","depends_on_id":"bd-3014","type":"blocks","created_at":"2026-02-20T07:48:15.238341905Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-20eg","depends_on_id":"bd-33kj","type":"blocks","created_at":"2026-02-20T07:48:14.476202260Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-20eg","depends_on_id":"bd-3epz","type":"blocks","created_at":"2026-02-20T15:02:21.806309495Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-20eg","depends_on_id":"bd-3gnh","type":"blocks","created_at":"2026-02-20T07:48:14.666356923Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-20eg","depends_on_id":"bd-3h63","type":"blocks","created_at":"2026-02-20T07:48:15.145068368Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-20eg","depends_on_id":"bd-3tpg","type":"blocks","created_at":"2026-02-20T07:48:14.856468736Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-20eg","depends_on_id":"bd-3u6o","type":"blocks","created_at":"2026-02-20T07:48:14.810956257Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-20eg","depends_on_id":"bd-721z","type":"blocks","created_at":"2026-02-20T07:48:15.476416351Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-20eg","depends_on_id":"bd-cuut","type":"blocks","created_at":"2026-02-20T07:48:15.284850720Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-20eg","depends_on_id":"bd-h93z","type":"blocks","created_at":"2026-02-20T07:48:14.719037824Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-20eg","depends_on_id":"bd-tyr2","type":"blocks","created_at":"2026-02-20T07:48:14.948864107Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-20l","title":"[10.1] Add ADR: \"Hybrid Baseline Strategy\" codifying no Bun-first clone, spec-first compatibility extraction, and native franken architecture from day one.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.1 — Charter + Split Governance\n\nWhy This Exists:\nProgram charter and governance baseline: split contracts, reproducibility, and anti-regression rules for strategic integrity.\n\nTask Objective:\nAdd ADR: \"Hybrid Baseline Strategy\" codifying no Bun-first clone, spec-first compatibility extraction, and native franken architecture from day one.\n\nAcceptance Criteria:\n- Implement with explicit success/failure invariants and deterministic behavior under normal, edge, and fault scenarios.\n- Ensure outcomes are verifiable via automated tests and reproducible artifact outputs.\n\nExpected Artifacts:\n- Section-owned design/spec artifact at `docs/specs/section_10_1/bd-20l_contract.md`, capturing decision rationale, invariants, and interface boundaries.\n- Machine-readable verification artifact at `artifacts/section_10_1/bd-20l/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_1/bd-20l/verification_summary.md` linking implementation intent to measured outcomes.\n\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.1] Add ADR: \"Hybrid Baseline Strategy\" codifying no Bun-first clone, spec-first compatibility extraction, and native franken architecture from day one.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.1] Add ADR: \"Hybrid Baseline Strategy\" codifying no Bun-first clone, spec-first compatibility extraction, and native franken architecture from day one.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.1] Add ADR: \"Hybrid Baseline Strategy\" codifying no Bun-first clone, spec-first compatibility extraction, and native franken architecture from day one.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.1] Add ADR: \"Hybrid Baseline Strategy\" codifying no Bun-first clone, spec-first compatibility extraction, and native franken architecture from day one.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.1] Add ADR: \"Hybrid Baseline Strategy\" codifying no Bun-first clone, spec-first compatibility extraction, and native franken architecture from day one.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","status":"closed","priority":1,"issue_type":"task","assignee":"CrimsonCrane","created_at":"2026-02-20T07:36:43.680535788Z","created_by":"ubuntu","updated_at":"2026-02-20T09:23:59.423500678Z","closed_at":"2026-02-20T09:23:59.423474329Z","close_reason":"done","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-1","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-20l","depends_on_id":"bd-1mj","type":"blocks","created_at":"2026-02-20T07:43:10.743693489Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-20uo","title":"[10.14] Integrate proof-carrying repair artifacts into decode/reconstruction paths.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.14 — FrankenSQLite Deep-Mined Expansion Execution Track (9J)\n\nWhy This Exists:\nFrankenSQLite deep-mined control integrity track: evidence ledgers, proofs, epochs, remote effects, markers/MMR, and deterministic fault labs.\n\nTask Objective:\nIntegrate proof-carrying repair artifacts into decode/reconstruction paths.\n\nAcceptance Criteria:\n- Repair operations emit proof metadata in required modes; proof verification API validates emitted artifacts; missing proofs are flagged where mandatory.\n\nExpected Artifacts:\n- `src/repair/proof_carrying_decode.rs`, `tests/conformance/proof_carrying_repair.rs`, `artifacts/10.14/repair_proof_samples.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_14/bd-20uo/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_14/bd-20uo/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.14] Integrate proof-carrying repair artifacts into decode/reconstruction paths.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.14] Integrate proof-carrying repair artifacts into decode/reconstruction paths.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.14] Integrate proof-carrying repair artifacts into decode/reconstruction paths.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.14] Integrate proof-carrying repair artifacts into decode/reconstruction paths.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.14] Integrate proof-carrying repair artifacts into decode/reconstruction paths.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"Repair operations emit proof metadata in required modes; proof verification API validates emitted artifacts; missing proofs are flagged where mandatory.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:36:56.625163980Z","created_by":"ubuntu","updated_at":"2026-02-20T15:44:08.839349643Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-14","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-20uo","depends_on_id":"bd-1l62","type":"blocks","created_at":"2026-02-20T07:43:14.980735544Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-20z","title":"[PLAN 10.11] FrankenSQLite-Inspired Runtime Systems Integration Track","description":"Section: 10.11 — FrankenSQLite-Inspired Runtime Systems Integration Track\n\nStrategic Context:\nFrankenSQLite-inspired systems integration of capabilities, cancellation protocol, obligations, deterministic labs, and anti-entropy.\n\nExecution Requirements:\n- Preserve all scoped capabilities from the canonical plan.\n- Keep contracts self-contained so future contributors can execute without reopening the master plan.\n- Require explicit testing strategy (unit + integration/e2e) and structured logging/telemetry for every child bead.\n- Require artifact-backed validation for performance, security, and correctness claims.\n\nDependency Semantics:\n- This epic is blocked by its child implementation beads.\n- Cross-epic dependencies encode strategic sequencing and canonical ownership boundaries.\n\n## Success Criteria\n- All child beads for this section are completed with acceptance artifacts attached and no unresolved blockers.\n- Section-level verification gate for comprehensive unit tests, integration/e2e workflows, and detailed structured logging evidence is green.\n- Scope-to-plan traceability is explicit, with no feature loss versus the canonical plan section.\n\n## Optimization Notes\n- User-Outcome Lens: \"[PLAN 10.11] FrankenSQLite-Inspired Runtime Systems Integration Track\" must improve operator confidence, safety posture, and deterministic recovery behavior under both normal and adversarial conditions.\n- Cross-Section Coordination: child beads must encode integration assumptions explicitly to avoid local optimizations that degrade system-wide correctness.\n- Verification Non-Negotiable: completion requires reproducible unit/integration/E2E evidence and structured logs suitable for independent replay.\n- Scope Protection: any simplification must preserve canonical-plan feature intent and be justified with explicit tradeoff documentation.","status":"open","priority":2,"issue_type":"epic","created_at":"2026-02-20T07:36:41.112788935Z","created_by":"ubuntu","updated_at":"2026-02-20T08:16:47.109184553Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-11"],"dependencies":[{"issue_id":"bd-20z","depends_on_id":"bd-1jpo","type":"blocks","created_at":"2026-02-20T07:48:08.241412787Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-20z","depends_on_id":"bd-24k","type":"blocks","created_at":"2026-02-20T07:36:50.018349403Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-20z","depends_on_id":"bd-2ah","type":"blocks","created_at":"2026-02-20T07:36:50.097560728Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-20z","depends_on_id":"bd-2gr","type":"blocks","created_at":"2026-02-20T07:36:50.507533577Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-20z","depends_on_id":"bd-2ko","type":"blocks","created_at":"2026-02-20T07:36:50.262374764Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-20z","depends_on_id":"bd-2nt","type":"blocks","created_at":"2026-02-20T07:36:50.423815637Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-20z","depends_on_id":"bd-390","type":"blocks","created_at":"2026-02-20T07:36:50.788797873Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-20z","depends_on_id":"bd-3he","type":"blocks","created_at":"2026-02-20T07:36:50.178419883Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-20z","depends_on_id":"bd-3hw","type":"blocks","created_at":"2026-02-20T07:36:50.592136395Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-20z","depends_on_id":"bd-3qo","type":"blocks","created_at":"2026-02-20T07:37:10.820071904Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-20z","depends_on_id":"bd-3u4","type":"blocks","created_at":"2026-02-20T07:36:50.344097979Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-20z","depends_on_id":"bd-3vm","type":"blocks","created_at":"2026-02-20T07:36:49.780345147Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-20z","depends_on_id":"bd-5rh","type":"blocks","created_at":"2026-02-20T07:37:10.781857082Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-20z","depends_on_id":"bd-7om","type":"blocks","created_at":"2026-02-20T07:36:49.938282063Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-20z","depends_on_id":"bd-93k","type":"blocks","created_at":"2026-02-20T07:36:49.859363223Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-20z","depends_on_id":"bd-cda","type":"blocks","created_at":"2026-02-20T07:37:09.466777348Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-20z","depends_on_id":"bd-cvt","type":"blocks","created_at":"2026-02-20T07:36:49.701076385Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-20z","depends_on_id":"bd-lus","type":"blocks","created_at":"2026-02-20T07:36:50.675525232Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-214l","title":"Epic: Radical Expansion - Verifier SDK + Claims [10.17d]","description":"- type: epic","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-20T07:47:58.072163029Z","updated_at":"2026-02-20T07:49:21.300299832Z","closed_at":"2026-02-20T07:49:21.300278963Z","close_reason":"Superseded by canonical detailed master-plan graph (bd-33v) with full 10.N-10.21 and 11-16 coverage, explicit dependencies, and per-section verification gates.","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-2177","title":"[10.15] Define high-impact workflow inventory mapped to required asupersync primitives.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.15 — Asupersync-First Integration Execution Track (8.4-8.6)\n\nWhy This Exists:\nAsupersync-first control-plane migration track enforcing Cx-first, region ownership, cancellation correctness, and protocol-grade verification gates.\n\nTask Objective:\nDefine high-impact workflow inventory mapped to required asupersync primitives.\n\nAcceptance Criteria:\n- Every critical workflow is mapped to `Cx`, region, cancellation, obligation, remote, epoch, and evidence requirements; unmapped workflows fail planning gate.\n\nExpected Artifacts:\n- `docs/architecture/high_impact_workflow_map.md`, `artifacts/10.15/workflow_primitive_matrix.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_15/bd-2177/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_15/bd-2177/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.15] Define high-impact workflow inventory mapped to required asupersync primitives.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.15] Define high-impact workflow inventory mapped to required asupersync primitives.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.15] Define high-impact workflow inventory mapped to required asupersync primitives.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.15] Define high-impact workflow inventory mapped to required asupersync primitives.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.15] Define high-impact workflow inventory mapped to required asupersync primitives.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- Every critical workflow is mapped to `Cx`, region, cancellation, obligation, remote, epoch, and evidence requirements; unmapped workflows fail planning gate.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:36:59.561049939Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:54.155311499Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-15","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-2177","depends_on_id":"bd-1id0","type":"blocks","created_at":"2026-02-20T07:43:16.496208957Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-21fo","title":"[10.17] Build self-evolving optimization governor with safety-envelope enforcement.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.17 — Radical Expansion Execution Track (9K)\n\nWhy This Exists:\nRadical expansion track for proof-carrying speculation, Bayesian adversary control, time-travel replay, ZK attestations, and claim compiler systems.\n\nTask Objective:\nBuild self-evolving optimization governor with safety-envelope enforcement.\n\nAcceptance Criteria:\n- Candidate optimizations require shadow evaluation plus anytime-valid safety checks; unsafe or non-beneficial policies auto-reject or auto-revert with evidence; governor can only adjust exposed runtime knobs, not local engine-core internals.\n\nExpected Artifacts:\n- `docs/specs/optimization_governor.md`, `src/perf/optimization_governor.rs`, `tests/perf/governor_safety_envelope.rs`, `artifacts/10.17/governor_decision_log.jsonl`.\n\n- Machine-readable verification artifact at `artifacts/section_10_17/bd-21fo/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_17/bd-21fo/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.17] Build self-evolving optimization governor with safety-envelope enforcement.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.17] Build self-evolving optimization governor with safety-envelope enforcement.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.17] Build self-evolving optimization governor with safety-envelope enforcement.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.17] Build self-evolving optimization governor with safety-envelope enforcement.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.17] Build self-evolving optimization governor with safety-envelope enforcement.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- Candidate optimizations require shadow evaluation plus anytime-valid safety checks; unsafe or non-beneficial policies auto-reject or auto-revert with evidence; governor can only adjust exposed runtime knobs, not local engine-core internals.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:37:03.598298856Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:59.308943834Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-17","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-21fo","depends_on_id":"bd-26mk","type":"blocks","created_at":"2026-02-20T07:43:18.603142707Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-21qe","title":"Epic: Charter + Split Governance [10.1]","description":"- type: epic","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-20T07:47:58.072163029Z","updated_at":"2026-02-20T07:49:21.089828756Z","closed_at":"2026-02-20T07:49:21.089805192Z","close_reason":"Superseded by canonical detailed master-plan graph (bd-33v) with full 10.N-10.21 and 11-16 coverage, explicit dependencies, and per-section verification gates.","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-21z","title":"[10.5] Implement signed decision receipt export for high-impact actions.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.5 — Security + Policy Product Surfaces (Item 2 of 8)\n\nWhy This Exists:\nSigned decision receipts are the audit backbone of the policy system. Every high-impact action (quarantine, revocation, policy change, deployment promotion) must produce a cryptographically signed receipt that captures the decision context, evidence used, action taken, and rollback path. This enables deterministic post-hoc analysis and external verification.\n\nTask Objective:\nImplement signed decision receipt export for all high-impact actions in the policy/control system.\n\nDetailed Acceptance Criteria:\n1. Decision receipt schema captures: action type, decision timestamp, evidence references (ledger entry IDs), actor identity, policy rule chain that authorized the action, confidence context, and rollback command.\n2. Receipts are cryptographically signed by the acting control-plane identity.\n3. Receipt export in both machine-readable (JSON) and human-readable formats.\n4. Receipts are append-only and hash-chained for tamper evidence.\n5. CLI surface: receipt export accessible via franken-node incident bundle and trust commands.\n6. Receipts integrate with evidence ledger (10.14) and operator copilot (10.0.8).\n7. High-impact action classes requiring receipts: quarantine, revocation, policy change, deployment promotion, trust-level transition.\n\nKey Dependencies:\n- Depends on 10.14 (FrankenSQLite Deep-Mined) for evidence ledger integration.\n- Depends on 10.13 (FCP Deep-Mined) for authenticated control channel.\n- Consumed by 10.8 (Operational Readiness) for incident bundle retention.\n- Consumed by 10.17 (Radical Expansion) for verifier SDK integration.\n\nExpected Artifacts:\n- src/security/decision_receipt.rs — receipt schema, signing, export.\n- CLI integration for receipt export in incident and trust commands.\n- docs/specs/section_10_5/bd-21z_contract.md\n- artifacts/section_10_5/bd-21z/verification_evidence.json\n\nTesting and Logging Requirements:\n- Unit tests: receipt construction, signing, hash chain integrity, schema validation.\n- Integration tests: full action -> receipt generation -> export -> verification pipeline.\n- E2E tests: franken-node incident bundle producing complete receipt chain.\n- Adversarial tests: receipt tampering detection, replay of receipts from different contexts.\n- Structured logs: DECISION_RECEIPT_GENERATED, RECEIPT_SIGNED, RECEIPT_EXPORTED, HASH_CHAIN_VERIFIED with trace IDs.","acceptance_criteria":"1. Define a SignedReceipt struct with fields: receipt_id (UUID v7), action_name (string), actor_identity (string), timestamp (RFC-3339), input_hash (SHA-256 of serialized action input), output_hash (SHA-256 of serialized action output), decision (enum: Approved | Denied | Escalated), rationale (string), and signature (Ed25519 detached signature, base64-encoded).\n2. Implement sign_receipt(receipt: &Receipt, signing_key: &Ed25519PrivateKey) -> SignedReceipt that produces a deterministic canonical JSON serialization before signing (keys sorted, no optional whitespace).\n3. Implement verify_receipt(signed: &SignedReceipt, public_key: &Ed25519PublicKey) -> Result<bool> that returns true only if the signature matches the canonical form.\n4. High-impact actions are tagged via a #[high_impact] attribute macro or a runtime registry; any action so tagged must produce a receipt or the call returns Err.\n5. Receipts must be exportable as both JSON and CBOR; round-trip fidelity test must pass (deserialize(serialize(r)) == r).\n6. Provide an export_receipts(filter: ReceiptQuery) -> Vec<SignedReceipt> query API supporting time-range and action-name filters.\n7. Verification: scripts/check_signed_receipt.py --json validates signature correctness on sample receipts; unit tests cover sign, verify, tamper-detection (flipped bit fails verify), and round-trip; evidence artifact in artifacts/section_10_5/bd-21z/.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:36:46.140259819Z","created_by":"ubuntu","updated_at":"2026-02-20T15:15:11.072797345Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-5","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-21z","depends_on_id":"bd-137","type":"blocks","created_at":"2026-02-20T07:43:22.789468367Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-229","title":"[PLAN 10.3] Migration System","description":"Section: 10.3 — Migration System\n\nStrategic Context:\nMigration autopilot pipeline from audit to rollout, designed to collapse migration friction with deterministic confidence and replayability.\n\nExecution Requirements:\n- Preserve all scoped capabilities from the canonical plan.\n- Keep contracts self-contained so future contributors can execute without reopening the master plan.\n- Require explicit testing strategy (unit + integration/e2e) and structured logging/telemetry for every child bead.\n- Require artifact-backed validation for performance, security, and correctness claims.\n\nDependency Semantics:\n- This epic is blocked by its child implementation beads.\n- Cross-epic dependencies encode strategic sequencing and canonical ownership boundaries.\n\n## Success Criteria\n- All child beads for this section are completed with acceptance artifacts attached and no unresolved blockers.\n- Section-level verification gate for comprehensive unit tests, integration/e2e workflows, and detailed structured logging evidence is green.\n- Scope-to-plan traceability is explicit, with no feature loss versus the canonical plan section.\n\n## Optimization Notes\n- User-Outcome Lens: \"[PLAN 10.3] Migration System\" must improve operator confidence, safety posture, and deterministic recovery behavior under both normal and adversarial conditions.\n- Cross-Section Coordination: child beads must encode integration assumptions explicitly to avoid local optimizations that degrade system-wide correctness.\n- Verification Non-Negotiable: completion requires reproducible unit/integration/E2E evidence and structured logs suitable for independent replay.\n- Scope Protection: any simplification must preserve canonical-plan feature intent and be justified with explicit tradeoff documentation.","status":"closed","priority":1,"issue_type":"epic","created_at":"2026-02-20T07:36:40.464258670Z","created_by":"ubuntu","updated_at":"2026-02-20T10:23:12.513827884Z","closed_at":"2026-02-20T10:23:12.513802988Z","close_reason":"done","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-3"],"dependencies":[{"issue_id":"bd-229","depends_on_id":"bd-12f","type":"blocks","created_at":"2026-02-20T07:36:45.226343355Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-229","depends_on_id":"bd-2a0","type":"blocks","created_at":"2026-02-20T07:36:44.833338372Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-229","depends_on_id":"bd-2ew","type":"blocks","created_at":"2026-02-20T07:36:44.993367595Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-229","depends_on_id":"bd-2st","type":"blocks","created_at":"2026-02-20T07:36:45.071858368Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-229","depends_on_id":"bd-33x","type":"blocks","created_at":"2026-02-20T07:36:44.913766113Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-229","depends_on_id":"bd-3dn","type":"blocks","created_at":"2026-02-20T07:36:45.149421614Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-229","depends_on_id":"bd-3enl","type":"blocks","created_at":"2026-02-20T07:48:23.311983086Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-229","depends_on_id":"bd-3f9","type":"blocks","created_at":"2026-02-20T07:36:45.385689926Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-229","depends_on_id":"bd-3il","type":"blocks","created_at":"2026-02-20T07:37:09.932613653Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-229","depends_on_id":"bd-cda","type":"blocks","created_at":"2026-02-20T07:37:09.153087314Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-229","depends_on_id":"bd-hg1","type":"blocks","created_at":"2026-02-20T07:36:45.303263873Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-22yy","title":"[10.14] Add DPOR-style schedule exploration gates for control/epoch/remote protocols.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.14 — FrankenSQLite Deep-Mined Expansion Execution Track (9J)\n\nWhy This Exists:\nFrankenSQLite deep-mined control integrity track: evidence ledgers, proofs, epochs, remote effects, markers/MMR, and deterministic fault labs.\n\nTask Objective:\nAdd DPOR-style schedule exploration gates for control/epoch/remote protocols.\n\nAcceptance Criteria:\n- DPOR explorer covers targeted protocol classes; minimal counterexample traces are emitted on failure; gate runs within bounded CI budget.\n\nExpected Artifacts:\n- `tests/lab/dpor_protocol_exploration.rs`, `docs/testing/dpor_gate_scope.md`, `artifacts/10.14/dpor_exploration_summary.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_14/bd-22yy/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_14/bd-22yy/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.14] Add DPOR-style schedule exploration gates for control/epoch/remote protocols.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.14] Add DPOR-style schedule exploration gates for control/epoch/remote protocols.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.14] Add DPOR-style schedule exploration gates for control/epoch/remote protocols.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.14] Add DPOR-style schedule exploration gates for control/epoch/remote protocols.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.14] Add DPOR-style schedule exploration gates for control/epoch/remote protocols.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"DPOR explorer covers targeted protocol classes; minimal counterexample traces are emitted on failure; gate runs within bounded CI budget.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:36:59.312014395Z","created_by":"ubuntu","updated_at":"2026-02-20T15:44:01.979742641Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-14","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-22yy","depends_on_id":"bd-876n","type":"blocks","created_at":"2026-02-20T07:43:16.358057063Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-232t","title":"[10.21] Integrate BPET trajectory signals into trust cards and adversary graph posterior updates.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.21 — Behavioral Phenotype Evolution Tracker Execution Track (9O)\n\nWhy This Exists:\nBPET longitudinal phenotype intelligence track for pre-compromise trajectory detection and integration with DGIS/ATC/migration/economic policy.\n\nTask Objective:\nIntegrate BPET trajectory signals into trust cards and adversary graph posterior updates.\n\nAcceptance Criteria:\n- Trust surfaces show \"current state + trajectory path\" with interpretable risk deltas; adversary posteriors account for evolution velocity and suspicious sequence motifs.\n\nExpected Artifacts:\n- `src/security/bpet/trust_surface_integration.rs`, `tests/integration/bpet_trust_card_integration.rs`, `artifacts/10.21/bpet_trust_surface_snapshot.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_21/bd-232t/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_21/bd-232t/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.21] Integrate BPET trajectory signals into trust cards and adversary graph posterior updates.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.21] Integrate BPET trajectory signals into trust cards and adversary graph posterior updates.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.21] Integrate BPET trajectory signals into trust cards and adversary graph posterior updates.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.21] Integrate BPET trajectory signals into trust cards and adversary graph posterior updates.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.21] Integrate BPET trajectory signals into trust cards and adversary graph posterior updates.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- Trust surfaces show \"current state + trajectory path\" with interpretable risk deltas; adversary posteriors account for evolution velocity and suspicious sequence motifs.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:37:08.376285199Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:19.516280747Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-21","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-232t","depends_on_id":"bd-1jpc","type":"blocks","created_at":"2026-02-20T07:43:21.607695949Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-23ys","title":"[10.2] Section-wide verification gate: comprehensive unit+e2e+logging","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.2\n\nTask Objective:\nCreate a hard section completion gate that verifies all implemented behavior in this section with comprehensive unit tests, integration/e2e scripts, and detailed structured logging evidence.\n\nAcceptance Criteria:\n- Section test matrix covers happy-path, edge-case, and adversarial/error-path scenarios for all section deliverables.\n- E2E scripts execute representative end-user workflows and policy/control-plane transitions for this section.\n- Structured logs include stable event/error codes, trace correlation IDs, and enough context for deterministic replay triage.\n- Verification report is deterministic and machine-readable for CI/release gating.\n\nExpected Artifacts:\n- Section-level test matrix and coverage summary artifact.\n- E2E script suite with pass/fail outputs and reproducible fixtures/seeds.\n- Structured log validation report and traceability bundle.\n- Gate verdict artifact consumable by release automation.\n\n- Machine-readable verification artifact at `artifacts/section_10_2/bd-23ys/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_2/bd-23ys/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests must validate contracts, invariants, and failure semantics.\n- E2E tests must validate cross-component behavior from user/operator entrypoints to persisted effects.\n- Logging must support root-cause analysis without hidden context requirements.\n\nTask-Specific Clarification:\n- For \"[10.2] Section-wide verification gate: comprehensive unit+e2e+logging\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.2] Section-wide verification gate: comprehensive unit+e2e+logging\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.2] Section-wide verification gate: comprehensive unit+e2e+logging\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.2] Section-wide verification gate: comprehensive unit+e2e+logging\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.2] Section-wide verification gate: comprehensive unit+e2e+logging\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","status":"closed","priority":1,"issue_type":"task","assignee":"CrimsonCrane","created_at":"2026-02-20T07:48:19.853287882Z","created_by":"ubuntu","updated_at":"2026-02-20T10:05:13.441850691Z","closed_at":"2026-02-20T10:05:13.441825414Z","close_reason":"done","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-2","test-obligations","verification-gate"],"dependencies":[{"issue_id":"bd-23ys","depends_on_id":"bd-1ck","type":"blocks","created_at":"2026-02-20T07:48:20.135370837Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-23ys","depends_on_id":"bd-1dpd","type":"blocks","created_at":"2026-02-20T08:24:25.739671273Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-23ys","depends_on_id":"bd-1z3","type":"blocks","created_at":"2026-02-20T07:48:20.274745139Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-23ys","depends_on_id":"bd-240","type":"blocks","created_at":"2026-02-20T07:48:20.086658337Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-23ys","depends_on_id":"bd-2hs","type":"blocks","created_at":"2026-02-20T07:48:20.040594050Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-23ys","depends_on_id":"bd-2kf","type":"blocks","created_at":"2026-02-20T07:48:20.320334281Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-23ys","depends_on_id":"bd-2qf","type":"blocks","created_at":"2026-02-20T07:48:20.411648378Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-23ys","depends_on_id":"bd-2twu","type":"blocks","created_at":"2026-02-20T08:20:51.476069017Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-23ys","depends_on_id":"bd-2vi","type":"blocks","created_at":"2026-02-20T07:48:20.226260003Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-23ys","depends_on_id":"bd-2wz","type":"blocks","created_at":"2026-02-20T07:48:20.457425080Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-23ys","depends_on_id":"bd-32v","type":"blocks","created_at":"2026-02-20T07:48:20.180919113Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-23ys","depends_on_id":"bd-38l","type":"blocks","created_at":"2026-02-20T07:48:20.365949782Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-23ys","depends_on_id":"bd-7mt","type":"blocks","created_at":"2026-02-20T07:48:19.948593724Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-23ys","depends_on_id":"bd-80g","type":"blocks","created_at":"2026-02-20T07:48:19.994743491Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-240","title":"[10.2] Implement compatibility regression dashboard by API family.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.2 — Compatibility Core\n\nWhy This Exists:\nCompatibility core as strategic wedge: policy-visible behavior, divergence receipts, L1/L2 lockstep, and spec-first fixture governance.\n\nTask Objective:\nImplement compatibility regression dashboard by API family.\n\nAcceptance Criteria:\n- Implement with explicit success/failure invariants and deterministic behavior under normal, edge, and fault scenarios.\n- Ensure outcomes are verifiable via automated tests and reproducible artifact outputs.\n\nExpected Artifacts:\n- Section-owned design/spec artifact at `docs/specs/section_10_2/bd-240_contract.md`, capturing decision rationale, invariants, and interface boundaries.\n- Machine-readable verification artifact at `artifacts/section_10_2/bd-240/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_2/bd-240/verification_summary.md` linking implementation intent to measured outcomes.\n\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.2] Implement compatibility regression dashboard by API family.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.2] Implement compatibility regression dashboard by API family.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.2] Implement compatibility regression dashboard by API family.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.2] Implement compatibility regression dashboard by API family.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.2] Implement compatibility regression dashboard by API family.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","status":"closed","priority":1,"issue_type":"task","assignee":"CrimsonCrane","created_at":"2026-02-20T07:36:44.483262502Z","created_by":"ubuntu","updated_at":"2026-02-20T09:48:27.583939849Z","closed_at":"2026-02-20T09:48:27.583912297Z","close_reason":"done","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-2","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-240","depends_on_id":"bd-1ck","type":"blocks","created_at":"2026-02-20T07:43:20.390854638Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-2437","title":"Epic: Connector Lifecycle + State Management [10.13a]","description":"- type: epic","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-20T07:47:58.072163029Z","updated_at":"2026-02-20T07:49:21.159047190Z","closed_at":"2026-02-20T07:49:21.159027133Z","close_reason":"Superseded by canonical detailed master-plan graph (bd-33v) with full 10.N-10.21 and 11-16 coverage, explicit dependencies, and per-section verification gates.","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-24du","title":"[10.19] Define ATC degraded/offline modes and local-first fallback behavior.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.19 — Adversarial Trust Commons Execution Track (9M)\n\nWhy This Exists:\nATC federated intelligence track for privacy-preserving cross-deployment threat learning, robust aggregation, and verifier-backed trust metrics.\n\nTask Objective:\nDefine ATC degraded/offline modes and local-first fallback behavior.\n\nAcceptance Criteria:\n- Federation outage or partition triggers deterministic fallback policy; local risk controls remain functional; rejoin/reconciliation is audited.\n\nExpected Artifacts:\n- `docs/specs/atc_degraded_mode.md`, `tests/integration/atc_partition_fallback.rs`, `artifacts/10.19/atc_degraded_mode_events.jsonl`.\n\n- Machine-readable verification artifact at `artifacts/section_10_19/bd-24du/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_19/bd-24du/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.19] Define ATC degraded/offline modes and local-first fallback behavior.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.19] Define ATC degraded/offline modes and local-first fallback behavior.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.19] Define ATC degraded/offline modes and local-first fallback behavior.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.19] Define ATC degraded/offline modes and local-first fallback behavior.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.19] Define ATC degraded/offline modes and local-first fallback behavior.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- Federation outage or partition triggers deterministic fallback policy; local risk controls remain functional; rejoin/reconciliation is audited.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:37:06.252412913Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:19.756325152Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-19","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-24du","depends_on_id":"bd-2zip","type":"blocks","created_at":"2026-02-20T07:43:19.956967796Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-24k","title":"[10.11] Implement bounded masking helper for tiny atomic product operations.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.11 — FrankenSQLite-Inspired Runtime Systems Integration Track\n\nWhy This Exists:\nFrankenSQLite-inspired systems integration of capabilities, cancellation protocol, obligations, deterministic labs, and anti-entropy.\n\nTask Objective:\nImplement bounded masking helper for tiny atomic product operations.\n\nAcceptance Criteria:\n- Implement with explicit success/failure invariants and deterministic behavior under normal, edge, and fault scenarios.\n- Ensure outcomes are verifiable via automated tests and reproducible artifact outputs.\n\nExpected Artifacts:\n- Section-owned design/spec artifact at `docs/specs/section_10_11/bd-24k_contract.md`, capturing decision rationale, invariants, and interface boundaries.\n- Machine-readable verification artifact at `artifacts/section_10_11/bd-24k/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_11/bd-24k/verification_summary.md` linking implementation intent to measured outcomes.\n\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.11] Implement bounded masking helper for tiny atomic product operations.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.11] Implement bounded masking helper for tiny atomic product operations.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.11] Implement bounded masking helper for tiny atomic product operations.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.11] Implement bounded masking helper for tiny atomic product operations.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.11] Implement bounded masking helper for tiny atomic product operations.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"AC for bd-24k:\n1. A BoundedMask<T> helper type wraps tiny atomic operations (operations completing in bounded constant time, no I/O, no allocation) and suppresses cancellation signals for their duration.\n2. The masking window has a compile-time upper bound (MAX_MASK_DURATION_NS constant, default 1 microsecond); any operation exceeding this bound in test mode triggers a MASK_BUDGET_EXCEEDED warning.\n3. BoundedMask<T> implements a scoped guard pattern: cancellation tokens are checked before entering the mask and immediately after exiting; cancellation that arrives during the masked window is deferred, not dropped.\n4. The mask is NOT nestable: attempting to create a BoundedMask inside an existing BoundedMask panics with MASK_NESTING_VIOLATION to prevent unbounded masking chains.\n5. Operations inside a BoundedMask must not perform any async .await, heap allocation, or I/O syscall; a debug-mode assertion verifies no .await points exist within the masked scope (or a lint enforces this).\n6. Unit tests verify: (a) cancellation arriving during masked window is deferred and delivered after mask drops, (b) mask nesting panics, (c) operation completing within budget succeeds silently, (d) operation exceeding budget in test mode emits MASK_BUDGET_EXCEEDED, (e) cancellation before mask entry aborts immediately without entering the mask.\n7. Structured log events: MASK_ENTER / MASK_EXIT / MASK_BUDGET_EXCEEDED / MASK_NESTING_VIOLATION with operation name and elapsed nanoseconds.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:36:49.981757845Z","created_by":"ubuntu","updated_at":"2026-02-20T15:18:14.951832581Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-11","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-24k","depends_on_id":"bd-7om","type":"blocks","created_at":"2026-02-20T07:43:11.495497880Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-24s","title":"[10.13] Implement snapshot policy (`every_updates`, `every_bytes`) and bounded replay targets for connector state.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.13 — FCP Deep-Mined Expansion Execution Track (9I)\n\nWhy This Exists:\nDeep connector/provider contract track: lifecycle FSMs, conformance harnesses, fencing, sandboxing, revocation freshness, and protocol hardening.\n\nTask Objective:\nImplement snapshot policy (`every_updates`, `every_bytes`) and bounded replay targets for connector state.\n\nAcceptance Criteria:\n- Replay cost is bounded by configured thresholds; snapshots are validated against chain heads; snapshot policy changes are audited.\n\nExpected Artifacts:\n- `docs/specs/state_snapshot_policy.md`, `tests/perf/state_replay_bound.rs`, `artifacts/10.13/snapshot_policy_benchmark.csv`.\n\n- Machine-readable verification artifact at `artifacts/section_10_13/bd-24s/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_13/bd-24s/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.13] Implement snapshot policy (`every_updates`, `every_bytes`) and bounded replay targets for connector state.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.13] Implement snapshot policy (`every_updates`, `every_bytes`) and bounded replay targets for connector state.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.13] Implement snapshot policy (`every_updates`, `every_bytes`) and bounded replay targets for connector state.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.13] Implement snapshot policy (`every_updates`, `every_bytes`) and bounded replay targets for connector state.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.13] Implement snapshot policy (`every_updates`, `every_bytes`) and bounded replay targets for connector state.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","status":"closed","priority":1,"issue_type":"task","assignee":"CrimsonCrane","created_at":"2026-02-20T07:36:51.960580991Z","created_by":"ubuntu","updated_at":"2026-02-20T11:03:46.573161408Z","closed_at":"2026-02-20T11:03:46.573132714Z","close_reason":"done","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-13","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-24s","depends_on_id":"bd-19u","type":"blocks","created_at":"2026-02-20T07:43:12.524092544Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-253o","title":"[10.19] Integrate ATC global priors into Bayesian adversary graph and risk scoring pipelines.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.19 — Adversarial Trust Commons Execution Track (9M)\n\nWhy This Exists:\nATC federated intelligence track for privacy-preserving cross-deployment threat learning, robust aggregation, and verifier-backed trust metrics.\n\nTask Objective:\nIntegrate ATC global priors into Bayesian adversary graph and risk scoring pipelines.\n\nAcceptance Criteria:\n- Global priors influence local posterior updates under explicit weighting policy; local-vs-global attribution is explainable in evidence outputs.\n\nExpected Artifacts:\n- `src/security/adversary_graph_federated_priors.rs`, `tests/integration/atc_bayesian_prior_integration.rs`, `artifacts/10.19/atc_prior_influence_report.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_19/bd-253o/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_19/bd-253o/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.19] Integrate ATC global priors into Bayesian adversary graph and risk scoring pipelines.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.19] Integrate ATC global priors into Bayesian adversary graph and risk scoring pipelines.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.19] Integrate ATC global priors into Bayesian adversary graph and risk scoring pipelines.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.19] Integrate ATC global priors into Bayesian adversary graph and risk scoring pipelines.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.19] Integrate ATC global priors into Bayesian adversary graph and risk scoring pipelines.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- Global priors influence local posterior updates under explicit weighting policy; local-vs-global attribution is explainable in evidence outputs.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:37:06.003325443Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:19.983706574Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-19","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-253o","depends_on_id":"bd-3aqy","type":"blocks","created_at":"2026-02-20T15:01:14.848488682Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-253o","depends_on_id":"bd-3gwi","type":"blocks","created_at":"2026-02-20T07:43:19.830484114Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-2573","title":"[10.14] Define object-class profile registry (critical marker, trust receipt, replay bundle, telemetry artifact).","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.14 — FrankenSQLite Deep-Mined Expansion Execution Track (9J)\n\nWhy This Exists:\nFrankenSQLite deep-mined control integrity track: evidence ledgers, proofs, epochs, remote effects, markers/MMR, and deterministic fault labs.\n\nTask Objective:\nDefine object-class profile registry (critical marker, trust receipt, replay bundle, telemetry artifact).\n\nAcceptance Criteria:\n- Registry includes required classes and default policies; unknown class usage fails validation; class definitions are versioned.\n\nExpected Artifacts:\n- `docs/specs/object_class_profiles.md`, `config/object_class_profiles.toml`, `artifacts/10.14/object_class_registry.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_14/bd-2573/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_14/bd-2573/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.14] Define object-class profile registry (critical marker, trust receipt, replay bundle, telemetry artifact).\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.14] Define object-class profile registry (critical marker, trust receipt, replay bundle, telemetry artifact).\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.14] Define object-class profile registry (critical marker, trust receipt, replay bundle, telemetry artifact).\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.14] Define object-class profile registry (critical marker, trust receipt, replay bundle, telemetry artifact).\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.14] Define object-class profile registry (critical marker, trust receipt, replay bundle, telemetry artifact).\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"Registry includes required classes and default policies; unknown class usage fails validation; class definitions are versioned.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:36:57.055364136Z","created_by":"ubuntu","updated_at":"2026-02-20T15:44:07.781774785Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-14","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-2573","depends_on_id":"bd-1iyx","type":"blocks","created_at":"2026-02-20T07:43:15.190044015Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-25nl","title":"[10.14] Implement root-auth fail-closed bootstrap checks before accepting manifest updates.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.14 — FrankenSQLite Deep-Mined Expansion Execution Track (9J)\n\nWhy This Exists:\nFrankenSQLite deep-mined control integrity track: evidence ledgers, proofs, epochs, remote effects, markers/MMR, and deterministic fault labs.\n\nTask Objective:\nImplement root-auth fail-closed bootstrap checks before accepting manifest updates.\n\nAcceptance Criteria:\n- Bootstrap rejects unauthenticated or malformed root pointers; acceptance requires valid auth material and version checks; failures are diagnosable.\n\nExpected Artifacts:\n- `tests/security/root_bootstrap_fail_closed.rs`, `docs/specs/root_bootstrap_auth.md`, `artifacts/10.14/root_bootstrap_validation_report.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_14/bd-25nl/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_14/bd-25nl/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.14] Implement root-auth fail-closed bootstrap checks before accepting manifest updates.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.14] Implement root-auth fail-closed bootstrap checks before accepting manifest updates.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.14] Implement root-auth fail-closed bootstrap checks before accepting manifest updates.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.14] Implement root-auth fail-closed bootstrap checks before accepting manifest updates.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.14] Implement root-auth fail-closed bootstrap checks before accepting manifest updates.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"Bootstrap rejects unauthenticated or malformed root pointers; acceptance requires valid auth material and version checks; failures are diagnosable.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:36:58.955425474Z","created_by":"ubuntu","updated_at":"2026-02-20T15:44:02.839806800Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-14","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-25nl","depends_on_id":"bd-nwhn","type":"blocks","created_at":"2026-02-20T07:43:16.188914520Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-25oa","title":"[10.15] Enforce canonical DPOR-style schedule exploration (from `10.14`) for epoch/lease/remote/evidence interactions.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.15 — Asupersync-First Integration Execution Track (8.4-8.6)\n\nWhy This Exists:\nAsupersync-first control-plane migration track enforcing Cx-first, region ownership, cancellation correctness, and protocol-grade verification gates.\n\nTask Objective:\nEnforce canonical DPOR-style schedule exploration (from `10.14`) for epoch/lease/remote/evidence interactions.\n\nAcceptance Criteria:\n- Canonical explorer covers targeted protocol classes with bounded CI budget; minimal counterexample traces are emitted on violations and consumed by control-plane release gates.\n\nExpected Artifacts:\n- `tests/lab/control_dpor_exploration.rs`, `docs/testing/control_dpor_scope.md`, `artifacts/10.15/control_dpor_results.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_15/bd-25oa/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_15/bd-25oa/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.15] Enforce canonical DPOR-style schedule exploration (from `10.14`) for epoch/lease/remote/evidence interactions.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.15] Enforce canonical DPOR-style schedule exploration (from `10.14`) for epoch/lease/remote/evidence interactions.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.15] Enforce canonical DPOR-style schedule exploration (from `10.14`) for epoch/lease/remote/evidence interactions.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.15] Enforce canonical DPOR-style schedule exploration (from `10.14`) for epoch/lease/remote/evidence interactions.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.15] Enforce canonical DPOR-style schedule exploration (from `10.14`) for epoch/lease/remote/evidence interactions.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- Canonical explorer covers targeted protocol classes with bounded CI budget; minimal counterexample traces are emitted on violations and consumed by control-plane release gates.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:37:00.955164951Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:50.118767266Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-15","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-25oa","depends_on_id":"bd-22yy","type":"blocks","created_at":"2026-02-20T14:59:47.448553095Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-25oa","depends_on_id":"bd-3u6o","type":"blocks","created_at":"2026-02-20T07:43:17.224264688Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-261k","title":"[10.4] Section-wide verification gate: comprehensive unit+e2e+logging","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.4\n\nTask Objective:\nCreate a hard section completion gate that verifies all implemented behavior in this section with comprehensive unit tests, integration/e2e scripts, and detailed structured logging evidence.\n\nAcceptance Criteria:\n(See structured acceptance_criteria field for domain-specific criteria.)\n\n- Machine-readable verification artifact at `artifacts/section_10_4/bd-261k/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_4/bd-261k/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests must validate contracts, invariants, and failure semantics.\n- E2E tests must validate cross-component behavior from user/operator entrypoints to persisted effects.\n- Logging must support root-cause analysis without hidden context requirements.\n\nTask-Specific Clarification:\n- For \"[10.4] Section-wide verification gate: comprehensive unit+e2e+logging\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.4] Section-wide verification gate: comprehensive unit+e2e+logging\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.4] Section-wide verification gate: comprehensive unit+e2e+logging\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.4] Section-wide verification gate: comprehensive unit+e2e+logging\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.4] Section-wide verification gate: comprehensive unit+e2e+logging\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"1. Gate script (scripts/gate_section_10_4.py) runs all 8 section bead verification scripts in dependency order; any single bead failure fails the gate. 2. Unit test coverage: each bead's verification script (check_*.py) has a companion test file (test_check_*.py) with >=90% line coverage on the verification logic; coverage is measured and reported in the gate artifact. 3. Integration/E2E test suite covers the following cross-bead workflows: (a) full extension lifecycle: manifest creation -> signing -> provenance attestation -> registry publish -> trust card generation -> install with freshness check, (b) quarantine flow: publish extension -> trigger revocation -> verify quarantine enacted -> verify trust card updated -> verify fleet recall propagation, (c) certification upgrade path: uncertified extension -> add provenance -> reach Community -> add reproducibility -> reach Verified, (d) reputation impact: simulate security incident -> verify publisher reputation downgrade -> verify dependent extension certification downgrade -> verify telemetry anomaly alert. 4. Structured log validation: all 8 bead implementations emit their specified structured log events; gate verifies each event code appears in test logs with required fields present and non-empty. 5. Deterministic replay: each E2E test produces a fixture file that can be replayed to reproduce the exact same test outcome; replay fixtures are stored in fixtures/section_10_4/. 6. Gate produces machine-readable verdict at artifacts/section_10_4/bd-261k/verification_evidence.json with fields: gate_pass (bool), beads_tested[], per_bead_results[] (each with bead_id, unit_pass, integration_pass, log_events_validated), overall_coverage_pct, and timestamp. 7. Gate produces human-readable summary at artifacts/section_10_4/bd-261k/verification_summary.md with pass/fail table, coverage stats, and links to individual bead evidence. 8. All tests run without network access (air-gapped mode) using mock registry and mock revocation endpoints; test fixtures provide deterministic responses. 9. Gate execution completes within 5 minutes on a standard CI runner. 10. Gate is idempotent: running it twice with no code changes produces identical verdict artifacts (same content hash).","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:48:23.478467151Z","created_by":"ubuntu","updated_at":"2026-02-20T15:18:42.307533816Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-4","test-obligations","verification-gate"],"dependencies":[{"issue_id":"bd-261k","depends_on_id":"bd-12q","type":"blocks","created_at":"2026-02-20T07:48:23.815919644Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-261k","depends_on_id":"bd-1ah","type":"blocks","created_at":"2026-02-20T07:48:23.862901270Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-261k","depends_on_id":"bd-1dpd","type":"blocks","created_at":"2026-02-20T08:24:25.152773401Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-261k","depends_on_id":"bd-1gx","type":"blocks","created_at":"2026-02-20T07:48:23.912287455Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-261k","depends_on_id":"bd-1vm","type":"blocks","created_at":"2026-02-20T07:48:23.673400936Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-261k","depends_on_id":"bd-273","type":"blocks","created_at":"2026-02-20T07:48:23.625599543Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-261k","depends_on_id":"bd-2twu","type":"blocks","created_at":"2026-02-20T08:20:50.800068266Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-261k","depends_on_id":"bd-2yh","type":"blocks","created_at":"2026-02-20T07:48:23.766314863Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-261k","depends_on_id":"bd-ml1","type":"blocks","created_at":"2026-02-20T07:48:23.713120646Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-261k","depends_on_id":"bd-phf","type":"blocks","created_at":"2026-02-20T07:48:23.578140488Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-26k","title":"[PLAN 10.9] Moonshot Disruption Track","description":"Section: 10.9 — Moonshot Disruption Track\n\nStrategic Context:\nMoonshot disruption track for public benchmark leadership, adversarial campaigns, verifier economy, and category-shift reporting.\n\nExecution Requirements:\n- Preserve all scoped capabilities from the canonical plan.\n- Keep contracts self-contained so future contributors can execute without reopening the master plan.\n- Require explicit testing strategy (unit + integration/e2e) and structured logging/telemetry for every child bead.\n- Require artifact-backed validation for performance, security, and correctness claims.\n\nDependency Semantics:\n- This epic is blocked by its child implementation beads.\n- Cross-epic dependencies encode strategic sequencing and canonical ownership boundaries.\n\n## Success Criteria\n- All child beads for this section are completed with acceptance artifacts attached and no unresolved blockers.\n- Section-level verification gate for comprehensive unit tests, integration/e2e workflows, and detailed structured logging evidence is green.\n- Scope-to-plan traceability is explicit, with no feature loss versus the canonical plan section.\n\n## Optimization Notes\n- User-Outcome Lens: \"[PLAN 10.9] Moonshot Disruption Track\" must improve operator confidence, safety posture, and deterministic recovery behavior under both normal and adversarial conditions.\n- Cross-Section Coordination: child beads must encode integration assumptions explicitly to avoid local optimizations that degrade system-wide correctness.\n- Verification Non-Negotiable: completion requires reproducible unit/integration/E2E evidence and structured logs suitable for independent replay.\n- Scope Protection: any simplification must preserve canonical-plan feature intent and be justified with explicit tradeoff documentation.","status":"open","priority":2,"issue_type":"epic","created_at":"2026-02-20T07:36:40.950883086Z","created_by":"ubuntu","updated_at":"2026-02-20T08:16:47.979293914Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-9"],"dependencies":[{"issue_id":"bd-26k","depends_on_id":"bd-10c","type":"blocks","created_at":"2026-02-20T07:36:48.638742405Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-26k","depends_on_id":"bd-15t","type":"blocks","created_at":"2026-02-20T07:36:48.717638904Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-26k","depends_on_id":"bd-1e0","type":"blocks","created_at":"2026-02-20T07:36:48.481628402Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-26k","depends_on_id":"bd-1kfq","type":"blocks","created_at":"2026-02-20T07:48:26.958413458Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-26k","depends_on_id":"bd-1xg","type":"blocks","created_at":"2026-02-20T07:37:10.629763520Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-26k","depends_on_id":"bd-20a","type":"blocks","created_at":"2026-02-20T07:37:10.668196839Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-26k","depends_on_id":"bd-229","type":"blocks","created_at":"2026-02-20T07:37:10.588594125Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-26k","depends_on_id":"bd-3il","type":"blocks","created_at":"2026-02-20T07:37:10.550584435Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-26k","depends_on_id":"bd-9is","type":"blocks","created_at":"2026-02-20T07:36:48.401730338Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-26k","depends_on_id":"bd-cda","type":"blocks","created_at":"2026-02-20T07:37:09.388900058Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-26k","depends_on_id":"bd-f5d","type":"blocks","created_at":"2026-02-20T07:36:48.324029836Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-26k","depends_on_id":"bd-m8p","type":"blocks","created_at":"2026-02-20T07:36:48.560611953Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-26mk","title":"[10.17] Implement security staking and slashing framework for publisher trust governance.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.17 — Radical Expansion Execution Track (9K)\n\nWhy This Exists:\nRadical expansion track for proof-carrying speculation, Bayesian adversary control, time-travel replay, ZK attestations, and claim compiler systems.\n\nTask Objective:\nImplement security staking and slashing framework for publisher trust governance.\n\nAcceptance Criteria:\n- High-risk capabilities enforce stake policy gates; validated malicious behavior triggers deterministic slashing workflow with appeal/audit trail artifacts.\n\nExpected Artifacts:\n- `docs/policy/security_staking_and_slashing.md`, `src/registry/staking_governance.rs`, `tests/integration/staking_slashing_flows.rs`, `artifacts/10.17/staking_ledger_snapshot.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_17/bd-26mk/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_17/bd-26mk/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.17] Implement security staking and slashing framework for publisher trust governance.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.17] Implement security staking and slashing framework for publisher trust governance.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.17] Implement security staking and slashing framework for publisher trust governance.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.17] Implement security staking and slashing framework for publisher trust governance.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.17] Implement security staking and slashing framework for publisher trust governance.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- High-risk capabilities enforce stake policy gates; validated malicious behavior triggers deterministic slashing workflow with appeal/audit trail artifacts.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:37:03.516382462Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:59.522512515Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-17","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-26mk","depends_on_id":"bd-al8i","type":"blocks","created_at":"2026-02-20T07:43:18.561264270Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-26ux","title":"[10.16] Add migration path from interim/local stores to `frankensqlite` for relevant state domains.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.16 — Adjacent Substrate Integration Execution Track (8.7)\n\nWhy This Exists:\nAdjacent substrate integration track to enforce deep composition with frankentui, frankensqlite, sqlmodel_rust, and fastapi_rust.\n\nTask Objective:\nAdd migration path from interim/local stores to `frankensqlite` for relevant state domains.\n\nAcceptance Criteria:\n- Migration tooling is deterministic and idempotent; rollback path exists; migrated data matches source invariants.\n\nExpected Artifacts:\n- `docs/migration/to_frankensqlite.md`, `tests/migration/frankensqlite_migration_idempotence.rs`, `artifacts/10.16/frankensqlite_migration_report.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_16/bd-26ux/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_16/bd-26ux/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.16] Add migration path from interim/local stores to `frankensqlite` for relevant state domains.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.16] Add migration path from interim/local stores to `frankensqlite` for relevant state domains.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.16] Add migration path from interim/local stores to `frankensqlite` for relevant state domains.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.16] Add migration path from interim/local stores to `frankensqlite` for relevant state domains.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.16] Add migration path from interim/local stores to `frankensqlite` for relevant state domains.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- Migration tooling is deterministic and idempotent; rollback path exists; migrated data matches source invariants.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:37:02.102470926Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:46.969412205Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-16","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-26ux","depends_on_id":"bd-2tua","type":"blocks","created_at":"2026-02-20T07:43:17.834219370Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-273","title":"[10.4] Implement extension certification levels tied to policy controls.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.4 — Extension Ecosystem + Registry\n\nWhy This Exists:\nExtension ecosystem and registry trust foundation: signed artifacts, provenance, trust cards, revocation, and quarantine flows.\n\nTask Objective:\nImplement extension certification levels tied to policy controls.\n\nAcceptance Criteria:\n(See structured acceptance_criteria field for domain-specific criteria.)\n\nExpected Artifacts:\n- Section-owned design/spec artifact at `docs/specs/section_10_4/bd-273_contract.md`, capturing decision rationale, invariants, and interface boundaries.\n- Machine-readable verification artifact at `artifacts/section_10_4/bd-273/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_4/bd-273/verification_summary.md` linking implementation intent to measured outcomes.\n\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.4] Implement extension certification levels tied to policy controls.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.4] Implement extension certification levels tied to policy controls.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.4] Implement extension certification levels tied to policy controls.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.4] Implement extension certification levels tied to policy controls.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.4] Implement extension certification levels tied to policy controls.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"1. Define four certification levels in ascending order: Uncertified (no verification beyond valid manifest), Community (passes automated test suite + valid provenance chain), Verified (reproducible build + behavioral telemetry baseline established + publisher reputation >= Established), Certified (all Verified requirements + manual security audit + threshold-signed attestation from >=2 independent reviewers). 2. Each certification level maps to a policy control set: Uncertified extensions are limited to sandbox-only execution with no network/filesystem access; Community extensions may access declared capabilities within resource envelope; Verified extensions may access elevated capabilities (e.g., ProcessSpawn) with audit logging; Certified extensions may access all declared capabilities including cross-extension IPC. 3. Certification level is stored in the extension manifest (certification_level field) and independently verifiable: the trust card (bd-2yh) cross-references the certification evidence chain. 4. Level transitions require explicit evidence: Community->Verified requires provenance chain from bd-1ah with reproducibility proof; Verified->Certified requires signed audit report referencing specific code version hash. 5. Downgrade is automatic: if any certification requirement is violated (e.g., provenance chain broken, publisher reputation drops below threshold, revocation event on a dependency), the extension is downgraded to the highest level still satisfied; policy controls are adjusted immediately. 6. Fleet operators can set minimum certification level per deployment context via policy file: e.g., production requires >= Verified, staging allows >= Community. 7. CLI commands: 'franken-node ext cert show <ext-id>' (current level + evidence summary), 'franken-node ext cert requirements <level>' (list all requirements for a level), 'franken-node ext cert evaluate <ext-id> --target-level <level>' (gap analysis). 8. Certification level changes emit structured events: CERTIFICATION_LEVEL_CHANGED with ext_id, old_level, new_level, trigger (upgrade_evidence | downgrade_violation), and violation_details[] for downgrades. 9. Certification audit trail is append-only and tamper-evident (hash-chained log entries). 10. Integration tests cover: upgrade path through all four levels, automatic downgrade on revocation, policy enforcement blocking uncertified extension in production context, and certification re-evaluation after dependency update.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:36:45.904492560Z","created_by":"ubuntu","updated_at":"2026-02-20T15:18:42.020465362Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-4","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-273","depends_on_id":"bd-1vm","type":"blocks","created_at":"2026-02-20T07:43:22.643387816Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-274s","title":"[10.17] Implement Bayesian adversary graph and automated quarantine controller.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.17 — Radical Expansion Execution Track (9K)\n\nWhy This Exists:\nRadical expansion track for proof-carrying speculation, Bayesian adversary control, time-travel replay, ZK attestations, and claim compiler systems.\n\nTask Objective:\nImplement Bayesian adversary graph and automated quarantine controller.\n\nAcceptance Criteria:\n- Risk posterior updates are deterministic from identical evidence; policy thresholds trigger reproducible control actions (throttle/isolate/revoke/quarantine) with signed evidence entries.\n\nExpected Artifacts:\n- `src/security/adversary_graph.rs`, `src/security/quarantine_controller.rs`, `tests/integration/bayesian_risk_quarantine.rs`, `artifacts/10.17/adversary_graph_state.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_17/bd-274s/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_17/bd-274s/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.17] Implement Bayesian adversary graph and automated quarantine controller.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.17] Implement Bayesian adversary graph and automated quarantine controller.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.17] Implement Bayesian adversary graph and automated quarantine controller.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.17] Implement Bayesian adversary graph and automated quarantine controller.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.17] Implement Bayesian adversary graph and automated quarantine controller.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- Risk posterior updates are deterministic from identical evidence; policy thresholds trigger reproducible control actions (throttle/isolate/revoke/quarantine) with signed evidence entries.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:37:03.008093682Z","created_by":"ubuntu","updated_at":"2026-02-20T15:46:00.799133743Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-17","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-274s","depends_on_id":"bd-1nl1","type":"blocks","created_at":"2026-02-20T07:43:18.307975166Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-27o2","title":"[10.14] Add profile tuning harness and publish benchmark-driven policy updates as signed artifacts.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.14 — FrankenSQLite Deep-Mined Expansion Execution Track (9J)\n\nWhy This Exists:\nFrankenSQLite deep-mined control integrity track: evidence ledgers, proofs, epochs, remote effects, markers/MMR, and deterministic fault labs.\n\nTask Objective:\nAdd profile tuning harness and publish benchmark-driven policy updates as signed artifacts.\n\nAcceptance Criteria:\n- Harness recomputes candidate policy updates reproducibly; updates are signed and linked to benchmark provenance; unsafe regressions are auto-rejected.\n\nExpected Artifacts:\n- `tools/profile_tuning_harness.rs`, `docs/specs/policy_update_signing.md`, `artifacts/10.14/signed_policy_update_bundle.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_14/bd-27o2/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_14/bd-27o2/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.14] Add profile tuning harness and publish benchmark-driven policy updates as signed artifacts.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.14] Add profile tuning harness and publish benchmark-driven policy updates as signed artifacts.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.14] Add profile tuning harness and publish benchmark-driven policy updates as signed artifacts.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.14] Add profile tuning harness and publish benchmark-driven policy updates as signed artifacts.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.14] Add profile tuning harness and publish benchmark-driven policy updates as signed artifacts.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"Harness recomputes candidate policy updates reproducibly; updates are signed and linked to benchmark provenance; unsafe regressions are auto-rejected.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:36:57.222598430Z","created_by":"ubuntu","updated_at":"2026-02-20T15:44:07.315910092Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-14","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-27o2","depends_on_id":"bd-8tvs","type":"blocks","created_at":"2026-02-20T07:43:15.273847616Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-2808","title":"[10.14] Implement deterministic repro bundle export for control-plane failures and policy incidents.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.14 — FrankenSQLite Deep-Mined Expansion Execution Track (9J)\n\nWhy This Exists:\nFrankenSQLite deep-mined control integrity track: evidence ledgers, proofs, epochs, remote effects, markers/MMR, and deterministic fault labs.\n\nTask Objective:\nImplement deterministic repro bundle export for control-plane failures and policy incidents.\n\nAcceptance Criteria:\n- Repro bundles include seed, config, event-sequence trace, and evidence references; replay tool re-executes incident deterministically; bundle schema is versioned.\n\nExpected Artifacts:\n- `src/tools/repro_bundle_export.rs`, `tests/integration/repro_bundle_replay.rs`, `artifacts/10.14/repro_bundle_schema_v1.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_14/bd-2808/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_14/bd-2808/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.14] Implement deterministic repro bundle export for control-plane failures and policy incidents.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.14] Implement deterministic repro bundle export for control-plane failures and policy incidents.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.14] Implement deterministic repro bundle export for control-plane failures and policy incidents.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.14] Implement deterministic repro bundle export for control-plane failures and policy incidents.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.14] Implement deterministic repro bundle export for control-plane failures and policy incidents.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"Repro bundles include seed, config, event-sequence trace, and evidence references; replay tool re-executes incident deterministically; bundle schema is versioned.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:36:59.061914429Z","created_by":"ubuntu","updated_at":"2026-02-20T15:44:02.623593219Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-14","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-2808","depends_on_id":"bd-25nl","type":"blocks","created_at":"2026-02-20T07:43:16.231157867Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-28k6","title":"Epic: Monotonic Hardening System [10.14c]","description":"- type: epic","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-20T07:47:58.072163029Z","updated_at":"2026-02-20T07:49:21.209727165Z","closed_at":"2026-02-20T07:49:21.209709522Z","close_reason":"Superseded by canonical detailed master-plan graph (bd-33v) with full 10.N-10.21 and 11-16 coverage, explicit dependencies, and per-section verification gates.","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-28ld","title":"[10.16] Add architecture dependency map showing where each adjacent substrate is required in `franken_node`.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.16 — Adjacent Substrate Integration Execution Track (8.7)\n\nWhy This Exists:\nAdjacent substrate integration track to enforce deep composition with frankentui, frankensqlite, sqlmodel_rust, and fastapi_rust.\n\nTask Objective:\nAdd architecture dependency map showing where each adjacent substrate is required in `franken_node`.\n\nAcceptance Criteria:\n- Map covers presentation, persistence, model, and service planes; unmapped relevant modules fail architecture review gate.\n\nExpected Artifacts:\n- `docs/architecture/adjacent_substrate_dependency_map.md`, `artifacts/10.16/substrate_dependency_matrix.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_16/bd-28ld/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_16/bd-28ld/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.16] Add architecture dependency map showing where each adjacent substrate is required in `franken_node`.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.16] Add architecture dependency map showing where each adjacent substrate is required in `franken_node`.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.16] Add architecture dependency map showing where each adjacent substrate is required in `franken_node`.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.16] Add architecture dependency map showing where each adjacent substrate is required in `franken_node`.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.16] Add architecture dependency map showing where each adjacent substrate is required in `franken_node`.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- Map covers presentation, persistence, model, and service planes; unmapped relevant modules fail architecture review gate.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:37:01.607249937Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:48.315426220Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-16","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-28ld","depends_on_id":"bd-2owx","type":"blocks","created_at":"2026-02-20T07:43:17.575411709Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-28sz","title":"[13] Concrete target gate: >=95% compatibility corpus pass","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 13 — Program Success Criteria\nConcrete Target: >= 95% compatibility corpus pass\n\nWhy This Exists:\nThis is one of 6 concrete quantitative targets that define program success. The >= 95% compatibility corpus pass target means franken_node must correctly handle at least 95% of the targeted compatibility corpus (spanning core/high-value/edge API bands) as validated by the lockstep oracle.\n\nTask Objective:\nInstrument, measure, and gate on the >= 95% compatibility corpus pass target across the full targeted fixture corpus.\n\nDetailed Acceptance Criteria:\n1. Compatibility corpus defined and version-controlled (from 10.7 golden corpus bead).\n2. Automated measurement: corpus execution produces per-band pass/fail counts and overall percentage.\n3. Release gate: releases blocked when overall pass rate drops below 95%.\n4. Per-band breakdown: core band must have higher threshold (>= 99%), high-value >= 95%, edge >= 90%.\n5. Regression detection: any corpus pass rate decrease from previous release triggers investigation.\n6. Results published as machine-readable artifact for CI/release gating and public benchmark reporting.\n7. External reproducibility: any party with corpus access can independently verify the pass rate.\n\nKey Dependencies:\n- Depends on 10.2 (Compatibility Core) for fixture runner and band definitions.\n- Depends on 10.7 (Conformance) for golden corpus.\n- Depends on 10.0 (lockstep oracle) for measurement infrastructure.\n- Feeds into 14 (Benchmarks) as a key metric family.\n\nExpected Artifacts:\n- CI gate configuration for 95% threshold enforcement.\n- Measurement dashboard with per-band breakdown.\n- artifacts/section_13/bd-28sz/verification_evidence.json\n\nTesting and Logging Requirements:\n- Unit tests: threshold calculation, per-band aggregation, regression detection logic.\n- Integration tests: corpus execution producing accurate pass/fail metrics.\n- E2E tests: release gate blocking when below threshold.\n- Structured logs: CORPUS_PASS_RATE_COMPUTED, THRESHOLD_MET, THRESHOLD_BREACHED, REGRESSION_DETECTED with band breakdowns and trace IDs.","acceptance_criteria":"1. A targeted compatibility corpus exists with >= 500 test cases covering Node.js core APIs (fs, http, net, crypto, stream, buffer, path, os, child_process, cluster, events, timers, url, querystring, zlib, tls).\n2. Each test case is tagged by API family and risk band (critical/high/medium/low).\n3. franken_node achieves >= 95% pass rate across the full corpus, measured by automated CI run.\n4. Pass rate is reported broken down by API family; no single API family has pass rate < 80%.\n5. Failing tests are tracked as individual beads with investigation status.\n6. The corpus is versioned and reproducible: running the same corpus version always produces the same results on the same franken_node version.\n7. Evidence artifact: compatibility_corpus_results.json with per-test pass/fail, overall rate, and per-family breakdown.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:39:34.869993782Z","created_by":"ubuntu","updated_at":"2026-02-20T15:21:02.516217704Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-13","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-28sz","depends_on_id":"bd-3e74","type":"blocks","created_at":"2026-02-20T07:43:25.532140538Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-28u0","title":"[10.18] Implement receipt-window selection and proof-job scheduler with bounded latency budgets.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.18 — Verifiable Execution Fabric Execution Track (9L)\n\nWhy This Exists:\nVEF track for proof-carrying runtime compliance: receipt chains, commitment checkpoints, proof generation/verification, and claim gating.\n\nTask Objective:\nImplement receipt-window selection and proof-job scheduler with bounded latency budgets.\n\nAcceptance Criteria:\n- Proof windows are deterministic by policy and workload class; scheduler respects latency/resource budgets; backlog health is observable.\n\nExpected Artifacts:\n- `src/trust/vef_proof_scheduler.rs`, `tests/perf/vef_scheduler_latency_budget.rs`, `artifacts/10.18/vef_scheduler_metrics.csv`.\n\n- Machine-readable verification artifact at `artifacts/section_10_18/bd-28u0/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_18/bd-28u0/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.18] Implement receipt-window selection and proof-job scheduler with bounded latency budgets.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.18] Implement receipt-window selection and proof-job scheduler with bounded latency budgets.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.18] Implement receipt-window selection and proof-job scheduler with bounded latency budgets.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.18] Implement receipt-window selection and proof-job scheduler with bounded latency budgets.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.18] Implement receipt-window selection and proof-job scheduler with bounded latency budgets.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- Proof windows are deterministic by policy and workload class; scheduler respects latency/resource budgets; backlog health is observable.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:37:04.458416931Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:56.739479784Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-18","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-28u0","depends_on_id":"bd-3g4k","type":"blocks","created_at":"2026-02-20T07:43:19.050146729Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-293y","title":"[10.19] Define ATC federation trust model, participant identity contracts, and governance boundaries.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.19 — Adversarial Trust Commons Execution Track (9M)\n\nWhy This Exists:\nATC federated intelligence track for privacy-preserving cross-deployment threat learning, robust aggregation, and verifier-backed trust metrics.\n\nTask Objective:\nDefine ATC federation trust model, participant identity contracts, and governance boundaries.\n\nAcceptance Criteria:\n- Participant roles, identity requirements, trust zones, and governance controls are explicit and machine-readable; unauthorized participants fail closed.\n\nExpected Artifacts:\n- `docs/specs/atc_federation_trust_model.md`, `spec/atc_participant_contract_v1.json`, `artifacts/10.19/atc_participant_registry_snapshot.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_19/bd-293y/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_19/bd-293y/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.19] Define ATC federation trust model, participant identity contracts, and governance boundaries.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.19] Define ATC federation trust model, participant identity contracts, and governance boundaries.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.19] Define ATC federation trust model, participant identity contracts, and governance boundaries.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.19] Define ATC federation trust model, participant identity contracts, and governance boundaries.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.19] Define ATC federation trust model, participant identity contracts, and governance boundaries.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- Participant roles, identity requirements, trust zones, and governance controls are explicit and machine-readable; unauthorized participants fail closed.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:37:05.303535007Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:20.213332691Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-19","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-293y","depends_on_id":"bd-1wz","type":"blocks","created_at":"2026-02-20T07:46:34.600503314Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-293y","depends_on_id":"bd-32p","type":"blocks","created_at":"2026-02-20T07:46:34.666362629Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-293y","depends_on_id":"bd-cda","type":"blocks","created_at":"2026-02-20T07:46:34.725739941Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-295v","title":"[PROGRAM] Define cross-section integration journey matrix + deterministic fixtures","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md (Cross-cutting across Sections 10.0–10.21 and 11–16)\nSection: PROGRAM (Cross-section integration journey matrix)\n\nTask Objective:\nDefine a canonical program-wide integration journey matrix with deterministic fixture packs that exercise cross-section behavior at real product seams, not just within section-local boundaries.\n\nWhy This Improves User Outcomes:\nSection gates validate local correctness, but users experience the product through multi-section flows. This matrix ensures we validate full journeys where migration, compatibility, trust policy, incident handling, and ecosystem controls intersect.\n\nAcceptance Criteria:\n- Matrix enumerates all critical cross-section user/operator journeys (happy path, edge, adversarial/error).\n- Every journey maps to owning beads, required fixtures, expected outputs, and failure taxonomy.\n- Fixture packs are deterministic, replayable, and machine-indexed for CI and incident forensics.\n- Matrix explicitly identifies seams where section-local guarantees can conflict and defines resolution assertions.\n\nExpected Artifacts:\n- Program-wide journey matrix document with bead traceability and ownership map.\n- Deterministic fixture catalog for full-journey replay.\n- Machine-readable journey-to-evidence mapping artifact used by orchestration/gating tasks.\n\nTesting & Logging Requirements:\n- Unit tests for matrix/fixture schema validators and mapping integrity checks.\n- E2E dry-runs proving each matrix journey can be executed in deterministic order.\n- Detailed structured logs for journey selection, fixture resolution, and assertion mapping with stable event codes and trace IDs.\n\nTask-Specific Clarification:\n- Preserve full plan ambition by validating integrated behavior across sections, not reducing checks to isolated component tests.\n- Do not remove or simplify any section-level verification obligations; this layer is additive and cross-sectional.","status":"closed","priority":1,"issue_type":"task","assignee":"ubuntu","created_at":"2026-02-20T08:08:05.489422547Z","created_by":"ubuntu","updated_at":"2026-02-20T08:35:25.271069991Z","closed_at":"2026-02-20T08:35:25.270980965Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","program-integration","test-obligations","verification"]}
{"id":"bd-29ct","title":"[10.13] Build adversarial fuzz corpus gates, including decode-DoS and replay/splice handshake scenarios.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.13 — FCP Deep-Mined Expansion Execution Track (9I)\n\nWhy This Exists:\nDeep connector/provider contract track: lifecycle FSMs, conformance harnesses, fencing, sandboxing, revocation freshness, and protocol hardening.\n\nTask Objective:\nBuild adversarial fuzz corpus gates, including decode-DoS and replay/splice handshake scenarios.\n\nAcceptance Criteria:\n- Fuzz targets include parser, handshake, token validation, and decode-DoS corpora; CI gate enforces minimum fuzz health budget; regressions are triaged with seeds.\n\nExpected Artifacts:\n- `fuzz/targets/*`, `docs/security/adversarial_fuzzing.md`, `artifacts/10.13/fuzz_campaign_summary.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_13/bd-29ct/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_13/bd-29ct/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.13] Build adversarial fuzz corpus gates, including decode-DoS and replay/splice handshake scenarios.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.13] Build adversarial fuzz corpus gates, including decode-DoS and replay/splice handshake scenarios.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.13] Build adversarial fuzz corpus gates, including decode-DoS and replay/splice handshake scenarios.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.13] Build adversarial fuzz corpus gates, including decode-DoS and replay/splice handshake scenarios.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.13] Build adversarial fuzz corpus gates, including decode-DoS and replay/splice handshake scenarios.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","status":"closed","priority":1,"issue_type":"task","assignee":"CrimsonCrane","created_at":"2026-02-20T07:36:54.979948138Z","created_by":"ubuntu","updated_at":"2026-02-20T13:35:23.094631381Z","closed_at":"2026-02-20T13:35:23.094602778Z","close_reason":"done","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-13","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-29ct","depends_on_id":"bd-35by","type":"blocks","created_at":"2026-02-20T07:43:14.107826128Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-29q","title":"Add transplant re-sync + drift detection workflow","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md (Bootstrap bridge for continuous transplant integrity)\n\nTask Objective:\nImplement a reproducible transplant re-sync and drift detection workflow that keeps transplanted assets aligned with upstream source while preserving local auditability.\n\nIn Scope:\n- Re-sync procedure definition and automation entrypoint.\n- Drift detection categories (content drift, missing files, unexpected files, metadata drift).\n- Operator/CI-facing outputs for safe review and decision-making.\n\nAcceptance Criteria:\n- Re-sync workflow is deterministic and documents each transformation step.\n- Drift detection emits categorized, actionable findings with stable IDs.\n- Workflow can run non-destructively for preview and produce reproducible evidence bundles.\n\nExpected Artifacts:\n- Re-sync + drift workflow document and executable script entrypoint.\n- Drift report schema with stable category/error codes.\n- Before/after fixture bundle demonstrating expected workflow behavior.\n\nTesting & Logging Requirements:\n- Unit tests for drift classification and report formatting.\n- Integration tests validating re-sync behavior against controlled fixture changes.\n- E2E tests for full restore -> lock -> drift -> re-sync cycle.\n- Structured logs with workflow stage events, drift categories, and trace correlation IDs.\n\nTask-Specific Clarification:\n- For \"Add transplant re-sync + drift detection workflow\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"Add transplant re-sync + drift detection workflow\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"Add transplant re-sync + drift detection workflow\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"Add transplant re-sync + drift detection workflow\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"Add transplant re-sync + drift detection workflow\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","status":"closed","priority":1,"issue_type":"task","assignee":"ubuntu","created_at":"2026-02-20T07:26:02.925883480Z","created_by":"ubuntu","updated_at":"2026-02-20T08:16:16.700695689Z","closed_at":"2026-02-20T08:16:16.700607174Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["transplant","workflow"],"dependencies":[{"issue_id":"bd-29q","depends_on_id":"bd-7rt","type":"blocks","created_at":"2026-02-20T07:32:08.028944379Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-29r6","title":"[10.14] Implement content-derived deterministic seed derivation for encoding/repair schedules.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.14 — FrankenSQLite Deep-Mined Expansion Execution Track (9J)\n\nWhy This Exists:\nFrankenSQLite deep-mined control integrity track: evidence ledgers, proofs, epochs, remote effects, markers/MMR, and deterministic fault labs.\n\nTask Objective:\nImplement content-derived deterministic seed derivation for encoding/repair schedules.\n\nAcceptance Criteria:\n- Seed derivation is domain-separated and stable; identical content/config produces identical schedule; schedule changes require version bump artifact.\n\nExpected Artifacts:\n- `src/encoding/deterministic_seed.rs`, `tests/conformance/deterministic_seed_derivation.rs`, `artifacts/10.14/seed_derivation_vectors.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_14/bd-29r6/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_14/bd-29r6/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.14] Implement content-derived deterministic seed derivation for encoding/repair schedules.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.14] Implement content-derived deterministic seed derivation for encoding/repair schedules.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.14] Implement content-derived deterministic seed derivation for encoding/repair schedules.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.14] Implement content-derived deterministic seed derivation for encoding/repair schedules.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.14] Implement content-derived deterministic seed derivation for encoding/repair schedules.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"Seed derivation is domain-separated and stable; identical content/config produces identical schedule; schedule changes require version bump artifact.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:36:56.889689537Z","created_by":"ubuntu","updated_at":"2026-02-20T15:44:08.200373338Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-14","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-29r6","depends_on_id":"bd-3ort","type":"blocks","created_at":"2026-02-20T07:43:15.106442259Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-29w6","title":"[10.13] Implement offline coverage tracker and SLO dashboards (`coverage`, `availability`, `repair debt`).","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.13 — FCP Deep-Mined Expansion Execution Track (9I)\n\nWhy This Exists:\nDeep connector/provider contract track: lifecycle FSMs, conformance harnesses, fencing, sandboxing, revocation freshness, and protocol hardening.\n\nTask Objective:\nImplement offline coverage tracker and SLO dashboards (`coverage`, `availability`, `repair debt`).\n\nAcceptance Criteria:\n- Coverage metrics are computed continuously and per policy scope; SLO breach alerts trigger automatically; dashboard values are traceable to raw events.\n\nExpected Artifacts:\n- `docs/observability/offline_slo_metrics.md`, `tests/integration/offline_coverage_metrics.rs`, `artifacts/10.13/offline_slo_dashboard_snapshot.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_13/bd-29w6/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_13/bd-29w6/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.13] Implement offline coverage tracker and SLO dashboards (`coverage`, `availability`, `repair debt`).\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.13] Implement offline coverage tracker and SLO dashboards (`coverage`, `availability`, `repair debt`).\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.13] Implement offline coverage tracker and SLO dashboards (`coverage`, `availability`, `repair debt`).\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.13] Implement offline coverage tracker and SLO dashboards (`coverage`, `availability`, `repair debt`).\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.13] Implement offline coverage tracker and SLO dashboards (`coverage`, `availability`, `repair debt`).\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","status":"closed","priority":1,"issue_type":"task","assignee":"CrimsonCrane","created_at":"2026-02-20T07:36:53.760738770Z","created_by":"ubuntu","updated_at":"2026-02-20T12:36:00.001208050Z","closed_at":"2026-02-20T12:36:00.001180449Z","close_reason":"done","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-13","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-29w6","depends_on_id":"bd-2t5u","type":"blocks","created_at":"2026-02-20T07:43:13.474744273Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-29yx","title":"[10.14] Add suspicious-artifact challenge flow that requests proof artifacts before trust promotion.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.14 — FrankenSQLite Deep-Mined Expansion Execution Track (9J)\n\nWhy This Exists:\nFrankenSQLite deep-mined control integrity track: evidence ledgers, proofs, epochs, remote effects, markers/MMR, and deterministic fault labs.\n\nTask Objective:\nAdd suspicious-artifact challenge flow that requests proof artifacts before trust promotion.\n\nAcceptance Criteria:\n- Challenge workflow can defer promotion pending proof response; unresolved challenges timeout to deny by default; challenge states are auditable.\n\nExpected Artifacts:\n- `docs/specs/suspicious_artifact_challenge.md`, `tests/security/challenge_flow_before_promotion.rs`, `artifacts/10.14/challenge_flow_transcript.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_14/bd-29yx/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_14/bd-29yx/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.14] Add suspicious-artifact challenge flow that requests proof artifacts before trust promotion.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.14] Add suspicious-artifact challenge flow that requests proof artifacts before trust promotion.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.14] Add suspicious-artifact challenge flow that requests proof artifacts before trust promotion.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.14] Add suspicious-artifact challenge flow that requests proof artifacts before trust promotion.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.14] Add suspicious-artifact challenge flow that requests proof artifacts before trust promotion.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"Challenge workflow can defer promotion pending proof response; unresolved challenges timeout to deny by default; challenge states are auditable.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:36:56.708172389Z","created_by":"ubuntu","updated_at":"2026-02-20T15:44:08.623851591Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-14","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-29yx","depends_on_id":"bd-20uo","type":"blocks","created_at":"2026-02-20T07:43:15.022726130Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-2a0","title":"[10.3] Build project scanner for API/runtime/dependency risk inventory.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.3 — Migration System\n\nWhy This Exists:\nMigration autopilot pipeline from audit to rollout, designed to collapse migration friction with deterministic confidence and replayability.\n\nTask Objective:\nBuild project scanner for API/runtime/dependency risk inventory.\n\nAcceptance Criteria:\n- Implement with explicit success/failure invariants and deterministic behavior under normal, edge, and fault scenarios.\n- Ensure outcomes are verifiable via automated tests and reproducible artifact outputs.\n\nExpected Artifacts:\n- Section-owned design/spec artifact at `docs/specs/section_10_3/bd-2a0_contract.md`, capturing decision rationale, invariants, and interface boundaries.\n- Machine-readable verification artifact at `artifacts/section_10_3/bd-2a0/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_3/bd-2a0/verification_summary.md` linking implementation intent to measured outcomes.\n\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.3] Build project scanner for API/runtime/dependency risk inventory.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.3] Build project scanner for API/runtime/dependency risk inventory.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.3] Build project scanner for API/runtime/dependency risk inventory.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.3] Build project scanner for API/runtime/dependency risk inventory.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.3] Build project scanner for API/runtime/dependency risk inventory.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","status":"closed","priority":1,"issue_type":"task","assignee":"CrimsonCrane","created_at":"2026-02-20T07:36:44.797550931Z","created_by":"ubuntu","updated_at":"2026-02-20T10:08:33.597464974Z","closed_at":"2026-02-20T10:08:33.597440017Z","close_reason":"done","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-3","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-2a0","depends_on_id":"bd-3il","type":"blocks","created_at":"2026-02-20T07:46:35.805293080Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2a0","depends_on_id":"bd-cda","type":"blocks","created_at":"2026-02-20T07:46:35.855759255Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-2a3","title":"Run baseline workspace checks via rch offload","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md (Bootstrap quality baseline / CI-readiness)\nSection: BOOTSTRAP (Quality baseline and CI readiness)\n\nTask Objective:\nRun baseline workspace quality checks exclusively via `rch` offload to avoid local CPU contention and establish deterministic quality evidence before deeper implementation.\n\nIn Scope:\n- Execute required baseline commands through `rch exec`:\n  - `cargo fmt --check`\n  - `cargo check --all-targets`\n  - `cargo clippy --all-targets -- -D warnings`\n- Capture outputs in reproducible machine/human-readable artifacts.\n- Report failures with actionable remediation context.\n\nAcceptance Criteria:\n- All baseline checks execute via `rch` (no direct local cargo execution for this bead).\n- Results are captured with command, environment, and timestamp provenance.\n- Failure reports include exact failing targets/lints and reproduction hints.\n\nExpected Artifacts:\n- Baseline-check report bundle (command outputs + summarized status table).\n- Machine-readable pass/fail artifact suitable for CI gating.\n- Traceability note linking baseline outcomes to bootstrap readiness status.\n\n- Machine-readable verification artifact at `artifacts/section_bootstrap/bd-2a3/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_bootstrap/bd-2a3/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit-style validation for report parser/formatter (if implemented).\n- E2E execution script that runs the full `rch` baseline sequence end-to-end.\n- Detailed structured logs capturing each offloaded command lifecycle and exit semantics.\n- Stable error/status codes for each baseline check class.\n\nTask-Specific Clarification:\n- For \"Run baseline workspace checks via rch offload\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"Run baseline workspace checks via rch offload\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"Run baseline workspace checks via rch offload\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"Run baseline workspace checks via rch offload\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"Run baseline workspace checks via rch offload\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","status":"in_progress","priority":1,"issue_type":"task","assignee":"TurquoiseHarbor","created_at":"2026-02-20T07:26:05.580672327Z","created_by":"ubuntu","updated_at":"2026-02-20T08:46:44.422808785Z","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-2a4l","title":"[13] Success criterion: externally verifiable trust/security claims","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 13\n\nTask Objective:\nEnsure all trust/security claims are externally verifiable and reproducible.\n\nExecution Requirements:\n- Make this requirement machine-verifiable and release-gated where applicable.\n- Keep behavior self-documenting so future contributors do not need to re-open the master plan.\n\nTesting & Logging Requirements:\n- Unit tests for rule/contract logic and error conditions.\n- Integration/E2E tests for workflow-level enforcement.\n- Structured logs with stable codes and trace IDs.\n- Reproducible artifacts that prove contract satisfaction.\n\nAcceptance Criteria:\n- Success and failure invariants for [13] Success criterion: externally verifiable trust/security claims are explicitly quantified and machine-verifiable.\n- Determinism requirements for [13] Success criterion: externally verifiable trust/security claims are validated across repeated runs and adversarial perturbations.\n\n\nExpected Artifacts:\n- Machine-readable verification artifact with explicit canonical path under artifacts/section_13/bd-2a4l/verification_evidence.json, suitable for CI/release gating.\n- Human-readable verification summary with explicit canonical path under artifacts/section_13/bd-2a4l/verification_summary.md, linking implementation intent to measured validation outcomes.\n\nTask-Specific Clarification:\n- The implementation must deliver the exact capability named in the title, with no scope dilution and no silent feature omission.\n- Validation artifacts must include capability-specific thresholds, pass/fail criteria, and reproducible evidence bundles tied to this bead ID.\n- Program/section verification gates must be able to consume this bead's outputs without manual interpretation.\n\nWhy This Improves User Outcomes:\n- \"[13] Success criterion: externally verifiable trust/security claims\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[13] Success criterion: externally verifiable trust/security claims\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"1. Every trust and security claim in the documentation has a corresponding verifiable evidence artifact.\n2. An external verifier (without source code access) can validate claims using the published verifier toolkit.\n3. Verifiable claims include: (a) compromise reduction ratio, (b) trust decision determinism, (c) privacy budget compliance, (d) containment latency.\n4. Each claim has a machine-readable evidence format (JSON) with: claim statement, measurement methodology, raw data reference, computed result, confidence interval.\n5. External verification has been performed by >= 1 independent party and results are published.\n6. Claims are versioned: when the system changes, claims are re-verified and version-stamped.\n7. Evidence: verifiable_claims_registry.json listing each claim, its evidence artifact path, verification status, and last-verified version.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:39:34.500284922Z","created_by":"ubuntu","updated_at":"2026-02-20T15:22:40.765125212Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-13","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-2a4l","depends_on_id":"bd-1w78","type":"blocks","created_at":"2026-02-20T07:43:25.357215995Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-2a6g","title":"[14] Metric family: containment/revocation latency and convergence","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 14\n\nTask Objective:\nInstrument containment and revocation latency/convergence metric family.\n\nExecution Requirements:\n- Make this requirement machine-verifiable and release-gated where applicable.\n- Keep behavior self-documenting so future contributors do not need to re-open the master plan.\n\nTesting & Logging Requirements:\n- Unit tests for rule/contract logic and error conditions.\n- Integration/E2E tests for workflow-level enforcement.\n- Structured logs with stable codes and trace IDs.\n- Reproducible artifacts that prove contract satisfaction.\n\nAcceptance Criteria:\n- Success and failure invariants for [14] Metric family: containment/revocation latency and convergence are explicitly quantified and machine-verifiable.\n- Determinism requirements for [14] Metric family: containment/revocation latency and convergence are validated across repeated runs and adversarial perturbations.\n\n\nExpected Artifacts:\n- Machine-readable verification artifact with explicit canonical path under artifacts/section_14/bd-2a6g/verification_evidence.json, suitable for CI/release gating.\n- Human-readable verification summary with explicit canonical path under artifacts/section_14/bd-2a6g/verification_summary.md, linking implementation intent to measured validation outcomes.\n\nTask-Specific Clarification:\n- The implementation must deliver the exact capability named in the title, with no scope dilution and no silent feature omission.\n- Validation artifacts must include capability-specific thresholds, pass/fail criteria, and reproducible evidence bundles tied to this bead ID.\n- Program/section verification gates must be able to consume this bead's outputs without manual interpretation.\n\nWhy This Improves User Outcomes:\n- \"[14] Metric family: containment/revocation latency and convergence\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[14] Metric family: containment/revocation latency and convergence\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"METRIC FAMILY: Containment/revocation latency and convergence.\n1. Metrics measured: (a) detection-to-containment latency (ms), (b) containment-to-full-isolation latency (ms), (c) revocation propagation time (time for all nodes to receive revocation), (d) convergence time (time for system to reach stable state post-incident).\n2. Measured for incident types: malicious extension detected, compromised node detected, trust graph corruption, supply-chain attack detected.\n3. Latency gates: detection-to-containment <= 30 seconds (automated), revocation propagation <= 60 seconds (10-node cluster), convergence <= 5 minutes.\n4. Measured under load conditions: idle, moderate (50% capacity), high (90% capacity).\n5. Revocation completeness: 100% of affected nodes must receive and enforce revocation within the propagation window.\n6. Publication: latency metrics included in benchmark report with percentile distributions.\n7. Evidence: containment_latency_metrics.json with per-incident-type, per-load-condition latency percentiles.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:39:35.815915491Z","created_by":"ubuntu","updated_at":"2026-02-20T15:24:52.780011344Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-14","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-2a6g","depends_on_id":"bd-ka0n","type":"blocks","created_at":"2026-02-20T07:43:26.023257801Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-2ac","title":"[10.0] Implement secure extension distribution network.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.0 — Top 10 Initiative Tracking (Initiative #7)\nCross-references: 9A.7, 9B.7, 9C.7, 9D.7\n\nWhy This Exists:\nSecure extension distribution network is the #7 strategic initiative. It builds a signed registry and distribution model with revocation propagation and reputation linkage to reduce supply-chain compromise windows. This is the infrastructure that makes the trust ecosystem viable.\n\nTask Objective:\nBuild the signed extension registry and distribution network with end-to-end integrity guarantees: signed packages, provenance attestation, revocation propagation, and publisher reputation linkage.\n\nDetailed Acceptance Criteria:\n1. Signed extension package format with manifest schema (10.4), provenance attestation chain, and content integrity verification.\n2. Registry supports publish, search, and install with signature verification at every stage.\n3. Revocation propagation with canonical freshness checks (from 10.13) — compromised packages are rapidly recalled.\n4. Publisher reputation linkage: registry entries linked to publisher trust cards with explainable transitions.\n5. Key-transparency and threshold-signing flows for high-impact trust operations (9B.7).\n6. Cryptographic decision receipts and inclusion proofs for trust transitions (9C.7).\n7. Signature/provenance verification optimized at scale with batched pipelines (9D.7).\n8. CLI surface: franken-node registry publish/search commands.\n\nKey Dependencies:\n- Depends on 10.4 (Extension Ecosystem) for manifest schema and provenance requirements.\n- Depends on 10.13 (FCP Deep-Mined) for revocation freshness semantics.\n- Consumed by 10.5 (Security) for policy-gated distribution.\n- Consumed by 10.15 (Ecosystem Capture) for signed extension registry pillar.\n\nExpected Artifacts:\n- src/supply_chain/registry.rs — registry client and verification.\n- src/supply_chain/distribution.rs — package distribution with integrity.\n- CLI integration for registry commands in cli.rs.\n- docs/specs/section_10_0/bd-2ac_contract.md\n- artifacts/section_10_0/bd-2ac/verification_evidence.json\n\nTesting and Logging Requirements:\n- Unit tests: package signing, signature verification, revocation check, reputation query, threshold signing.\n- Integration tests: full publish -> search -> install -> verify pipeline with revocation injection.\n- E2E tests: franken-node registry publish/search CLI workflows.\n- Adversarial tests: tampered packages, stale revocation data, expired signatures, threshold signing failures.\n- Structured logs: PACKAGE_PUBLISHED, SIGNATURE_VERIFIED, REVOCATION_PROPAGATED, REPUTATION_LINKED, INCLUSION_PROOF_GENERATED with trace IDs.","acceptance_criteria":"1. Signed registry: every published extension artifact is signed with publisher key; signature verified on download before installation; unsigned artifacts rejected by default.\n2. Signature scheme uses Ed25519 or equivalent; key management supports rotation with overlap period; compromised key revocation propagates within <= 60 seconds.\n3. Revocation propagation: revocation list updates distributed via push channel to all fleet nodes; node-local cache expires within <= 300 seconds; offline nodes sync on reconnect.\n4. Reputation linkage: extension reputation score derived from trust card data (bd-y4g), download telemetry, vulnerability history, and behavioral anomaly flags.\n5. Registry API supports: publish, search, download, verify, revoke, audit-log query; all endpoints authenticated and rate-limited.\n6. Integrity verification: downloaded artifacts verified against content-addressable hash (SHA-256 minimum) and publisher signature; double-verification before installation.\n7. Compromise reduction: secure distribution network contributes to >= 10x compromise reduction target (Section 3) by preventing supply-chain attacks at distribution layer.\n8. Audit log: every registry operation (publish/download/revoke/key-rotate) logged with timestamp, actor identity, artifact hash, operation result; append-only.\n9. Offline resilience: nodes cache verified artifacts locally; cached artifacts usable without network; cache invalidation triggered by revocation events.\n10. Verification evidence includes: signature verification round-trip test, revocation propagation latency measurement, tampered-artifact rejection test, offline-cache validity test.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:36:42.960936524Z","created_by":"ubuntu","updated_at":"2026-02-20T15:36:15.363919858Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-0","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-2ac","depends_on_id":"bd-1ah","type":"blocks","created_at":"2026-02-20T15:01:24.535795128Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2ac","depends_on_id":"bd-1gx","type":"blocks","created_at":"2026-02-20T15:01:24.359647442Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2ac","depends_on_id":"bd-yqz","type":"blocks","created_at":"2026-02-20T07:43:10.352633662Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-2ad0","title":"[16] Contribution: reproducible migration and incident datasets","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 16\n\nTask Objective:\nPublish reproducible migration and incident datasets with artifact bundles.\n\nExecution Requirements:\n- Make this requirement machine-verifiable and release-gated where applicable.\n- Keep behavior self-documenting so future contributors do not need to re-open the master plan.\n\nTesting & Logging Requirements:\n- Unit tests for rule/contract logic and error conditions.\n- Integration/E2E tests for workflow-level enforcement.\n- Structured logs with stable codes and trace IDs.\n- Reproducible artifacts that prove contract satisfaction.\n\nAcceptance Criteria:\n- Success and failure invariants for [16] Contribution: reproducible migration and incident datasets are explicitly quantified and machine-verifiable.\n- Determinism requirements for [16] Contribution: reproducible migration and incident datasets are validated across repeated runs and adversarial perturbations.\n\n\nExpected Artifacts:\n- Machine-readable verification artifact with explicit canonical path under artifacts/section_16/bd-2ad0/verification_evidence.json, suitable for CI/release gating.\n- Human-readable verification summary with explicit canonical path under artifacts/section_16/bd-2ad0/verification_summary.md, linking implementation intent to measured validation outcomes.\n\nTask-Specific Clarification:\n- The implementation must deliver the exact capability named in the title, with no scope dilution and no silent feature omission.\n- Validation artifacts must include capability-specific thresholds, pass/fail criteria, and reproducible evidence bundles tied to this bead ID.\n- Program/section verification gates must be able to consume this bead's outputs without manual interpretation.\n\nWhy This Improves User Outcomes:\n- \"[16] Contribution: reproducible migration and incident datasets\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[16] Contribution: reproducible migration and incident datasets\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"1. Reproducible migration dataset published: >= 10 anonymized migration traces capturing: project structure, migration steps taken, timing per step, blockers encountered, final outcome.\n2. Reproducible incident dataset published: >= 20 incident replay artifacts covering all high-severity incident types, with sanitized inputs and expected outputs.\n3. Datasets are versioned, hosted on a public repository or data archive (e.g., Zenodo, GitHub Releases), and have DOI or permanent identifier.\n4. Each dataset includes: (a) README with schema description, (b) data dictionary for all fields, (c) loading scripts in Python and JavaScript, (d) license (CC-BY-4.0 or equivalent open license).\n5. Datasets are validated: loading scripts run without error on fresh environment and produce expected record counts.\n6. Privacy: all datasets are reviewed for PII and sensitive information before publication; no real organization names, IP addresses, or credentials.\n7. Datasets are cited in project documentation and at least 1 external publication uses them.\n8. Evidence: dataset_publication_registry.json with per-dataset: name, version, DOI, record count, download URL, and citation count.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:39:36.870913606Z","created_by":"ubuntu","updated_at":"2026-02-20T15:28:08.209014118Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-16","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-2ad0","depends_on_id":"bd-f955","type":"blocks","created_at":"2026-02-20T07:43:26.592445237Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-2ah","title":"[10.11] Adopt canonical obligation-tracked two-phase channel contracts (from `10.15`) for critical flows.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.11 — FrankenSQLite-Inspired Runtime Systems Integration Track\n\nWhy This Exists:\nFrankenSQLite-inspired systems integration of capabilities, cancellation protocol, obligations, deterministic labs, and anti-entropy.\n\nTask Objective:\nAdopt canonical obligation-tracked two-phase channel contracts (from `10.15`) for critical flows.\n\nAcceptance Criteria:\n- Implement with explicit success/failure invariants and deterministic behavior under normal, edge, and fault scenarios.\n- Ensure outcomes are verifiable via automated tests and reproducible artifact outputs.\n\nExpected Artifacts:\n- Section-owned design/spec artifact at `docs/specs/section_10_11/bd-2ah_contract.md`, capturing decision rationale, invariants, and interface boundaries.\n- Machine-readable verification artifact at `artifacts/section_10_11/bd-2ah/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_11/bd-2ah/verification_summary.md` linking implementation intent to measured outcomes.\n\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.11] Adopt canonical obligation-tracked two-phase channel contracts (from `10.15`) for critical flows.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.11] Adopt canonical obligation-tracked two-phase channel contracts (from `10.15`) for critical flows.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.11] Adopt canonical obligation-tracked two-phase channel contracts (from `10.15`) for critical flows.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.11] Adopt canonical obligation-tracked two-phase channel contracts (from `10.15`) for critical flows.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.11] Adopt canonical obligation-tracked two-phase channel contracts (from `10.15`) for critical flows.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"AC for bd-2ah:\n1. All critical flows adopt obligation-tracked two-phase channels from 10.15: Phase 1 (Prepare) reserves resources and returns an ObligationToken; Phase 2 (Commit/Rollback) consumes the token to finalize or release.\n2. An ObligationToken is a linear type (must be consumed exactly once); dropping an unconsumed token triggers a LEAKED_OBLIGATION panic in debug mode and a structured error log + forced rollback in release mode.\n3. The ObligationChannel<T> type enforces the two-phase contract: prepare(payload) -> Result<ObligationToken>, commit(token) -> Result<T>, rollback(token) -> Result<()>.\n4. Obligation tokens carry a monotonic sequence number and creation timestamp; tokens from a previous epoch (see bd-2gr) are automatically rejected with STALE_OBLIGATION_EPOCH.\n5. A configurable obligation timeout ensures that prepare-without-commit/rollback is detected: if a token is neither committed nor rolled back within the timeout, a background reaper logs OBLIGATION_TIMEOUT and forces rollback.\n6. The channel tracks outstanding obligation count as a gauge metric; the gauge must return to zero after all flows complete (verified in integration tests).\n7. Unit tests verify: (a) prepare -> commit round-trip succeeds, (b) prepare -> rollback releases resources, (c) dropped token triggers leak detection, (d) stale-epoch token is rejected, (e) timeout triggers forced rollback, (f) double-commit on same token returns OBLIGATION_ALREADY_CONSUMED.\n8. Structured log events: OBLIGATION_PREPARE / OBLIGATION_COMMIT / OBLIGATION_ROLLBACK / OBLIGATION_TIMEOUT / LEAKED_OBLIGATION with channel name, sequence number, and trace correlation ID.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:36:50.060962999Z","created_by":"ubuntu","updated_at":"2026-02-20T15:18:18.017934657Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-11","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-2ah","depends_on_id":"bd-1n5p","type":"blocks","created_at":"2026-02-20T15:00:17.732037151Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2ah","depends_on_id":"bd-24k","type":"blocks","created_at":"2026-02-20T07:43:11.537657651Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-2aj","title":"[10.12] Implement ecosystem network-effect APIs (registry/reputation/compliance evidence).","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.12 — Frontier Programs Execution Track (9H)\n\nWhy This Exists:\nFrontier program execution turning migration singularity, trust fabric, verifier economy, and operator intelligence into production flow.\n\nTask Objective:\nImplement ecosystem network-effect APIs (registry/reputation/compliance evidence).\n\nAcceptance Criteria:\n- Implement with explicit success/failure invariants and deterministic behavior under normal, edge, and fault scenarios.\n- Ensure outcomes are verifiable via automated tests and reproducible artifact outputs.\n\nExpected Artifacts:\n- Section-owned design/spec artifact at `docs/specs/section_10_12/bd-2aj_contract.md`, capturing decision rationale, invariants, and interface boundaries.\n- Machine-readable verification artifact at `artifacts/section_10_12/bd-2aj/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_12/bd-2aj/verification_summary.md` linking implementation intent to measured outcomes.\n\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.12] Implement ecosystem network-effect APIs (registry/reputation/compliance evidence).\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.12] Implement ecosystem network-effect APIs (registry/reputation/compliance evidence).\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.12] Implement ecosystem network-effect APIs (registry/reputation/compliance evidence).\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.12] Implement ecosystem network-effect APIs (registry/reputation/compliance evidence).\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.12] Implement ecosystem network-effect APIs (registry/reputation/compliance evidence).\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"1. Implement a ComponentRegistry API with: (a) register(component_id, metadata) -> RegistryEntry that registers a component (migration tool, verifier, plugin) with its name, version, capabilities, and public key, (b) lookup(component_id) -> Option<RegistryEntry>, (c) search(query) -> Vec<RegistryEntry> supporting filtering by capability, version range, and reputation score, (d) deregister(component_id, authority_key) -> Result.\n2. Implement a ReputationScoring system: each registered component accumulates a reputation score based on: (a) successful_verifications (count of times it produced correct verification results), (b) failed_verifications (incorrect results), (c) uptime_ratio (availability over rolling 30-day window), (d) compliance_attestations (count of signed compliance evidence submitted). Score = weighted combination with configurable weights, normalized to [0.0, 1.0].\n3. Implement ComplianceEvidence submission: (a) submit_evidence(component_id, evidence_type, evidence_hash, signer_key) -> EvidenceReceipt that records a compliance claim, (b) verify_evidence(receipt_id) -> VerificationResult that checks the evidence hash and signature. Evidence types include: AUDIT_PASS, PENTEST_CLEAR, LICENSE_COMPLIANT, INTEROP_CERTIFIED.\n4. Implement API access control: registry mutations (register, deregister, submit_evidence) require audience-bound tokens (from bd-1r2) with appropriate action scopes. Read operations (lookup, search) are public.\n5. Implement registry consistency: all mutations produce a monotonic sequence number and are append-only in the audit log. Provide a registry_audit_log(since_sequence) -> Vec<AuditEntry> API.\n6. Implement network-effect metrics: expose total_registered_components, average_reputation_score, total_compliance_attestations, and components_by_capability as structured metrics.\n7. Unit tests: (a) register/lookup/search lifecycle, (b) reputation score calculation, (c) compliance evidence submission and verification, (d) unauthorized mutation rejection, (e) deregister removes from search results, (f) audit log captures all mutations.\n8. Integration test: register 10 components, submit evidence for 5, compute reputation scores, verify search ranking matches reputation order.\n9. Verification: scripts/check_ecosystem_apis.py --json, artifacts at artifacts/section_10_12/bd-2aj/.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:36:51.234881133Z","created_by":"ubuntu","updated_at":"2026-02-20T15:40:51.375979854Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-12","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-2aj","depends_on_id":"bd-y0v","type":"blocks","created_at":"2026-02-20T07:43:12.138318452Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-2ao3","title":"[10.21] Implement temporal drift feature engine (velocity, acceleration, entropy, novelty, capability-creep gradient).","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.21 — Behavioral Phenotype Evolution Tracker Execution Track (9O)\n\nWhy This Exists:\nBPET longitudinal phenotype intelligence track for pre-compromise trajectory detection and integration with DGIS/ATC/migration/economic policy.\n\nTask Objective:\nImplement temporal drift feature engine (velocity, acceleration, entropy, novelty, capability-creep gradient).\n\nAcceptance Criteria:\n- Drift features are numerically stable and reproducible; feature-store interfaces support historical replay and windowed recomputation.\n\nExpected Artifacts:\n- `src/security/bpet/drift_features.rs`, `tests/security/bpet_drift_feature_stability.rs`, `artifacts/10.21/bpet_drift_feature_matrix.csv`.\n\n- Machine-readable verification artifact at `artifacts/section_10_21/bd-2ao3/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_21/bd-2ao3/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.21] Implement temporal drift feature engine (velocity, acceleration, entropy, novelty, capability-creep gradient).\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.21] Implement temporal drift feature engine (velocity, acceleration, entropy, novelty, capability-creep gradient).\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.21] Implement temporal drift feature engine (velocity, acceleration, entropy, novelty, capability-creep gradient).\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.21] Implement temporal drift feature engine (velocity, acceleration, entropy, novelty, capability-creep gradient).\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.21] Implement temporal drift feature engine (velocity, acceleration, entropy, novelty, capability-creep gradient).\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- Drift features are numerically stable and reproducible; feature-store interfaces support historical replay and windowed recomputation.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:37:08.033916716Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:20.443405291Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-21","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-2ao3","depends_on_id":"bd-1ga5","type":"blocks","created_at":"2026-02-20T07:43:21.432359671Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-2bj4","title":"[10.20] Implement deterministic graph ingestion pipeline from lockfiles, extension manifests, registry metadata, and local execution evidence.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.20 — Dependency Graph Immune System Execution Track (9N)\n\nWhy This Exists:\nDGIS topological immune system track for dependency contagion modeling, choke-point immunization, and graph-aware containment economics.\n\nTask Objective:\nImplement deterministic graph ingestion pipeline from lockfiles, extension manifests, registry metadata, and local execution evidence.\n\nAcceptance Criteria:\n- Ingestion reproducibly resolves graph state from the same source set; stale/missing provenance is explicitly surfaced as typed risk signals; ingestion supports replay.\n\nExpected Artifacts:\n- `src/security/dgis/graph_ingestion.rs`, `tests/conformance/dgis_graph_ingestion.rs`, `artifacts/10.20/dgis_ingestion_replay_report.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_20/bd-2bj4/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_20/bd-2bj4/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.20] Implement deterministic graph ingestion pipeline from lockfiles, extension manifests, registry metadata, and local execution evidence.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.20] Implement deterministic graph ingestion pipeline from lockfiles, extension manifests, registry metadata, and local execution evidence.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.20] Implement deterministic graph ingestion pipeline from lockfiles, extension manifests, registry metadata, and local execution evidence.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.20] Implement deterministic graph ingestion pipeline from lockfiles, extension manifests, registry metadata, and local execution evidence.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.20] Implement deterministic graph ingestion pipeline from lockfiles, extension manifests, registry metadata, and local execution evidence.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- Ingestion reproducibly resolves graph state from the same source set; stale/missing provenance is explicitly surfaced as typed risk signals; ingestion supports replay.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:37:06.502245942Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:20.689654976Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-20","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-2bj4","depends_on_id":"bd-b541","type":"blocks","created_at":"2026-02-20T07:43:20.619105578Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-2cfz","title":"Epic: Adversarial Trust Commons (ATC) [10.19]","description":"- type: epic","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-20T07:47:58.072163029Z","updated_at":"2026-02-20T07:49:21.311326149Z","closed_at":"2026-02-20T07:49:21.311305090Z","close_reason":"Superseded by canonical detailed master-plan graph (bd-33v) with full 10.N-10.21 and 11-16 coverage, explicit dependencies, and per-section verification gates.","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-2d0","title":"Backfill beads graph from TODO_ULTRA_DETAILED","description":"Create initial actionable beads from docs/TODO_ULTRA_DETAILED.md and wire dependencies for parallel execution.\n\nTesting & Logging Requirements:\n- Comprehensive unit tests for all core logic, edge cases, and error paths.\n- Integration and end-to-end test scripts that exercise full user-facing workflows.\n- Detailed structured logging with stable error/status codes and trace correlation IDs.\n- Deterministic artifacts (reports/log bundles) sufficient to reproduce failures and verify fixes.\n","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-20T07:26:05.244464447Z","created_by":"ubuntu","updated_at":"2026-02-20T07:44:42.337185339Z","closed_at":"2026-02-20T07:44:42.337164901Z","close_reason":"Superseded by full 10.x + 11-16 master-plan graph in bd-33v; backlog seeding objective complete.","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-2d17","title":"[10.20] Integrate DGIS health scoring into migration autopilot admission and progression gates.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.20 — Dependency Graph Immune System Execution Track (9N)\n\nWhy This Exists:\nDGIS topological immune system track for dependency contagion modeling, choke-point immunization, and graph-aware containment economics.\n\nTask Objective:\nIntegrate DGIS health scoring into migration autopilot admission and progression gates.\n\nAcceptance Criteria:\n- Migration plans include graph-health baselines and target thresholds; migrations that worsen cascade risk beyond policy budgets are blocked or auto-replanned.\n\nExpected Artifacts:\n- `src/migration/dgis_migration_gate.rs`, `tests/integration/dgis_migration_gate.rs`, `artifacts/10.20/dgis_migration_health_report.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_20/bd-2d17/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_20/bd-2d17/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.20] Integrate DGIS health scoring into migration autopilot admission and progression gates.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.20] Integrate DGIS health scoring into migration autopilot admission and progression gates.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.20] Integrate DGIS health scoring into migration autopilot admission and progression gates.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.20] Integrate DGIS health scoring into migration autopilot admission and progression gates.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.20] Integrate DGIS health scoring into migration autopilot admission and progression gates.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- Migration plans include graph-health baselines and target thresholds; migrations that worsen cascade risk beyond policy budgets are blocked or auto-replanned.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:37:07.444273469Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:20.921814126Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-20","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-2d17","depends_on_id":"bd-1f8v","type":"blocks","created_at":"2026-02-20T07:43:21.107205310Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2d17","depends_on_id":"bd-2fid","type":"blocks","created_at":"2026-02-20T15:01:16.397885486Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2d17","depends_on_id":"bd-t89w","type":"blocks","created_at":"2026-02-20T15:01:16.183397567Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-2de","title":"[10.0] Implement migration autopilot pipeline.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.0 — Top 10 Initiative Tracking (Initiative #2)\nCross-references: 9A.2, 9B.2, 9C.2, 9D.2\n\nWhy This Exists:\nMigration autopilot is the #2 strategic initiative. It provides one-command migration workflows that inventory APIs, detect risk hotspots, propose transformations, run compatibility validation, and emit rollout guidance with confidence grades. This is the primary mechanism for collapsing migration friction — the key barrier to franken_node adoption.\n\nTask Objective:\nBuild the full migration autopilot pipeline from audit through rollout: scan project -> score risks -> suggest rewrites -> validate with lockstep -> plan rollout stages -> generate confidence report -> export enterprise review bundle -> enable deterministic failure replay.\n\nDetailed Acceptance Criteria:\n1. Project scanner inventories all API/runtime/dependency usage with risk classification per band.\n2. Risk scoring model produces explainable feature-level scores with uncertainty bands.\n3. Rewrite suggestion engine generates transformation proposals with rollback plan artifacts and hypothesis-tested confidence intervals (9C.2).\n4. Validation runner executes lockstep checks against compatibility fixtures.\n5. Rollout planner creates staged deployment plan (shadow -> canary -> ramp -> default) per project.\n6. Migration confidence report includes uncertainty bands and per-API risk breakdowns.\n7. One-command enterprise review export produces self-contained migration assessment bundle.\n8. Deterministic failure replay tooling captures and replays any migration failure.\n9. Scan and transform throughput optimized with deterministic batching and cache reuse (9D.2).\n10. Incremental/self-adjusting computation so large project migrations re-run quickly and reproducibly (9B.2).\n\nKey Dependencies:\n- Depends on 10.2 (Compatibility Core) for fixture runners and band definitions.\n- Depends on 10.1 (Charter) for governance boundaries.\n- This is the foundation for 10.3 (Migration System) detailed implementation beads.\n- Consumed by 10.9 (Moonshot) for migration singularity demo pipeline.\n\nExpected Artifacts:\n- src/migration/ module with scanner, risk_scorer, rewrite_engine, validation_runner, rollout_planner, confidence_report, export, replay submodules.\n- docs/specs/section_10_0/bd-2de_contract.md\n- artifacts/section_10_0/bd-2de/verification_evidence.json\n- artifacts/section_10_0/bd-2de/verification_summary.md\n\nTesting and Logging Requirements:\n- Unit tests: scanner API detection, risk scoring accuracy, rewrite transformation correctness, rollout stage computation, confidence interval calibration.\n- Integration tests: full pipeline execution on sample Node.js projects with known API surfaces.\n- E2E tests: franken-node migrate audit/rewrite/validate CLI commands on real-world fixture projects.\n- Performance tests: scanner throughput on large monorepo fixtures (>10k files).\n- Structured logs: MIGRATION_SCAN_START, RISK_SCORED, REWRITE_PROPOSED, VALIDATION_PASSED/FAILED, ROLLOUT_PLANNED with trace IDs and per-API breakdown.","acceptance_criteria":"1. Single-command invocation (`franken-node migrate <project-dir>`) executes full pipeline: inventory, risk detection, transformation proposal, validation, rollout guidance.\n2. API inventory phase catalogs all Node.js/Bun API calls in target project with >= 99% recall (verified against manual audit of 5 reference projects).\n3. Risk hotspot detection identifies: deprecated APIs, polyfilled behaviors, platform-specific code paths, divergence-ledger matches; each hotspot assigned severity (critical/high/medium/low).\n4. Transformation proposals are generated as AST-safe patches (not regex); each proposal includes before/after diff, confidence grade (A/B/C/D), and rollback instruction.\n5. Migration velocity target: >= 3x faster than manual migration baseline (Section 3), measured on reference project corpus.\n6. Validation phase runs transformed code against compatibility envelope test suite; reports pass/fail per API category.\n7. Rollout guidance emits confidence grades per module: A (>= 95% pass), B (>= 85%), C (>= 70%), D (< 70% — manual review required).\n8. Pipeline produces machine-readable migration report (JSON) with: total APIs, migrated count, risk hotspots, confidence distribution, estimated remaining manual effort.\n9. Idempotent execution: running pipeline twice on same input produces identical output.\n10. Cross-references to enhancement maps 9A-9O verified; pipeline stages map to canonical owner tracks in 10.N.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:36:42.563832677Z","created_by":"ubuntu","updated_at":"2026-02-20T15:35:27.919235569Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-0","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-2de","depends_on_id":"bd-1qp","type":"blocks","created_at":"2026-02-20T07:43:10.137771649Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-2e73","title":"[10.14] Implement bounded evidence ledger ring buffer plus lab spill-to-artifacts mode.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.14 — FrankenSQLite Deep-Mined Expansion Execution Track (9J)\n\nWhy This Exists:\nFrankenSQLite deep-mined control integrity track: evidence ledgers, proofs, epochs, remote effects, markers/MMR, and deterministic fault labs.\n\nTask Objective:\nImplement bounded evidence ledger ring buffer plus lab spill-to-artifacts mode.\n\nAcceptance Criteria:\n- Production ledger memory stays within configured bound; overflow policy is deterministic; lab mode writes full spill artifacts for failing scenarios.\n\nExpected Artifacts:\n- `src/observability/evidence_ledger.rs`, `tests/integration/evidence_ledger_bounds.rs`, `artifacts/10.14/evidence_spill_example.jsonl`.\n\n- Machine-readable verification artifact at `artifacts/section_10_14/bd-2e73/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_14/bd-2e73/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.14] Implement bounded evidence ledger ring buffer plus lab spill-to-artifacts mode.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.14] Implement bounded evidence ledger ring buffer plus lab spill-to-artifacts mode.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.14] Implement bounded evidence ledger ring buffer plus lab spill-to-artifacts mode.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.14] Implement bounded evidence ledger ring buffer plus lab spill-to-artifacts mode.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.14] Implement bounded evidence ledger ring buffer plus lab spill-to-artifacts mode.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"Production ledger memory stays within configured bound; overflow policy is deterministic; lab mode writes full spill artifacts for failing scenarios.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:36:55.222468326Z","created_by":"ubuntu","updated_at":"2026-02-20T15:44:12.537578423Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-14","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-2e73","depends_on_id":"bd-nupr","type":"blocks","created_at":"2026-02-20T07:43:14.244117446Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-2eun","title":"[10.13] Implement quarantine-by-default store for unreferenced objects with quota + TTL enforcement.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.13 — FCP Deep-Mined Expansion Execution Track (9I)\n\nWhy This Exists:\nDeep connector/provider contract track: lifecycle FSMs, conformance harnesses, fencing, sandboxing, revocation freshness, and protocol hardening.\n\nTask Objective:\nImplement quarantine-by-default store for unreferenced objects with quota + TTL enforcement.\n\nAcceptance Criteria:\n- Unknown objects enter quarantine class by default; quota and TTL eviction enforce hard caps; quarantined objects are excluded from primary gossip state.\n\nExpected Artifacts:\n- `src/admission/quarantine_store.rs`, `tests/integration/quarantine_retention.rs`, `artifacts/10.13/quarantine_usage_metrics.csv`.\n\n- Machine-readable verification artifact at `artifacts/section_10_13/bd-2eun/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_13/bd-2eun/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.13] Implement quarantine-by-default store for unreferenced objects with quota + TTL enforcement.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.13] Implement quarantine-by-default store for unreferenced objects with quota + TTL enforcement.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.13] Implement quarantine-by-default store for unreferenced objects with quota + TTL enforcement.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.13] Implement quarantine-by-default store for unreferenced objects with quota + TTL enforcement.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.13] Implement quarantine-by-default store for unreferenced objects with quota + TTL enforcement.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","status":"closed","priority":1,"issue_type":"task","assignee":"CrimsonCrane","created_at":"2026-02-20T07:36:54.087635905Z","created_by":"ubuntu","updated_at":"2026-02-20T12:51:47.028565935Z","closed_at":"2026-02-20T12:51:47.028537071Z","close_reason":"done","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-13","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-2eun","depends_on_id":"bd-3b8m","type":"blocks","created_at":"2026-02-20T07:43:13.643348493Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-2ew","title":"[10.3] Build automated rewrite suggestion engine with rollback plan artifacts.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.3 — Migration System\n\nWhy This Exists:\nMigration autopilot pipeline from audit to rollout, designed to collapse migration friction with deterministic confidence and replayability.\n\nTask Objective:\nBuild automated rewrite suggestion engine with rollback plan artifacts.\n\nAcceptance Criteria:\n- Implement with explicit success/failure invariants and deterministic behavior under normal, edge, and fault scenarios.\n- Ensure outcomes are verifiable via automated tests and reproducible artifact outputs.\n\nExpected Artifacts:\n- Section-owned design/spec artifact at `docs/specs/section_10_3/bd-2ew_contract.md`, capturing decision rationale, invariants, and interface boundaries.\n- Machine-readable verification artifact at `artifacts/section_10_3/bd-2ew/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_3/bd-2ew/verification_summary.md` linking implementation intent to measured outcomes.\n\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.3] Build automated rewrite suggestion engine with rollback plan artifacts.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.3] Build automated rewrite suggestion engine with rollback plan artifacts.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.3] Build automated rewrite suggestion engine with rollback plan artifacts.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.3] Build automated rewrite suggestion engine with rollback plan artifacts.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.3] Build automated rewrite suggestion engine with rollback plan artifacts.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","status":"closed","priority":1,"issue_type":"task","assignee":"CrimsonCrane","created_at":"2026-02-20T07:36:44.957177915Z","created_by":"ubuntu","updated_at":"2026-02-20T10:12:52.375674295Z","closed_at":"2026-02-20T10:12:52.375651132Z","close_reason":"done","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-3","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-2ew","depends_on_id":"bd-33x","type":"blocks","created_at":"2026-02-20T07:43:22.098871560Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-2f43","title":"[13] Success criterion: low-risk migration pathways","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 13\n\nTask Objective:\nInstrument and verify that franken_node delivers practical low-risk migration pathways for Node/Bun cohorts.\n\nExecution Requirements:\n- Make this requirement machine-verifiable and release-gated where applicable.\n- Keep behavior self-documenting so future contributors do not need to re-open the master plan.\n\nTesting & Logging Requirements:\n- Unit tests for rule/contract logic and error conditions.\n- Integration/E2E tests for workflow-level enforcement.\n- Structured logs with stable codes and trace IDs.\n- Reproducible artifacts that prove contract satisfaction.\n\nAcceptance Criteria:\n- Success and failure invariants for [13] Success criterion: low-risk migration pathways are explicitly quantified and machine-verifiable.\n- Determinism requirements for [13] Success criterion: low-risk migration pathways are validated across repeated runs and adversarial perturbations.\n\n\nExpected Artifacts:\n- Machine-readable verification artifact with explicit canonical path under artifacts/section_13/bd-2f43/verification_evidence.json, suitable for CI/release gating.\n- Human-readable verification summary with explicit canonical path under artifacts/section_13/bd-2f43/verification_summary.md, linking implementation intent to measured validation outcomes.\n\nTask-Specific Clarification:\n- The implementation must deliver the exact capability named in the title, with no scope dilution and no silent feature omission.\n- Validation artifacts must include capability-specific thresholds, pass/fail criteria, and reproducible evidence bundles tied to this bead ID.\n- Program/section verification gates must be able to consume this bead's outputs without manual interpretation.\n\nWhy This Improves User Outcomes:\n- \"[13] Success criterion: low-risk migration pathways\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[13] Success criterion: low-risk migration pathways\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"1. Migration pathways are documented for the top 5 Node.js project archetypes: Express/Fastify web server, Next.js/Remix SSR app, CLI tool, npm library package, background worker/queue processor.\n2. Each pathway includes: pre-migration compatibility check, automated migration steps, manual intervention points, post-migration validation suite.\n3. Migration risk score (0-100) is computed automatically for each project before migration begins.\n4. Projects with risk score <= 30 ('low risk') complete migration with zero manual steps in >= 90% of cases.\n5. Bun migration pathway exists for at least 2 archetypes (web server, CLI tool) with documented compatibility delta.\n6. Rollback from franken_node to original runtime is supported and tested for all pathways.\n7. Evidence: migration_pathway_matrix.json mapping each archetype to pathway steps, risk score range, and success rate.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:39:34.303595863Z","created_by":"ubuntu","updated_at":"2026-02-20T16:08:27.977113562Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-13","self-contained","test-obligations"]}
{"id":"bd-2f5l","title":"[10.16] Build `fastapi_rust` service skeleton for required operator/verifier/fleet-control endpoints.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.16 — Adjacent Substrate Integration Execution Track (8.7)\n\nWhy This Exists:\nAdjacent substrate integration track to enforce deep composition with frankentui, frankensqlite, sqlmodel_rust, and fastapi_rust.\n\nTask Objective:\nBuild `fastapi_rust` service skeleton for required operator/verifier/fleet-control endpoints.\n\nAcceptance Criteria:\n- Skeleton exposes required endpoint groups with policy and trace correlation hooks; service conformance tests pass.\n\nExpected Artifacts:\n- `services/control_plane_fastapi_rust/*`, `tests/integration/fastapi_control_plane_endpoints.rs`, `artifacts/10.16/fastapi_endpoint_report.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_16/bd-2f5l/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_16/bd-2f5l/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.16] Build `fastapi_rust` service skeleton for required operator/verifier/fleet-control endpoints.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.16] Build `fastapi_rust` service skeleton for required operator/verifier/fleet-control endpoints.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.16] Build `fastapi_rust` service skeleton for required operator/verifier/fleet-control endpoints.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.16] Build `fastapi_rust` service skeleton for required operator/verifier/fleet-control endpoints.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.16] Build `fastapi_rust` service skeleton for required operator/verifier/fleet-control endpoints.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- Skeleton exposes required endpoint groups with policy and trace correlation hooks; service conformance tests pass.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:37:02.431909915Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:46.055922516Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-16","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-2f5l","depends_on_id":"bd-3ndj","type":"blocks","created_at":"2026-02-20T07:43:18.004021091Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-2fa","title":"[10.5] Implement counterfactual replay mode for policy simulation.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.5 — Security + Policy Product Surfaces\n\nWhy This Exists:\nSecurity and policy product surfaces: decision receipts, incident replay, expected-loss policying, and auditable degraded-mode behavior.\n\nTask Objective:\nImplement counterfactual replay mode for policy simulation.\n\nAcceptance Criteria:\n- Implement with explicit success/failure invariants and deterministic behavior under normal, edge, and fault scenarios.\n- Ensure outcomes are verifiable via automated tests and reproducible artifact outputs.\n\nExpected Artifacts:\n- Section-owned design/spec artifact at `docs/specs/section_10_5/bd-2fa_contract.md`, capturing decision rationale, invariants, and interface boundaries.\n- Machine-readable verification artifact at `artifacts/section_10_5/bd-2fa/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_5/bd-2fa/verification_summary.md` linking implementation intent to measured outcomes.\n\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.5] Implement counterfactual replay mode for policy simulation.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.5] Implement counterfactual replay mode for policy simulation.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.5] Implement counterfactual replay mode for policy simulation.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.5] Implement counterfactual replay mode for policy simulation.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.5] Implement counterfactual replay mode for policy simulation.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"1. Implement a CounterfactualReplayEngine that accepts a ReplayBundle (from bd-vll) and an alternate PolicyConfig, then re-executes the timeline under the alternate policy to produce a CounterfactualResult.\n2. CounterfactualResult contains: original_outcomes (Vec<DecisionPoint>), counterfactual_outcomes (Vec<DecisionPoint>), divergence_points (Vec<DivergenceRecord>), and summary_statistics (struct with fields: total_decisions, changed_decisions, severity_delta).\n3. Each DivergenceRecord includes: sequence_number, original_decision, counterfactual_decision, original_rationale, counterfactual_rationale, and impact_estimate (enum: None | Low | Medium | High | Critical).\n4. Replay must be fully deterministic and side-effect-free: no I/O, no network calls, no mutable global state; enforce this via a SandboxedExecutor trait that only permits pure computation.\n5. Support at least two simulation modes: SinglePolicySwap (replace one policy entirely) and ParameterSweep (vary a numeric parameter across N values, returning N CounterfactualResults).\n6. Execution must be bounded: enforce a max_replay_steps (default 100,000) and max_wall_clock (default 30s) timeout; exceeding either returns Err with partial results.\n7. Verification: scripts/check_counterfactual.py --json runs a counterfactual replay on a known fixture bundle with a policy that flips at least one decision, asserts divergence_points is non-empty; unit tests in tests/test_check_counterfactual.py cover both modes and the timeout guard; evidence in artifacts/section_10_5/bd-2fa/.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:36:46.300977215Z","created_by":"ubuntu","updated_at":"2026-02-20T15:15:29.742846828Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-5","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-2fa","depends_on_id":"bd-vll","type":"blocks","created_at":"2026-02-20T07:43:22.878820503Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-2fid","title":"[10.20] Implement critical-node immunization planner and choke-point barrier synthesis engine.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.20 — Dependency Graph Immune System Execution Track (9N)\n\nWhy This Exists:\nDGIS topological immune system track for dependency contagion modeling, choke-point immunization, and graph-aware containment economics.\n\nTask Objective:\nImplement critical-node immunization planner and choke-point barrier synthesis engine.\n\nAcceptance Criteria:\n- Planner proposes minimum-cost barrier sets that reduce expected cascade loss under policy/performance constraints; recommendation rationale is machine-readable and replayable.\n\nExpected Artifacts:\n- `docs/specs/dgis_immunization_planner.md`, `src/security/dgis/immunization_planner.rs`, `artifacts/10.20/dgis_barrier_plan_catalog.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_20/bd-2fid/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_20/bd-2fid/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.20] Implement critical-node immunization planner and choke-point barrier synthesis engine.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.20] Implement critical-node immunization planner and choke-point barrier synthesis engine.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.20] Implement critical-node immunization planner and choke-point barrier synthesis engine.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.20] Implement critical-node immunization planner and choke-point barrier synthesis engine.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.20] Implement critical-node immunization planner and choke-point barrier synthesis engine.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- Planner proposes minimum-cost barrier sets that reduce expected cascade loss under policy/performance constraints; recommendation rationale is machine-readable and replayable.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:37:06.831761194Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:21.163051555Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-20","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-2fid","depends_on_id":"bd-1q38","type":"blocks","created_at":"2026-02-20T07:43:20.800566765Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-2fkq","title":"[14] Metric family: migration speed and failure-rate improvements","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 14\n\nTask Objective:\nInstrument migration speed/failure-rate improvement metric family.\n\nExecution Requirements:\n- Make this requirement machine-verifiable and release-gated where applicable.\n- Keep behavior self-documenting so future contributors do not need to re-open the master plan.\n\nTesting & Logging Requirements:\n- Unit tests for rule/contract logic and error conditions.\n- Integration/E2E tests for workflow-level enforcement.\n- Structured logs with stable codes and trace IDs.\n- Reproducible artifacts that prove contract satisfaction.\n\nAcceptance Criteria:\n- Success and failure invariants for [14] Metric family: migration speed and failure-rate improvements are explicitly quantified and machine-verifiable.\n- Determinism requirements for [14] Metric family: migration speed and failure-rate improvements are validated across repeated runs and adversarial perturbations.\n\n\nExpected Artifacts:\n- Machine-readable verification artifact with explicit canonical path under artifacts/section_14/bd-2fkq/verification_evidence.json, suitable for CI/release gating.\n- Human-readable verification summary with explicit canonical path under artifacts/section_14/bd-2fkq/verification_summary.md, linking implementation intent to measured validation outcomes.\n\nTask-Specific Clarification:\n- The implementation must deliver the exact capability named in the title, with no scope dilution and no silent feature omission.\n- Validation artifacts must include capability-specific thresholds, pass/fail criteria, and reproducible evidence bundles tied to this bead ID.\n- Program/section verification gates must be able to consume this bead's outputs without manual interpretation.\n\nWhy This Improves User Outcomes:\n- \"[14] Metric family: migration speed and failure-rate improvements\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[14] Metric family: migration speed and failure-rate improvements\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"METRIC FAMILY: Migration speed and failure-rate improvements.\n1. Metrics measured: (a) migration wall-clock time per project archetype, (b) manual intervention count per migration, (c) migration failure rate (% of projects that fail to complete migration), (d) post-migration defect rate (bugs found within 7 days), (e) velocity improvement ratio (tooled vs manual).\n2. Measured across project archetypes: Express/Fastify, Next.js/Remix, CLI tool, library, worker service, monorepo.\n3. Velocity target: >= 3x improvement (tooled migration takes <= 1/3 of manual time).\n4. Failure rate target: <= 5% of migration attempts fail (defined as: migrated project does not pass its original test suite).\n5. Post-migration defect rate target: <= 2 defects per migration within 7-day window.\n6. Metrics tracked over time: each release measures migration metrics on the standard cohort; regressions > 10% trigger investigation.\n7. Publication: migration metrics in benchmark report with per-archetype breakdown and trend charts.\n8. Evidence: migration_speed_metrics.json with per-archetype timings, failure rates, defect rates, and velocity ratios.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:39:36.071625027Z","created_by":"ubuntu","updated_at":"2026-02-20T15:25:34.264601049Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-14","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-2fkq","depends_on_id":"bd-2ps7","type":"blocks","created_at":"2026-02-20T07:43:26.157242133Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-2fpj","title":"[11] Contract field: expected-loss model","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 11\n\nTask Objective:\nRequire explicit expected-loss model inputs, assumptions, and output for decision-bearing changes.\n\nExecution Requirements:\n- Make this requirement machine-verifiable and release-gated where applicable.\n- Keep behavior self-documenting so future contributors do not need to re-open the master plan.\n\nTesting & Logging Requirements:\n- Unit tests for rule/contract logic and error conditions.\n- Integration/E2E tests for workflow-level enforcement.\n- Structured logs with stable codes and trace IDs.\n- Reproducible artifacts that prove contract satisfaction.\n\nAcceptance Criteria:\n- Success and failure invariants for [11] Contract field: expected-loss model are explicitly quantified and machine-verifiable.\n- Determinism requirements for [11] Contract field: expected-loss model are validated across repeated runs and adversarial perturbations.\n\n\nExpected Artifacts:\n- Machine-readable verification artifact with explicit canonical path under artifacts/section_11/bd-2fpj/verification_evidence.json, suitable for CI/release gating.\n- Human-readable verification summary with explicit canonical path under artifacts/section_11/bd-2fpj/verification_summary.md, linking implementation intent to measured validation outcomes.\n\nTask-Specific Clarification:\n- The implementation must deliver the exact capability named in the title, with no scope dilution and no silent feature omission.\n- Validation artifacts must include capability-specific thresholds, pass/fail criteria, and reproducible evidence bundles tied to this bead ID.\n- Program/section verification gates must be able to consume this bead's outputs without manual interpretation.\n\nWhy This Improves User Outcomes:\n- \"[11] Contract field: expected-loss model\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[11] Contract field: expected-loss model\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"1. Every evidence contract includes an expected-loss model section with: (a) probability of adverse outcome (numeric, 0-1), (b) estimated cost/impact in concrete units (latency ms, error rate %, incidents/month), (c) expected loss = probability * impact.\n2. The model must specify at least two scenarios: best-case and worst-case, with distinct probability/impact pairs.\n3. Loss estimates must cite data sources: historical metrics, benchmark results, or threat model assumptions.\n4. CI rejects contracts where expected-loss section is missing or contains non-numeric probability/impact values.\n5. Unit test: contract with valid two-scenario model passes; contract with single scenario or non-numeric values fails.\n6. Expected loss must be cross-referenced with the EV score — if expected loss exceeds EV benefit, the contract must include explicit justification.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:39:32.734458311Z","created_by":"ubuntu","updated_at":"2026-02-20T15:16:16.675389872Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-11","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-2fpj","depends_on_id":"bd-1jmq","type":"blocks","created_at":"2026-02-20T07:43:24.419804592Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-2g0","title":"[10.0] Implement economic trust layer.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.0 — Top 10 Initiative Tracking (Initiative #9)\nCross-references: 9A.9, 9B.9, 9C.9, 9D.9\n\nWhy This Exists:\nEconomic trust layer is the #9 strategic initiative. It quantifies attack-cost amplification and privilege-risk pricing so trust policy tuning is economically grounded instead of threshold folklore. This makes security policy decisions rigorous and defensible.\n\nTask Objective:\nBuild the economic trust layer that models attacker economics (cost of attack, cost of defense, expected damage) and uses these to inform policy thresholds, trust card risk tiers, and copilot recommendations with quantified rationale.\n\nDetailed Acceptance Criteria:\n1. Attack-cost amplification model: given extension/publisher profile, estimate cost to compromise.\n2. Privilege-risk pricing: quantify the risk exposure from granting specific capabilities to extensions.\n3. Policy threshold derivation: automatically derive recommended thresholds from economic model outputs.\n4. Decision-theoretic expected-loss and robust posterior updates for pricing and policy recommendations (9B.9).\n5. Posterior attacker ROI models maintained and calibration diagnostics published (9C.9).\n6. Model update and scoring hot paths optimized under heavy event streams (9D.9).\n7. Integration with trust cards for risk tier assignment and operator copilot for recommendation scoring.\n8. Dashboard surface showing attacker-ROI deltas and category-shift reporting (10.9).\n\nKey Dependencies:\n- Depends on trust cards (10.0.3) for extension risk data.\n- Depends on 10.5 (Security) for expected-loss action scoring framework.\n- Consumed by operator copilot (10.0.8) for action recommendation scoring.\n- Consumed by 10.21 (BPET) for evolution-risk scoring integration.\n\nExpected Artifacts:\n- src/security/economic_trust.rs — attack cost model, privilege pricing, threshold derivation.\n- src/security/attacker_roi.rs — posterior ROI models with calibration.\n- docs/specs/section_10_0/bd-2g0_contract.md\n- artifacts/section_10_0/bd-2g0/verification_evidence.json\n\nTesting and Logging Requirements:\n- Unit tests: cost model computation, risk pricing correctness, threshold derivation, posterior update determinism.\n- Integration tests: economic model integration with trust card data and copilot scoring.\n- E2E tests: end-to-end flow from extension risk data through economic model to policy recommendation.\n- Calibration tests: model predictions vs historical incident data (when available).\n- Structured logs: ATTACK_COST_COMPUTED, RISK_PRICED, THRESHOLD_DERIVED, POSTERIOR_UPDATED, CALIBRATION_DIAGNOSTIC with trace IDs.","acceptance_criteria":"1. Attack-cost amplification: system quantifies minimum attack cost for each privilege level; target >= 10x cost amplification vs. baseline (unauthenticated attacker baseline).\n2. Privilege-risk pricing: each privilege grant has an associated risk price (computed from: blast radius, historical exploit frequency, asset value); price visible in policy decisions.\n3. Trust policy tuning: economic model provides recommended policy threshold adjustments based on cost-benefit analysis; tuning suggestions include expected-loss delta and confidence interval.\n4. Risk pricing model is deterministic: same input state produces identical risk prices across runs; model parameters versioned and auditable.\n5. Economic signals consumed by operator safety copilot (bd-1nf): risk prices feed into expected-loss calculations for recommended actions.\n6. Integration with trust cards (bd-y4g): extension trust score incorporates economic risk price; low-trust extensions face higher privilege-risk prices (economic deterrent).\n7. Compromise reduction contribution: economic trust layer contributes to >= 10x compromise reduction target (Section 3) by making attacks economically irrational at policy-enforced thresholds.\n8. CLI queryable: `franken-node trust economics --extension <name> --format json` outputs risk price decomposition, attack-cost estimate, and policy threshold status.\n9. Model transparency: all pricing parameters, formulas, and calibration data documented and reproducible; no opaque ML models without explainability layer.\n10. Verification evidence includes: attack-cost amplification measurement for 3+ attack scenarios, privilege-risk price calculation test, policy tuning recommendation validation, economic model determinism test.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:36:43.124138307Z","created_by":"ubuntu","updated_at":"2026-02-20T15:36:33.858594641Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-0","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-2g0","depends_on_id":"bd-1nf","type":"blocks","created_at":"2026-02-20T07:43:10.436537951Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-2g6r","title":"[10.15] Enforce Cx-first signature policy for control-plane async entrypoints.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.15 — Asupersync-First Integration Execution Track (8.4-8.6)\n\nWhy This Exists:\nAsupersync-first control-plane migration track enforcing Cx-first, region ownership, cancellation correctness, and protocol-grade verification gates.\n\nTask Objective:\nEnforce Cx-first signature policy for control-plane async entrypoints.\n\nAcceptance Criteria:\n- Lint/gate rejects new high-impact async APIs missing `&Cx`; existing exceptions are enumerated and time-bounded.\n\nExpected Artifacts:\n- `tools/lints/cx_first_policy.rs`, `tests/conformance/cx_first_api_gate.rs`, `artifacts/10.15/cx_first_compliance.csv`.\n\n- Machine-readable verification artifact at `artifacts/section_10_15/bd-2g6r/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_15/bd-2g6r/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.15] Enforce Cx-first signature policy for control-plane async entrypoints.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.15] Enforce Cx-first signature policy for control-plane async entrypoints.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.15] Enforce Cx-first signature policy for control-plane async entrypoints.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.15] Enforce Cx-first signature policy for control-plane async entrypoints.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.15] Enforce Cx-first signature policy for control-plane async entrypoints.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- Lint/gate rejects new high-impact async APIs missing `&Cx`; existing exceptions are enumerated and time-bounded.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:36:59.645330297Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:53.918199806Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-15","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-2g6r","depends_on_id":"bd-2177","type":"blocks","created_at":"2026-02-20T07:43:16.538800001Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-2g8","title":"[PLAN 12] Risk Register Countermeasure Program","description":"Section 12 risk-control epic. Convert each enumerated risk (compat illusion, scope explosion, trust complexity, migration friction, perf regressions, federation privacy/poisoning, topology blind spots, false positives, temporal drift, trajectory privacy, camouflage attacks) into explicit validation and control gates.\n\n## Success Criteria\n- All child beads for this section are completed with acceptance artifacts attached and no unresolved blockers.\n- Section-level verification gate for comprehensive unit tests, integration/e2e workflows, and detailed structured logging evidence is green.\n- Scope-to-plan traceability is explicit, with no feature loss versus the canonical plan section.\n\n## Optimization Notes\n- User-Outcome Lens: \"[PLAN 12] Risk Register Countermeasure Program\" must improve real operator and end-user reliability, explainability, and time-to-safe-outcome under both normal and degraded conditions.\n- Cross-Section Coordination: this epic's child beads must explicitly encode integration expectations with neighboring sections to prevent local optimizations that break global behavior.\n- Verification Non-Negotiable: completion requires deterministic unit coverage, integration/E2E replay evidence, and structured logs sufficient for independent third-party reproduction and triage.\n- Scope Protection: any proposed simplification must prove feature parity against plan intent and document tradeoffs explicitly; silent scope reduction is forbidden.","status":"open","priority":1,"issue_type":"epic","created_at":"2026-02-20T07:36:42.092936537Z","created_by":"ubuntu","updated_at":"2026-02-20T08:12:47.650465713Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-12"],"dependencies":[{"issue_id":"bd-2g8","depends_on_id":"bd-13yn","type":"blocks","created_at":"2026-02-20T07:39:33.807060717Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2g8","depends_on_id":"bd-1n1t","type":"blocks","created_at":"2026-02-20T07:39:33.893841732Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2g8","depends_on_id":"bd-1nab","type":"blocks","created_at":"2026-02-20T07:39:33.716859451Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2g8","depends_on_id":"bd-1rff","type":"blocks","created_at":"2026-02-20T07:39:34.170254321Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2g8","depends_on_id":"bd-1ta","type":"blocks","created_at":"2026-02-20T07:38:35.059186428Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2g8","depends_on_id":"bd-1wz","type":"blocks","created_at":"2026-02-20T07:38:35.230482467Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2g8","depends_on_id":"bd-1xg","type":"blocks","created_at":"2026-02-20T07:38:34.858388615Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2g8","depends_on_id":"bd-20a","type":"blocks","created_at":"2026-02-20T07:38:34.902411025Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2g8","depends_on_id":"bd-229","type":"blocks","created_at":"2026-02-20T07:38:34.812920813Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2g8","depends_on_id":"bd-2w4u","type":"blocks","created_at":"2026-02-20T07:39:33.625969943Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2g8","depends_on_id":"bd-2x1e","type":"blocks","created_at":"2026-02-20T07:48:28.831969458Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2g8","depends_on_id":"bd-32p","type":"blocks","created_at":"2026-02-20T07:38:35.271740839Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2g8","depends_on_id":"bd-35m7","type":"blocks","created_at":"2026-02-20T07:39:34.259054778Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2g8","depends_on_id":"bd-37i","type":"blocks","created_at":"2026-02-20T07:38:35.404410229Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2g8","depends_on_id":"bd-38ri","type":"blocks","created_at":"2026-02-20T07:39:33.370620378Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2g8","depends_on_id":"bd-39a","type":"blocks","created_at":"2026-02-20T07:38:35.313287627Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2g8","depends_on_id":"bd-3il","type":"blocks","created_at":"2026-02-20T07:38:34.768066494Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2g8","depends_on_id":"bd-3jc1","type":"blocks","created_at":"2026-02-20T07:39:33.541241801Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2g8","depends_on_id":"bd-3qo","type":"blocks","created_at":"2026-02-20T07:38:35.146848574Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2g8","depends_on_id":"bd-3rc","type":"blocks","created_at":"2026-02-20T07:38:34.944491768Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2g8","depends_on_id":"bd-5rh","type":"blocks","created_at":"2026-02-20T07:38:35.102416181Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2g8","depends_on_id":"bd-c4f","type":"blocks","created_at":"2026-02-20T07:38:34.986878411Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2g8","depends_on_id":"bd-kiqr","type":"blocks","created_at":"2026-02-20T07:39:33.456215505Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2g8","depends_on_id":"bd-n71","type":"blocks","created_at":"2026-02-20T07:38:35.189081501Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2g8","depends_on_id":"bd-paui","type":"blocks","created_at":"2026-02-20T07:39:33.980269069Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2g8","depends_on_id":"bd-s4cu","type":"blocks","created_at":"2026-02-20T07:39:33.283669537Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2g8","depends_on_id":"bd-v4ps","type":"blocks","created_at":"2026-02-20T07:39:34.076647050Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2g8","depends_on_id":"bd-ybe","type":"blocks","created_at":"2026-02-20T07:38:35.358534437Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-2gh","title":"[10.13] Implement connector lifecycle enum, transition table, and illegal-transition rejection tests.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.13 — FCP Deep-Mined Expansion Execution Track (9I)\n\nWhy This Exists:\nDeep connector/provider contract track: lifecycle FSMs, conformance harnesses, fencing, sandboxing, revocation freshness, and protocol hardening.\n\nTask Objective:\nImplement connector lifecycle enum, transition table, and illegal-transition rejection tests.\n\nAcceptance Criteria:\n- FSM is complete and deterministic for all states; illegal transitions return stable codes; full transition matrix tests pass.\n\nExpected Artifacts:\n- `docs/specs/connector_lifecycle.md`, `tests/conformance/connector_lifecycle_transitions.rs`, `artifacts/10.13/lifecycle_transition_matrix.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_13/bd-2gh/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_13/bd-2gh/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.13] Implement connector lifecycle enum, transition table, and illegal-transition rejection tests.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.13] Implement connector lifecycle enum, transition table, and illegal-transition rejection tests.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.13] Implement connector lifecycle enum, transition table, and illegal-transition rejection tests.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.13] Implement connector lifecycle enum, transition table, and illegal-transition rejection tests.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.13] Implement connector lifecycle enum, transition table, and illegal-transition rejection tests.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","status":"closed","priority":1,"issue_type":"task","assignee":"CrimsonCrane","created_at":"2026-02-20T07:36:51.393382090Z","created_by":"ubuntu","updated_at":"2026-02-20T10:32:12.375932254Z","closed_at":"2026-02-20T10:32:12.375907738Z","close_reason":"done","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-13","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-2gh","depends_on_id":"bd-1ow","type":"blocks","created_at":"2026-02-20T07:46:32.585807024Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2gh","depends_on_id":"bd-cda","type":"blocks","created_at":"2026-02-20T07:46:32.648320507Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-2gr","title":"[10.11] Integrate canonical monotonic security epochs and transition barriers (from `10.14`) across product services.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.11 — FrankenSQLite-Inspired Runtime Systems Integration Track\n\nWhy This Exists:\nFrankenSQLite-inspired systems integration of capabilities, cancellation protocol, obligations, deterministic labs, and anti-entropy.\n\nTask Objective:\nIntegrate canonical monotonic security epochs and transition barriers (from `10.14`) across product services.\n\nAcceptance Criteria:\n- Implement with explicit success/failure invariants and deterministic behavior under normal, edge, and fault scenarios.\n- Ensure outcomes are verifiable via automated tests and reproducible artifact outputs.\n\nExpected Artifacts:\n- Section-owned design/spec artifact at `docs/specs/section_10_11/bd-2gr_contract.md`, capturing decision rationale, invariants, and interface boundaries.\n- Machine-readable verification artifact at `artifacts/section_10_11/bd-2gr/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_11/bd-2gr/verification_summary.md` linking implementation intent to measured outcomes.\n\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.11] Integrate canonical monotonic security epochs and transition barriers (from `10.14`) across product services.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.11] Integrate canonical monotonic security epochs and transition barriers (from `10.14`) across product services.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.11] Integrate canonical monotonic security epochs and transition barriers (from `10.14`) across product services.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.11] Integrate canonical monotonic security epochs and transition barriers (from `10.14`) across product services.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.11] Integrate canonical monotonic security epochs and transition barriers (from `10.14`) across product services.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"AC for bd-2gr:\n1. Integrate the canonical monotonic security epoch model from 10.14: every product service reads the current epoch_id from the shared manifest state and binds all operations to that epoch; epoch_id is a monotonically increasing u64 that never decreases.\n2. An EpochBarrier mechanism gates epoch transitions: before epoch N+1 activates, all in-flight operations bound to epoch N must complete or be cancelled via the drain protocol (bd-7om); the barrier blocks new-epoch operations until drain is confirmed.\n3. Operations that arrive with a stale epoch_id (< current) are rejected with STALE_EPOCH_REJECTED error code and a structured log event; operations must not silently proceed under an old epoch.\n4. The epoch transition sequence is: (a) propose new epoch, (b) broadcast drain signal for current epoch, (c) await drain confirmation from all services, (d) atomically advance epoch_id, (e) unblock new-epoch operations.\n5. A split-brain guard prevents two services from simultaneously believing they are in different epochs: the epoch_id is sourced from a single authoritative store, and services poll/subscribe with bounded staleness (configurable max_epoch_lag, default: 1).\n6. Epoch metadata (transition timestamp, reason, initiator) is recorded in an append-only epoch history log for audit purposes.\n7. Unit tests verify: (a) monotonicity invariant (epoch never decreases), (b) stale-epoch operations are rejected, (c) barrier blocks new-epoch work until drain completes, (d) concurrent epoch advance attempts are serialized (only one wins), (e) epoch history log records all transitions.\n8. Integration test: three simulated services coordinate an epoch transition with one slow-draining service, verifying barrier wait and eventual successful transition.\n9. Structured log events: EPOCH_PROPOSED / EPOCH_DRAIN_REQUESTED / EPOCH_DRAIN_CONFIRMED / EPOCH_ADVANCED / STALE_EPOCH_REJECTED with epoch_id, service_id, and transition_reason.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:36:50.469186589Z","created_by":"ubuntu","updated_at":"2026-02-20T15:19:09.913769792Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-11","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-2gr","depends_on_id":"bd-2nt","type":"blocks","created_at":"2026-02-20T07:43:11.744813201Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2gr","depends_on_id":"bd-2wsm","type":"blocks","created_at":"2026-02-20T15:00:18.464825451Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2gr","depends_on_id":"bd-3hdv","type":"blocks","created_at":"2026-02-20T15:00:18.283439361Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-2h2s","title":"[10.15] Add migration plan for existing non-asupersync control surfaces with scope burn-down tracking.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.15 — Asupersync-First Integration Execution Track (8.4-8.6)\n\nWhy This Exists:\nAsupersync-first control-plane migration track enforcing Cx-first, region ownership, cancellation correctness, and protocol-grade verification gates.\n\nTask Objective:\nAdd migration plan for existing non-asupersync control surfaces with scope burn-down tracking.\n\nAcceptance Criteria:\n- Legacy control paths are inventoried with migration status and closure criteria; remaining exceptions are explicitly justified.\n\nExpected Artifacts:\n- `docs/migration/asupersync_control_surface_migration.md`, `artifacts/10.15/control_surface_burndown.csv`.\n\n- Machine-readable verification artifact at `artifacts/section_10_15/bd-2h2s/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_15/bd-2h2s/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.15] Add migration plan for existing non-asupersync control surfaces with scope burn-down tracking.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.15] Add migration plan for existing non-asupersync control surfaces with scope burn-down tracking.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.15] Add migration plan for existing non-asupersync control surfaces with scope burn-down tracking.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.15] Add migration plan for existing non-asupersync control surfaces with scope burn-down tracking.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.15] Add migration plan for existing non-asupersync control surfaces with scope burn-down tracking.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- Legacy control paths are inventoried with migration status and closure criteria; remaining exceptions are explicitly justified.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:37:01.282248904Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:49.217770681Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-15","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-2h2s","depends_on_id":"bd-1f8m","type":"blocks","created_at":"2026-02-20T07:43:17.393254416Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-2hjg","title":"[10.18] Section-wide verification gate: comprehensive unit+e2e+logging","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.18\n\nTask Objective:\nCreate a hard section completion gate that verifies all implemented behavior in this section with comprehensive unit tests, integration/e2e scripts, and detailed structured logging evidence.\n\nAcceptance Criteria:\n- Section test matrix covers happy-path, edge-case, and adversarial/error-path scenarios for all section deliverables.\n- E2E scripts execute representative end-user workflows and policy/control-plane transitions for this section.\n- Structured logs include stable event/error codes, trace correlation IDs, and enough context for deterministic replay triage.\n- Verification report is deterministic and machine-readable for CI/release gating.\n\nExpected Artifacts:\n- Section-level test matrix and coverage summary artifact.\n- E2E script suite with pass/fail outputs and reproducible fixtures/seeds.\n- Structured log validation report and traceability bundle.\n- Gate verdict artifact consumable by release automation.\n\n- Machine-readable verification artifact at `artifacts/section_10_18/bd-2hjg/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_18/bd-2hjg/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests must validate contracts, invariants, and failure semantics.\n- E2E tests must validate cross-component behavior from user/operator entrypoints to persisted effects.\n- Logging must support root-cause analysis without hidden context requirements.\n\nTask-Specific Clarification:\n- For \"[10.18] Section-wide verification gate: comprehensive unit+e2e+logging\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.18] Section-wide verification gate: comprehensive unit+e2e+logging\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.18] Section-wide verification gate: comprehensive unit+e2e+logging\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.18] Section-wide verification gate: comprehensive unit+e2e+logging\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.18] Section-wide verification gate: comprehensive unit+e2e+logging\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:48:17.956638503Z","created_by":"ubuntu","updated_at":"2026-02-20T08:43:51.194721206Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-18","test-obligations","verification-gate"],"dependencies":[{"issue_id":"bd-2hjg","depends_on_id":"bd-16fq","type":"blocks","created_at":"2026-02-20T07:48:18.683822682Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2hjg","depends_on_id":"bd-1dpd","type":"blocks","created_at":"2026-02-20T08:24:26.013679638Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2hjg","depends_on_id":"bd-1o4v","type":"blocks","created_at":"2026-02-20T07:48:18.441228177Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2hjg","depends_on_id":"bd-1u8m","type":"blocks","created_at":"2026-02-20T07:48:18.489261712Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2hjg","depends_on_id":"bd-28u0","type":"blocks","created_at":"2026-02-20T07:48:18.537473529Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2hjg","depends_on_id":"bd-2twu","type":"blocks","created_at":"2026-02-20T08:20:51.790676075Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2hjg","depends_on_id":"bd-3g4k","type":"blocks","created_at":"2026-02-20T07:48:18.585332549Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2hjg","depends_on_id":"bd-3go4","type":"blocks","created_at":"2026-02-20T07:48:18.205857867Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2hjg","depends_on_id":"bd-3lzk","type":"blocks","created_at":"2026-02-20T07:48:18.060944819Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2hjg","depends_on_id":"bd-3pds","type":"blocks","created_at":"2026-02-20T07:48:18.253250879Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2hjg","depends_on_id":"bd-3ptu","type":"blocks","created_at":"2026-02-20T07:48:18.158148506Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2hjg","depends_on_id":"bd-4jh9","type":"blocks","created_at":"2026-02-20T07:48:18.304202149Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2hjg","depends_on_id":"bd-8qlj","type":"blocks","created_at":"2026-02-20T07:48:18.377396307Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2hjg","depends_on_id":"bd-p73r","type":"blocks","created_at":"2026-02-20T07:48:18.634851360Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2hjg","depends_on_id":"bd-ufk5","type":"blocks","created_at":"2026-02-20T07:48:18.109688547Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-2hrg","title":"[3.2] Impossible-by-Default Capability Index — 10 mandatory category differentiators","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md — Section 3.2\n\n## Why This Exists\nThis is the CORE differentiator list. These 10 capabilities define what franken_node can do that incumbents (Node.js, Bun) CANNOT do by default. Every one of these must be productionized. If users can get the same outcomes with a thin wrapper around Node/Bun defaults, the feature is insufficient. If claims cannot be independently verified, the feature is insufficient.\n\n## The 10 Impossible-by-Default Capabilities (Non-Negotiable)\n\n1. **Policy-visible compatibility behavior with explicit divergence receipts.** Owner: 10.2 + 10.5. Every compatibility shim is typed, auditable, and policy-gated.\n2. **One-command migration audit and risk map for Node/Bun projects.** Owner: 10.3 + 10.12. Zero-to-first-safe-run pipeline with rollout guidance.\n3. **Signed policy checkpoints and revocation-aware execution gates.** Owner: 10.13 + 10.10. Revocation freshness semantics per safety tier with degraded-mode policy.\n4. **Deterministic incident replay with counterfactual policy simulation.** Owner: 10.5 + 10.17. Full-fidelity deterministic capture/replay for extension-host execution.\n5. **Fleet quarantine propagation with bounded convergence guarantees.** Owner: 10.8 + 10.20. Global scope, blast-radius views, convergence indicators, rollback controls.\n6. **Extension trust cards combining provenance, behavior, and revocation state.** Owner: 10.4 + 10.21. Single explainable trust model for humans and automation.\n7. **Compatibility lockstep oracle across Node/Bun/franken_node.** Owner: 10.2 (L1) + 10.17 (L2). Dual-layer oracle for external behavior and runtime integrity.\n8. **Control-plane recommended actions with expected-loss rationale.** Owner: 10.5 + 10.17. VOI-based ranking, confidence context, deterministic rollback commands.\n9. **Ecosystem reputation graph with explainable trust transitions.** Owner: 10.4 + 10.19 + 10.21. Bayesian adversary graph, publisher reputation, federated intelligence.\n10. **Public verifier toolkit for benchmark and security claims.** Owner: 10.17 + 10.14. Universal verifier SDK, replay capsules, claim compiler, public trust scoreboard.\n\n## Category-Creation Test\n- If users can get the same outcomes with a thin wrapper around Node/Bun defaults, the feature is insufficient.\n- If claims cannot be independently verified, the feature is insufficient.\n- If migration cost remains high for real teams, the feature is insufficient.\n\n## Quantitative Targets (from Section 3)\n- >= 95% pass on targeted compatibility corpus for high-value Node/Bun usage bands\n- >= 3x migration throughput and confidence quality versus baseline\n- >= 10x reduction in successful host compromise under adversarial extension campaigns\n- 100% deterministic replay artifact availability for high-severity incidents\n- >= 3 impossible-by-default capabilities broadly adopted by production users\n\n## Acceptance Criteria\n- All 10 capabilities are productionized with verifiable evidence artifacts\n- Each capability maps to at least one \"impossible without franken_node\" demo scenario\n- Independent external verification of at least 5/10 capabilities\n- Public documentation showing how each capability surpasses incumbent defaults","status":"open","priority":0,"issue_type":"epic","created_at":"2026-02-20T16:13:40.354320581Z","created_by":"ubuntu","updated_at":"2026-02-20T16:13:40.354320581Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["capability-index","category-defining","plan","section-3"]}
{"id":"bd-2hs","title":"[10.2] Create the four-doc spec pack for compatibility extraction (`PLAN_TO_PORT_NODE_BUN_SURFACES_TO_RUST.md`, `EXISTING_NODE_BUN_STRUCTURE.md`, `PROPOSED_ARCHITECTURE.md`, `FEATURE_PARITY.md`) and keep it release-gated.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.2 — Compatibility Core\n\nWhy This Exists:\nCompatibility core as strategic wedge: policy-visible behavior, divergence receipts, L1/L2 lockstep, and spec-first fixture governance.\n\nTask Objective:\nCreate the four-doc spec pack for compatibility extraction (`PLAN_TO_PORT_NODE_BUN_SURFACES_TO_RUST.md`, `EXISTING_NODE_BUN_STRUCTURE.md`, `PROPOSED_ARCHITECTURE.md`, `FEATURE_PARITY.md`) and keep it release-gated.\n\nAcceptance Criteria:\n- Implement with explicit success/failure invariants and deterministic behavior under normal, edge, and fault scenarios.\n- Ensure outcomes are verifiable via automated tests and reproducible artifact outputs.\n\nExpected Artifacts:\n- Section-owned design/spec artifact at `docs/specs/section_10_2/bd-2hs_contract.md`, capturing decision rationale, invariants, and interface boundaries.\n- Machine-readable verification artifact at `artifacts/section_10_2/bd-2hs/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_2/bd-2hs/verification_summary.md` linking implementation intent to measured outcomes.\n\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.2] Create the four-doc spec pack for compatibility extraction (`PLAN_TO_PORT_NODE_BUN_SURFACES_TO_RUST.md`, `EXISTING_NODE_BUN_STRUCTURE.md`, `PROPOSED_ARCHITECTURE.md`, `FEATURE_PARITY.md`) and keep it release-gated.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.2] Create the four-doc spec pack for compatibility extraction (`PLAN_TO_PORT_NODE_BUN_SURFACES_TO_RUST.md`, `EXISTING_NODE_BUN_STRUCTURE.md`, `PROPOSED_ARCHITECTURE.md`, `FEATURE_PARITY.md`) and keep it release-gated.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.2] Create the four-doc spec pack for compatibility extraction (`PLAN_TO_PORT_NODE_BUN_SURFACES_TO_RUST.md`, `EXISTING_NODE_BUN_STRUCTURE.md`, `PROPOSED_ARCHITECTURE.md`, `FEATURE_PARITY.md`) and keep it release-gated.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.2] Create the four-doc spec pack for compatibility extraction (`PLAN_TO_PORT_NODE_BUN_SURFACES_TO_RUST.md`, `EXISTING_NODE_BUN_STRUCTURE.md`, `PROPOSED_ARCHITECTURE.md`, `FEATURE_PARITY.md`) and keep it release-gated.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.2] Create the four-doc spec pack for compatibility extraction (`PLAN_TO_PORT_NODE_BUN_SURFACES_TO_RUST.md`, `EXISTING_NODE_BUN_STRUCTURE.md`, `PROPOSED_ARCHITECTURE.md`, `FEATURE_PARITY.md`) and keep it release-gated.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","status":"closed","priority":1,"issue_type":"task","assignee":"CrimsonCrane","created_at":"2026-02-20T07:36:44.562237978Z","created_by":"ubuntu","updated_at":"2026-02-20T09:52:58.480235289Z","closed_at":"2026-02-20T09:52:58.480209722Z","close_reason":"done","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-2","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-2hs","depends_on_id":"bd-240","type":"blocks","created_at":"2026-02-20T07:43:20.432482358Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-2igi","title":"[10.14] Implement Bayesian posterior diagnostics for explainable policy ranking.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.14 — FrankenSQLite Deep-Mined Expansion Execution Track (9J)\n\nWhy This Exists:\nFrankenSQLite deep-mined control integrity track: evidence ledgers, proofs, epochs, remote effects, markers/MMR, and deterministic fault labs.\n\nTask Objective:\nImplement Bayesian posterior diagnostics for explainable policy ranking.\n\nAcceptance Criteria:\n- Posterior metrics are surfaced for ranking diagnostics; diagnostics do not bypass hard guardrails; posterior updates are reproducible from stored observations.\n\nExpected Artifacts:\n- `src/policy/bayesian_diagnostics.rs`, `tests/integration/bayesian_policy_ranking.rs`, `artifacts/10.14/posterior_diagnostics_report.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_14/bd-2igi/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_14/bd-2igi/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.14] Implement Bayesian posterior diagnostics for explainable policy ranking.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.14] Implement Bayesian posterior diagnostics for explainable policy ranking.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.14] Implement Bayesian posterior diagnostics for explainable policy ranking.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.14] Implement Bayesian posterior diagnostics for explainable policy ranking.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.14] Implement Bayesian posterior diagnostics for explainable policy ranking.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"Posterior metrics are surfaced for ranking diagnostics; diagnostics do not bypass hard guardrails; posterior updates are reproducible from stored observations.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:36:55.792973375Z","created_by":"ubuntu","updated_at":"2026-02-20T15:44:11.011613963Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-14","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-2igi","depends_on_id":"bd-3a3q","type":"blocks","created_at":"2026-02-20T07:43:14.554777641Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-2iyk","title":"[10.17] Implement information-flow lineage and exfiltration sentinel.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.17 — Radical Expansion Execution Track (9K)\n\nWhy This Exists:\nRadical expansion track for proof-carrying speculation, Bayesian adversary control, time-travel replay, ZK attestations, and claim compiler systems.\n\nTask Objective:\nImplement information-flow lineage and exfiltration sentinel.\n\nAcceptance Criteria:\n- Sensitive lineage tags persist across supported execution flows; simulated covert exfiltration scenarios are detected and auto-contained above defined recall/precision thresholds.\n\nExpected Artifacts:\n- `docs/specs/information_flow_sentinel.md`, `src/security/lineage_tracker.rs`, `tests/security/exfiltration_sentinel_scenarios.rs`, `artifacts/10.17/exfiltration_detector_metrics.csv`.\n\n- Machine-readable verification artifact at `artifacts/section_10_17/bd-2iyk/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_17/bd-2iyk/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.17] Implement information-flow lineage and exfiltration sentinel.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.17] Implement information-flow lineage and exfiltration sentinel.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.17] Implement information-flow lineage and exfiltration sentinel.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.17] Implement information-flow lineage and exfiltration sentinel.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.17] Implement information-flow lineage and exfiltration sentinel.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- Sensitive lineage tags persist across supported execution flows; simulated covert exfiltration scenarios are detected and auto-contained above defined recall/precision thresholds.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:37:03.761723914Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:58.844019725Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-17","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-2iyk","depends_on_id":"bd-3l2p","type":"blocks","created_at":"2026-02-20T07:43:18.686029611Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-2j9w","title":"[PROGRAM] Program-wide verification gate: comprehensive unit+e2e+logging","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md (Cross-cutting final verification layer)\nSection: PROGRAM (Cross-cutting final verification)\n\nTask Objective:\nCreate a hard program-wide verification gate that requires section-level gates, bootstrap gate, and program-level integration evidence to all be green before master-plan closure.\n\nWhy This Improves User Outcomes:\nThis enforces that local correctness and global integration both hold, preventing release of systems that are individually valid but compositionally unsafe.\n\nAcceptance Criteria:\n- Gate consumes all section verification gate artifacts, bootstrap verification gate output, and program-level orchestration evidence.\n- Gate fails closed on missing, stale, nondeterministic, or contradictory evidence.\n- Verdict is deterministic and machine-readable for CI/release automation.\n- Failure output pinpoints failing section/integration dimension and required remediation bead families.\n\nExpected Artifacts:\n- Program-wide gate policy/spec with evidence contract.\n- Deterministic gate verdict schema and sample pass/fail bundles.\n- Traceability report linking every section/program verification obligation to consumed evidence.\n\n- Machine-readable verification artifact at `artifacts/section_program/bd-2j9w/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_program/bd-2j9w/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for gate aggregation logic, conflict resolution, and fail-closed semantics.\n- E2E tests for green, partial, contradictory, and failing evidence scenarios.\n- Detailed structured gate logs with explicit failing-dimension tags, evidence IDs, and trace-correlation IDs.\n\nTask-Specific Clarification:\n- This gate is additive and must not weaken or bypass any existing section/bootstrap verification gate.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T08:08:05.794261594Z","created_by":"ubuntu","updated_at":"2026-02-20T08:46:07.992035368Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","program-integration","test-obligations","verification-gate"],"dependencies":[{"issue_id":"bd-2j9w","depends_on_id":"bd-10g0","type":"blocks","created_at":"2026-02-20T08:08:09.391224571Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2j9w","depends_on_id":"bd-16sk","type":"blocks","created_at":"2026-02-20T08:08:10.467877163Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2j9w","depends_on_id":"bd-1d6x","type":"blocks","created_at":"2026-02-20T08:08:10.014682301Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2j9w","depends_on_id":"bd-1dpd","type":"blocks","created_at":"2026-02-20T08:24:23.341844703Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2j9w","depends_on_id":"bd-1fi2","type":"blocks","created_at":"2026-02-20T08:08:07.518405352Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2j9w","depends_on_id":"bd-1jjq","type":"blocks","created_at":"2026-02-20T08:08:10.319492344Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2j9w","depends_on_id":"bd-1jpo","type":"blocks","created_at":"2026-02-20T08:08:10.164900284Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2j9w","depends_on_id":"bd-1kfq","type":"blocks","created_at":"2026-02-20T08:08:07.369263845Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2j9w","depends_on_id":"bd-1koz","type":"blocks","created_at":"2026-02-20T08:08:07.965907530Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2j9w","depends_on_id":"bd-1neb","type":"blocks","created_at":"2026-02-20T08:08:07.220572606Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2j9w","depends_on_id":"bd-1rwq","type":"blocks","created_at":"2026-02-20T08:08:07.666540506Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2j9w","depends_on_id":"bd-20eg","type":"blocks","created_at":"2026-02-20T08:08:09.542574211Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2j9w","depends_on_id":"bd-23ys","type":"blocks","created_at":"2026-02-20T08:08:08.768121611Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2j9w","depends_on_id":"bd-261k","type":"blocks","created_at":"2026-02-20T08:08:08.167768015Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2j9w","depends_on_id":"bd-2hjg","type":"blocks","created_at":"2026-02-20T08:08:09.072856965Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2j9w","depends_on_id":"bd-2l4i","type":"blocks","created_at":"2026-02-20T08:08:06.619991807Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2j9w","depends_on_id":"bd-2nlu","type":"blocks","created_at":"2026-02-20T08:08:06.091914616Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2j9w","depends_on_id":"bd-2nre","type":"blocks","created_at":"2026-02-20T08:08:06.454722208Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2j9w","depends_on_id":"bd-2twu","type":"blocks","created_at":"2026-02-20T08:20:48.639817526Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2j9w","depends_on_id":"bd-2x1e","type":"blocks","created_at":"2026-02-20T08:08:06.923504764Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2j9w","depends_on_id":"bd-3enl","type":"blocks","created_at":"2026-02-20T08:08:08.317360262Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2j9w","depends_on_id":"bd-3epz","type":"blocks","created_at":"2026-02-20T08:08:09.697439991Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2j9w","depends_on_id":"bd-3hr2","type":"blocks","created_at":"2026-02-20T08:08:08.921923609Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2j9w","depends_on_id":"bd-3ohj","type":"blocks","created_at":"2026-02-20T08:08:10.780524784Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2j9w","depends_on_id":"bd-3p9n","type":"blocks","created_at":"2026-02-20T08:08:07.816820113Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2j9w","depends_on_id":"bd-3po7","type":"blocks","created_at":"2026-02-20T08:08:08.619979364Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2j9w","depends_on_id":"bd-3qsp","type":"blocks","created_at":"2026-02-20T08:08:10.630467972Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2j9w","depends_on_id":"bd-3t08","type":"blocks","created_at":"2026-02-20T08:08:09.231159707Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2j9w","depends_on_id":"bd-3uoo","type":"blocks","created_at":"2026-02-20T08:08:09.861617386Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2j9w","depends_on_id":"bd-c781","type":"blocks","created_at":"2026-02-20T08:08:07.071651649Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2j9w","depends_on_id":"bd-unkm","type":"blocks","created_at":"2026-02-20T08:08:06.306728528Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2j9w","depends_on_id":"bd-z7bt","type":"blocks","created_at":"2026-02-20T08:08:06.773912857Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2j9w","depends_on_id":"bd-zm5b","type":"blocks","created_at":"2026-02-20T08:08:08.466281760Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-2ja","title":"[10.7] Build compatibility golden corpus and fixture metadata schema.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.7 — Conformance + Verification (Item 1 of 6)\n\nWhy This Exists:\nThe compatibility golden corpus is the authoritative reference set of test fixtures that define expected behavior for Node/Bun API compatibility. It serves as the ground truth for the lockstep oracle (10.0 Initiative #4), the migration autopilot (10.0 Initiative #2), and all conformance claims.\n\nTask Objective:\nBuild and maintain the compatibility golden corpus: a comprehensive, version-controlled collection of test fixtures covering all API bands, with structured metadata enabling automated comparison across runtimes.\n\nDetailed Acceptance Criteria:\n1. Corpus covers all four compatibility bands (core/high-value/edge/unsafe) with representative fixtures per API family.\n2. Fixture metadata schema includes: API surface, band classification, expected behavior description, Node.js reference version, Bun reference version, fixture inputs, expected outputs, edge cases, known divergences.\n3. Fixtures are deterministic and reproducible across environments (pinned dependencies, controlled randomness).\n4. Corpus version-controlled and release-gated — new fixtures require review and linkage to spec sections.\n5. Integration with lockstep runner (10.2) for automated three-runtime comparison.\n6. Spec-first governance: fixtures cite spec sections and fixture IDs per 10.1 governance policy.\n7. Prioritized by API family importance: CLI/process/fs/network/module/tooling bands per 10.2.\n\nExpected Artifacts:\n- fixtures/ directory with organized corpus per API band.\n- Fixture metadata schema (JSON) and validation tooling.\n- docs/specs/section_10_7/bd-2ja_contract.md\n- artifacts/section_10_7/bd-2ja/verification_evidence.json\n\nTesting and Logging Requirements:\n- Unit tests: fixture metadata validation, band classification correctness.\n- Integration tests: full corpus execution against each runtime producing comparison reports.\n- E2E tests: franken-node verify lockstep consuming corpus and producing divergence reports.\n- Structured logs: CORPUS_LOADED, FIXTURE_EXECUTED, COMPARISON_COMPLETED, DIVERGENCE_FOUND with fixture IDs and band metadata.","acceptance_criteria":"1. Golden corpus contains at least 50 representative compatibility test fixtures covering: module formats (CJS, ESM, dual), API shims, extension hooks, and edge cases.\n2. Fixture metadata schema is defined in a JSON Schema file under spec/ and every fixture includes a conforming metadata sidecar.\n3. Metadata fields include: fixture ID, category, expected-output hash, compatibility dimensions tested, and provenance (which spec section it validates).\n4. Corpus is versioned: schema changes bump a semver version and old fixtures are migrated or explicitly deprecated.\n5. A validation script (scripts/validate_corpus.py) checks all fixtures against the schema and reports any violations as structured JSON.\n6. Per Section 5.4 porting discipline: each fixture's provenance traces back to a specific extraction-and-proof chain.\n7. Corpus is usable by both the lockstep oracle (Rust) and the external verifier toolkit (Section 3.2 capability #10) without format conversion.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:36:47.265087454Z","created_by":"ubuntu","updated_at":"2026-02-20T15:16:36.389538959Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-7","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-2ja","depends_on_id":"bd-1ta","type":"blocks","created_at":"2026-02-20T07:46:37.081710626Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2ja","depends_on_id":"bd-229","type":"blocks","created_at":"2026-02-20T07:46:37.126480Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2ja","depends_on_id":"bd-3il","type":"blocks","created_at":"2026-02-20T07:46:37.171136664Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2ja","depends_on_id":"bd-5rh","type":"blocks","created_at":"2026-02-20T07:46:37.215490705Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2ja","depends_on_id":"bd-cda","type":"blocks","created_at":"2026-02-20T07:46:37.260186052Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-2ji2","title":"[10.16] Add claim-language gate tying UI/service/storage claims to substrate-backed evidence.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.16 — Adjacent Substrate Integration Execution Track (8.7)\n\nWhy This Exists:\nAdjacent substrate integration track to enforce deep composition with frankentui, frankensqlite, sqlmodel_rust, and fastapi_rust.\n\nTask Objective:\nAdd claim-language gate tying UI/service/storage claims to substrate-backed evidence.\n\nAcceptance Criteria:\n- Documentation and release claims about TUI/API/storage behavior require linked substrate conformance artifacts; unlinked claims are blocked.\n\nExpected Artifacts:\n- `docs/policy/adjacent_substrate_claim_language.md`, `tests/conformance/adjacent_claim_language_gate.rs`, `artifacts/10.16/adjacent_claim_language_gate_report.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_16/bd-2ji2/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_16/bd-2ji2/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.16] Add claim-language gate tying UI/service/storage claims to substrate-backed evidence.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.16] Add claim-language gate tying UI/service/storage claims to substrate-backed evidence.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.16] Add claim-language gate tying UI/service/storage claims to substrate-backed evidence.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.16] Add claim-language gate tying UI/service/storage claims to substrate-backed evidence.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.16] Add claim-language gate tying UI/service/storage claims to substrate-backed evidence.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- Documentation and release claims about TUI/API/storage behavior require linked substrate conformance artifacts; unlinked claims are blocked.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:37:02.845922819Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:08.547927223Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-16","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-2ji2","depends_on_id":"bd-35l5","type":"blocks","created_at":"2026-02-20T07:43:18.212144454Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-2jns","title":"[10.20] Implement maintainer/publisher fragility model and single-point-of-failure detector.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.20 — Dependency Graph Immune System Execution Track (9N)\n\nWhy This Exists:\nDGIS topological immune system track for dependency contagion modeling, choke-point immunization, and graph-aware containment economics.\n\nTask Objective:\nImplement maintainer/publisher fragility model and single-point-of-failure detector.\n\nAcceptance Criteria:\n- Graph nodes with concentrated maintainer or provenance risk are flagged with stable severity classes; false-negatives against seeded risk fixtures remain below defined threshold.\n\nExpected Artifacts:\n- `docs/specs/dgis_maintainer_fragility.md`, `src/security/dgis/fragility_model.rs`, `artifacts/10.20/dgis_fragility_findings.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_20/bd-2jns/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_20/bd-2jns/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.20] Implement maintainer/publisher fragility model and single-point-of-failure detector.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.20] Implement maintainer/publisher fragility model and single-point-of-failure detector.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.20] Implement maintainer/publisher fragility model and single-point-of-failure detector.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.20] Implement maintainer/publisher fragility model and single-point-of-failure detector.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.20] Implement maintainer/publisher fragility model and single-point-of-failure detector.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- Graph nodes with concentrated maintainer or provenance risk are flagged with stable severity classes; false-negatives against seeded risk fixtures remain below defined threshold.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:37:06.667070488Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:21.397855566Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-20","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-2jns","depends_on_id":"bd-t89w","type":"blocks","created_at":"2026-02-20T07:43:20.711533884Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-2k74","title":"[10.13] Implement per-peer admission budgets (bytes/symbols/failed-auth/inflight-decode/decode-cpu).","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.13 — FCP Deep-Mined Expansion Execution Track (9I)\n\nWhy This Exists:\nDeep connector/provider contract track: lifecycle FSMs, conformance harnesses, fencing, sandboxing, revocation freshness, and protocol hardening.\n\nTask Objective:\nImplement per-peer admission budgets (bytes/symbols/failed-auth/inflight-decode/decode-cpu).\n\nAcceptance Criteria:\n- Admission checks enforce all budget dimensions; limit breaches are rate-limited and logged; budgets can be tuned without code changes.\n\nExpected Artifacts:\n- `docs/specs/admission_budget_model.md`, `tests/security/per_peer_budget_enforcement.rs`, `artifacts/10.13/admission_budget_violation_report.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_13/bd-2k74/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_13/bd-2k74/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.13] Implement per-peer admission budgets (bytes/symbols/failed-auth/inflight-decode/decode-cpu).\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.13] Implement per-peer admission budgets (bytes/symbols/failed-auth/inflight-decode/decode-cpu).\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.13] Implement per-peer admission budgets (bytes/symbols/failed-auth/inflight-decode/decode-cpu).\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.13] Implement per-peer admission budgets (bytes/symbols/failed-auth/inflight-decode/decode-cpu).\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.13] Implement per-peer admission budgets (bytes/symbols/failed-auth/inflight-decode/decode-cpu).\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","status":"closed","priority":1,"issue_type":"task","assignee":"CrimsonCrane","created_at":"2026-02-20T07:36:53.923542532Z","created_by":"ubuntu","updated_at":"2026-02-20T12:45:43.136833278Z","closed_at":"2026-02-20T12:45:43.136806638Z","close_reason":"done","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-13","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-2k74","depends_on_id":"bd-91gg","type":"blocks","created_at":"2026-02-20T07:43:13.560138166Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-2kd9","title":"[10.17] Implement claim compiler and public trust scoreboard pipeline.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.17 — Radical Expansion Execution Track (9K)\n\nWhy This Exists:\nRadical expansion track for proof-carrying speculation, Bayesian adversary control, time-travel replay, ZK attestations, and claim compiler systems.\n\nTask Objective:\nImplement claim compiler and public trust scoreboard pipeline.\n\nAcceptance Criteria:\n- External claims must compile to executable evidence contracts; unverifiable claim text is blocked and scoreboard updates publish signed evidence links.\n\nExpected Artifacts:\n- `docs/specs/claim_compiler.md`, `src/claims/claim_compiler.rs`, `tests/conformance/claim_compiler_gate.rs`, `artifacts/10.17/public_trust_scoreboard_snapshot.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_17/bd-2kd9/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_17/bd-2kd9/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.17] Implement claim compiler and public trust scoreboard pipeline.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.17] Implement claim compiler and public trust scoreboard pipeline.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.17] Implement claim compiler and public trust scoreboard pipeline.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.17] Implement claim compiler and public trust scoreboard pipeline.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.17] Implement claim compiler and public trust scoreboard pipeline.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- External claims must compile to executable evidence contracts; unverifiable claim text is blocked and scoreboard updates publish signed evidence links.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:37:04.089509755Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:57.814970944Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-17","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-2kd9","depends_on_id":"bd-383z","type":"blocks","created_at":"2026-02-20T07:43:18.867528418Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-2ke","title":"[PLAN 14] Benchmark + Standardization Ownership","description":"Section 14 standards epic. Publish benchmark specs/harnesses/datasets/scoring, include security+trust co-metrics, ship verifier toolkit, and version standards with migration guidance.\n\n## Success Criteria\n- All child beads for this section are completed with acceptance artifacts attached and no unresolved blockers.\n- Section-level verification gate for comprehensive unit tests, integration/e2e workflows, and detailed structured logging evidence is green.\n- Scope-to-plan traceability is explicit, with no feature loss versus the canonical plan section.\n\n## Optimization Notes\n- User-Outcome Lens: \"[PLAN 14] Benchmark + Standardization Ownership\" must improve real operator and end-user reliability, explainability, and time-to-safe-outcome under both normal and degraded conditions.\n- Cross-Section Coordination: this epic's child beads must explicitly encode integration expectations with neighboring sections to prevent local optimizations that break global behavior.\n- Verification Non-Negotiable: completion requires deterministic unit coverage, integration/E2E replay evidence, and structured logs sufficient for independent third-party reproduction and triage.\n- Scope Protection: any proposed simplification must prove feature parity against plan intent and document tradeoffs explicitly; silent scope reduction is forbidden.","status":"open","priority":2,"issue_type":"epic","created_at":"2026-02-20T07:36:42.247104303Z","created_by":"ubuntu","updated_at":"2026-02-20T08:12:49.352145606Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-14"],"dependencies":[{"issue_id":"bd-2ke","depends_on_id":"bd-18ie","type":"blocks","created_at":"2026-02-20T07:39:35.682867365Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2ke","depends_on_id":"bd-1wz","type":"blocks","created_at":"2026-02-20T07:38:36.031629879Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2ke","depends_on_id":"bd-26k","type":"blocks","created_at":"2026-02-20T07:38:35.986646149Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2ke","depends_on_id":"bd-2a6g","type":"blocks","created_at":"2026-02-20T07:39:35.856096616Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2ke","depends_on_id":"bd-2fkq","type":"blocks","created_at":"2026-02-20T07:39:36.115155149Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2ke","depends_on_id":"bd-2l4i","type":"blocks","created_at":"2026-02-20T07:48:30.433694147Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2ke","depends_on_id":"bd-2ps7","type":"blocks","created_at":"2026-02-20T07:39:36.025058889Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2ke","depends_on_id":"bd-32p","type":"blocks","created_at":"2026-02-20T07:38:36.073942985Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2ke","depends_on_id":"bd-37i","type":"blocks","created_at":"2026-02-20T07:38:36.204175767Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2ke","depends_on_id":"bd-39a","type":"blocks","created_at":"2026-02-20T07:38:36.116020652Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2ke","depends_on_id":"bd-3h1g","type":"blocks","created_at":"2026-02-20T07:39:35.340860336Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2ke","depends_on_id":"bd-3rc","type":"blocks","created_at":"2026-02-20T07:38:35.944204053Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2ke","depends_on_id":"bd-3v8g","type":"blocks","created_at":"2026-02-20T07:39:35.597294651Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2ke","depends_on_id":"bd-jbp1","type":"blocks","created_at":"2026-02-20T07:39:35.940582236Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2ke","depends_on_id":"bd-ka0n","type":"blocks","created_at":"2026-02-20T07:39:35.770767445Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2ke","depends_on_id":"bd-wzjl","type":"blocks","created_at":"2026-02-20T07:39:35.425761880Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2ke","depends_on_id":"bd-ybe","type":"blocks","created_at":"2026-02-20T07:38:36.158563887Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2ke","depends_on_id":"bd-yz3t","type":"blocks","created_at":"2026-02-20T07:39:35.511596563Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-2kf","title":"[10.2] Implement compatibility mode selection policy (`strict`, `balanced`, `legacy-risky`).","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.2 — Compatibility Core\n\nWhy This Exists:\nCompatibility core as strategic wedge: policy-visible behavior, divergence receipts, L1/L2 lockstep, and spec-first fixture governance.\n\nTask Objective:\nImplement compatibility mode selection policy (`strict`, `balanced`, `legacy-risky`).\n\nAcceptance Criteria:\n- Implement with explicit success/failure invariants and deterministic behavior under normal, edge, and fault scenarios.\n- Ensure outcomes are verifiable via automated tests and reproducible artifact outputs.\n\nExpected Artifacts:\n- Section-owned design/spec artifact at `docs/specs/section_10_2/bd-2kf_contract.md`, capturing decision rationale, invariants, and interface boundaries.\n- Machine-readable verification artifact at `artifacts/section_10_2/bd-2kf/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_2/bd-2kf/verification_summary.md` linking implementation intent to measured outcomes.\n\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.2] Implement compatibility mode selection policy (`strict`, `balanced`, `legacy-risky`).\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.2] Implement compatibility mode selection policy (`strict`, `balanced`, `legacy-risky`).\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.2] Implement compatibility mode selection policy (`strict`, `balanced`, `legacy-risky`).\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.2] Implement compatibility mode selection policy (`strict`, `balanced`, `legacy-risky`).\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.2] Implement compatibility mode selection policy (`strict`, `balanced`, `legacy-risky`).\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","status":"closed","priority":1,"issue_type":"task","assignee":"CrimsonCrane","created_at":"2026-02-20T07:36:44.077237537Z","created_by":"ubuntu","updated_at":"2026-02-20T09:38:09.529574909Z","closed_at":"2026-02-20T09:38:09.529546275Z","close_reason":"done","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-2","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-2kf","depends_on_id":"bd-38l","type":"blocks","created_at":"2026-02-20T07:43:20.178807085Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-2ko","title":"[10.11] Adopt canonical deterministic lab runtime and protocol scenario suites (from `10.14` + `10.15`) for product control-plane logic.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.11 — FrankenSQLite-Inspired Runtime Systems Integration Track\n\nWhy This Exists:\nFrankenSQLite-inspired systems integration of capabilities, cancellation protocol, obligations, deterministic labs, and anti-entropy.\n\nTask Objective:\nAdopt canonical deterministic lab runtime and protocol scenario suites (from `10.14` + `10.15`) for product control-plane logic.\n\nAcceptance Criteria:\n- Implement with explicit success/failure invariants and deterministic behavior under normal, edge, and fault scenarios.\n- Ensure outcomes are verifiable via automated tests and reproducible artifact outputs.\n\nExpected Artifacts:\n- Section-owned design/spec artifact at `docs/specs/section_10_11/bd-2ko_contract.md`, capturing decision rationale, invariants, and interface boundaries.\n- Machine-readable verification artifact at `artifacts/section_10_11/bd-2ko/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_11/bd-2ko/verification_summary.md` linking implementation intent to measured outcomes.\n\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.11] Adopt canonical deterministic lab runtime and protocol scenario suites (from `10.14` + `10.15`) for product control-plane logic.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.11] Adopt canonical deterministic lab runtime and protocol scenario suites (from `10.14` + `10.15`) for product control-plane logic.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.11] Adopt canonical deterministic lab runtime and protocol scenario suites (from `10.14` + `10.15`) for product control-plane logic.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.11] Adopt canonical deterministic lab runtime and protocol scenario suites (from `10.14` + `10.15`) for product control-plane logic.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.11] Adopt canonical deterministic lab runtime and protocol scenario suites (from `10.14` + `10.15`) for product control-plane logic.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"AC for bd-2ko:\n1. Product control-plane logic runs under a deterministic lab runtime (DeterministicRuntime) that replaces all sources of non-determinism: clocks return injectable timestamps, random generators use seeded PRNGs, I/O is replaced by in-memory fakes with scripted responses.\n2. The DeterministicRuntime implements the same trait interfaces as the production runtime, allowing control-plane code to be runtime-agnostic via generic bounds (Runtime: Clock + Rng + Transport).\n3. Protocol scenario suites are defined as declarative YAML/JSON fixtures specifying: initial state, sequence of events (with injected faults), and expected final state + emitted side-effects.\n4. A scenario runner loads fixtures, replays them through the DeterministicRuntime, and produces a pass/fail verdict with a diff if the actual outcome diverges from expected.\n5. Every protocol in the 10.11 scope (cancellation, two-phase obligations, supervision, capability narrowing) has at least 3 scenario fixtures: happy path, single fault, and cascading fault.\n6. Scenario execution is fully reproducible: given the same seed and fixture, the output is bit-for-bit identical across runs; a CI check verifies this by running each scenario twice and comparing outputs.\n7. Fault injection covers: message delay/drop/reorder, clock skew, OOM simulation, and cancellation-during-prepare.\n8. Unit tests verify: (a) seeded runtime produces identical outputs across runs, (b) clock injection correctly advances time, (c) fault-injected scenario detects expected failure mode, (d) scenario runner correctly diffs expected vs actual.\n9. Structured log events: SCENARIO_START / SCENARIO_STEP / SCENARIO_PASS / SCENARIO_FAIL / FAULT_INJECTED with scenario name, step index, and seed.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:36:50.224385543Z","created_by":"ubuntu","updated_at":"2026-02-20T15:18:26.299141523Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-11","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-2ko","depends_on_id":"bd-145n","type":"blocks","created_at":"2026-02-20T15:00:18.104446139Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2ko","depends_on_id":"bd-2qqu","type":"blocks","created_at":"2026-02-20T15:00:17.912572305Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2ko","depends_on_id":"bd-3he","type":"blocks","created_at":"2026-02-20T07:43:11.620739538Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-2l1k","title":"[13] Concrete target gate: 100% replay artifact coverage","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 13\n\nTask Objective:\nBuild KPI gate for complete high-severity replay artifact coverage.\n\nExecution Requirements:\n- Make this requirement machine-verifiable and release-gated where applicable.\n- Keep behavior self-documenting so future contributors do not need to re-open the master plan.\n\nTesting & Logging Requirements:\n- Unit tests for rule/contract logic and error conditions.\n- Integration/E2E tests for workflow-level enforcement.\n- Structured logs with stable codes and trace IDs.\n- Reproducible artifacts that prove contract satisfaction.\n\nAcceptance Criteria:\n- Success and failure invariants for [13] Concrete target gate: 100% replay artifact coverage are explicitly quantified and machine-verifiable.\n- Determinism requirements for [13] Concrete target gate: 100% replay artifact coverage are validated across repeated runs and adversarial perturbations.\n\n\nExpected Artifacts:\n- Machine-readable verification artifact with explicit canonical path under artifacts/section_13/bd-2l1k/verification_evidence.json, suitable for CI/release gating.\n- Human-readable verification summary with explicit canonical path under artifacts/section_13/bd-2l1k/verification_summary.md, linking implementation intent to measured validation outcomes.\n\nTask-Specific Clarification:\n- The implementation must deliver the exact capability named in the title, with no scope dilution and no silent feature omission.\n- Validation artifacts must include capability-specific thresholds, pass/fail criteria, and reproducible evidence bundles tied to this bead ID.\n- Program/section verification gates must be able to consume this bead's outputs without manual interpretation.\n\nWhy This Improves User Outcomes:\n- \"[13] Concrete target gate: 100% replay artifact coverage\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[13] Concrete target gate: 100% replay artifact coverage\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"1. Every high-severity incident type has a corresponding replay artifact that captures sufficient state to reproduce the incident deterministically.\n2. High-severity incident types are enumerated: RCE, privilege escalation, data exfiltration, sandbox escape, trust system bypass, supply-chain compromise, denial of service, memory corruption.\n3. 100% coverage means: for every enumerated incident type, at least one replay artifact exists and successfully reproduces the incident in a test environment.\n4. Replay artifacts include: initial state snapshot, input sequence, expected behavior trace, actual behavior trace, and divergence point.\n5. Replay is deterministic: running the replay artifact 10 times produces identical behavior traces each time.\n6. New high-severity incident types added to the enumeration must have replay artifacts within 1 sprint of discovery.\n7. Evidence artifact: replay_coverage_matrix.json mapping each incident type to its replay artifact path and last-verified date.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:39:35.128318458Z","created_by":"ubuntu","updated_at":"2026-02-20T15:21:39.230413969Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-13","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-2l1k","depends_on_id":"bd-3cpa","type":"blocks","created_at":"2026-02-20T07:43:25.663870672Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-2l4i","title":"[14] Section-wide verification gate: comprehensive unit+e2e+logging","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 14\n\nTask Objective:\nCreate a hard section completion gate that verifies all implemented behavior in this section with comprehensive unit tests, integration/e2e scripts, and detailed structured logging evidence.\n\nAcceptance Criteria:\n- Section test matrix covers happy-path, edge-case, and adversarial/error-path scenarios for all section deliverables.\n- E2E scripts execute representative end-user workflows and policy/control-plane transitions for this section.\n- Structured logs include stable event/error codes, trace correlation IDs, and enough context for deterministic replay triage.\n- Verification report is deterministic and machine-readable for CI/release gating.\n\nExpected Artifacts:\n- Section-level test matrix and coverage summary artifact.\n- E2E script suite with pass/fail outputs and reproducible fixtures/seeds.\n- Structured log validation report and traceability bundle.\n- Gate verdict artifact consumable by release automation.\n\n- Machine-readable verification artifact at `artifacts/section_14/bd-2l4i/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_14/bd-2l4i/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests must validate contracts, invariants, and failure semantics.\n- E2E tests must validate cross-component behavior from user/operator entrypoints to persisted effects.\n- Logging must support root-cause analysis without hidden context requirements.\n\nTask-Specific Clarification:\n- For \"[14] Section-wide verification gate: comprehensive unit+e2e+logging\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[14] Section-wide verification gate: comprehensive unit+e2e+logging\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[14] Section-wide verification gate: comprehensive unit+e2e+logging\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[14] Section-wide verification gate: comprehensive unit+e2e+logging\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[14] Section-wide verification gate: comprehensive unit+e2e+logging\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"1. Section 14 verification gate runs all benchmark and standardization check scripts and confirms 100% pass rate.\n2. Gate validates: (a) benchmark harness runs end-to-end on CI and produces valid output, (b) all 6 metric families produce results, (c) verifier toolkit installs and runs successfully, (d) version standards are documented.\n3. All metric families have defined thresholds and currently meet them.\n4. Gate produces section_14_verification_summary.md with per-metric-family status and publication readiness checklist.\n5. Publication artifacts are present: benchmark spec, harness, datasets, verifier toolkit, version migration guide.\n6. The gate itself has a unit test verifying correct metric aggregation and threshold evaluation.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:48:29.845475628Z","created_by":"ubuntu","updated_at":"2026-02-20T15:25:45.559253447Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-14","test-obligations","verification-gate"],"dependencies":[{"issue_id":"bd-2l4i","depends_on_id":"bd-18ie","type":"blocks","created_at":"2026-02-20T07:48:30.188691617Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2l4i","depends_on_id":"bd-1dpd","type":"blocks","created_at":"2026-02-20T08:24:23.742176064Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2l4i","depends_on_id":"bd-2a6g","type":"blocks","created_at":"2026-02-20T07:48:30.092623735Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2l4i","depends_on_id":"bd-2fkq","type":"blocks","created_at":"2026-02-20T07:48:29.945150438Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2l4i","depends_on_id":"bd-2ps7","type":"blocks","created_at":"2026-02-20T07:48:29.994460220Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2l4i","depends_on_id":"bd-2twu","type":"blocks","created_at":"2026-02-20T08:20:49.135077279Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2l4i","depends_on_id":"bd-3h1g","type":"blocks","created_at":"2026-02-20T07:48:30.383099582Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2l4i","depends_on_id":"bd-3v8g","type":"blocks","created_at":"2026-02-20T07:48:30.235872834Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2l4i","depends_on_id":"bd-jbp1","type":"blocks","created_at":"2026-02-20T07:48:30.044008466Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2l4i","depends_on_id":"bd-ka0n","type":"blocks","created_at":"2026-02-20T07:48:30.141209208Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2l4i","depends_on_id":"bd-wzjl","type":"blocks","created_at":"2026-02-20T07:48:30.334669959Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2l4i","depends_on_id":"bd-yz3t","type":"blocks","created_at":"2026-02-20T07:48:30.286007353Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-2lb","title":"Bootstrap clap CLI surface for franken-node","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md (Bootstrap bridge for Sections 10.0, 10.2, 10.4)\nSection: BOOTSTRAP (Initial CLI command surface)\n\nBootstrap Context:\nThis bead establishes the minimal but production-worthy CLI baseline so implementation work can proceed without command-surface ambiguity.\n\nTask Objective:\nImplement the foundational Clap CLI in `crates/franken-node` with two real command paths (`run`, `doctor`) and deterministic dispatch/exit behavior.\n\nIn Scope:\n- Top-level command parser, stable help output, and deterministic exit code mapping.\n- `run` command path that routes JavaScript eval input through HybridRouter.\n- `doctor` command path that reports extension-host snapshot path/state availability.\n\nOut of Scope:\n- Full command-family scaffolding (`init`, `migrate`, `verify`, `trust`, `incident`) which is handled in `bd-3vk`.\n\nAcceptance Criteria:\n- CLI parsing is deterministic and rejects malformed flags/args with stable diagnostics.\n- `run` path executes through the intended router path and emits deterministic success/failure envelopes.\n- `doctor` path returns actionable diagnostics for missing/corrupt snapshot metadata.\n- Surface is ready for extension by `bd-3vk` without refactoring command-core internals.\n\nExpected Artifacts:\n- CLI command/argument contract note with examples.\n- Golden output fixtures for `--help`, `run`, and `doctor` command paths.\n- Machine-readable run summaries usable by CI.\n\n- Machine-readable verification artifact at `artifacts/section_bootstrap/bd-2lb/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_bootstrap/bd-2lb/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for parsing, dispatch, and deterministic exit-code/error mapping.\n- Integration tests for `run` and `doctor` command behavior across normal + failure cases.\n- E2E smoke script invoking representative command sequences.\n- Structured logs with stable event/error codes and trace correlation IDs for each command invocation.\n\nTask-Specific Clarification:\n- For \"Bootstrap clap CLI surface for franken-node\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"Bootstrap clap CLI surface for franken-node\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"Bootstrap clap CLI surface for franken-node\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"Bootstrap clap CLI surface for franken-node\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"Bootstrap clap CLI surface for franken-node\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"1) CLI subcommands parse and dispatch cleanly. 2) `franken-node run` accepts script/eval input and executes through HybridRouter. 3) `franken-node doctor` reports extension-host snapshot path/state. 4) Build and lint pass.","status":"closed","priority":1,"issue_type":"task","assignee":"JadeHollow","created_at":"2026-02-20T07:25:48.975612375Z","created_by":"ubuntu","updated_at":"2026-02-20T13:08:49.066726161Z","closed_at":"2026-02-20T13:08:49.066687870Z","close_reason":"done","closed_by_session":"CoralReef","source_repo":".","compaction_level":0,"original_size":0,"labels":["bootstrap","cli"]}
{"id":"bd-2lll","title":"[10.21] Implement changepoint and regime-shift detection layer (Bayesian changepoint + HMM state transitions).","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.21 — Behavioral Phenotype Evolution Tracker Execution Track (9O)\n\nWhy This Exists:\nBPET longitudinal phenotype intelligence track for pre-compromise trajectory detection and integration with DGIS/ATC/migration/economic policy.\n\nTask Objective:\nImplement changepoint and regime-shift detection layer (Bayesian changepoint + HMM state transitions).\n\nAcceptance Criteria:\n- Regime shifts are detected with calibrated false-positive/false-negative bounds on historical and synthetic trajectories; shift explanations include dominant contributing dimensions.\n\nExpected Artifacts:\n- `src/security/bpet/regime_shift_detector.rs`, `tests/security/bpet_regime_shift_suite.rs`, `artifacts/10.21/bpet_regime_shift_eval.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_21/bd-2lll/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_21/bd-2lll/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.21] Implement changepoint and regime-shift detection layer (Bayesian changepoint + HMM state transitions).\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.21] Implement changepoint and regime-shift detection layer (Bayesian changepoint + HMM state transitions).\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.21] Implement changepoint and regime-shift detection layer (Bayesian changepoint + HMM state transitions).\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.21] Implement changepoint and regime-shift detection layer (Bayesian changepoint + HMM state transitions).\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.21] Implement changepoint and regime-shift detection layer (Bayesian changepoint + HMM state transitions).\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- Regime shifts are detected with calibrated false-positive/false-negative bounds on historical and synthetic trajectories; shift explanations include dominant contributing dimensions.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:37:08.119916096Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:21.636365398Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-21","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-2lll","depends_on_id":"bd-2ao3","type":"blocks","created_at":"2026-02-20T07:43:21.476291022Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-2m2b","title":"[10.13] Implement Network Guard egress layer with HTTP+TCP policy enforcement and audit emission.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.13 — FCP Deep-Mined Expansion Execution Track (9I)\n\nWhy This Exists:\nDeep connector/provider contract track: lifecycle FSMs, conformance harnesses, fencing, sandboxing, revocation freshness, and protocol hardening.\n\nTask Objective:\nImplement Network Guard egress layer with HTTP+TCP policy enforcement and audit emission.\n\nAcceptance Criteria:\n- All connector egress traverses guard path; allow/deny enforcement matches policy semantics; every decision emits structured audit event.\n\nExpected Artifacts:\n- `src/security/network_guard.rs`, `tests/conformance/network_guard_policy.rs`, `artifacts/10.13/network_guard_audit_samples.jsonl`.\n\n- Machine-readable verification artifact at `artifacts/section_10_13/bd-2m2b/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_13/bd-2m2b/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.13] Implement Network Guard egress layer with HTTP+TCP policy enforcement and audit emission.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.13] Implement Network Guard egress layer with HTTP+TCP policy enforcement and audit emission.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.13] Implement Network Guard egress layer with HTTP+TCP policy enforcement and audit emission.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.13] Implement Network Guard egress layer with HTTP+TCP policy enforcement and audit emission.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.13] Implement Network Guard egress layer with HTTP+TCP policy enforcement and audit emission.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","status":"closed","priority":1,"issue_type":"task","assignee":"CrimsonCrane","created_at":"2026-02-20T07:36:52.286074341Z","created_by":"ubuntu","updated_at":"2026-02-20T11:20:08.653028207Z","closed_at":"2026-02-20T11:20:08.652999594Z","close_reason":"done","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-13","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-2m2b","depends_on_id":"bd-1vvs","type":"blocks","created_at":"2026-02-20T07:43:12.700474500Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-2ms","title":"[10.10] Implement rollback/fork detection in control-plane state propagation using canonical divergence and marker proofs (from `10.14`).","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.10 — FCP-Inspired Hardening + Interop Integration Track\n\nWhy This Exists:\nFCP-inspired hardening/interop contract for IDs, serialization, control-channel auth, revocation freshness, and publication gating.\n\nTask Objective:\nImplement rollback/fork detection in control-plane state propagation using canonical divergence and marker proofs (from `10.14`).\n\nAcceptance Criteria:\n- Implement with explicit success/failure invariants and deterministic behavior under normal, edge, and fault scenarios.\n- Ensure outcomes are verifiable via automated tests and reproducible artifact outputs.\n\nExpected Artifacts:\n- Section-owned design/spec artifact at `docs/specs/section_10_10/bd-2ms_contract.md`, capturing decision rationale, invariants, and interface boundaries.\n- Machine-readable verification artifact at `artifacts/section_10_10/bd-2ms/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_10/bd-2ms/verification_summary.md` linking implementation intent to measured outcomes.\n\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.10] Implement rollback/fork detection in control-plane state propagation using canonical divergence and marker proofs (from `10.14`).\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.10] Implement rollback/fork detection in control-plane state propagation using canonical divergence and marker proofs (from `10.14`).\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.10] Implement rollback/fork detection in control-plane state propagation using canonical divergence and marker proofs (from `10.14`).\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.10] Implement rollback/fork detection in control-plane state propagation using canonical divergence and marker proofs (from `10.14`).\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.10] Implement rollback/fork detection in control-plane state propagation using canonical divergence and marker proofs (from `10.14`).\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"1. Define a StateVector struct containing: (a) epoch (u64), (b) marker_id (TrustObjectId with MARKER domain from bd-1l5), (c) state_hash (SHA-256 of canonical-serialized state at this epoch), (d) parent_state_hash (SHA-256 of previous epoch state), (e) timestamp.\n2. Implement a DivergenceDetector that compares two StateVectors from different replicas: (a) if epochs match and state_hashes match => CONVERGED, (b) if epochs match and state_hashes differ => FORKED, (c) if epochs differ by >1 => GAP_DETECTED, (d) if parent_state_hash of the newer does not match state_hash of the older => ROLLBACK_DETECTED.\n3. Implement marker proof verification: given a marker_id chain (from 10.14 bd-126h), verify that the state vector's marker_id appears in the append-only marker stream at the claimed epoch. Return MarkerNotFound or MarkerEpochMismatch on failure.\n4. Implement a rollback proof struct: RollbackProof containing (a) the two divergent StateVectors, (b) the expected parent hash, (c) the actual parent hash, (d) detection timestamp. This struct MUST be serializable for audit logging.\n5. On fork or rollback detection, emit a structured log event with severity=CRITICAL containing the RollbackProof fields and trace correlation ID.\n6. Implement a reconciliation suggestion: for GAP_DETECTED, return the range of missing epochs; for FORKED, return both state hashes for operator review.\n7. Unit tests: (a) CONVERGED case, (b) FORKED case, (c) GAP_DETECTED case, (d) ROLLBACK_DETECTED case, (e) marker proof valid/invalid, (f) RollbackProof serialization round-trip.\n8. Integration test: simulate a 100-epoch sequence, inject a fork at epoch 50, verify detection occurs at epoch 51.\n9. Verification: scripts/check_rollback_detection.py --json, artifacts at artifacts/section_10_10/bd-2ms/.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:36:49.002546997Z","created_by":"ubuntu","updated_at":"2026-02-20T15:36:48.981873855Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-10","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-2ms","depends_on_id":"bd-126h","type":"blocks","created_at":"2026-02-20T14:59:54.053342610Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2ms","depends_on_id":"bd-174","type":"blocks","created_at":"2026-02-20T07:43:10.963608704Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2ms","depends_on_id":"bd-1dar","type":"blocks","created_at":"2026-02-20T14:59:54.489020699Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2ms","depends_on_id":"bd-xwk5","type":"blocks","created_at":"2026-02-20T14:59:54.277489864Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-2nd","title":"Add explicit franken_node product charter document","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.1 — Charter + Split Governance\n\nTask Objective:\nProduce a canonical franken_node product charter document that codifies scope boundaries, split-governance constraints with franken_engine, non-negotiables, and decision rules for future roadmap changes.\n\nAcceptance Criteria:\n- Charter clearly defines product purpose, in-scope/out-of-scope boundaries, and ownership demarcation against franken_engine.\n- Governance section documents decision authority, escalation paths, and change-control criteria.\n- Document is cross-linked from README and key roadmap/spec docs so future agents/operators can find it deterministically.\n\nExpected Artifacts:\n- docs/PRODUCT_CHARTER.md with stable section structure.\n- Cross-link updates in docs/ROADMAP.md and docs/ENGINE_SPLIT_CONTRACT.md (or explicit notes if already linked).\n- Review note capturing rationale for any deliberate boundary decisions.\n\n- Machine-readable verification artifact at `artifacts/section_10_1/bd-2nd/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_1/bd-2nd/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit-style doc lint checks (format/heading/link validity) pass for the charter and updated references.\n- E2E documentation validation script confirms a newcomer can navigate from README to charter to split contract without dead links.\n- Detailed command/output logs from doc validation are attached for reproducible review.\n\nTask-Specific Clarification:\n- For \"Add explicit franken_node product charter document\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"Add explicit franken_node product charter document\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"Add explicit franken_node product charter document\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"Add explicit franken_node product charter document\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"Add explicit franken_node product charter document\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","status":"closed","priority":1,"issue_type":"docs","assignee":"CrimsonCrane","created_at":"2026-02-20T07:26:48.287664174Z","created_by":"ubuntu","updated_at":"2026-02-20T09:02:07.409952851Z","closed_at":"2026-02-20T09:02:07.409915422Z","close_reason":"Product charter created with 6/6 verification checks passing. Charter covers: product purpose, scope boundary, target users, non-negotiables, success criteria, impossible-by-default capabilities, governance model, execution tracks, off-charter behaviors, and cross-references. README and ROADMAP cross-linked.","source_repo":".","compaction_level":0,"original_size":0,"labels":["charter","governance"]}
{"id":"bd-2nlu","title":"[PROGRAM] Implement full-program e2e/chaos orchestration with trace-stable evidence bundles","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md (Cross-cutting across Sections 10.0–10.21 and 11–16)\nSection: PROGRAM (Cross-cutting E2E and chaos orchestration)\n\nTask Objective:\nImplement a program-level E2E + chaos orchestration suite that executes cross-section journeys from the integration matrix and emits deterministic evidence bundles for pass/fail and replay analysis.\n\nWhy This Improves User Outcomes:\nUsers are harmed by integration regressions that pass local tests. This suite detects emergent multi-system failures, safety regressions, and degraded-mode blind spots before release.\n\nAcceptance Criteria:\n- Orchestration executes all matrix-defined critical journeys and records deterministic verdicts.\n- Chaos/failure injections cover representative policy, dependency, and trust failure classes.\n- Outputs include machine-readable pass/fail evidence with stable failure categories and remediation pointers.\n- Runs are reproducible across equivalent inputs/environments with bounded nondeterminism policy.\n\nExpected Artifacts:\n- Program-level E2E orchestration scripts/harness configuration.\n- Chaos scenario catalog with expected invariant checks.\n- Evidence bundle schema + sample bundles for green and failing runs.\n\n- Machine-readable verification artifact at `artifacts/section_program_cross_cutting_e2e_and_chaos_orchestration/bd-2nlu/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_program_cross_cutting_e2e_and_chaos_orchestration/bd-2nlu/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for orchestration helpers, scenario loaders, and verdict aggregators.\n- E2E tests for full journey execution under normal and induced-failure conditions.\n- Detailed structured logs with journey IDs, scenario IDs, invariant IDs, durations, and trace-correlation IDs.\n\nTask-Specific Clarification:\n- This is not a duplicate of section E2E tests; it validates cross-section composition behavior and seam integrity.","status":"closed","priority":1,"issue_type":"task","assignee":"ubuntu","created_at":"2026-02-20T08:08:05.640353368Z","created_by":"ubuntu","updated_at":"2026-02-20T08:45:45.637728561Z","closed_at":"2026-02-20T08:45:45.637637120Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["e2e","logging","plan","program-integration","verification"],"dependencies":[{"issue_id":"bd-2nlu","depends_on_id":"bd-1dpd","type":"blocks","created_at":"2026-02-20T08:24:23.210733876Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2nlu","depends_on_id":"bd-295v","type":"blocks","created_at":"2026-02-20T08:08:05.941053906Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2nlu","depends_on_id":"bd-2twu","type":"blocks","created_at":"2026-02-20T08:20:48.473552031Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-2nre","title":"[15] Section-wide verification gate: comprehensive unit+e2e+logging","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 15\n\nTask Objective:\nCreate a hard section completion gate that verifies all implemented behavior in this section with comprehensive unit tests, integration/e2e scripts, and detailed structured logging evidence.\n\nAcceptance Criteria:\n- Section test matrix covers happy-path, edge-case, and adversarial/error-path scenarios for all section deliverables.\n- E2E scripts execute representative end-user workflows and policy/control-plane transitions for this section.\n- Structured logs include stable event/error codes, trace correlation IDs, and enough context for deterministic replay triage.\n- Verification report is deterministic and machine-readable for CI/release gating.\n\nExpected Artifacts:\n- Section-level test matrix and coverage summary artifact.\n- E2E script suite with pass/fail outputs and reproducible fixtures/seeds.\n- Structured log validation report and traceability bundle.\n- Gate verdict artifact consumable by release automation.\n\n- Machine-readable verification artifact at `artifacts/section_15/bd-2nre/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_15/bd-2nre/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests must validate contracts, invariants, and failure semantics.\n- E2E tests must validate cross-component behavior from user/operator entrypoints to persisted effects.\n- Logging must support root-cause analysis without hidden context requirements.\n\nTask-Specific Clarification:\n- For \"[15] Section-wide verification gate: comprehensive unit+e2e+logging\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[15] Section-wide verification gate: comprehensive unit+e2e+logging\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[15] Section-wide verification gate: comprehensive unit+e2e+logging\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[15] Section-wide verification gate: comprehensive unit+e2e+logging\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[15] Section-wide verification gate: comprehensive unit+e2e+logging\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"1. Section 15 verification gate runs all ecosystem-capture check scripts and confirms 100% pass rate.\n2. Gate validates: (a) extension registry operational with signing enforcement, (b) migration kits exist for >= 5 archetypes, (c) enterprise integrations tested, (d) reputation API spec published, (e) partner program active, (f) onboarding pathway tested end-to-end.\n3. Adoption metrics summarized: extension count, migration kit usage, partner count, case study count.\n4. Gate produces section_15_verification_summary.md with per-pillar status and adoption metrics.\n5. Any pillar below minimum viability threshold is flagged with gap analysis.\n6. The gate itself has a unit test verifying correct aggregation of sub-check results.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:48:30.630221561Z","created_by":"ubuntu","updated_at":"2026-02-20T15:27:41.359675750Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-15","test-obligations","verification-gate"],"dependencies":[{"issue_id":"bd-2nre","depends_on_id":"bd-1961","type":"blocks","created_at":"2026-02-20T07:48:30.901040145Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2nre","depends_on_id":"bd-1dpd","type":"blocks","created_at":"2026-02-20T08:24:23.605937283Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2nre","depends_on_id":"bd-209w","type":"blocks","created_at":"2026-02-20T07:48:31.046335606Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2nre","depends_on_id":"bd-2twu","type":"blocks","created_at":"2026-02-20T08:20:48.969307218Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2nre","depends_on_id":"bd-31tg","type":"blocks","created_at":"2026-02-20T07:48:30.852218883Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2nre","depends_on_id":"bd-3mj9","type":"blocks","created_at":"2026-02-20T07:48:30.949711478Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2nre","depends_on_id":"bd-cv49","type":"blocks","created_at":"2026-02-20T07:48:30.730117172Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2nre","depends_on_id":"bd-elog","type":"blocks","created_at":"2026-02-20T07:48:30.804530571Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2nre","depends_on_id":"bd-sxt5","type":"blocks","created_at":"2026-02-20T08:02:26.222071241Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2nre","depends_on_id":"bd-wpck","type":"blocks","created_at":"2026-02-20T07:48:30.998305196Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-2nt","title":"[10.11] Implement VOI-budgeted monitor scheduling for expensive diagnostics.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.11 — FrankenSQLite-Inspired Runtime Systems Integration Track\n\nWhy This Exists:\nFrankenSQLite-inspired systems integration of capabilities, cancellation protocol, obligations, deterministic labs, and anti-entropy.\n\nTask Objective:\nImplement VOI-budgeted monitor scheduling for expensive diagnostics.\n\nAcceptance Criteria:\n- Implement with explicit success/failure invariants and deterministic behavior under normal, edge, and fault scenarios.\n- Ensure outcomes are verifiable via automated tests and reproducible artifact outputs.\n\nExpected Artifacts:\n- Section-owned design/spec artifact at `docs/specs/section_10_11/bd-2nt_contract.md`, capturing decision rationale, invariants, and interface boundaries.\n- Machine-readable verification artifact at `artifacts/section_10_11/bd-2nt/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_11/bd-2nt/verification_summary.md` linking implementation intent to measured outcomes.\n\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.11] Implement VOI-budgeted monitor scheduling for expensive diagnostics.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.11] Implement VOI-budgeted monitor scheduling for expensive diagnostics.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.11] Implement VOI-budgeted monitor scheduling for expensive diagnostics.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.11] Implement VOI-budgeted monitor scheduling for expensive diagnostics.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.11] Implement VOI-budgeted monitor scheduling for expensive diagnostics.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"AC for bd-2nt:\n1. Implement a VOI-budgeted (Value of Information) monitor scheduler that prioritizes expensive diagnostic probes based on their expected information gain relative to their cost, subject to a per-epoch diagnostic budget.\n2. Each diagnostic probe is registered with: cost (in abstract budget units), a VOI estimator function that returns the expected reduction in decision uncertainty if the probe is executed, and a staleness threshold after which the probe's cached result expires.\n3. The scheduler solves a knapsack-style selection each scheduling epoch: maximize total VOI subject to total cost <= budget. The selection algorithm runs in O(n log n) time using a greedy VOI/cost ratio ranking (with optional exact solver for small n).\n4. The diagnostic budget is configurable per epoch (default: 100 units) and may be dynamically adjusted by the BOCPD regime detector (bd-3u4): regime-change events temporarily increase the budget by a configurable multiplier (default: 3x) for K epochs to accelerate diagnosis.\n5. Probes that have not been executed within their staleness threshold are promoted to mandatory priority (always scheduled regardless of VOI, consuming budget).\n6. The scheduler emits a per-epoch ScheduleReport JSON containing: probes selected, probes skipped, total VOI captured, total cost consumed, budget remaining, and any mandatory promotions.\n7. Unit tests verify: (a) highest-VOI/cost probes are selected first, (b) budget constraint is respected, (c) stale probes are force-promoted, (d) regime-change budget boost increases the number of probes scheduled, (e) zero-budget epoch schedules only mandatory stale probes.\n8. Integration test: a simulated monitoring scenario with 20 probes of varying cost/VOI demonstrates that the scheduler captures at least 80% of the theoretical maximum VOI given the budget.\n9. Structured log events: VOI_SCHEDULE_EPOCH / VOI_PROBE_SELECTED / VOI_PROBE_SKIPPED / VOI_BUDGET_BOOST / VOI_STALE_PROMOTION with probe_id, voi_score, cost, and epoch_id.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:36:50.387047590Z","created_by":"ubuntu","updated_at":"2026-02-20T15:18:58.881846347Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-11","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-2nt","depends_on_id":"bd-3u4","type":"blocks","created_at":"2026-02-20T07:43:11.703759280Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-2o8b","title":"[10.17] Implement heterogeneous hardware planner with policy-evidenced placements.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.17 — Radical Expansion Execution Track (9K)\n\nWhy This Exists:\nRadical expansion track for proof-carrying speculation, Bayesian adversary control, time-travel replay, ZK attestations, and claim compiler systems.\n\nTask Objective:\nImplement heterogeneous hardware planner with policy-evidenced placements.\n\nAcceptance Criteria:\n- Placement decisions satisfy capability/risk constraints and remain reproducible from identical inputs; planner reports policy reasoning and fallback path on resource contention; dispatch executes through approved runtime/engine interfaces.\n\nExpected Artifacts:\n- `docs/architecture/hardware_execution_planner.md`, `src/runtime/hardware_planner.rs`, `tests/perf/hardware_planner_policy_conformance.rs`, `artifacts/10.17/hardware_placement_trace.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_17/bd-2o8b/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_17/bd-2o8b/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.17] Implement heterogeneous hardware planner with policy-evidenced placements.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.17] Implement heterogeneous hardware planner with policy-evidenced placements.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.17] Implement heterogeneous hardware planner with policy-evidenced placements.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.17] Implement heterogeneous hardware planner with policy-evidenced placements.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.17] Implement heterogeneous hardware planner with policy-evidenced placements.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- Placement decisions satisfy capability/risk constraints and remain reproducible from identical inputs; planner reports policy reasoning and fallback path on resource contention; dispatch executes through approved runtime/engine interfaces.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:37:03.922820576Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:58.383935289Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-17","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-2o8b","depends_on_id":"bd-nbwo","type":"blocks","created_at":"2026-02-20T07:43:18.784240166Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-2ona","title":"[10.14] Add evidence-ledger replay validator that reproduces chosen action from captured inputs.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.14 — FrankenSQLite Deep-Mined Expansion Execution Track (9J)\n\nWhy This Exists:\nFrankenSQLite deep-mined control integrity track: evidence ledgers, proofs, epochs, remote effects, markers/MMR, and deterministic fault labs.\n\nTask Objective:\nAdd evidence-ledger replay validator that reproduces chosen action from captured inputs.\n\nAcceptance Criteria:\n- Validator deterministically replays recorded decision contexts; mismatches are reported with minimal diff; replay passes on canonical fixtures.\n\nExpected Artifacts:\n- `src/tools/evidence_replay_validator.rs`, `tests/conformance/evidence_replay_validator.rs`, `artifacts/10.14/evidence_replay_results.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_14/bd-2ona/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_14/bd-2ona/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.14] Add evidence-ledger replay validator that reproduces chosen action from captured inputs.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.14] Add evidence-ledger replay validator that reproduces chosen action from captured inputs.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.14] Add evidence-ledger replay validator that reproduces chosen action from captured inputs.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.14] Add evidence-ledger replay validator that reproduces chosen action from captured inputs.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.14] Add evidence-ledger replay validator that reproduces chosen action from captured inputs.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"Validator deterministically replays recorded decision contexts; mismatches are reported with minimal diff; replay passes on canonical fixtures.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:36:55.468653651Z","created_by":"ubuntu","updated_at":"2026-02-20T15:44:11.894084983Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-14","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-2ona","depends_on_id":"bd-1oof","type":"blocks","created_at":"2026-02-20T07:43:14.387347828Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-2owx","title":"[10.16] Publish substrate policy contract for `frankentui`, `frankensqlite`, `sqlmodel_rust`, and `fastapi_rust`.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.16 — Adjacent Substrate Integration Execution Track (8.7)\n\nWhy This Exists:\nAdjacent substrate integration track to enforce deep composition with frankentui, frankensqlite, sqlmodel_rust, and fastapi_rust.\n\nTask Objective:\nPublish substrate policy contract for `frankentui`, `frankensqlite`, `sqlmodel_rust`, and `fastapi_rust`.\n\nAcceptance Criteria:\n- Policy contract defines mandatory/should-use scopes, exceptions, and waiver process; CI can parse contract metadata.\n\nExpected Artifacts:\n- `docs/architecture/adjacent_substrate_policy.md`, `artifacts/10.16/adjacent_substrate_policy_manifest.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_16/bd-2owx/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_16/bd-2owx/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.16] Publish substrate policy contract for `frankentui`, `frankensqlite`, `sqlmodel_rust`, and `fastapi_rust`.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.16] Publish substrate policy contract for `frankentui`, `frankensqlite`, `sqlmodel_rust`, and `fastapi_rust`.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.16] Publish substrate policy contract for `frankentui`, `frankensqlite`, `sqlmodel_rust`, and `fastapi_rust`.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.16] Publish substrate policy contract for `frankentui`, `frankensqlite`, `sqlmodel_rust`, and `fastapi_rust`.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.16] Publish substrate policy contract for `frankentui`, `frankensqlite`, `sqlmodel_rust`, and `fastapi_rust`.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- Policy contract defines mandatory/should-use scopes, exceptions, and waiver process; CI can parse contract metadata.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:37:01.526840450Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:48.543572439Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-16","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-2owx","depends_on_id":"bd-1ow","type":"blocks","created_at":"2026-02-20T07:46:33.512084532Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2owx","depends_on_id":"bd-3qo","type":"blocks","created_at":"2026-02-20T07:46:33.557665779Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2owx","depends_on_id":"bd-cda","type":"blocks","created_at":"2026-02-20T07:46:33.602458817Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-2ozr","title":"[10.19] Implement poisoning-resilient aggregation and outlier-robust global prior updates.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.19 — Adversarial Trust Commons Execution Track (9M)\n\nWhy This Exists:\nATC federated intelligence track for privacy-preserving cross-deployment threat learning, robust aggregation, and verifier-backed trust metrics.\n\nTask Objective:\nImplement poisoning-resilient aggregation and outlier-robust global prior updates.\n\nAcceptance Criteria:\n- Aggregation resists bounded adversarial submissions per policy assumptions; poisoning test suites show bounded degradation and fail-closed behavior on threshold breach.\n\nExpected Artifacts:\n- `docs/security/atc_poisoning_resilience.md`, `tests/security/atc_poisoning_attack_suite.rs`, `artifacts/10.19/atc_poisoning_resilience_results.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_19/bd-2ozr/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_19/bd-2ozr/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.19] Implement poisoning-resilient aggregation and outlier-robust global prior updates.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.19] Implement poisoning-resilient aggregation and outlier-robust global prior updates.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.19] Implement poisoning-resilient aggregation and outlier-robust global prior updates.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.19] Implement poisoning-resilient aggregation and outlier-robust global prior updates.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.19] Implement poisoning-resilient aggregation and outlier-robust global prior updates.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- Aggregation resists bounded adversarial submissions per policy assumptions; poisoning test suites show bounded degradation and fail-closed behavior on threshold breach.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:37:05.755245088Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:21.861881481Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-19","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-2ozr","depends_on_id":"bd-3ps8","type":"blocks","created_at":"2026-02-20T07:43:19.702766083Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-2ps7","title":"[14] Metric family: adversarial resilience","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 14\n\nTask Objective:\nInstrument adversarial resilience metric family across evolving campaign corpora.\n\nExecution Requirements:\n- Make this requirement machine-verifiable and release-gated where applicable.\n- Keep behavior self-documenting so future contributors do not need to re-open the master plan.\n\nTesting & Logging Requirements:\n- Unit tests for rule/contract logic and error conditions.\n- Integration/E2E tests for workflow-level enforcement.\n- Structured logs with stable codes and trace IDs.\n- Reproducible artifacts that prove contract satisfaction.\n\nAcceptance Criteria:\n- Success and failure invariants for [14] Metric family: adversarial resilience are explicitly quantified and machine-verifiable.\n- Determinism requirements for [14] Metric family: adversarial resilience are validated across repeated runs and adversarial perturbations.\n\n\nExpected Artifacts:\n- Machine-readable verification artifact with explicit canonical path under artifacts/section_14/bd-2ps7/verification_evidence.json, suitable for CI/release gating.\n- Human-readable verification summary with explicit canonical path under artifacts/section_14/bd-2ps7/verification_summary.md, linking implementation intent to measured validation outcomes.\n\nTask-Specific Clarification:\n- The implementation must deliver the exact capability named in the title, with no scope dilution and no silent feature omission.\n- Validation artifacts must include capability-specific thresholds, pass/fail criteria, and reproducible evidence bundles tied to this bead ID.\n- Program/section verification gates must be able to consume this bead's outputs without manual interpretation.\n\nWhy This Improves User Outcomes:\n- \"[14] Metric family: adversarial resilience\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[14] Metric family: adversarial resilience\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"METRIC FAMILY: Adversarial resilience under evolving campaigns.\n1. Metrics measured: (a) detection rate of known attack patterns (%), (b) detection rate of novel/mutated attacks (%), (c) false positive rate under adversarial noise (%), (d) time-to-adapt (how quickly defenses update after new attack pattern identified), (e) resilience decay (detection rate over successive attack rounds).\n2. Attack campaign types: signal poisoning, Sybil attacks, mimicry/camouflage, supply-chain injection, evasion mutation.\n3. Detection gates: known patterns >= 95% detection, novel patterns >= 70% detection, false positive rate <= 2%.\n4. Time-to-adapt: defenses incorporate new attack patterns within 24 hours of identification (measured in CI simulation).\n5. Resilience decay: detection rate does not drop > 10% over 10 successive adversarial rounds.\n6. Measured under multi-round adaptive adversary simulation (adversary evolves strategy each round).\n7. Publication: adversarial resilience metrics in benchmark report with per-campaign-type breakdown.\n8. Evidence: adversarial_resilience_metrics.json with per-attack-type detection rates, FP rates, and round-by-round decay.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:39:35.985600891Z","created_by":"ubuntu","updated_at":"2026-02-20T15:25:19.038325820Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-14","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-2ps7","depends_on_id":"bd-jbp1","type":"blocks","created_at":"2026-02-20T07:43:26.113555718Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-2pu","title":"[10.7] Add external-reproduction playbook and automation scripts.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.7 — Conformance + Verification\n\nWhy This Exists:\nConformance and verification evidence stack for compatibility, trust protocols, fuzzing, and external reproducibility.\n\nTask Objective:\nAdd external-reproduction playbook and automation scripts.\n\nAcceptance Criteria:\n- Implement with explicit success/failure invariants and deterministic behavior under normal, edge, and fault scenarios.\n- Ensure outcomes are verifiable via automated tests and reproducible artifact outputs.\n\nExpected Artifacts:\n- Section-owned design/spec artifact at `docs/specs/section_10_7/bd-2pu_contract.md`, capturing decision rationale, invariants, and interface boundaries.\n- Machine-readable verification artifact at `artifacts/section_10_7/bd-2pu/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_7/bd-2pu/verification_summary.md` linking implementation intent to measured outcomes.\n\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.7] Add external-reproduction playbook and automation scripts.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.7] Add external-reproduction playbook and automation scripts.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.7] Add external-reproduction playbook and automation scripts.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.7] Add external-reproduction playbook and automation scripts.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.7] Add external-reproduction playbook and automation scripts.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"1. External-reproduction playbook is a standalone Markdown document under docs/ that enables a third party to reproduce all verification results from scratch.\n2. Playbook requires only: git clone, a supported Rust toolchain, and standard POSIX tools — no internal infrastructure dependencies.\n3. Automation scripts (scripts/reproduce_all.sh or equivalent) execute the full reproduction pipeline with a single command.\n4. Reproduction output is diff-comparable against published verification evidence: script exits 0 if results match, non-zero with a diff on mismatch.\n5. Playbook includes troubleshooting section for common environment differences (OS, toolchain version, locale).\n6. Scripts support a --subset flag to reproduce a specific section or bead's evidence without running the entire suite.\n7. At least one CI job runs the external-reproduction pipeline on a clean container image to validate the playbook stays current.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:36:47.670221550Z","created_by":"ubuntu","updated_at":"2026-02-20T15:17:39.318327778Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-7","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-2pu","depends_on_id":"bd-3ex","type":"blocks","created_at":"2026-02-20T07:43:23.663923074Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-2pw","title":"[10.6] Add artifact signing and checksum verification for releases.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.6 — Performance + Packaging\n\nWhy This Exists:\nPerformance and packaging reliability gates: benchmark rigor, latency targets, release integrity, and deterministic rollback bundles.\n\nTask Objective:\nAdd artifact signing and checksum verification for releases.\n\nAcceptance Criteria:\n- Implement with explicit success/failure invariants and deterministic behavior under normal, edge, and fault scenarios.\n- Ensure outcomes are verifiable via automated tests and reproducible artifact outputs.\n\nExpected Artifacts:\n- Section-owned design/spec artifact at `docs/specs/section_10_6/bd-2pw_contract.md`, capturing decision rationale, invariants, and interface boundaries.\n- Machine-readable verification artifact at `artifacts/section_10_6/bd-2pw/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_6/bd-2pw/verification_summary.md` linking implementation intent to measured outcomes.\n\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.6] Add artifact signing and checksum verification for releases.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.6] Add artifact signing and checksum verification for releases.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.6] Add artifact signing and checksum verification for releases.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.6] Add artifact signing and checksum verification for releases.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.6] Add artifact signing and checksum verification for releases.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"1. All release artifacts (binaries, tarballs, packages) are signed with a project-controlled key using a documented signing scheme (e.g., minisign, cosign, or GPG).\n2. SHA-256 checksums are generated for every release artifact and published alongside the artifact in a CHECKSUMS.txt file.\n3. A verification command (e.g., scripts/verify_release.sh) validates both signature and checksum for any downloaded artifact.\n4. CI pipeline automatically signs and checksums artifacts during the release build step — no manual signing allowed.\n5. Signature key rotation procedure is documented, including how to verify artifacts signed with prior keys.\n6. Verification script returns a structured JSON result with pass/fail status and details per artifact.\n7. Tampered artifacts (bit-flip test) are correctly rejected by the verification command.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:36:47.101599959Z","created_by":"ubuntu","updated_at":"2026-02-20T15:15:57.688254594Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-6","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-2pw","depends_on_id":"bd-3kn","type":"blocks","created_at":"2026-02-20T07:43:23.336384753Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-2q5","title":"[10.6] Optimize migration scanner throughput for large monorepos.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.6 — Performance + Packaging\n\nWhy This Exists:\nPerformance and packaging reliability gates: benchmark rigor, latency targets, release integrity, and deterministic rollback bundles.\n\nTask Objective:\nOptimize migration scanner throughput for large monorepos.\n\nAcceptance Criteria:\n- Implement with explicit success/failure invariants and deterministic behavior under normal, edge, and fault scenarios.\n- Ensure outcomes are verifiable via automated tests and reproducible artifact outputs.\n\nExpected Artifacts:\n- Section-owned design/spec artifact at `docs/specs/section_10_6/bd-2q5_contract.md`, capturing decision rationale, invariants, and interface boundaries.\n- Machine-readable verification artifact at `artifacts/section_10_6/bd-2q5/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_6/bd-2q5/verification_summary.md` linking implementation intent to measured outcomes.\n\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.6] Optimize migration scanner throughput for large monorepos.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.6] Optimize migration scanner throughput for large monorepos.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.6] Optimize migration scanner throughput for large monorepos.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.6] Optimize migration scanner throughput for large monorepos.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.6] Optimize migration scanner throughput for large monorepos.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"1. Migration scanner throughput on a 10k-file monorepo benchmark completes within a defined time ceiling (documented in spec).\n2. Scanner supports incremental mode: re-scanning after a single-file change processes only the delta, not the full tree.\n3. Before/after throughput comparison table is produced per Section 7 performance doctrine.\n4. Memory usage stays bounded (no O(n^2) growth) — verified with a memory profile artifact for the large-monorepo benchmark.\n5. Parallelism: scanner utilizes available CPU cores (configurable concurrency level) for file traversal and analysis.\n6. Correctness proof: scanner output on the golden corpus is identical before and after optimization.\n7. Benchmark is reproducible from a clean checkout with a single command and produces structured JSON results.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:36:46.936795081Z","created_by":"ubuntu","updated_at":"2026-02-20T15:15:36.929023576Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-6","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-2q5","depends_on_id":"bd-38m","type":"blocks","created_at":"2026-02-20T07:43:23.250684309Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-2qf","title":"[10.2] Implement compatibility behavior registry with typed shim metadata.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.2 — Compatibility Core\n\nWhy This Exists:\nCompatibility core as strategic wedge: policy-visible behavior, divergence receipts, L1/L2 lockstep, and spec-first fixture governance.\n\nTask Objective:\nImplement compatibility behavior registry with typed shim metadata.\n\nAcceptance Criteria:\n- Implement with explicit success/failure invariants and deterministic behavior under normal, edge, and fault scenarios.\n- Ensure outcomes are verifiable via automated tests and reproducible artifact outputs.\n\nExpected Artifacts:\n- Section-owned design/spec artifact at `docs/specs/section_10_2/bd-2qf_contract.md`, capturing decision rationale, invariants, and interface boundaries.\n- Machine-readable verification artifact at `artifacts/section_10_2/bd-2qf/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_2/bd-2qf/verification_summary.md` linking implementation intent to measured outcomes.\n\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.2] Implement compatibility behavior registry with typed shim metadata.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.2] Implement compatibility behavior registry with typed shim metadata.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.2] Implement compatibility behavior registry with typed shim metadata.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.2] Implement compatibility behavior registry with typed shim metadata.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.2] Implement compatibility behavior registry with typed shim metadata.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","status":"closed","priority":1,"issue_type":"task","assignee":"CrimsonCrane","created_at":"2026-02-20T07:36:43.914447842Z","created_by":"ubuntu","updated_at":"2026-02-20T09:34:03.425939378Z","closed_at":"2026-02-20T09:34:03.425914892Z","close_reason":"done","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-2","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-2qf","depends_on_id":"bd-2wz","type":"blocks","created_at":"2026-02-20T07:43:20.095228292Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-2qmf","title":"Epic: Asupersync Lab + Release Gates [10.15d]","description":"- type: epic","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-20T07:47:58.072163029Z","updated_at":"2026-02-20T07:49:21.272669298Z","closed_at":"2026-02-20T07:49:21.272649331Z","close_reason":"Superseded by canonical detailed master-plan graph (bd-33v) with full 10.N-10.21 and 11-16 coverage, explicit dependencies, and per-section verification gates.","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-2qqu","title":"[10.14] Implement virtual transport fault harness (drop/reorder/corrupt) for remote-control protocol testing.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.14 — FrankenSQLite Deep-Mined Expansion Execution Track (9J)\n\nWhy This Exists:\nFrankenSQLite deep-mined control integrity track: evidence ledgers, proofs, epochs, remote effects, markers/MMR, and deterministic fault labs.\n\nTask Objective:\nImplement virtual transport fault harness (drop/reorder/corrupt) for remote-control protocol testing.\n\nAcceptance Criteria:\n- Harness supports deterministic fault schedules from seed; scenarios cover drop/reorder/corrupt classes; reproductions include exact fault sequence.\n\nExpected Artifacts:\n- `tests/harness/virtual_transport_faults.rs`, `docs/testing/virtual_transport_harness.md`, `artifacts/10.14/virtual_fault_campaign_results.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_14/bd-2qqu/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_14/bd-2qqu/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.14] Implement virtual transport fault harness (drop/reorder/corrupt) for remote-control protocol testing.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.14] Implement virtual transport fault harness (drop/reorder/corrupt) for remote-control protocol testing.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.14] Implement virtual transport fault harness (drop/reorder/corrupt) for remote-control protocol testing.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.14] Implement virtual transport fault harness (drop/reorder/corrupt) for remote-control protocol testing.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.14] Implement virtual transport fault harness (drop/reorder/corrupt) for remote-control protocol testing.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"Harness supports deterministic fault schedules from seed; scenarios cover drop/reorder/corrupt classes; reproductions include exact fault sequence.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:36:59.145618233Z","created_by":"ubuntu","updated_at":"2026-02-20T15:44:02.412956168Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-14","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-2qqu","depends_on_id":"bd-2808","type":"blocks","created_at":"2026-02-20T07:43:16.273570529Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-2rg1","title":"Epic: Epoch Management + Marker Streams [10.14g]","description":"- type: epic","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-20T07:47:58.072163029Z","updated_at":"2026-02-20T07:49:21.244772489Z","closed_at":"2026-02-20T07:49:21.244751930Z","close_reason":"Superseded by canonical detailed master-plan graph (bd-33v) with full 10.N-10.21 and 11-16 coverage, explicit dependencies, and per-section verification gates.","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-2rwm","title":"Epic: Verifiable Execution Fabric (VEF) [10.18]","description":"- type: epic","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-20T07:47:58.072163029Z","updated_at":"2026-02-20T07:49:21.305829281Z","closed_at":"2026-02-20T07:49:21.305808733Z","close_reason":"Superseded by canonical detailed master-plan graph (bd-33v) with full 10.N-10.21 and 11-16 coverage, explicit dependencies, and per-section verification gates.","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-2sbj","title":"Epic: Radical Expansion - Advanced Security [10.17c]","description":"- type: epic","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-20T07:47:58.072163029Z","updated_at":"2026-02-20T07:49:21.294762809Z","closed_at":"2026-02-20T07:49:21.294743764Z","close_reason":"Superseded by canonical detailed master-plan graph (bd-33v) with full 10.N-10.21 and 11-16 coverage, explicit dependencies, and per-section verification gates.","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-2st","title":"[10.3] Build migration validation runner with lockstep checks.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.3 — Migration System\n\nWhy This Exists:\nMigration autopilot pipeline from audit to rollout, designed to collapse migration friction with deterministic confidence and replayability.\n\nTask Objective:\nBuild migration validation runner with lockstep checks.\n\nAcceptance Criteria:\n- Implement with explicit success/failure invariants and deterministic behavior under normal, edge, and fault scenarios.\n- Ensure outcomes are verifiable via automated tests and reproducible artifact outputs.\n\nExpected Artifacts:\n- Section-owned design/spec artifact at `docs/specs/section_10_3/bd-2st_contract.md`, capturing decision rationale, invariants, and interface boundaries.\n- Machine-readable verification artifact at `artifacts/section_10_3/bd-2st/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_3/bd-2st/verification_summary.md` linking implementation intent to measured outcomes.\n\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.3] Build migration validation runner with lockstep checks.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.3] Build migration validation runner with lockstep checks.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.3] Build migration validation runner with lockstep checks.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.3] Build migration validation runner with lockstep checks.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.3] Build migration validation runner with lockstep checks.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","status":"closed","priority":1,"issue_type":"task","assignee":"CrimsonCrane","created_at":"2026-02-20T07:36:45.035952247Z","created_by":"ubuntu","updated_at":"2026-02-20T10:14:47.613427595Z","closed_at":"2026-02-20T10:14:47.613402448Z","close_reason":"done","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-3","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-2st","depends_on_id":"bd-2ew","type":"blocks","created_at":"2026-02-20T07:43:22.142282181Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-2sx","title":"[10.10] Integrate canonical revocation freshness semantics (from `10.13`) before risky and dangerous product actions.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.10 — FCP-Inspired Hardening + Interop Integration Track\n\nWhy This Exists:\nFCP-inspired hardening/interop contract for IDs, serialization, control-channel auth, revocation freshness, and publication gating.\n\nTask Objective:\nIntegrate canonical revocation freshness semantics (from `10.13`) before risky and dangerous product actions.\n\nAcceptance Criteria:\n- Implement with explicit success/failure invariants and deterministic behavior under normal, edge, and fault scenarios.\n- Ensure outcomes are verifiable via automated tests and reproducible artifact outputs.\n\nExpected Artifacts:\n- Section-owned design/spec artifact at `docs/specs/section_10_10/bd-2sx_contract.md`, capturing decision rationale, invariants, and interface boundaries.\n- Machine-readable verification artifact at `artifacts/section_10_10/bd-2sx/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_10/bd-2sx/verification_summary.md` linking implementation intent to measured outcomes.\n\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.10] Integrate canonical revocation freshness semantics (from `10.13`) before risky and dangerous product actions.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.10] Integrate canonical revocation freshness semantics (from `10.13`) before risky and dangerous product actions.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.10] Integrate canonical revocation freshness semantics (from `10.13`) before risky and dangerous product actions.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.10] Integrate canonical revocation freshness semantics (from `10.13`) before risky and dangerous product actions.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.10] Integrate canonical revocation freshness semantics (from `10.13`) before risky and dangerous product actions.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"1. Define a RevocationFreshnessCheck struct containing: (a) check_id (unique per invocation), (b) target_key_id or target_token_id being checked, (c) revocation_list_version (monotonic u64 from the canonical revocation registry in 10.13), (d) max_staleness_seconds (configurable per action risk tier), (e) check_timestamp (UTC), (f) result enum (FRESH, STALE, REVOKED, UNAVAILABLE).\n2. Define risk tiers for product actions: DANGEROUS (destructive migration, key deletion) requires max_staleness <= 10s; RISKY (rollback, policy change) requires max_staleness <= 60s; NORMAL (read, query) requires max_staleness <= 300s. These thresholds MUST be configurable but have these defaults.\n3. Implement a pre-action gate: before executing any DANGEROUS or RISKY action, call check_revocation_freshness(target_id, risk_tier) which: (a) fetches the latest revocation list version, (b) compares its age against the tier threshold, (c) returns STALE if the revocation list is older than the threshold, (d) returns REVOKED if the target appears in the revocation list, (e) returns UNAVAILABLE if the revocation source cannot be reached.\n4. Enforce fail-closed semantics: if the freshness check returns STALE, REVOKED, or UNAVAILABLE, the action MUST NOT proceed. Return a typed error (RevocationCheckFailed) with the check struct for audit.\n5. Implement a freshness cache with TTL equal to the risk tier threshold. Cache hits skip the network fetch but still validate staleness against the cached timestamp.\n6. Emit structured log for every freshness check with: check_id, target_id, risk_tier, result, latency_ms, and trace correlation ID.\n7. Unit tests: (a) FRESH result allows action, (b) STALE result blocks action, (c) REVOKED result blocks action, (d) UNAVAILABLE result blocks action (fail-closed), (e) cache hit within TTL, (f) cache miss after TTL expiry, (g) tier threshold configuration override.\n8. Integration test: simulate revocation list update delay, verify DANGEROUS action is blocked while NORMAL action proceeds.\n9. Verification: scripts/check_revocation_freshness.py --json, artifacts at artifacts/section_10_10/bd-2sx/.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:36:49.326230276Z","created_by":"ubuntu","updated_at":"2026-02-20T15:37:59.117284541Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-10","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-2sx","depends_on_id":"bd-1m8r","type":"blocks","created_at":"2026-02-20T14:59:52.112302923Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2sx","depends_on_id":"bd-oty","type":"blocks","created_at":"2026-02-20T07:43:11.130638711Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-2t5u","title":"[10.13] Implement predictive pre-staging engine for high-probability offline artifacts.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.13 — FCP Deep-Mined Expansion Execution Track (9I)\n\nWhy This Exists:\nDeep connector/provider contract track: lifecycle FSMs, conformance harnesses, fencing, sandboxing, revocation freshness, and protocol hardening.\n\nTask Objective:\nImplement predictive pre-staging engine for high-probability offline artifacts.\n\nAcceptance Criteria:\n- Pre-staging model raises offline coverage on benchmark scenarios; budget limits prevent prefetch storms; prediction quality is measured and reported.\n\nExpected Artifacts:\n- `docs/specs/predictive_prestaging.md`, `tests/perf/prestaging_coverage_improvement.rs`, `artifacts/10.13/prestaging_model_report.csv`.\n\n- Machine-readable verification artifact at `artifacts/section_10_13/bd-2t5u/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_13/bd-2t5u/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.13] Implement predictive pre-staging engine for high-probability offline artifacts.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.13] Implement predictive pre-staging engine for high-probability offline artifacts.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.13] Implement predictive pre-staging engine for high-probability offline artifacts.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.13] Implement predictive pre-staging engine for high-probability offline artifacts.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.13] Implement predictive pre-staging engine for high-probability offline artifacts.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","status":"closed","priority":1,"issue_type":"task","assignee":"CrimsonCrane","created_at":"2026-02-20T07:36:53.680520990Z","created_by":"ubuntu","updated_at":"2026-02-20T12:32:43.613770964Z","closed_at":"2026-02-20T12:32:43.613743884Z","close_reason":"done","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-13","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-2t5u","depends_on_id":"bd-jxgt","type":"blocks","created_at":"2026-02-20T07:43:13.433328627Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-2tdi","title":"[10.15] Migrate lifecycle/rollout orchestration to region-owned execution trees.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.15 — Asupersync-First Integration Execution Track (8.4-8.6)\n\nWhy This Exists:\nAsupersync-first control-plane migration track enforcing Cx-first, region ownership, cancellation correctness, and protocol-grade verification gates.\n\nTask Objective:\nMigrate lifecycle/rollout orchestration to region-owned execution trees.\n\nAcceptance Criteria:\n- Lifecycle orchestration runs under region ownership; region close implies quiescence in conformance tests.\n\nExpected Artifacts:\n- `tests/integration/region_owned_lifecycle.rs`, `docs/specs/region_tree_topology.md`, `artifacts/10.15/region_quiescence_trace.jsonl`.\n\n- Machine-readable verification artifact at `artifacts/section_10_15/bd-2tdi/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_15/bd-2tdi/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.15] Migrate lifecycle/rollout orchestration to region-owned execution trees.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.15] Migrate lifecycle/rollout orchestration to region-owned execution trees.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.15] Migrate lifecycle/rollout orchestration to region-owned execution trees.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.15] Migrate lifecycle/rollout orchestration to region-owned execution trees.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.15] Migrate lifecycle/rollout orchestration to region-owned execution trees.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- Lifecycle orchestration runs under region ownership; region close implies quiescence in conformance tests.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:36:59.809633782Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:53.439130915Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-15","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-2tdi","depends_on_id":"bd-721z","type":"blocks","created_at":"2026-02-20T07:43:16.623596121Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-2tua","title":"[10.16] Implement `frankensqlite` adapter layer for required `franken_node` persistence surfaces.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.16 — Adjacent Substrate Integration Execution Track (8.7)\n\nWhy This Exists:\nAdjacent substrate integration track to enforce deep composition with frankentui, frankensqlite, sqlmodel_rust, and fastapi_rust.\n\nTask Objective:\nImplement `frankensqlite` adapter layer for required `franken_node` persistence surfaces.\n\nAcceptance Criteria:\n- Required persistence APIs route through adapter; conformance tests validate deterministic read/write/replay semantics.\n\nExpected Artifacts:\n- `src/storage/frankensqlite_adapter.rs`, `tests/integration/frankensqlite_adapter_conformance.rs`, `artifacts/10.16/frankensqlite_adapter_report.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_16/bd-2tua/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_16/bd-2tua/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.16] Implement `frankensqlite` adapter layer for required `franken_node` persistence surfaces.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.16] Implement `frankensqlite` adapter layer for required `franken_node` persistence surfaces.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.16] Implement `frankensqlite` adapter layer for required `franken_node` persistence surfaces.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.16] Implement `frankensqlite` adapter layer for required `franken_node` persistence surfaces.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.16] Implement `frankensqlite` adapter layer for required `franken_node` persistence surfaces.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- Required persistence APIs route through adapter; conformance tests validate deterministic read/write/replay semantics.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:37:02.018964620Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:47.199140795Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-16","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-2tua","depends_on_id":"bd-1a1j","type":"blocks","created_at":"2026-02-20T07:43:17.792602681Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-2twu","title":"[PROGRAM] Enforce canonical evidence-artifact namespace + collision gate","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md (Cross-cutting verification discipline across Sections 10.0–10.21 and 11–16)\nSection: PROGRAM (Cross-cutting verification discipline)\n\nTask Objective:\nDefine and enforce a canonical evidence-artifact namespace contract so every bead produces deterministic, non-colliding, machine-indexable artifacts that can be replayed and audited without ambiguous filenames or overwritten outputs.\n\nWhy This Exists:\nCurrent bead descriptions intentionally preserve capability scope, but many still use generic artifact placeholders. Without explicit namespace rules and automated collision checks, downstream verification can become ambiguous, especially when multiple section gates run concurrently.\n\nAcceptance Criteria:\n- Publish canonical artifact naming schema covering unit, integration, e2e, benchmark, and verification outputs.\n- Define mandatory metadata fields for artifact manifests (bead id, section, scenario id, seed, profile, timestamp, commit, trace id).\n- Add automated collision detector that fails when two beads map to the same canonical artifact path.\n- Require all section/program verification gates to consume the canonical manifest and validate completeness.\n- Document migration rules for legacy/generic artifact placeholders to canonical paths.\n\nExpected Artifacts:\n- docs/verification/ARTIFACT_NAMESPACE_CONTRACT.md\n- schemas/artifact_manifest.schema.json\n- scripts/verify_artifact_namespace.sh\n- artifacts/program/artifact_namespace_validation_report.json\n\nTesting & Logging Requirements:\n- Unit tests for schema validator and path canonicalization logic.\n- E2E tests that execute multi-section verification workflows and assert collision-free artifact emission.\n- Structured logs with stable event codes for namespace resolution, collision checks, and manifest validation outcomes.\n- CPU-intensive checks (full matrix/e2e sweeps) must run via rch offload and include worker metadata in logs.\n\nTask-Specific Clarification:\n- Preserve full feature scope by strengthening evidence rigor only; no capability reduction or gate relaxation is allowed.\n- This bead is additive and must not weaken any existing section-level testing/e2e/logging obligations.\n- Outputs must be deterministic and independently replayable without hidden local context.\n\nWhy This Improves User Outcomes:\n- Prevents false-green verification caused by artifact path collisions or ambiguous outputs.\n- Improves incident forensics by making every result traceable to an exact bead/scenario/seed/profile.\n- Reduces operator confusion and accelerates root-cause analysis in large-scale, parallel execution flows.","status":"closed","priority":1,"issue_type":"task","assignee":"ubuntu","created_at":"2026-02-20T08:20:37.459103037Z","created_by":"ubuntu","updated_at":"2026-02-20T08:37:35.823839955Z","closed_at":"2026-02-20T08:37:35.823749517Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","program-integration","test-obligations","verification"],"dependencies":[{"issue_id":"bd-2twu","depends_on_id":"bd-1dpd","type":"blocks","created_at":"2026-02-20T08:24:27.498877187Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-2ut3","title":"[11] No-contract-no-merge gate","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 11\n\nTask Objective:\nImplement hard CI/release gate enforcing 'No contract, no merge'.\n\nExecution Requirements:\n- Make this requirement machine-verifiable and release-gated where applicable.\n- Keep behavior self-documenting so future contributors do not need to re-open the master plan.\n\nTesting & Logging Requirements:\n- Unit tests for rule/contract logic and error conditions.\n- Integration/E2E tests for workflow-level enforcement.\n- Structured logs with stable codes and trace IDs.\n- Reproducible artifacts that prove contract satisfaction.\n\nAcceptance Criteria:\n- Success and failure invariants for [11] No-contract-no-merge gate are explicitly quantified and machine-verifiable.\n- Determinism requirements for [11] No-contract-no-merge gate are validated across repeated runs and adversarial perturbations.\n\n\nExpected Artifacts:\n- Machine-readable verification artifact with explicit canonical path under artifacts/section_11/bd-2ut3/verification_evidence.json, suitable for CI/release gating.\n- Human-readable verification summary with explicit canonical path under artifacts/section_11/bd-2ut3/verification_summary.md, linking implementation intent to measured validation outcomes.\n\nTask-Specific Clarification:\n- The implementation must deliver the exact capability named in the title, with no scope dilution and no silent feature omission.\n- Validation artifacts must include capability-specific thresholds, pass/fail criteria, and reproducible evidence bundles tied to this bead ID.\n- Program/section verification gates must be able to consume this bead's outputs without manual interpretation.\n\nWhy This Improves User Outcomes:\n- \"[11] No-contract-no-merge gate\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[11] No-contract-no-merge gate\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"1. A CI merge-gate check validates that every PR touching production code includes a complete evidence contract.\n2. The gate checks presence and validity of ALL contract fields: change summary, compatibility/threat evidence, EV score+tier, expected-loss model, fallback trigger, rollout wedge, rollback command, benchmark/correctness artifacts.\n3. PRs missing any required contract field are blocked from merge with a clear error message identifying which fields are missing.\n4. The gate is implemented as a pre-merge CI job (not just a linter warning) — merge is physically blocked.\n5. Escape hatch: a designated approver can override the gate with an explicit 'contract-override' label, but this is logged and auditable.\n6. Unit test: a mock PR with complete contract passes the gate; a mock PR missing any single field fails.\n7. Integration test: attempt to merge a PR without contract via CI simulation and verify it is rejected.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:39:33.156047417Z","created_by":"ubuntu","updated_at":"2026-02-20T15:17:12.901647857Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-11","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-2ut3","depends_on_id":"bd-3l8d","type":"blocks","created_at":"2026-02-20T07:43:24.650540061Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-2vcg","title":"Epic: Moonshot Disruption Track [10.9]","description":"- type: epic","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-20T07:47:58.072163029Z","updated_at":"2026-02-20T07:49:21.135680718Z","closed_at":"2026-02-20T07:49:21.135658747Z","close_reason":"Superseded by canonical detailed master-plan graph (bd-33v) with full 10.N-10.21 and 11-16 coverage, explicit dependencies, and per-section verification gates.","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-2vi","title":"[10.2] Implement L1 lockstep runner integration for Node/Bun/franken_node.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.2 — Compatibility Core\n\nWhy This Exists:\nCompatibility core as strategic wedge: policy-visible behavior, divergence receipts, L1/L2 lockstep, and spec-first fixture governance.\n\nTask Objective:\nImplement L1 lockstep runner integration for Node/Bun/franken_node.\n\nAcceptance Criteria:\n- Implement with explicit success/failure invariants and deterministic behavior under normal, edge, and fault scenarios.\n- Ensure outcomes are verifiable via automated tests and reproducible artifact outputs.\n\nExpected Artifacts:\n- Section-owned design/spec artifact at `docs/specs/section_10_2/bd-2vi_contract.md`, capturing decision rationale, invariants, and interface boundaries.\n- Machine-readable verification artifact at `artifacts/section_10_2/bd-2vi/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_2/bd-2vi/verification_summary.md` linking implementation intent to measured outcomes.\n\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.2] Implement L1 lockstep runner integration for Node/Bun/franken_node.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.2] Implement L1 lockstep runner integration for Node/Bun/franken_node.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.2] Implement L1 lockstep runner integration for Node/Bun/franken_node.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.2] Implement L1 lockstep runner integration for Node/Bun/franken_node.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.2] Implement L1 lockstep runner integration for Node/Bun/franken_node.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","status":"closed","priority":1,"issue_type":"task","assignee":"CrimsonCrane","created_at":"2026-02-20T07:36:44.240551048Z","created_by":"ubuntu","updated_at":"2026-02-20T09:42:40.382499910Z","closed_at":"2026-02-20T09:42:40.382472980Z","close_reason":"done","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-2","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-2vi","depends_on_id":"bd-1z3","type":"blocks","created_at":"2026-02-20T07:43:20.261971737Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-2vs4","title":"[10.13] Implement deterministic lease coordinator selection and quorum signature verification.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.13 — FCP Deep-Mined Expansion Execution Track (9I)\n\nWhy This Exists:\nDeep connector/provider contract track: lifecycle FSMs, conformance harnesses, fencing, sandboxing, revocation freshness, and protocol hardening.\n\nTask Objective:\nImplement deterministic lease coordinator selection and quorum signature verification.\n\nAcceptance Criteria:\n- Coordinator selection is deterministic for identical inputs; quorum requirements vary by safety tier and are enforced; verification failures are classified.\n\nExpected Artifacts:\n- `tests/conformance/lease_coordinator_selection.rs`, `docs/specs/lease_quorum_rules.md`, `artifacts/10.13/lease_quorum_vectors.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_13/bd-2vs4/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_13/bd-2vs4/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.13] Implement deterministic lease coordinator selection and quorum signature verification.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.13] Implement deterministic lease coordinator selection and quorum signature verification.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.13] Implement deterministic lease coordinator selection and quorum signature verification.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.13] Implement deterministic lease coordinator selection and quorum signature verification.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.13] Implement deterministic lease coordinator selection and quorum signature verification.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","status":"closed","priority":1,"issue_type":"task","assignee":"CrimsonCrane","created_at":"2026-02-20T07:36:53.355836717Z","created_by":"ubuntu","updated_at":"2026-02-20T12:17:55.060711836Z","closed_at":"2026-02-20T12:17:55.060684175Z","close_reason":"done","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-13","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-2vs4","depends_on_id":"bd-bq6y","type":"blocks","created_at":"2026-02-20T07:43:13.267723744Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-2w4u","title":"[12] Risk control: hardening perf regression","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 12\n\nTask Objective:\nImplement profile-governed tuning plus p99 guardrails against hardening-induced regressions.\n\nExecution Requirements:\n- Make this requirement machine-verifiable and release-gated where applicable.\n- Keep behavior self-documenting so future contributors do not need to re-open the master plan.\n\nTesting & Logging Requirements:\n- Unit tests for rule/contract logic and error conditions.\n- Integration/E2E tests for workflow-level enforcement.\n- Structured logs with stable codes and trace IDs.\n- Reproducible artifacts that prove contract satisfaction.\n\nAcceptance Criteria:\n- Success and failure invariants for [12] Risk control: hardening perf regression are explicitly quantified and machine-verifiable.\n- Determinism requirements for [12] Risk control: hardening perf regression are validated across repeated runs and adversarial perturbations.\n\n\nExpected Artifacts:\n- Machine-readable verification artifact with explicit canonical path under artifacts/section_12/bd-2w4u/verification_evidence.json, suitable for CI/release gating.\n- Human-readable verification summary with explicit canonical path under artifacts/section_12/bd-2w4u/verification_summary.md, linking implementation intent to measured validation outcomes.\n\nTask-Specific Clarification:\n- The implementation must deliver the exact capability named in the title, with no scope dilution and no silent feature omission.\n- Validation artifacts must include capability-specific thresholds, pass/fail criteria, and reproducible evidence bundles tied to this bead ID.\n- Program/section verification gates must be able to consume this bead's outputs without manual interpretation.\n\nWhy This Improves User Outcomes:\n- \"[12] Risk control: hardening perf regression\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[12] Risk control: hardening perf regression\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"RISK: Performance regressions from hardening — security hardening (sandboxing, validation, encryption) introduces unacceptable latency or throughput loss.\nIMPACT: Users disable hardening to meet performance SLAs, negating security benefits; franken_node perceived as slower than Node.js.\nCOUNTERMEASURES:\n  (a) Profile-governed tuning: hardening features have tunable profiles (strict/balanced/permissive) with documented performance tradeoffs.\n  (b) p99 gates: CI enforces that p99 latency under 'balanced' profile does not exceed baseline by more than 15%.\n  (c) Continuous benchmarking: every PR runs performance benchmarks; regressions > 5% on key metrics block merge.\nVERIFICATION:\n  1. At least 3 hardening profiles exist (strict/balanced/permissive) with documented performance characteristics.\n  2. p99 latency gate: CI benchmark suite measures p99 latency; 'balanced' profile stays within 15% of unhardened baseline.\n  3. Throughput gate: requests/sec under 'balanced' profile is >= 85% of unhardened baseline.\n  4. Profile switching is runtime-configurable (no restart required).\nTEST SCENARIOS:\n  - Scenario A: Run benchmark suite under 'strict' profile; document overhead vs baseline (informational, no gate).\n  - Scenario B: Run benchmark under 'balanced' profile; verify p99 latency within 15% of baseline (gate).\n  - Scenario C: Introduce a hardening change that adds 20% latency; verify CI blocks the merge.\n  - Scenario D: Switch profiles at runtime under load; verify no request failures during switch.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:39:33.586113032Z","created_by":"ubuntu","updated_at":"2026-02-20T15:18:47.432469822Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-12","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-2w4u","depends_on_id":"bd-3jc1","type":"blocks","created_at":"2026-02-20T07:43:24.907429550Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-2wod","title":"[10.20] Integrate graph-aware quarantine and rollback orchestration with choke-point-first containment strategy.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.20 — Dependency Graph Immune System Execution Track (9N)\n\nWhy This Exists:\nDGIS topological immune system track for dependency contagion modeling, choke-point immunization, and graph-aware containment economics.\n\nTask Objective:\nIntegrate graph-aware quarantine and rollback orchestration with choke-point-first containment strategy.\n\nAcceptance Criteria:\n- Quarantine plans can target upstream choke points and downstream blast zones deterministically; rollback sequencing avoids reintroducing known high-risk paths.\n\nExpected Artifacts:\n- `docs/specs/dgis_quarantine_orchestration.md`, `tests/security/dgis_quarantine_containment.rs`, `artifacts/10.20/dgis_quarantine_drill_results.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_20/bd-2wod/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_20/bd-2wod/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.20] Integrate graph-aware quarantine and rollback orchestration with choke-point-first containment strategy.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.20] Integrate graph-aware quarantine and rollback orchestration with choke-point-first containment strategy.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.20] Integrate graph-aware quarantine and rollback orchestration with choke-point-first containment strategy.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.20] Integrate graph-aware quarantine and rollback orchestration with choke-point-first containment strategy.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.20] Integrate graph-aware quarantine and rollback orchestration with choke-point-first containment strategy.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- Quarantine plans can target upstream choke points and downstream blast zones deterministically; rollback sequencing avoids reintroducing known high-risk paths.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:37:07.078364648Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:22.086026626Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-20","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-2wod","depends_on_id":"bd-c97l","type":"blocks","created_at":"2026-02-20T07:43:20.931662467Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-2wsm","title":"[10.14] Implement epoch transition barrier protocol across core services with drain requirements.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.14 — FrankenSQLite Deep-Mined Expansion Execution Track (9J)\n\nWhy This Exists:\nFrankenSQLite deep-mined control integrity track: evidence ledgers, proofs, epochs, remote effects, markers/MMR, and deterministic fault labs.\n\nTask Objective:\nImplement epoch transition barrier protocol across core services with drain requirements.\n\nAcceptance Criteria:\n- Barrier requires participant drain acknowledgements; transition commits only on full barrier success; timeout path aborts safely with evidence.\n\nExpected Artifacts:\n- `docs/specs/epoch_barrier_protocol.md`, `tests/integration/epoch_transition_barrier.rs`, `artifacts/10.14/epoch_barrier_transcripts.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_14/bd-2wsm/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_14/bd-2wsm/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.14] Implement epoch transition barrier protocol across core services with drain requirements.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.14] Implement epoch transition barrier protocol across core services with drain requirements.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.14] Implement epoch transition barrier protocol across core services with drain requirements.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.14] Implement epoch transition barrier protocol across core services with drain requirements.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.14] Implement epoch transition barrier protocol across core services with drain requirements.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"Barrier requires participant drain acknowledgements; transition commits only on full barrier success; timeout path aborts safely with evidence.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:36:58.384523616Z","created_by":"ubuntu","updated_at":"2026-02-20T15:44:04.335673151Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-14","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-2wsm","depends_on_id":"bd-3cs3","type":"blocks","created_at":"2026-02-20T07:43:15.893524044Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-2wz","title":"[10.2] Define compatibility bands (`core`, `high-value`, `edge`, `unsafe`) with policy defaults.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.2 — Compatibility Core\n\nWhy This Exists:\nCompatibility core as strategic wedge: policy-visible behavior, divergence receipts, L1/L2 lockstep, and spec-first fixture governance.\n\nTask Objective:\nDefine compatibility bands (`core`, `high-value`, `edge`, `unsafe`) with policy defaults.\n\nAcceptance Criteria:\n- Implement with explicit success/failure invariants and deterministic behavior under normal, edge, and fault scenarios.\n- Ensure outcomes are verifiable via automated tests and reproducible artifact outputs.\n\nExpected Artifacts:\n- Section-owned design/spec artifact at `docs/specs/section_10_2/bd-2wz_contract.md`, capturing decision rationale, invariants, and interface boundaries.\n- Machine-readable verification artifact at `artifacts/section_10_2/bd-2wz/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_2/bd-2wz/verification_summary.md` linking implementation intent to measured outcomes.\n\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.2] Define compatibility bands (`core`, `high-value`, `edge`, `unsafe`) with policy defaults.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.2] Define compatibility bands (`core`, `high-value`, `edge`, `unsafe`) with policy defaults.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.2] Define compatibility bands (`core`, `high-value`, `edge`, `unsafe`) with policy defaults.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.2] Define compatibility bands (`core`, `high-value`, `edge`, `unsafe`) with policy defaults.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.2] Define compatibility bands (`core`, `high-value`, `edge`, `unsafe`) with policy defaults.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","status":"closed","priority":1,"issue_type":"task","assignee":"CrimsonCrane","created_at":"2026-02-20T07:36:43.836577935Z","created_by":"ubuntu","updated_at":"2026-02-20T09:31:55.289761153Z","closed_at":"2026-02-20T09:31:55.289738070Z","close_reason":"done","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-2","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-2wz","depends_on_id":"bd-1ow","type":"blocks","created_at":"2026-02-20T07:46:34.943916721Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2wz","depends_on_id":"bd-cda","type":"blocks","created_at":"2026-02-20T07:46:34.988209318Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-2x1e","title":"[12] Section-wide verification gate: comprehensive unit+e2e+logging","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 12\n\nTask Objective:\nCreate a hard section completion gate that verifies all implemented behavior in this section with comprehensive unit tests, integration/e2e scripts, and detailed structured logging evidence.\n\nAcceptance Criteria:\n- Section test matrix covers happy-path, edge-case, and adversarial/error-path scenarios for all section deliverables.\n- E2E scripts execute representative end-user workflows and policy/control-plane transitions for this section.\n- Structured logs include stable event/error codes, trace correlation IDs, and enough context for deterministic replay triage.\n- Verification report is deterministic and machine-readable for CI/release gating.\n\nExpected Artifacts:\n- Section-level test matrix and coverage summary artifact.\n- E2E script suite with pass/fail outputs and reproducible fixtures/seeds.\n- Structured log validation report and traceability bundle.\n- Gate verdict artifact consumable by release automation.\n\n- Machine-readable verification artifact at `artifacts/section_12/bd-2x1e/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_12/bd-2x1e/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests must validate contracts, invariants, and failure semantics.\n- E2E tests must validate cross-component behavior from user/operator entrypoints to persisted effects.\n- Logging must support root-cause analysis without hidden context requirements.\n\nTask-Specific Clarification:\n- For \"[12] Section-wide verification gate: comprehensive unit+e2e+logging\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[12] Section-wide verification gate: comprehensive unit+e2e+logging\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[12] Section-wide verification gate: comprehensive unit+e2e+logging\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[12] Section-wide verification gate: comprehensive unit+e2e+logging\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[12] Section-wide verification gate: comprehensive unit+e2e+logging\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"1. Section 12 verification gate runs all 12 risk-control check scripts and confirms 100% pass rate.\n2. Gate validates: (a) every risk-control bead has a verification script with self_test(), (b) every risk-control bead has unit tests, (c) all evidence artifacts are present under artifacts/section_12/.\n3. Risk register summary document exists listing all 12 risks with their current status (mitigated/open/monitoring).\n4. Each risk countermeasure has at least one passing test scenario demonstrating effectiveness.\n5. Gate produces section_12_verification_summary.md with per-risk pass/fail matrix.\n6. The gate itself has a unit test verifying correct aggregation of sub-check results.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:48:28.133441922Z","created_by":"ubuntu","updated_at":"2026-02-20T15:20:51.336229276Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-12","test-obligations","verification-gate"],"dependencies":[{"issue_id":"bd-2x1e","depends_on_id":"bd-13yn","type":"blocks","created_at":"2026-02-20T07:48:28.485340643Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2x1e","depends_on_id":"bd-1dpd","type":"blocks","created_at":"2026-02-20T08:24:24.032820826Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2x1e","depends_on_id":"bd-1n1t","type":"blocks","created_at":"2026-02-20T07:48:28.434689061Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2x1e","depends_on_id":"bd-1nab","type":"blocks","created_at":"2026-02-20T07:48:28.532715822Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2x1e","depends_on_id":"bd-1rff","type":"blocks","created_at":"2026-02-20T07:48:28.287856077Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2x1e","depends_on_id":"bd-2twu","type":"blocks","created_at":"2026-02-20T08:20:49.471016940Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2x1e","depends_on_id":"bd-2w4u","type":"blocks","created_at":"2026-02-20T07:48:28.582491612Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2x1e","depends_on_id":"bd-35m7","type":"blocks","created_at":"2026-02-20T07:48:28.231925393Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2x1e","depends_on_id":"bd-38ri","type":"blocks","created_at":"2026-02-20T07:48:28.732748133Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2x1e","depends_on_id":"bd-3jc1","type":"blocks","created_at":"2026-02-20T07:48:28.630944538Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2x1e","depends_on_id":"bd-kiqr","type":"blocks","created_at":"2026-02-20T07:48:28.684961477Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2x1e","depends_on_id":"bd-paui","type":"blocks","created_at":"2026-02-20T07:48:28.387315105Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2x1e","depends_on_id":"bd-s4cu","type":"blocks","created_at":"2026-02-20T07:48:28.782073965Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2x1e","depends_on_id":"bd-v4ps","type":"blocks","created_at":"2026-02-20T07:48:28.339293332Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-2xgs","title":"[10.21] Implement deterministic phenotype feature extraction per version from runtime evidence, manifests, and code metadata.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.21 — Behavioral Phenotype Evolution Tracker Execution Track (9O)\n\nWhy This Exists:\nBPET longitudinal phenotype intelligence track for pre-compromise trajectory detection and integration with DGIS/ATC/migration/economic policy.\n\nTask Objective:\nImplement deterministic phenotype feature extraction per version from runtime evidence, manifests, and code metadata.\n\nAcceptance Criteria:\n- Identical inputs produce identical phenotype vectors; extraction records feature provenance and uncertainty; missing fields are typed rather than silently dropped.\n\nExpected Artifacts:\n- `src/security/bpet/phenotype_extractor.rs`, `tests/conformance/bpet_feature_extraction.rs`, `artifacts/10.21/bpet_feature_samples.jsonl`.\n\n- Machine-readable verification artifact at `artifacts/section_10_21/bd-2xgs/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_21/bd-2xgs/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.21] Implement deterministic phenotype feature extraction per version from runtime evidence, manifests, and code metadata.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.21] Implement deterministic phenotype feature extraction per version from runtime evidence, manifests, and code metadata.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.21] Implement deterministic phenotype feature extraction per version from runtime evidence, manifests, and code metadata.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.21] Implement deterministic phenotype feature extraction per version from runtime evidence, manifests, and code metadata.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.21] Implement deterministic phenotype feature extraction per version from runtime evidence, manifests, and code metadata.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- Identical inputs produce identical phenotype vectors; extraction records feature provenance and uncertainty; missing fields are typed rather than silently dropped.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:37:07.774886105Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:22.314224759Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-21","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-2xgs","depends_on_id":"bd-39ga","type":"blocks","created_at":"2026-02-20T07:43:21.298439639Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-2xv8","title":"[10.14] Implement fail-closed validity window check rejecting future-epoch artifacts.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.14 — FrankenSQLite Deep-Mined Expansion Execution Track (9J)\n\nWhy This Exists:\nFrankenSQLite deep-mined control integrity track: evidence ledgers, proofs, epochs, remote effects, markers/MMR, and deterministic fault labs.\n\nTask Objective:\nImplement fail-closed validity window check rejecting future-epoch artifacts.\n\nAcceptance Criteria:\n- Future-epoch artifacts are rejected before use; validity window policy is explicit and test-covered; rejection telemetry includes epoch context.\n\nExpected Artifacts:\n- `tests/security/future_epoch_rejection.rs`, `docs/specs/validity_window_rules.md`, `artifacts/10.14/epoch_rejection_events.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_14/bd-2xv8/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_14/bd-2xv8/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.14] Implement fail-closed validity window check rejecting future-epoch artifacts.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.14] Implement fail-closed validity window check rejecting future-epoch artifacts.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.14] Implement fail-closed validity window check rejecting future-epoch artifacts.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.14] Implement fail-closed validity window check rejecting future-epoch artifacts.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.14] Implement fail-closed validity window check rejecting future-epoch artifacts.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"Future-epoch artifacts are rejected before use; validity window policy is explicit and test-covered; rejection telemetry includes epoch context.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:36:58.221485027Z","created_by":"ubuntu","updated_at":"2026-02-20T15:44:04.758998194Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-14","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-2xv8","depends_on_id":"bd-3hdv","type":"blocks","created_at":"2026-02-20T07:43:15.807378621Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-2yc","title":"[10.5] Implement operator copilot action recommendation API.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.5 — Security + Policy Product Surfaces\n\nWhy This Exists:\nSecurity and policy product surfaces: decision receipts, incident replay, expected-loss policying, and auditable degraded-mode behavior.\n\nTask Objective:\nImplement operator copilot action recommendation API.\n\nAcceptance Criteria:\n- Implement with explicit success/failure invariants and deterministic behavior under normal, edge, and fault scenarios.\n- Ensure outcomes are verifiable via automated tests and reproducible artifact outputs.\n\nExpected Artifacts:\n- Section-owned design/spec artifact at `docs/specs/section_10_5/bd-2yc_contract.md`, capturing decision rationale, invariants, and interface boundaries.\n- Machine-readable verification artifact at `artifacts/section_10_5/bd-2yc/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_5/bd-2yc/verification_summary.md` linking implementation intent to measured outcomes.\n\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.5] Implement operator copilot action recommendation API.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.5] Implement operator copilot action recommendation API.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.5] Implement operator copilot action recommendation API.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.5] Implement operator copilot action recommendation API.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.5] Implement operator copilot action recommendation API.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"1. Implement an ActionRecommendationEngine that, given current system state and an operator context, returns a ranked Vec<RecommendedAction> ordered by VOI (Value of Information) score descending.\n2. Each RecommendedAction contains: action_id (string), display_name (string), description (string), voi_score (f64, higher is better), expected_loss (ExpectedLossVector), uncertainty_band (ConfidenceInterval with lower_bound, upper_bound, confidence_level fields), preconditions (Vec<String> listing required gate passes), and estimated_duration (Duration).\n3. ExpectedLossVector is a struct with named fields for each loss dimension: availability_loss (f64), integrity_loss (f64), confidentiality_loss (f64), financial_loss (f64), and reputation_loss (f64). All values are non-negative; the engine must validate this invariant.\n4. VOI-based ranking must implement the formula: VOI = expected_gain_if_act - expected_gain_if_wait, using uncertainty bands from the loss vectors. Provide a pure function compute_voi(action: &ActionCandidate, state: &SystemState) -> f64 that is unit-testable in isolation.\n5. The API must return at most top_k recommendations (configurable, default 5) and must complete within 200 ms for up to 100 candidate actions.\n6. Each recommendation must include a human-readable rationale string explaining why this action ranks where it does, referencing the dominant loss dimension.\n7. Verification: scripts/check_copilot_api.py --json exercises the engine with a fixture system state containing at least 10 candidate actions, asserts correct VOI ordering and that uncertainty bands are non-degenerate (upper > lower); unit tests in tests/test_check_copilot_api.py cover ranking stability, edge cases (zero candidates, tied VOI), and the 200 ms latency bound; evidence in artifacts/section_10_5/bd-2yc/.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:36:46.383202614Z","created_by":"ubuntu","updated_at":"2026-02-20T15:15:47.199311383Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-5","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-2yc","depends_on_id":"bd-2fa","type":"blocks","created_at":"2026-02-20T07:43:22.930984657Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-2yc4","title":"[10.13] Implement crash-loop detector with automatic rollback and known-good pin fallback.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.13 — FCP Deep-Mined Expansion Execution Track (9I)\n\nWhy This Exists:\nDeep connector/provider contract track: lifecycle FSMs, conformance harnesses, fencing, sandboxing, revocation freshness, and protocol hardening.\n\nTask Objective:\nImplement crash-loop detector with automatic rollback and known-good pin fallback.\n\nAcceptance Criteria:\n- Crash-loop thresholds are configurable and enforced; rollback to known-good pin is automatic and auditable; rollback cannot bypass trust policy.\n\nExpected Artifacts:\n- `src/runtime/crash_loop_detector.rs`, `tests/integration/crash_loop_rollback.rs`, `artifacts/10.13/crash_loop_incident_bundle.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_13/bd-2yc4/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_13/bd-2yc4/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.13] Implement crash-loop detector with automatic rollback and known-good pin fallback.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.13] Implement crash-loop detector with automatic rollback and known-good pin fallback.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.13] Implement crash-loop detector with automatic rollback and known-good pin fallback.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.13] Implement crash-loop detector with automatic rollback and known-good pin fallback.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.13] Implement crash-loop detector with automatic rollback and known-good pin fallback.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","status":"closed","priority":1,"issue_type":"task","assignee":"CrimsonCrane","created_at":"2026-02-20T07:36:52.950806826Z","created_by":"ubuntu","updated_at":"2026-02-20T11:57:03.050784879Z","closed_at":"2026-02-20T11:57:03.050757678Z","close_reason":"done","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-13","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-2yc4","depends_on_id":"bd-1d7n","type":"blocks","created_at":"2026-02-20T07:43:13.054292565Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-2yh","title":"[10.4] Implement extension trust-card API and CLI surfaces.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.4 — Extension Ecosystem + Registry\n\nWhy This Exists:\nExtension ecosystem and registry trust foundation: signed artifacts, provenance, trust cards, revocation, and quarantine flows.\n\nTask Objective:\nImplement extension trust-card API and CLI surfaces.\n\nAcceptance Criteria:\n(See structured acceptance_criteria field for domain-specific criteria.)\n\nExpected Artifacts:\n- Section-owned design/spec artifact at `docs/specs/section_10_4/bd-2yh_contract.md`, capturing decision rationale, invariants, and interface boundaries.\n- Machine-readable verification artifact at `artifacts/section_10_4/bd-2yh/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_4/bd-2yh/verification_summary.md` linking implementation intent to measured outcomes.\n\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.4] Implement extension trust-card API and CLI surfaces.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.4] Implement extension trust-card API and CLI surfaces.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.4] Implement extension trust-card API and CLI surfaces.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.4] Implement extension trust-card API and CLI surfaces.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.4] Implement extension trust-card API and CLI surfaces.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"1. Trust card data model combines four dimensions: provenance summary (attestation chain status, source linkage), behavioral telemetry (resource usage histograms, capability exercise frequency, anomaly scores), revocation status (real-time from 10.13 revocation registry), and policy constraints (allowed capabilities, resource envelope limits, required certification level). 2. REST API endpoints: GET /api/v1/extensions/{id}/trust-card (full card), GET /api/v1/extensions/{id}/trust-card/delta (changes since timestamp), POST /api/v1/extensions/{id}/trust-card/evaluate (policy evaluation against a deployment context). 3. CLI commands: 'franken-node ext trust-card show <ext-id>' (human-readable summary), 'franken-node ext trust-card diff <ext-id> --since <timestamp>' (delta view), 'franken-node ext trust-card evaluate <ext-id> --context <policy-file>' (policy check). 4. Trust card deltas are decomposed into posterior components per 9C: each delta field includes a counterfactual_impact score indicating how much that specific change affects the overall trust assessment. 5. Trust card is cryptographically bound to the extension manifest version; manifest version bump requires trust card re-evaluation. 6. API responses include cache-control headers aligned with safety-tier freshness requirements from bd-12q. 7. Trust card rendering supports machine-readable (JSON) and human-readable (terminal-formatted, markdown) output formats. 8. Policy evaluation endpoint returns allow/deny with a structured explanation listing each constraint that passed or failed and the contributing trust card fields. 9. Trust card API requires authentication; write operations (manual trust overrides) require operator role with audit trail. 10. Rate limiting on trust card API: minimum 100 req/s for read operations per node.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:36:45.664911607Z","created_by":"ubuntu","updated_at":"2026-02-20T15:18:41.145487386Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-4","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-2yh","depends_on_id":"bd-12q","type":"blocks","created_at":"2026-02-20T07:43:22.506996992Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-2yhs","title":"[10.N] Implement duplicate-implementation CI gate","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.N — Execution Normalization Contract\n\nTask Objective:\nImplement a CI gate that detects duplicate implementation semantics across tracks and blocks merges when a non-canonical track attempts to re-implement canonical logic.\n\nAcceptance Criteria:\n- Duplicate-implementation detector identifies prohibited semantic redefinitions with deterministic findings.\n- CI gate blocks violating changes and emits actionable remediation guidance.\n- Waiver flow is explicit, scoped, and auditable when exceptions are necessary.\n\nExpected Artifacts:\n- CI workflow + detector configuration.\n- Duplicate-implementation findings report on representative fixtures.\n\nTesting & Logging Requirements:\n- Unit tests for rule matching and false-positive guardrails.\n- E2E tests covering pass/fail CI scenarios with fixture PRs.\n- Structured violation logs with stable rule IDs.\n\nTask-Specific Clarification:\n- For \"[10.N] Implement duplicate-implementation CI gate\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.N] Implement duplicate-implementation CI gate\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.N] Implement duplicate-implementation CI gate\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.N] Implement duplicate-implementation CI gate\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.N] Implement duplicate-implementation CI gate\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","status":"closed","priority":1,"issue_type":"task","assignee":"ubuntu","created_at":"2026-02-20T07:50:04.132828860Z","created_by":"ubuntu","updated_at":"2026-02-20T08:17:50.478847165Z","closed_at":"2026-02-20T08:17:50.478755294Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-N","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-2yhs","depends_on_id":"bd-zxk8","type":"blocks","created_at":"2026-02-20T07:50:04.258758834Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-2ymp","title":"[11] Contract field: rollout wedge","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 11\n\nTask Objective:\nRequire explicit rollout wedge description for staged enablement and safe rollback.\n\nExecution Requirements:\n- Make this requirement machine-verifiable and release-gated where applicable.\n- Keep behavior self-documenting so future contributors do not need to re-open the master plan.\n\nTesting & Logging Requirements:\n- Unit tests for rule/contract logic and error conditions.\n- Integration/E2E tests for workflow-level enforcement.\n- Structured logs with stable codes and trace IDs.\n- Reproducible artifacts that prove contract satisfaction.\n\nAcceptance Criteria:\n- Success and failure invariants for [11] Contract field: rollout wedge are explicitly quantified and machine-verifiable.\n- Determinism requirements for [11] Contract field: rollout wedge are validated across repeated runs and adversarial perturbations.\n\n\nExpected Artifacts:\n- Machine-readable verification artifact with explicit canonical path under artifacts/section_11/bd-2ymp/verification_evidence.json, suitable for CI/release gating.\n- Human-readable verification summary with explicit canonical path under artifacts/section_11/bd-2ymp/verification_summary.md, linking implementation intent to measured validation outcomes.\n\nTask-Specific Clarification:\n- The implementation must deliver the exact capability named in the title, with no scope dilution and no silent feature omission.\n- Validation artifacts must include capability-specific thresholds, pass/fail criteria, and reproducible evidence bundles tied to this bead ID.\n- Program/section verification gates must be able to consume this bead's outputs without manual interpretation.\n\nWhy This Improves User Outcomes:\n- \"[11] Contract field: rollout wedge\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[11] Contract field: rollout wedge\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"1. Every evidence contract specifies a rollout wedge: the incremental deployment strategy with explicit percentage/stage progression.\n2. Wedge must define: (a) stages (e.g., 1% -> 5% -> 25% -> 100%), (b) hold duration per stage (minimum observation window), (c) promotion criteria (metrics that must be green to advance), (d) automatic vs manual promotion decision.\n3. The rollout wedge must reference the fallback trigger — if trigger fires at any stage, rollout halts and rollback executes.\n4. CI rejects contracts missing rollout wedge or with fewer than 2 stages.\n5. Unit test: wedge with 3+ stages, hold durations, and promotion criteria passes; wedge with single stage or no hold duration fails.\n6. The wedge definition must be machine-parseable for integration with deployment automation.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:39:32.903551969Z","created_by":"ubuntu","updated_at":"2026-02-20T15:16:38.347605658Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-11","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-2ymp","depends_on_id":"bd-3v8f","type":"blocks","created_at":"2026-02-20T07:43:24.511155651Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-2yvw","title":"[10.19] Implement Sybil-resistant participation controls tied to attestation/staking/reputation evidence.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.19 — Adversarial Trust Commons Execution Track (9M)\n\nWhy This Exists:\nATC federated intelligence track for privacy-preserving cross-deployment threat learning, robust aggregation, and verifier-backed trust metrics.\n\nTask Objective:\nImplement Sybil-resistant participation controls tied to attestation/staking/reputation evidence.\n\nAcceptance Criteria:\n- Participation weighting rejects untrusted identity inflation; weighting policy is auditable and deterministic; attack simulations validate resistance properties.\n\nExpected Artifacts:\n- `src/federation/atc_participation_weighting.rs`, `tests/security/atc_sybil_resistance.rs`, `artifacts/10.19/atc_weighting_audit_report.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_19/bd-2yvw/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_19/bd-2yvw/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.19] Implement Sybil-resistant participation controls tied to attestation/staking/reputation evidence.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.19] Implement Sybil-resistant participation controls tied to attestation/staking/reputation evidence.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.19] Implement Sybil-resistant participation controls tied to attestation/staking/reputation evidence.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.19] Implement Sybil-resistant participation controls tied to attestation/staking/reputation evidence.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.19] Implement Sybil-resistant participation controls tied to attestation/staking/reputation evidence.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- Participation weighting rejects untrusted identity inflation; weighting policy is auditable and deterministic; attack simulations validate resistance properties.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:37:05.836638959Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:22.680624768Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-19","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-2yvw","depends_on_id":"bd-2ozr","type":"blocks","created_at":"2026-02-20T07:43:19.744440731Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-2zip","title":"[10.19] Add verifier APIs and proof artifacts for ATC computations and published ecosystem metrics.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.19 — Adversarial Trust Commons Execution Track (9M)\n\nWhy This Exists:\nATC federated intelligence track for privacy-preserving cross-deployment threat learning, robust aggregation, and verifier-backed trust metrics.\n\nTask Objective:\nAdd verifier APIs and proof artifacts for ATC computations and published ecosystem metrics.\n\nAcceptance Criteria:\n- External verifiers can validate federation computation integrity and metric provenance without private raw participant data; verifier outputs are deterministic.\n\nExpected Artifacts:\n- `docs/specs/atc_verifier_contract.md`, `tests/conformance/atc_verifier_apis.rs`, `artifacts/10.19/atc_verifier_report.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_19/bd-2zip/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_19/bd-2zip/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.19] Add verifier APIs and proof artifacts for ATC computations and published ecosystem metrics.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.19] Add verifier APIs and proof artifacts for ATC computations and published ecosystem metrics.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.19] Add verifier APIs and proof artifacts for ATC computations and published ecosystem metrics.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.19] Add verifier APIs and proof artifacts for ATC computations and published ecosystem metrics.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.19] Add verifier APIs and proof artifacts for ATC computations and published ecosystem metrics.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- External verifiers can validate federation computation integrity and metric provenance without private raw participant data; verifier outputs are deterministic.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:37:06.170376736Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:22.904204038Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-19","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-2zip","depends_on_id":"bd-1eot","type":"blocks","created_at":"2026-02-20T07:43:19.915249016Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-2zl","title":"Add transplant hash lockfile for tamper detection","description":"Hash each transplanted file and persist deterministic lockfile with provenance metadata.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-02-20T07:26:05.379629417Z","created_by":"ubuntu","updated_at":"2026-02-20T07:27:13.094134728Z","closed_at":"2026-02-20T07:27:13.094114280Z","close_reason":"Duplicate scope; superseded by bd-7rt currently in progress","source_repo":".","compaction_level":0,"original_size":0,"dependencies":[{"issue_id":"bd-2zl","depends_on_id":"bd-1qz","type":"blocks","created_at":"2026-02-20T07:26:09.609484458Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-2zo1","title":"[10.21] Integrate BPET with ATC for privacy-preserving federated temporal intelligence exchange.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.21 — Behavioral Phenotype Evolution Tracker Execution Track (9O)\n\nWhy This Exists:\nBPET longitudinal phenotype intelligence track for pre-compromise trajectory detection and integration with DGIS/ATC/migration/economic policy.\n\nTask Objective:\nIntegrate BPET with ATC for privacy-preserving federated temporal intelligence exchange.\n\nAcceptance Criteria:\n- BPET exports anonymized trajectory summaries and consumes federated temporal priors without raw longitudinal leakage; contracts are verifier-checkable and versioned.\n\nExpected Artifacts:\n- `src/federation/bpet_atc_bridge.rs`, `tests/integration/bpet_atc_temporal_interop.rs`, `artifacts/10.21/bpet_atc_exchange_report.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_21/bd-2zo1/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_21/bd-2zo1/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.21] Integrate BPET with ATC for privacy-preserving federated temporal intelligence exchange.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.21] Integrate BPET with ATC for privacy-preserving federated temporal intelligence exchange.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.21] Integrate BPET with ATC for privacy-preserving federated temporal intelligence exchange.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.21] Integrate BPET with ATC for privacy-preserving federated temporal intelligence exchange.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.21] Integrate BPET with ATC for privacy-preserving federated temporal intelligence exchange.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- BPET exports anonymized trajectory summaries and consumes federated temporal priors without raw longitudinal leakage; contracts are verifier-checkable and versioned.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:37:08.544511331Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:23.134660742Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-21","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-2zo1","depends_on_id":"bd-kwwg","type":"blocks","created_at":"2026-02-20T07:43:21.727719400Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-2zo1","depends_on_id":"bd-ukh7","type":"blocks","created_at":"2026-02-20T15:01:15.545264479Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-2zr4","title":"Epic: Frontier Programs Execution [10.12]","description":"- type: epic","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-20T07:47:58.072163029Z","updated_at":"2026-02-20T07:49:21.153388340Z","closed_at":"2026-02-20T07:49:21.153367661Z","close_reason":"Superseded by canonical detailed master-plan graph (bd-33v) with full 10.N-10.21 and 11-16 coverage, explicit dependencies, and per-section verification gates.","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-2zz","title":"[10.1] Add dependency-direction guard preventing local engine crate reintroduction.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.1 — Charter + Split Governance\n\nWhy This Exists:\nProgram charter and governance baseline: split contracts, reproducibility, and anti-regression rules for strategic integrity.\n\nTask Objective:\nAdd dependency-direction guard preventing local engine crate reintroduction.\n\nAcceptance Criteria:\n- Implement with explicit success/failure invariants and deterministic behavior under normal, edge, and fault scenarios.\n- Ensure outcomes are verifiable via automated tests and reproducible artifact outputs.\n\nExpected Artifacts:\n- Section-owned design/spec artifact at `docs/specs/section_10_1/bd-2zz_contract.md`, capturing decision rationale, invariants, and interface boundaries.\n- Machine-readable verification artifact at `artifacts/section_10_1/bd-2zz/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_1/bd-2zz/verification_summary.md` linking implementation intent to measured outcomes.\n\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.1] Add dependency-direction guard preventing local engine crate reintroduction.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.1] Add dependency-direction guard preventing local engine crate reintroduction.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.1] Add dependency-direction guard preventing local engine crate reintroduction.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.1] Add dependency-direction guard preventing local engine crate reintroduction.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.1] Add dependency-direction guard preventing local engine crate reintroduction.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","status":"closed","priority":1,"issue_type":"task","assignee":"CrimsonCrane","created_at":"2026-02-20T07:36:43.448201283Z","created_by":"ubuntu","updated_at":"2026-02-20T09:08:43.244168356Z","closed_at":"2026-02-20T09:08:43.244143199Z","close_reason":"Dependency-direction guard implemented. 4 checks (workspace members, package names, dependency direction, crates dir) all PASS. 9 unit tests all pass. Spec, guard script, and verification artifacts created.","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-1","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-2zz","depends_on_id":"bd-1j2","type":"blocks","created_at":"2026-02-20T07:43:10.617269548Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-3014","title":"[10.15] Integrate canonical remote named-computation registry (from `10.14`) for control-plane distributed actions.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.15 — Asupersync-First Integration Execution Track (8.4-8.6)\n\nWhy This Exists:\nAsupersync-first control-plane migration track enforcing Cx-first, region ownership, cancellation correctness, and protocol-grade verification gates.\n\nTask Objective:\nIntegrate canonical remote named-computation registry (from `10.14`) for control-plane distributed actions.\n\nAcceptance Criteria:\n- Control-plane paths use the same canonical registry semantics as `10.14`; unknown names fail closed with stable error class; no divergent registry behavior is introduced.\n\nExpected Artifacts:\n- `docs/integration/control_remote_registry_adoption.md`, `tests/conformance/named_remote_computations.rs`, `artifacts/10.15/remote_registry_adoption_report.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_15/bd-3014/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_15/bd-3014/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.15] Integrate canonical remote named-computation registry (from `10.14`) for control-plane distributed actions.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.15] Integrate canonical remote named-computation registry (from `10.14`) for control-plane distributed actions.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.15] Integrate canonical remote named-computation registry (from `10.14`) for control-plane distributed actions.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.15] Integrate canonical remote named-computation registry (from `10.14`) for control-plane distributed actions.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.15] Integrate canonical remote named-computation registry (from `10.14`) for control-plane distributed actions.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- Control-plane paths use the same canonical registry semantics as `10.14`; unknown names fail closed with stable error class; no divergent registry behavior is introduced.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:37:00.138232005Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:52.382430970Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-15","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-3014","depends_on_id":"bd-ac83","type":"blocks","created_at":"2026-02-20T14:59:47.584707824Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3014","depends_on_id":"bd-cuut","type":"blocks","created_at":"2026-02-20T07:43:16.797309617Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-31tg","title":"[15] Pillar: partner and lighthouse programs","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 15\n\nTask Objective:\nImplement partner/lighthouse adoption programs proving category-shift outcomes.\n\nExecution Requirements:\n- Make this requirement machine-verifiable and release-gated where applicable.\n- Keep behavior self-documenting so future contributors do not need to re-open the master plan.\n\nTesting & Logging Requirements:\n- Unit tests for rule/contract logic and error conditions.\n- Integration/E2E tests for workflow-level enforcement.\n- Structured logs with stable codes and trace IDs.\n- Reproducible artifacts that prove contract satisfaction.\n\nAcceptance Criteria:\n- Success and failure invariants for [15] Pillar: partner and lighthouse programs are explicitly quantified and machine-verifiable.\n- Determinism requirements for [15] Pillar: partner and lighthouse programs are validated across repeated runs and adversarial perturbations.\n\n\nExpected Artifacts:\n- Machine-readable verification artifact with explicit canonical path under artifacts/section_15/bd-31tg/verification_evidence.json, suitable for CI/release gating.\n- Human-readable verification summary with explicit canonical path under artifacts/section_15/bd-31tg/verification_summary.md, linking implementation intent to measured validation outcomes.\n\nTask-Specific Clarification:\n- The implementation must deliver the exact capability named in the title, with no scope dilution and no silent feature omission.\n- Validation artifacts must include capability-specific thresholds, pass/fail criteria, and reproducible evidence bundles tied to this bead ID.\n- Program/section verification gates must be able to consume this bead's outputs without manual interpretation.\n\nWhy This Improves User Outcomes:\n- \"[15] Pillar: partner and lighthouse programs\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[15] Pillar: partner and lighthouse programs\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"1. Partner program defined with tiers: (a) Lighthouse (early adopters, deep integration, direct support channel), (b) Partner (validated migration, co-marketing), (c) Community (self-service, public resources).\n2. Lighthouse program has >= 3 active participants running franken_node in production or staging.\n3. Each lighthouse partner has: (a) documented use case, (b) migration case study (published or in-progress), (c) feedback channel with response SLA <= 48 hours, (d) quarterly review cadence.\n4. Partner program has clear entry criteria: minimum project size, commitment to provide feedback, willingness to publish anonymized results.\n5. Benefits documented: priority bug fixes, early access to features, co-marketing opportunities, benchmark co-design input.\n6. Program produces >= 2 published case studies within first 6 months.\n7. Partner satisfaction tracked via quarterly survey; target NPS >= 30.\n8. Evidence: partner_program_status.json with partner count by tier, case study list, and satisfaction scores.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:39:36.527116261Z","created_by":"ubuntu","updated_at":"2026-02-20T15:26:52.601799077Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-15","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-31tg","depends_on_id":"bd-1961","type":"blocks","created_at":"2026-02-20T07:43:26.385358774Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-329y","title":"Epic: Supply Chain Trust Infrastructure [10.13c]","description":"- type: epic","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-20T07:47:58.072163029Z","updated_at":"2026-02-20T07:49:21.170406598Z","closed_at":"2026-02-20T07:49:21.170388003Z","close_reason":"Superseded by canonical detailed master-plan graph (bd-33v) with full 10.N-10.21 and 11-16 coverage, explicit dependencies, and per-section verification gates.","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-32e","title":"Implement init command with profile bootstrapping","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md (Bootstrap bridge for Sections 10.0 and 10.1 operator onboarding)\nSection: BOOTSTRAP (CLI onboarding bridge)\n\nTask Objective:\nImplement `franken-node init` with profile bootstrapping so first-time operators can create deterministic, policy-aligned project configuration safely.\n\nIn Scope:\n- `init` command flow to generate baseline config/profile files.\n- Deterministic profile template selection and safe overwrite semantics.\n- Clear onboarding diagnostics for missing prerequisites and invalid target states.\n\nAcceptance Criteria:\n- `init` produces deterministic output files for equivalent inputs/options.\n- Existing configuration handling is explicit (confirm/abort/backup semantics) and non-destructive by default.\n- Generated profile artifacts are immediately consumable by downstream run/doctor flows.\n\nExpected Artifacts:\n- Init flow contract note with option matrix and file-output expectations.\n- Generated fixture snapshots for representative init scenarios.\n- Machine-readable init summary artifact for CI assertions.\n\n- Machine-readable verification artifact at `artifacts/section_bootstrap/bd-32e/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_bootstrap/bd-32e/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for template rendering, path handling, and overwrite-policy logic.\n- Integration tests validating end-to-end init behavior in clean and pre-existing directories.\n- E2E tests simulating first-run operator onboarding workflows.\n- Structured logs containing init phase events, file actions, and policy decisions with trace IDs.\n\nTask-Specific Clarification:\n- For \"Implement init command with profile bootstrapping\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"Implement init command with profile bootstrapping\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"Implement init command with profile bootstrapping\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"Implement init command with profile bootstrapping\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"Implement init command with profile bootstrapping\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:29:25.296726699Z","created_by":"ubuntu","updated_at":"2026-02-20T08:46:43.431587277Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["cli","config"],"dependencies":[{"issue_id":"bd-32e","depends_on_id":"bd-3rp","type":"blocks","created_at":"2026-02-20T07:29:39.546835453Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-32e","depends_on_id":"bd-3vk","type":"blocks","created_at":"2026-02-20T08:04:16.558688526Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-32e","depends_on_id":"bd-n9r","type":"blocks","created_at":"2026-02-20T07:29:39.613041834Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-32p","title":"[PLAN 10.18] Verifiable Execution Fabric Execution Track (9L)","description":"Section: 10.18 — Verifiable Execution Fabric Execution Track (9L)\n\nStrategic Context:\nVEF track for proof-carrying runtime compliance: receipt chains, commitment checkpoints, proof generation/verification, and claim gating.\n\nExecution Requirements:\n- Preserve all scoped capabilities from the canonical plan.\n- Keep contracts self-contained so future contributors can execute without reopening the master plan.\n- Require explicit testing strategy (unit + integration/e2e) and structured logging/telemetry for every child bead.\n- Require artifact-backed validation for performance, security, and correctness claims.\n\nDependency Semantics:\n- This epic is blocked by its child implementation beads.\n- Cross-epic dependencies encode strategic sequencing and canonical ownership boundaries.\n\n## Success Criteria\n- All child beads for this section are completed with acceptance artifacts attached and no unresolved blockers.\n- Section-level verification gate for comprehensive unit tests, integration/e2e workflows, and detailed structured logging evidence is green.\n- Scope-to-plan traceability is explicit, with no feature loss versus the canonical plan section.\n\n## Optimization Notes\n- User-Outcome Lens: \"[PLAN 10.18] Verifiable Execution Fabric Execution Track (9L)\" must improve operator confidence, safety posture, and deterministic recovery behavior under both normal and adversarial conditions.\n- Cross-Section Coordination: child beads must encode integration assumptions explicitly to avoid local optimizations that degrade system-wide correctness.\n- Verification Non-Negotiable: completion requires reproducible unit/integration/E2E evidence and structured logs suitable for independent replay.\n- Scope Protection: any simplification must preserve canonical-plan feature intent and be justified with explicit tradeoff documentation.","status":"open","priority":2,"issue_type":"epic","created_at":"2026-02-20T07:36:41.705187214Z","created_by":"ubuntu","updated_at":"2026-02-20T08:16:45.857951351Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-18"],"dependencies":[{"issue_id":"bd-32p","depends_on_id":"bd-16fq","type":"blocks","created_at":"2026-02-20T07:37:04.213682609Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-32p","depends_on_id":"bd-1o4v","type":"blocks","created_at":"2026-02-20T07:37:04.663389460Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-32p","depends_on_id":"bd-1u8m","type":"blocks","created_at":"2026-02-20T07:37:04.581684810Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-32p","depends_on_id":"bd-1wz","type":"blocks","created_at":"2026-02-20T07:37:11.557148743Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-32p","depends_on_id":"bd-28u0","type":"blocks","created_at":"2026-02-20T07:37:04.496043147Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-32p","depends_on_id":"bd-2hjg","type":"blocks","created_at":"2026-02-20T07:48:18.733878534Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-32p","depends_on_id":"bd-3g4k","type":"blocks","created_at":"2026-02-20T07:37:04.413295084Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-32p","depends_on_id":"bd-3go4","type":"blocks","created_at":"2026-02-20T07:37:04.992192425Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-32p","depends_on_id":"bd-3lzk","type":"blocks","created_at":"2026-02-20T07:37:05.238696122Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-32p","depends_on_id":"bd-3pds","type":"blocks","created_at":"2026-02-20T07:37:04.909485368Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-32p","depends_on_id":"bd-3ptu","type":"blocks","created_at":"2026-02-20T07:37:05.073989607Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-32p","depends_on_id":"bd-3qo","type":"blocks","created_at":"2026-02-20T07:37:11.516760954Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-32p","depends_on_id":"bd-4jh9","type":"blocks","created_at":"2026-02-20T07:37:04.827567831Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-32p","depends_on_id":"bd-5rh","type":"blocks","created_at":"2026-02-20T07:37:11.475902728Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-32p","depends_on_id":"bd-8qlj","type":"blocks","created_at":"2026-02-20T07:37:04.745789915Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-32p","depends_on_id":"bd-cda","type":"blocks","created_at":"2026-02-20T07:37:09.741081780Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-32p","depends_on_id":"bd-p73r","type":"blocks","created_at":"2026-02-20T07:37:04.327089580Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-32p","depends_on_id":"bd-ufk5","type":"blocks","created_at":"2026-02-20T07:37:05.155969188Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-32v","title":"[10.2] Implement minimized divergence fixture generation.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.2 — Compatibility Core\n\nWhy This Exists:\nCompatibility core as strategic wedge: policy-visible behavior, divergence receipts, L1/L2 lockstep, and spec-first fixture governance.\n\nTask Objective:\nImplement minimized divergence fixture generation.\n\nAcceptance Criteria:\n- Implement with explicit success/failure invariants and deterministic behavior under normal, edge, and fault scenarios.\n- Ensure outcomes are verifiable via automated tests and reproducible artifact outputs.\n\nExpected Artifacts:\n- Section-owned design/spec artifact at `docs/specs/section_10_2/bd-32v_contract.md`, capturing decision rationale, invariants, and interface boundaries.\n- Machine-readable verification artifact at `artifacts/section_10_2/bd-32v/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_2/bd-32v/verification_summary.md` linking implementation intent to measured outcomes.\n\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.2] Implement minimized divergence fixture generation.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.2] Implement minimized divergence fixture generation.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.2] Implement minimized divergence fixture generation.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.2] Implement minimized divergence fixture generation.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.2] Implement minimized divergence fixture generation.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","status":"closed","priority":1,"issue_type":"task","assignee":"CrimsonCrane","created_at":"2026-02-20T07:36:44.318888576Z","created_by":"ubuntu","updated_at":"2026-02-20T09:44:43.563344477Z","closed_at":"2026-02-20T09:44:43.563317597Z","close_reason":"done","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-2","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-32v","depends_on_id":"bd-2vi","type":"blocks","created_at":"2026-02-20T07:43:20.304057300Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-33b","title":"[10.5] Implement expected-loss action scoring with explicit loss matrices.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.5 — Security + Policy Product Surfaces\n\nWhy This Exists:\nSecurity and policy product surfaces: decision receipts, incident replay, expected-loss policying, and auditable degraded-mode behavior.\n\nTask Objective:\nImplement expected-loss action scoring with explicit loss matrices.\n\nAcceptance Criteria:\n- Implement with explicit success/failure invariants and deterministic behavior under normal, edge, and fault scenarios.\n- Ensure outcomes are verifiable via automated tests and reproducible artifact outputs.\n\nExpected Artifacts:\n- Section-owned design/spec artifact at `docs/specs/section_10_5/bd-33b_contract.md`, capturing decision rationale, invariants, and interface boundaries.\n- Machine-readable verification artifact at `artifacts/section_10_5/bd-33b/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_5/bd-33b/verification_summary.md` linking implementation intent to measured outcomes.\n\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.5] Implement expected-loss action scoring with explicit loss matrices.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.5] Implement expected-loss action scoring with explicit loss matrices.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.5] Implement expected-loss action scoring with explicit loss matrices.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.5] Implement expected-loss action scoring with explicit loss matrices.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.5] Implement expected-loss action scoring with explicit loss matrices.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"1. Define a LossMatrix struct as a named 2D matrix where rows are possible actions (including 'do nothing') and columns are possible outcome states; each cell holds an f64 loss value. The matrix must be explicitly constructed (no implicit defaults) so that every action-outcome pair has a deliberate loss assignment.\n2. Implement score_action(action: &str, loss_matrix: &LossMatrix, state_probabilities: &[f64]) -> ExpectedLossScore where ExpectedLossScore contains: action (string), expected_loss (f64, computed as dot product of the action's row with state_probabilities), dominant_outcome (the outcome state contributing the most to expected loss), and breakdown (Vec<(String, f64)> mapping each outcome to its weighted loss contribution).\n3. State probabilities must sum to 1.0 (within epsilon 1e-9); return Err if they do not.\n4. Provide a compare_actions(actions: &[&str], matrix: &LossMatrix, probs: &[f64]) -> Vec<ExpectedLossScore> that returns all actions sorted by expected_loss ascending (lowest loss = best action).\n5. Support sensitivity analysis: vary each state probability by +/- delta (configurable, default 0.05) and report which actions change rank, returned as a Vec<SensitivityRecord> with fields: parameter_name, delta, original_rank, perturbed_rank.\n6. Loss matrices must be serializable to/from JSON and must include a schema_version field for forward compatibility.\n7. Verification: scripts/check_loss_scoring.py --json constructs a 4-action x 5-outcome loss matrix from plan Section 9A.8 scenarios, computes scores, and asserts the lowest-loss action matches the analytically known answer; unit tests in tests/test_check_loss_scoring.py cover degenerate matrices (single action, single outcome), probability validation, and sensitivity analysis; evidence in artifacts/section_10_5/bd-33b/.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:36:46.464089771Z","created_by":"ubuntu","updated_at":"2026-02-20T15:15:57.825895657Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-5","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-33b","depends_on_id":"bd-2yc","type":"blocks","created_at":"2026-02-20T07:43:22.975658220Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-33kj","title":"[10.15] Define claim-language policy tying trust/replay claims to asupersync-backed invariant evidence.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.15 — Asupersync-First Integration Execution Track (8.4-8.6)\n\nWhy This Exists:\nAsupersync-first control-plane migration track enforcing Cx-first, region ownership, cancellation correctness, and protocol-grade verification gates.\n\nTask Objective:\nDefine claim-language policy tying trust/replay claims to asupersync-backed invariant evidence.\n\nAcceptance Criteria:\n- Public claim templates enforce evidence references; unverifiable claim text is blocked by documentation gate.\n\nExpected Artifacts:\n- `docs/policy/claim_language_asupersync_requirements.md`, `tests/conformance/claim_language_gate.rs`, `artifacts/10.15/claim_language_gate_report.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_15/bd-33kj/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_15/bd-33kj/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.15] Define claim-language policy tying trust/replay claims to asupersync-backed invariant evidence.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.15] Define claim-language policy tying trust/replay claims to asupersync-backed invariant evidence.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.15] Define claim-language policy tying trust/replay claims to asupersync-backed invariant evidence.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.15] Define claim-language policy tying trust/replay claims to asupersync-backed invariant evidence.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.15] Define claim-language policy tying trust/replay claims to asupersync-backed invariant evidence.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- Public claim templates enforce evidence references; unverifiable claim text is blocked by documentation gate.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:37:01.445380165Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:48.768622104Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-15","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-33kj","depends_on_id":"bd-1xwz","type":"blocks","created_at":"2026-02-20T07:43:17.478388446Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-33u2","title":"[16] Output contract: widely used verifier/benchmark releases","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 16\n\nTask Objective:\nDeliver widely used open verifier or benchmark tool releases.\n\nExecution Requirements:\n- Make this requirement machine-verifiable and release-gated where applicable.\n- Keep behavior self-documenting so future contributors do not need to re-open the master plan.\n\nTesting & Logging Requirements:\n- Unit tests for rule/contract logic and error conditions.\n- Integration/E2E tests for workflow-level enforcement.\n- Structured logs with stable codes and trace IDs.\n- Reproducible artifacts that prove contract satisfaction.\n\nAcceptance Criteria:\n- Success and failure invariants for [16] Output contract: widely used verifier/benchmark releases are explicitly quantified and machine-verifiable.\n- Determinism requirements for [16] Output contract: widely used verifier/benchmark releases are validated across repeated runs and adversarial perturbations.\n\n\nExpected Artifacts:\n- Machine-readable verification artifact with explicit canonical path under artifacts/section_16/bd-33u2/verification_evidence.json, suitable for CI/release gating.\n- Human-readable verification summary with explicit canonical path under artifacts/section_16/bd-33u2/verification_summary.md, linking implementation intent to measured validation outcomes.\n\nTask-Specific Clarification:\n- The implementation must deliver the exact capability named in the title, with no scope dilution and no silent feature omission.\n- Validation artifacts must include capability-specific thresholds, pass/fail criteria, and reproducible evidence bundles tied to this bead ID.\n- Program/section verification gates must be able to consume this bead's outputs without manual interpretation.\n\nWhy This Improves User Outcomes:\n- \"[16] Output contract: widely used verifier/benchmark releases\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[16] Output contract: widely used verifier/benchmark releases\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"1. Verifier toolkit has >= 100 downloads/installs across all distribution channels (npm, cargo, Docker) within 6 months of release.\n2. Benchmark suite has >= 50 external runs (tracked via telemetry opt-in or usage reports) within 6 months of release.\n3. At least 3 external projects or organizations have adopted the verifier or benchmark tools (documented via case studies, blog posts, or direct feedback).\n4. Tools are maintained with: (a) bug fixes within 14 days of report, (b) compatibility updates within 30 days of major dependency changes, (c) documentation updates with each release.\n5. External contribution: at least 2 external pull requests or issues from non-team members (indicating community engagement).\n6. Tools are listed/indexed in relevant package registries and discovery platforms.\n7. User feedback is collected and acted upon: at least 1 feature or improvement driven by external user feedback per quarter.\n8. Evidence: tool_adoption_metrics.json with download counts, known users, external contributions, and feedback-driven improvements.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:39:37.389351490Z","created_by":"ubuntu","updated_at":"2026-02-20T15:29:25.575123721Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-16","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-33u2","depends_on_id":"bd-e5cz","type":"blocks","created_at":"2026-02-20T07:43:26.856869179Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-33v","title":"[PLAN] franken_node master execution graph (full 10.x)","description":"Master execution graph for PLAN_TO_CREATE_FRANKEN_NODE.md.\n\nPurpose:\n- Preserve full feature scope and ambition of the canonical plan.\n- Organize all 10.x execution tasks into self-contained, dependency-aware beads.\n- Ensure every capability has explicit implementation, testing, observability, and evidence obligations.\n\nDelivery doctrine:\n- No oversimplification and no silent feature loss.\n- Unit tests + integration/e2e + detailed structured logging are mandatory for every implementation family.\n- Claims must be verifier-backed with reproducible artifacts.\n\n## Success Criteria\n- All child beads for this section are completed with acceptance artifacts attached and no unresolved blockers.\n- Section-level verification gate for comprehensive unit tests, integration/e2e workflows, and detailed structured logging evidence is green.\n- Scope-to-plan traceability is explicit, with no feature loss versus the canonical plan section.\n\n## Optimization Notes\n- User-Outcome Lens: \"[PLAN] franken_node master execution graph (full 10.x)\" must improve operator confidence, safety posture, and deterministic recovery behavior under both normal and adversarial conditions.\n- Cross-Section Coordination: child beads must encode integration assumptions explicitly to avoid local optimizations that degrade system-wide correctness.\n- Verification Non-Negotiable: completion requires reproducible unit/integration/E2E evidence and structured logs suitable for independent replay.\n- Scope Protection: any simplification must preserve canonical-plan feature intent and be justified with explicit tradeoff documentation.","status":"open","priority":0,"issue_type":"epic","created_at":"2026-02-20T07:35:22.836795409Z","created_by":"ubuntu","updated_at":"2026-02-20T08:16:38.889381813Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["execution-graph","master","plan"],"dependencies":[{"issue_id":"bd-33v","depends_on_id":"bd-10zx","type":"blocks","created_at":"2026-02-20T07:56:11.666208988Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-33v","depends_on_id":"bd-1hf","type":"blocks","created_at":"2026-02-20T07:36:41.067060798Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-33v","depends_on_id":"bd-1ow","type":"blocks","created_at":"2026-02-20T07:36:40.333074686Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-33v","depends_on_id":"bd-1ps","type":"blocks","created_at":"2026-02-20T07:36:42.199819366Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-33v","depends_on_id":"bd-1ta","type":"blocks","created_at":"2026-02-20T07:36:41.320945114Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-33v","depends_on_id":"bd-1u9","type":"blocks","created_at":"2026-02-20T07:36:40.740950950Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-33v","depends_on_id":"bd-1wz","type":"blocks","created_at":"2026-02-20T07:36:41.660104369Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-33v","depends_on_id":"bd-1xg","type":"blocks","created_at":"2026-02-20T07:36:40.581261539Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-33v","depends_on_id":"bd-20a","type":"blocks","created_at":"2026-02-20T07:36:40.660962957Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-33v","depends_on_id":"bd-20z","type":"blocks","created_at":"2026-02-20T07:36:41.148065604Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-33v","depends_on_id":"bd-229","type":"blocks","created_at":"2026-02-20T07:36:40.499974958Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-33v","depends_on_id":"bd-26k","type":"blocks","created_at":"2026-02-20T07:36:40.986774751Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-33v","depends_on_id":"bd-2g8","type":"blocks","created_at":"2026-02-20T07:36:42.128788568Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-33v","depends_on_id":"bd-2j9w","type":"blocks","created_at":"2026-02-20T08:08:10.938497041Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-33v","depends_on_id":"bd-2ke","type":"blocks","created_at":"2026-02-20T07:36:42.293903525Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-33v","depends_on_id":"bd-32p","type":"blocks","created_at":"2026-02-20T07:36:41.740397650Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-33v","depends_on_id":"bd-37i","type":"blocks","created_at":"2026-02-20T07:36:41.985807540Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-33v","depends_on_id":"bd-39a","type":"blocks","created_at":"2026-02-20T07:36:41.823195546Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-33v","depends_on_id":"bd-3fo","type":"blocks","created_at":"2026-02-20T07:36:40.251374936Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-33v","depends_on_id":"bd-3il","type":"blocks","created_at":"2026-02-20T07:36:40.417428981Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-33v","depends_on_id":"bd-3qo","type":"blocks","created_at":"2026-02-20T07:36:41.489494708Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-33v","depends_on_id":"bd-3rc","type":"blocks","created_at":"2026-02-20T07:36:40.824379771Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-33v","depends_on_id":"bd-4ou","type":"blocks","created_at":"2026-02-20T07:36:42.057208007Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-33v","depends_on_id":"bd-5rh","type":"blocks","created_at":"2026-02-20T07:36:41.405409033Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-33v","depends_on_id":"bd-c4f","type":"blocks","created_at":"2026-02-20T07:36:40.905079449Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-33v","depends_on_id":"bd-cda","type":"blocks","created_at":"2026-02-20T07:36:40.169253630Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-33v","depends_on_id":"bd-go4","type":"blocks","created_at":"2026-02-20T07:36:41.232660257Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-33v","depends_on_id":"bd-n71","type":"blocks","created_at":"2026-02-20T07:36:41.576712857Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-33v","depends_on_id":"bd-r6i","type":"blocks","created_at":"2026-02-20T07:36:42.440815415Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-33v","depends_on_id":"bd-t8m","type":"blocks","created_at":"2026-02-20T07:36:42.367219649Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-33v","depends_on_id":"bd-ybe","type":"blocks","created_at":"2026-02-20T07:36:41.904704050Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-33x","title":"[10.3] Build migration risk scoring model with explainable features.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.3 — Migration System\n\nWhy This Exists:\nMigration autopilot pipeline from audit to rollout, designed to collapse migration friction with deterministic confidence and replayability.\n\nTask Objective:\nBuild migration risk scoring model with explainable features.\n\nAcceptance Criteria:\n- Implement with explicit success/failure invariants and deterministic behavior under normal, edge, and fault scenarios.\n- Ensure outcomes are verifiable via automated tests and reproducible artifact outputs.\n\nExpected Artifacts:\n- Section-owned design/spec artifact at `docs/specs/section_10_3/bd-33x_contract.md`, capturing decision rationale, invariants, and interface boundaries.\n- Machine-readable verification artifact at `artifacts/section_10_3/bd-33x/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_3/bd-33x/verification_summary.md` linking implementation intent to measured outcomes.\n\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.3] Build migration risk scoring model with explainable features.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.3] Build migration risk scoring model with explainable features.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.3] Build migration risk scoring model with explainable features.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.3] Build migration risk scoring model with explainable features.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.3] Build migration risk scoring model with explainable features.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","status":"closed","priority":1,"issue_type":"task","assignee":"CrimsonCrane","created_at":"2026-02-20T07:36:44.877076923Z","created_by":"ubuntu","updated_at":"2026-02-20T10:10:42.465633073Z","closed_at":"2026-02-20T10:10:42.465607315Z","close_reason":"done","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-3","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-33x","depends_on_id":"bd-2a0","type":"blocks","created_at":"2026-02-20T07:43:22.054752439Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-3429","title":"Epic: Evidence Ledger System [10.14a]","description":"- type: epic","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-20T07:47:58.072163029Z","updated_at":"2026-02-20T07:49:21.198491417Z","closed_at":"2026-02-20T07:49:21.198474215Z","close_reason":"Superseded by canonical detailed master-plan graph (bd-33v) with full 10.N-10.21 and 11-16 coverage, explicit dependencies, and per-section verification gates.","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-34d5","title":"[13] Concrete target gate: friction-minimized install-to-first-safe-production pathway for representative setups","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 13 — Program Success Criteria\n\nWhy This Exists:\nSection 13 defines 6 qualitative success criteria and 6 concrete quantitative target gates. This bead covers the quantitative target requiring a friction-minimized install-to-first-safe-production pathway that works for representative project setups.\n\nTask Objective:\nDefine and validate a friction-minimized install-to-first-safe-production pathway for representative project setups. The onboarding experience from curl install through franken-node init through franken-node run --policy balanced must complete with minimal manual steps, clear feedback, and no silent failures for common Node/Bun project archetypes.\n\nAcceptance Criteria:\n- Define representative setups cohort (minimum 5 project archetypes).\n- Measure end-to-end install-to-production time for each archetype.\n- Gate requires completion under defined time budget.\n- Zero manual file edits required for balanced-profile onboarding on standard archetypes.\n- All steps emit structured progress/error telemetry.\n- Gate failure blocks release.\n\nExpected Artifacts:\n- tests/e2e/install_to_production_pathway.sh\n- docs/success_criteria/friction_minimized_pathway.md\n- artifacts/13/friction_pathway_report.json\n\n- Machine-readable verification artifact at `artifacts/section_13/bd-34d5/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_13/bd-34d5/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- E2E test scripts exercising full install-init-audit-run pipeline per archetype.\n- Structured logging with stable codes and trace correlation IDs.\n- Deterministic failure reproduction via captured telemetry bundles.\n\nTask-Specific Clarification:\n- For \"[13] Concrete target gate: friction-minimized install-to-first-safe-production pathway for representative setups\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[13] Concrete target gate: friction-minimized install-to-first-safe-production pathway for representative setups\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[13] Concrete target gate: friction-minimized install-to-first-safe-production pathway for representative setups\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[13] Concrete target gate: friction-minimized install-to-first-safe-production pathway for representative setups\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[13] Concrete target gate: friction-minimized install-to-first-safe-production pathway for representative setups\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"1. A representative set of >= 5 setup configurations is defined: (a) macOS + npm, (b) Linux + npm, (c) Windows + npm, (d) Docker container, (e) CI environment (GitHub Actions).\n2. For each setup, the install-to-first-safe-production pathway is documented step-by-step.\n3. Total time from 'npm install franken-node' to first production-safe process running is <= 10 minutes for each setup.\n4. 'Production-safe' means: hardening profile active, trust system initialized, compatibility checks passing, health endpoint responding.\n5. No step in the pathway requires manual configuration beyond environment variables or a single config file.\n6. Pathway is tested in CI for at least 3 of the 5 setups (macOS, Linux, Docker).\n7. Failure modes are documented: if any step fails, the user gets an actionable error message with resolution steps.\n8. Evidence artifact: onboarding_timing_report.json with per-setup step timings and total elapsed time.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T08:01:30.881812092Z","created_by":"ubuntu","updated_at":"2026-02-20T16:08:17.871753515Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-13","self-contained","test-obligations"]}
{"id":"bd-34ll","title":"[10.16] Define `frankentui` integration contract for all relevant console/TUI surfaces.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.16 — Adjacent Substrate Integration Execution Track (8.7)\n\nWhy This Exists:\nAdjacent substrate integration track to enforce deep composition with frankentui, frankensqlite, sqlmodel_rust, and fastapi_rust.\n\nTask Objective:\nDefine `frankentui` integration contract for all relevant console/TUI surfaces.\n\nAcceptance Criteria:\n- Contract specifies component boundaries, styling/token strategy, and rendering/event-loop integration expectations.\n\nExpected Artifacts:\n- `docs/specs/frankentui_integration_contract.md`, `artifacts/10.16/frankentui_contract_checklist.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_16/bd-34ll/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_16/bd-34ll/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.16] Define `frankentui` integration contract for all relevant console/TUI surfaces.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.16] Define `frankentui` integration contract for all relevant console/TUI surfaces.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.16] Define `frankentui` integration contract for all relevant console/TUI surfaces.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.16] Define `frankentui` integration contract for all relevant console/TUI surfaces.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.16] Define `frankentui` integration contract for all relevant console/TUI surfaces.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- Contract specifies component boundaries, styling/token strategy, and rendering/event-loop integration expectations.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:37:01.689778611Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:48.094303517Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-16","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-34ll","depends_on_id":"bd-28ld","type":"blocks","created_at":"2026-02-20T07:43:17.619107822Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-351r","title":"[10.20] Add ATC interoperability for topology indicators and federated cascade priors.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.20 — Dependency Graph Immune System Execution Track (9N)\n\nWhy This Exists:\nDGIS topological immune system track for dependency contagion modeling, choke-point immunization, and graph-aware containment economics.\n\nTask Objective:\nAdd ATC interoperability for topology indicators and federated cascade priors.\n\nAcceptance Criteria:\n- DGIS emits privacy-preserving topology indicators to ATC and consumes federated priors without raw dependency disclosure; ingestion/output contracts are versioned and verifier-checkable.\n\nExpected Artifacts:\n- `src/federation/dgis_atc_bridge.rs`, `tests/integration/dgis_atc_interop.rs`, `artifacts/10.20/dgis_atc_exchange_report.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_20/bd-351r/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_20/bd-351r/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.20] Add ATC interoperability for topology indicators and federated cascade priors.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.20] Add ATC interoperability for topology indicators and federated cascade priors.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.20] Add ATC interoperability for topology indicators and federated cascade priors.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.20] Add ATC interoperability for topology indicators and federated cascade priors.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.20] Add ATC interoperability for topology indicators and federated cascade priors.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- DGIS emits privacy-preserving topology indicators to ATC and consumes federated priors without raw dependency disclosure; ingestion/output contracts are versioned and verifier-checkable.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:37:07.161493170Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:23.367014023Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-20","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-351r","depends_on_id":"bd-2wod","type":"blocks","created_at":"2026-02-20T07:43:20.975596172Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-351r","depends_on_id":"bd-3aqy","type":"blocks","created_at":"2026-02-20T15:01:15.095236299Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-35by","title":"[10.13] Build mandatory serialization/object-id/signature/revocation/source-diversity interop suites.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.13 — FCP Deep-Mined Expansion Execution Track (9I)\n\nWhy This Exists:\nDeep connector/provider contract track: lifecycle FSMs, conformance harnesses, fencing, sandboxing, revocation freshness, and protocol hardening.\n\nTask Objective:\nBuild mandatory serialization/object-id/signature/revocation/source-diversity interop suites.\n\nAcceptance Criteria:\n- Interop suite covers all mandatory classes and passes across independent implementations; failures include minimal reproducer fixtures.\n\nExpected Artifacts:\n- `tests/interop/*.rs`, `fixtures/interop/*.json`, `artifacts/10.13/interop_results_matrix.csv`.\n\n- Machine-readable verification artifact at `artifacts/section_10_13/bd-35by/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_13/bd-35by/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.13] Build mandatory serialization/object-id/signature/revocation/source-diversity interop suites.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.13] Build mandatory serialization/object-id/signature/revocation/source-diversity interop suites.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.13] Build mandatory serialization/object-id/signature/revocation/source-diversity interop suites.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.13] Build mandatory serialization/object-id/signature/revocation/source-diversity interop suites.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.13] Build mandatory serialization/object-id/signature/revocation/source-diversity interop suites.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","status":"closed","priority":1,"issue_type":"task","assignee":"CrimsonCrane","created_at":"2026-02-20T07:36:54.899465986Z","created_by":"ubuntu","updated_at":"2026-02-20T13:32:26.457742510Z","closed_at":"2026-02-20T13:32:26.457715409Z","close_reason":"done","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-13","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-35by","depends_on_id":"bd-ck2h","type":"blocks","created_at":"2026-02-20T07:43:14.062691295Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-35l5","title":"[10.16] Add performance overhead guardrails for adjacent substrate integrations.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.16 — Adjacent Substrate Integration Execution Track (8.7)\n\nWhy This Exists:\nAdjacent substrate integration track to enforce deep composition with frankentui, frankensqlite, sqlmodel_rust, and fastapi_rust.\n\nTask Objective:\nAdd performance overhead guardrails for adjacent substrate integrations.\n\nAcceptance Criteria:\n- Integration overhead budgets are defined and enforced; regressions fail perf gate with before/after evidence.\n\nExpected Artifacts:\n- `tests/perf/adjacent_substrate_overhead_gate.rs`, `artifacts/10.16/adjacent_substrate_overhead_report.csv`.\n\n- Machine-readable verification artifact at `artifacts/section_10_16/bd-35l5/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_16/bd-35l5/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.16] Add performance overhead guardrails for adjacent substrate integrations.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.16] Add performance overhead guardrails for adjacent substrate integrations.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.16] Add performance overhead guardrails for adjacent substrate integrations.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.16] Add performance overhead guardrails for adjacent substrate integrations.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.16] Add performance overhead guardrails for adjacent substrate integrations.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- Integration overhead budgets are defined and enforced; regressions fail perf gate with before/after evidence.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:37:02.764016223Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:45.168787828Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-16","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-35l5","depends_on_id":"bd-159q","type":"blocks","created_at":"2026-02-20T07:43:18.170268051Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-35m7","title":"[12] Risk control: trajectory-gaming camouflage","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 12\n\nTask Objective:\nImplement mimicry corpus tests, motif randomization stress tests, and hybrid signal fusion safeguards.\n\nExecution Requirements:\n- Make this requirement machine-verifiable and release-gated where applicable.\n- Keep behavior self-documenting so future contributors do not need to re-open the master plan.\n\nTesting & Logging Requirements:\n- Unit tests for rule/contract logic and error conditions.\n- Integration/E2E tests for workflow-level enforcement.\n- Structured logs with stable codes and trace IDs.\n- Reproducible artifacts that prove contract satisfaction.\n\nAcceptance Criteria:\n- Success and failure invariants for [12] Risk control: trajectory-gaming camouflage are explicitly quantified and machine-verifiable.\n- Determinism requirements for [12] Risk control: trajectory-gaming camouflage are validated across repeated runs and adversarial perturbations.\n\n\nExpected Artifacts:\n- Machine-readable verification artifact with explicit canonical path under artifacts/section_12/bd-35m7/verification_evidence.json, suitable for CI/release gating.\n- Human-readable verification summary with explicit canonical path under artifacts/section_12/bd-35m7/verification_summary.md, linking implementation intent to measured validation outcomes.\n\nTask-Specific Clarification:\n- The implementation must deliver the exact capability named in the title, with no scope dilution and no silent feature omission.\n- Validation artifacts must include capability-specific thresholds, pass/fail criteria, and reproducible evidence bundles tied to this bead ID.\n- Program/section verification gates must be able to consume this bead's outputs without manual interpretation.\n\nWhy This Improves User Outcomes:\n- \"[12] Risk control: trajectory-gaming camouflage\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[12] Risk control: trajectory-gaming camouflage\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"RISK: Trajectory-gaming camouflage — malicious actors craft behavioral trajectories that mimic legitimate patterns to evade detection.\nIMPACT: Malicious extensions pass trust checks by mimicking benign behavior patterns, undermining the entire behavioral trust system.\nCOUNTERMEASURES:\n  (a) Adversarial mimicry corpus: maintain a dataset of known mimicry patterns; trust models are trained to detect them.\n  (b) Motif randomization: detection features include randomized behavioral motifs that are hard for attackers to predict and replicate.\n  (c) Hybrid signal fusion: trust decisions fuse behavioral signals with non-behavioral signals (provenance, code analysis, reputation) so gaming one channel is insufficient.\nVERIFICATION:\n  1. Adversarial mimicry corpus contains >= 100 mimicry patterns, updated at least quarterly.\n  2. Trust model detects >= 90% of known mimicry patterns in the corpus (measured by recall).\n  3. Hybrid fusion: a node gaming behavioral signals but failing provenance or code-analysis checks is still correctly flagged.\n  4. Motif randomization: two consecutive evaluations of the same trajectory use different feature subsets (verified by feature-set logging).\nTEST SCENARIOS:\n  - Scenario A: Submit a trajectory matching a known mimicry pattern; verify trust system flags it with >= 90% confidence.\n  - Scenario B: Submit a trajectory that games behavioral signals perfectly but has suspicious provenance; verify hybrid fusion catches it.\n  - Scenario C: Run the same trajectory through detection twice; verify different randomized motifs are used each time.\n  - Scenario D: Add a new mimicry pattern to the corpus; retrain model; verify detection rate remains >= 90%.\n  - Scenario E: Adaptive adversary: evolve mimicry across 10 rounds; verify detection rate stays >= 80% even against evolving attacks.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:39:34.218605784Z","created_by":"ubuntu","updated_at":"2026-02-20T15:20:40.084263243Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-12","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-35m7","depends_on_id":"bd-1rff","type":"blocks","created_at":"2026-02-20T07:43:25.215361876Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-35q1","title":"[10.13] Implement threshold signature verification for connector publication artifacts.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.13 — FCP Deep-Mined Expansion Execution Track (9I)\n\nWhy This Exists:\nDeep connector/provider contract track: lifecycle FSMs, conformance harnesses, fencing, sandboxing, revocation freshness, and protocol hardening.\n\nTask Objective:\nImplement threshold signature verification for connector publication artifacts.\n\nAcceptance Criteria:\n- Publication requires configured threshold quorum; partial signature sets are rejected; verification failures produce stable failure reasons.\n\nExpected Artifacts:\n- `docs/specs/threshold_signatures.md`, `tests/security/threshold_signature_verification.rs`, `artifacts/10.13/threshold_signature_vectors.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_13/bd-35q1/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_13/bd-35q1/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.13] Implement threshold signature verification for connector publication artifacts.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.13] Implement threshold signature verification for connector publication artifacts.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.13] Implement threshold signature verification for connector publication artifacts.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.13] Implement threshold signature verification for connector publication artifacts.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.13] Implement threshold signature verification for connector publication artifacts.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","status":"closed","priority":1,"issue_type":"task","assignee":"CrimsonCrane","created_at":"2026-02-20T07:36:52.618388717Z","created_by":"ubuntu","updated_at":"2026-02-20T11:39:28.801633636Z","closed_at":"2026-02-20T11:39:28.801608279Z","close_reason":"done","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-13","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-35q1","depends_on_id":"bd-3n58","type":"blocks","created_at":"2026-02-20T07:43:12.887467919Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-364","title":"[10.10] Implement key-role separation for control-plane signing/encryption/issuance.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.10 — FCP-Inspired Hardening + Interop Integration Track\n\nWhy This Exists:\nFCP-inspired hardening/interop contract for IDs, serialization, control-channel auth, revocation freshness, and publication gating.\n\nTask Objective:\nImplement key-role separation for control-plane signing/encryption/issuance.\n\nAcceptance Criteria:\n- Implement with explicit success/failure invariants and deterministic behavior under normal, edge, and fault scenarios.\n- Ensure outcomes are verifiable via automated tests and reproducible artifact outputs.\n\nExpected Artifacts:\n- Section-owned design/spec artifact at `docs/specs/section_10_10/bd-364_contract.md`, capturing decision rationale, invariants, and interface boundaries.\n- Machine-readable verification artifact at `artifacts/section_10_10/bd-364/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_10/bd-364/verification_summary.md` linking implementation intent to measured outcomes.\n\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.10] Implement key-role separation for control-plane signing/encryption/issuance.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.10] Implement key-role separation for control-plane signing/encryption/issuance.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.10] Implement key-role separation for control-plane signing/encryption/issuance.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.10] Implement key-role separation for control-plane signing/encryption/issuance.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.10] Implement key-role separation for control-plane signing/encryption/issuance.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"1. Define a KeyRole enum with exactly four variants: SIGNING (Ed25519/ECDSA for authentication), ENCRYPTION (X25519/AES for confidentiality), ISSUANCE (dedicated key for minting tokens/certificates), ATTESTATION (dedicated key for operator attestation signatures). Each variant has a fixed 2-byte role tag.\n2. Define a KeyRoleBinding struct containing: (a) key_id (TrustObjectId with KEY domain), (b) role (KeyRole), (c) public_key_bytes, (d) bound_at (UTC timestamp), (e) bound_by (TrustObjectId of the authority that approved the binding), (f) max_validity_seconds (u64).\n3. Enforce role exclusivity: a single key_id MUST NOT be bound to more than one role. Attempting to bind the same key_id to a second role returns RoleSeparationViolation error.\n4. Implement a KeyRoleRegistry that stores active bindings and supports: (a) bind(key_id, role, public_key, authority) -> Result, (b) lookup(key_id) -> Option<KeyRoleBinding>, (c) lookup_by_role(role) -> Vec<KeyRoleBinding>, (d) revoke(key_id, authority) that moves the binding to a revoked set.\n5. Enforce that cryptographic operations check role before use: a SIGNING key MUST NOT be used for encryption operations, and vice versa. Provide a guard function verify_role(key_id, expected_role) -> Result.\n6. Implement key rotation: bind a new key_id to the same role while revoking the old one, atomically (both operations succeed or neither does).\n7. Emit structured log events for: bind, revoke, rotation, and role-violation-attempt, each with trace correlation ID and severity.\n8. Unit tests: (a) bind each role type, (b) role exclusivity violation, (c) lookup by ID and by role, (d) revoke and re-lookup returns None, (e) rotation atomicity (verify old key is revoked and new key is bound after rotation), (f) verify_role guard pass/fail.\n9. Verification: scripts/check_key_role_separation.py --json, artifacts at artifacts/section_10_10/bd-364/.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:36:49.167021491Z","created_by":"ubuntu","updated_at":"2026-02-20T15:37:23.243761939Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-10","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-364","depends_on_id":"bd-1r2","type":"blocks","created_at":"2026-02-20T07:43:11.045991599Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-36wa","title":"[11] Contract field: compatibility and threat evidence","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 11\n\nTask Objective:\nRequire compatibility and threat evidence payloads for each major subsystem proposal.\n\nExecution Requirements:\n- Make this requirement machine-verifiable and release-gated where applicable.\n- Keep behavior self-documenting so future contributors do not need to re-open the master plan.\n\nTesting & Logging Requirements:\n- Unit tests for rule/contract logic and error conditions.\n- Integration/E2E tests for workflow-level enforcement.\n- Structured logs with stable codes and trace IDs.\n- Reproducible artifacts that prove contract satisfaction.\n\nAcceptance Criteria:\n- Success and failure invariants for [11] Contract field: compatibility and threat evidence are explicitly quantified and machine-verifiable.\n- Determinism requirements for [11] Contract field: compatibility and threat evidence are validated across repeated runs and adversarial perturbations.\n\n\nExpected Artifacts:\n- Machine-readable verification artifact with explicit canonical path under artifacts/section_11/bd-36wa/verification_evidence.json, suitable for CI/release gating.\n- Human-readable verification summary with explicit canonical path under artifacts/section_11/bd-36wa/verification_summary.md, linking implementation intent to measured validation outcomes.\n\nTask-Specific Clarification:\n- The implementation must deliver the exact capability named in the title, with no scope dilution and no silent feature omission.\n- Validation artifacts must include capability-specific thresholds, pass/fail criteria, and reproducible evidence bundles tied to this bead ID.\n- Program/section verification gates must be able to consume this bead's outputs without manual interpretation.\n\nWhy This Improves User Outcomes:\n- \"[11] Contract field: compatibility and threat evidence\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[11] Contract field: compatibility and threat evidence\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"1. Every evidence contract includes a compatibility-and-threat-evidence section with: (a) list of compatibility test suites exercised and pass/fail counts, (b) threat model delta — new attack surfaces introduced or closed, (c) regression risk assessment citing specific API families.\n2. Compatibility evidence must reference actual test run artifact paths (verification_evidence.json) not just claims.\n3. Threat evidence must enumerate at least: privilege escalation, data exfiltration, and denial-of-service vectors with mitigations.\n4. CI validation rejects contracts where compatibility evidence references zero test suites or threat section is empty.\n5. Unit test: contract with full evidence passes; contract missing threat model or test references fails.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:39:32.564264525Z","created_by":"ubuntu","updated_at":"2026-02-20T15:15:53.889613653Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-11","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-36wa","depends_on_id":"bd-3se1","type":"blocks","created_at":"2026-02-20T07:43:24.327391786Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-37i","title":"[PLAN 10.21] Behavioral Phenotype Evolution Tracker Execution Track (9O)","description":"Section: 10.21 — Behavioral Phenotype Evolution Tracker Execution Track (9O)\n\nStrategic Context:\nBPET longitudinal phenotype intelligence track for pre-compromise trajectory detection and integration with DGIS/ATC/migration/economic policy.\n\nExecution Requirements:\n- Preserve all scoped capabilities from the canonical plan.\n- Keep contracts self-contained so future contributors can execute without reopening the master plan.\n- Require explicit testing strategy (unit + integration/e2e) and structured logging/telemetry for every child bead.\n- Require artifact-backed validation for performance, security, and correctness claims.\n\nDependency Semantics:\n- This epic is blocked by its child implementation beads.\n- Cross-epic dependencies encode strategic sequencing and canonical ownership boundaries.\n\n## Success Criteria\n- All child beads for this section are completed with acceptance artifacts attached and no unresolved blockers.\n- Section-level verification gate for comprehensive unit tests, integration/e2e workflows, and detailed structured logging evidence is green.\n- Scope-to-plan traceability is explicit, with no feature loss versus the canonical plan section.\n\n## Optimization Notes\n- User-Outcome Lens: \"[PLAN 10.21] Behavioral Phenotype Evolution Tracker Execution Track (9O)\" must improve operator confidence, safety posture, and deterministic recovery behavior under both normal and adversarial conditions.\n- Cross-Section Coordination: child beads must encode integration assumptions explicitly to avoid local optimizations that degrade system-wide correctness.\n- Verification Non-Negotiable: completion requires reproducible unit/integration/E2E evidence and structured logs suitable for independent replay.\n- Scope Protection: any simplification must preserve canonical-plan feature intent and be justified with explicit tradeoff documentation.","status":"open","priority":2,"issue_type":"epic","created_at":"2026-02-20T07:36:41.949926696Z","created_by":"ubuntu","updated_at":"2026-02-20T08:16:44.191036940Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-21"],"dependencies":[{"issue_id":"bd-37i","depends_on_id":"bd-1b9x","type":"blocks","created_at":"2026-02-20T07:37:08.245687528Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-37i","depends_on_id":"bd-1ga5","type":"blocks","created_at":"2026-02-20T07:37:07.983305173Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-37i","depends_on_id":"bd-1jpc","type":"blocks","created_at":"2026-02-20T07:37:08.330982325Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-37i","depends_on_id":"bd-1naf","type":"blocks","created_at":"2026-02-20T07:37:08.916309542Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-37i","depends_on_id":"bd-1wz","type":"blocks","created_at":"2026-02-20T07:37:11.751750073Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-37i","depends_on_id":"bd-232t","type":"blocks","created_at":"2026-02-20T07:37:08.414777809Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-37i","depends_on_id":"bd-2ao3","type":"blocks","created_at":"2026-02-20T07:37:08.072795746Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-37i","depends_on_id":"bd-2lll","type":"blocks","created_at":"2026-02-20T07:37:08.158043515Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-37i","depends_on_id":"bd-2xgs","type":"blocks","created_at":"2026-02-20T07:37:07.812739454Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-37i","depends_on_id":"bd-2zo1","type":"blocks","created_at":"2026-02-20T07:37:08.582873568Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-37i","depends_on_id":"bd-39a","type":"blocks","created_at":"2026-02-20T07:37:11.790632409Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-37i","depends_on_id":"bd-39ga","type":"blocks","created_at":"2026-02-20T07:37:07.728748295Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-37i","depends_on_id":"bd-3cbi","type":"blocks","created_at":"2026-02-20T07:37:08.748979390Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-37i","depends_on_id":"bd-3rai","type":"blocks","created_at":"2026-02-20T07:37:07.894941800Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-37i","depends_on_id":"bd-3v9l","type":"blocks","created_at":"2026-02-20T07:37:08.999649869Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-37i","depends_on_id":"bd-aoq6","type":"blocks","created_at":"2026-02-20T07:37:08.664956492Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-37i","depends_on_id":"bd-cda","type":"blocks","created_at":"2026-02-20T07:37:09.855676864Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-37i","depends_on_id":"bd-kwwg","type":"blocks","created_at":"2026-02-20T07:37:08.498553707Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-37i","depends_on_id":"bd-ybe","type":"blocks","created_at":"2026-02-20T07:37:11.829668260Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-37i","depends_on_id":"bd-ye4m","type":"blocks","created_at":"2026-02-20T07:37:08.831448764Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-37i","depends_on_id":"bd-zm5b","type":"blocks","created_at":"2026-02-20T07:48:22.644441684Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-383z","title":"[10.17] Build counterfactual incident lab and mitigation synthesis workflow.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.17 — Radical Expansion Execution Track (9K)\n\nWhy This Exists:\nRadical expansion track for proof-carrying speculation, Bayesian adversary control, time-travel replay, ZK attestations, and claim compiler systems.\n\nTask Objective:\nBuild counterfactual incident lab and mitigation synthesis workflow.\n\nAcceptance Criteria:\n- Real incident traces can be replayed and compared against synthesized mitigations with expected-loss deltas; promoted mitigations require signed rollout and rollback contracts.\n\nExpected Artifacts:\n- `docs/specs/counterfactual_incident_lab.md`, `tests/lab/counterfactual_mitigation_eval.rs`, `src/ops/mitigation_synthesis.rs`, `artifacts/10.17/counterfactual_eval_report.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_17/bd-383z/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_17/bd-383z/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.17] Build counterfactual incident lab and mitigation synthesis workflow.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.17] Build counterfactual incident lab and mitigation synthesis workflow.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.17] Build counterfactual incident lab and mitigation synthesis workflow.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.17] Build counterfactual incident lab and mitigation synthesis workflow.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.17] Build counterfactual incident lab and mitigation synthesis workflow.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- Real incident traces can be replayed and compared against synthesized mitigations with expected-loss deltas; promoted mitigations require signed rollout and rollback contracts.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:37:04.007645237Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:58.139525461Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-17","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-383z","depends_on_id":"bd-2o8b","type":"blocks","created_at":"2026-02-20T07:43:18.825966610Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-38l","title":"[10.2] Implement divergence ledger with signed rationale entries.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.2 — Compatibility Core\n\nWhy This Exists:\nCompatibility core as strategic wedge: policy-visible behavior, divergence receipts, L1/L2 lockstep, and spec-first fixture governance.\n\nTask Objective:\nImplement divergence ledger with signed rationale entries.\n\nAcceptance Criteria:\n- Implement with explicit success/failure invariants and deterministic behavior under normal, edge, and fault scenarios.\n- Ensure outcomes are verifiable via automated tests and reproducible artifact outputs.\n\nExpected Artifacts:\n- Section-owned design/spec artifact at `docs/specs/section_10_2/bd-38l_contract.md`, capturing decision rationale, invariants, and interface boundaries.\n- Machine-readable verification artifact at `artifacts/section_10_2/bd-38l/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_2/bd-38l/verification_summary.md` linking implementation intent to measured outcomes.\n\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.2] Implement divergence ledger with signed rationale entries.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.2] Implement divergence ledger with signed rationale entries.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.2] Implement divergence ledger with signed rationale entries.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.2] Implement divergence ledger with signed rationale entries.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.2] Implement divergence ledger with signed rationale entries.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","status":"closed","priority":1,"issue_type":"task","assignee":"CrimsonCrane","created_at":"2026-02-20T07:36:43.998141036Z","created_by":"ubuntu","updated_at":"2026-02-20T09:36:09.242921857Z","closed_at":"2026-02-20T09:36:09.242897141Z","close_reason":"done","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-2","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-38l","depends_on_id":"bd-2qf","type":"blocks","created_at":"2026-02-20T07:43:20.137245348Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-38m","title":"[10.6] Optimize lockstep harness throughput and memory profile.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.6 — Performance + Packaging\n\nWhy This Exists:\nPerformance and packaging reliability gates: benchmark rigor, latency targets, release integrity, and deterministic rollback bundles.\n\nTask Objective:\nOptimize lockstep harness throughput and memory profile.\n\nAcceptance Criteria:\n- Implement with explicit success/failure invariants and deterministic behavior under normal, edge, and fault scenarios.\n- Ensure outcomes are verifiable via automated tests and reproducible artifact outputs.\n\nExpected Artifacts:\n- Section-owned design/spec artifact at `docs/specs/section_10_6/bd-38m_contract.md`, capturing decision rationale, invariants, and interface boundaries.\n- Machine-readable verification artifact at `artifacts/section_10_6/bd-38m/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_6/bd-38m/verification_summary.md` linking implementation intent to measured outcomes.\n\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.6] Optimize lockstep harness throughput and memory profile.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.6] Optimize lockstep harness throughput and memory profile.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.6] Optimize lockstep harness throughput and memory profile.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.6] Optimize lockstep harness throughput and memory profile.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.6] Optimize lockstep harness throughput and memory profile.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"1. Lockstep harness throughput improves by at least 2x over current baseline, measured in operations/second on the standard compatibility test corpus.\n2. Peak memory usage of the lockstep harness does not exceed a defined ceiling (documented in spec) during full-corpus runs.\n3. Memory profile artifact (heap snapshot or allocation trace) is generated and persisted under artifacts/.\n4. Before/after table comparing throughput and memory is produced per Section 7 doctrine.\n5. Optimization does not regress correctness: all existing lockstep oracle tests continue to pass.\n6. Compatibility proof: output diff between pre- and post-optimization runs on the golden corpus is empty.\n7. Profile-driven optimization loop per Section 9D: at least one profiling pass informs each optimization, with evidence recorded.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:36:46.858398443Z","created_by":"ubuntu","updated_at":"2026-02-20T15:15:25.168639560Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-6","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-38m","depends_on_id":"bd-3lh","type":"blocks","created_at":"2026-02-20T07:43:23.207401546Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-38ri","title":"[12] Risk control: scope explosion","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 12\n\nTask Objective:\nImplement capability gates and artifact-gated delivery controls to contain scope explosion.\n\nExecution Requirements:\n- Make this requirement machine-verifiable and release-gated where applicable.\n- Keep behavior self-documenting so future contributors do not need to re-open the master plan.\n\nTesting & Logging Requirements:\n- Unit tests for rule/contract logic and error conditions.\n- Integration/E2E tests for workflow-level enforcement.\n- Structured logs with stable codes and trace IDs.\n- Reproducible artifacts that prove contract satisfaction.\n\nAcceptance Criteria:\n- Success and failure invariants for [12] Risk control: scope explosion are explicitly quantified and machine-verifiable.\n- Determinism requirements for [12] Risk control: scope explosion are validated across repeated runs and adversarial perturbations.\n\n\nExpected Artifacts:\n- Machine-readable verification artifact with explicit canonical path under artifacts/section_12/bd-38ri/verification_evidence.json, suitable for CI/release gating.\n- Human-readable verification summary with explicit canonical path under artifacts/section_12/bd-38ri/verification_summary.md, linking implementation intent to measured validation outcomes.\n\nTask-Specific Clarification:\n- The implementation must deliver the exact capability named in the title, with no scope dilution and no silent feature omission.\n- Validation artifacts must include capability-specific thresholds, pass/fail criteria, and reproducible evidence bundles tied to this bead ID.\n- Program/section verification gates must be able to consume this bead's outputs without manual interpretation.\n\nWhy This Improves User Outcomes:\n- \"[12] Risk control: scope explosion\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[12] Risk control: scope explosion\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"RISK: Scope explosion — unbounded feature creep expanding the project surface area beyond what can be verified and maintained.\nIMPACT: Missed deadlines, incomplete verification coverage, accumulated technical debt, inability to close sections.\nCOUNTERMEASURES:\n  (a) Capability gates: each of the 16 capabilities has a defined boundary; new work must map to an existing capability or go through formal scope-change review.\n  (b) Artifact-gated delivery: no capability is considered complete without its full bead delivery pattern (spec, impl, verification, evidence, tests).\n  (c) Bead budget: each section has a maximum bead count; exceeding it requires explicit justification and approval.\nVERIFICATION:\n  1. Every bead maps to exactly one of the 16 capabilities via its section tag.\n  2. A CI check validates that new beads include a capability mapping and do not exceed section bead budget.\n  3. Scope-change proposals are tracked as dedicated beads with explicit justification.\n  4. Quarterly audit: actual bead count vs planned bead count per section, with variance report.\nTEST SCENARIOS:\n  - Scenario A: Attempt to create a bead outside any capability boundary; verify it is flagged for review.\n  - Scenario B: Section reaches bead budget; verify new bead creation requires explicit override.\n  - Scenario C: Verify all existing beads have valid capability mappings (no orphans).","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:39:33.329588509Z","created_by":"ubuntu","updated_at":"2026-02-20T15:17:59.112604233Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-12","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-38ri","depends_on_id":"bd-s4cu","type":"blocks","created_at":"2026-02-20T07:43:24.776786171Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-38yt","title":"[10.20] Add performance/scale budgets and release claim gates for DGIS-derived security assertions.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.20 — Dependency Graph Immune System Execution Track (9N)\n\nWhy This Exists:\nDGIS topological immune system track for dependency contagion modeling, choke-point immunization, and graph-aware containment economics.\n\nTask Objective:\nAdd performance/scale budgets and release claim gates for DGIS-derived security assertions.\n\nAcceptance Criteria:\n- DGIS computation overhead and decision latency remain within p95/p99 budgets at target graph scales; release pipeline blocks topology-security claims lacking signed DGIS evidence artifacts.\n\nExpected Artifacts:\n- `tests/perf/dgis_budget_gate.rs`, `.github/workflows/dgis-claim-gate.yml`, `artifacts/10.20/dgis_release_gate_report.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_20/bd-38yt/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_20/bd-38yt/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.20] Add performance/scale budgets and release claim gates for DGIS-derived security assertions.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.20] Add performance/scale budgets and release claim gates for DGIS-derived security assertions.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.20] Add performance/scale budgets and release claim gates for DGIS-derived security assertions.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.20] Add performance/scale budgets and release claim gates for DGIS-derived security assertions.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.20] Add performance/scale budgets and release claim gates for DGIS-derived security assertions.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- DGIS computation overhead and decision latency remain within p95/p99 budgets at target graph scales; release pipeline blocks topology-security claims lacking signed DGIS evidence artifacts.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:37:07.609887205Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:23.600014981Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-20","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-38yt","depends_on_id":"bd-cclm","type":"blocks","created_at":"2026-02-20T07:43:21.195631682Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-390","title":"[10.11] Implement anti-entropy reconciliation for distributed product trust state.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.11 — FrankenSQLite-Inspired Runtime Systems Integration Track\n\nWhy This Exists:\nFrankenSQLite-inspired systems integration of capabilities, cancellation protocol, obligations, deterministic labs, and anti-entropy.\n\nTask Objective:\nImplement anti-entropy reconciliation for distributed product trust state.\n\nAcceptance Criteria:\n- Implement with explicit success/failure invariants and deterministic behavior under normal, edge, and fault scenarios.\n- Ensure outcomes are verifiable via automated tests and reproducible artifact outputs.\n\nExpected Artifacts:\n- Section-owned design/spec artifact at `docs/specs/section_10_11/bd-390_contract.md`, capturing decision rationale, invariants, and interface boundaries.\n- Machine-readable verification artifact at `artifacts/section_10_11/bd-390/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_11/bd-390/verification_summary.md` linking implementation intent to measured outcomes.\n\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.11] Implement anti-entropy reconciliation for distributed product trust state.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.11] Implement anti-entropy reconciliation for distributed product trust state.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.11] Implement anti-entropy reconciliation for distributed product trust state.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.11] Implement anti-entropy reconciliation for distributed product trust state.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.11] Implement anti-entropy reconciliation for distributed product trust state.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"AC for bd-390:\n1. Implement an anti-entropy reconciliation protocol for distributed product trust state: each node maintains a local trust state (capability grants, epoch bindings, obligation tokens) and periodically synchronizes with peers to detect and resolve divergence.\n2. The reconciliation uses a Merkle-tree digest of the local trust state; peers exchange root hashes and, on mismatch, perform a tree-diff to identify the minimal set of divergent entries.\n3. Conflict resolution follows a deterministic policy: (a) higher epoch_id wins, (b) within the same epoch, the entry with the later timestamp wins, (c) ties are broken by lexicographic ordering of the node_id. This ensures all nodes converge to the same state without coordination.\n4. Reconciliation runs on a configurable interval (default: 30 seconds) and also triggers immediately on epoch transition events (bd-2gr) to accelerate convergence during security-critical transitions.\n5. A convergence SLA is enforced: after a state mutation, all nodes must agree within max_convergence_time (configurable, default: 3 reconciliation intervals). A RECONCILIATION_SLA_BREACH event fires if convergence is not achieved within the deadline.\n6. The reconciliation protocol is bandwidth-efficient: only divergent entries are transferred, not the full state; a test verifies that reconciling 1 divergent entry out of 10,000 transfers O(log N) data, not O(N).\n7. Unit tests verify: (a) identical states produce matching Merkle roots (no false divergence), (b) single-entry divergence is detected and resolved per conflict policy, (c) epoch-based conflict resolution picks higher epoch, (d) immediate reconciliation triggers on epoch transition, (e) SLA breach event fires when convergence deadline is exceeded.\n8. Integration test: a 3-node cluster with injected network partition heals after partition removal and converges within the SLA.\n9. Structured log events: RECONCILIATION_START / RECONCILIATION_DIVERGENCE_DETECTED / RECONCILIATION_RESOLVED / RECONCILIATION_CONVERGED / RECONCILIATION_SLA_BREACH with node_id, peer_id, divergent_entry_count, and merkle_root_hash.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:36:50.721442902Z","created_by":"ubuntu","updated_at":"2026-02-20T15:19:45.749545773Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-11","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-390","depends_on_id":"bd-lus","type":"blocks","created_at":"2026-02-20T07:43:11.874252438Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-39a","title":"[PLAN 10.19] Adversarial Trust Commons Execution Track (9M)","description":"Section: 10.19 — Adversarial Trust Commons Execution Track (9M)\n\nStrategic Context:\nATC federated intelligence track for privacy-preserving cross-deployment threat learning, robust aggregation, and verifier-backed trust metrics.\n\nExecution Requirements:\n- Preserve all scoped capabilities from the canonical plan.\n- Keep contracts self-contained so future contributors can execute without reopening the master plan.\n- Require explicit testing strategy (unit + integration/e2e) and structured logging/telemetry for every child bead.\n- Require artifact-backed validation for performance, security, and correctness claims.\n\nDependency Semantics:\n- This epic is blocked by its child implementation beads.\n- Cross-epic dependencies encode strategic sequencing and canonical ownership boundaries.\n\n## Success Criteria\n- All child beads for this section are completed with acceptance artifacts attached and no unresolved blockers.\n- Section-level verification gate for comprehensive unit tests, integration/e2e workflows, and detailed structured logging evidence is green.\n- Scope-to-plan traceability is explicit, with no feature loss versus the canonical plan section.\n\n## Optimization Notes\n- User-Outcome Lens: \"[PLAN 10.19] Adversarial Trust Commons Execution Track (9M)\" must improve operator confidence, safety posture, and deterministic recovery behavior under both normal and adversarial conditions.\n- Cross-Section Coordination: child beads must encode integration assumptions explicitly to avoid local optimizations that degrade system-wide correctness.\n- Verification Non-Negotiable: completion requires reproducible unit/integration/E2E evidence and structured logs suitable for independent replay.\n- Scope Protection: any simplification must preserve canonical-plan feature intent and be justified with explicit tradeoff documentation.","status":"open","priority":2,"issue_type":"epic","created_at":"2026-02-20T07:36:41.786603797Z","created_by":"ubuntu","updated_at":"2026-02-20T08:16:44.998351215Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-19"],"dependencies":[{"issue_id":"bd-39a","depends_on_id":"bd-11rz","type":"blocks","created_at":"2026-02-20T07:37:06.374039234Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-39a","depends_on_id":"bd-1eot","type":"blocks","created_at":"2026-02-20T07:37:06.124908784Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-39a","depends_on_id":"bd-1hj3","type":"blocks","created_at":"2026-02-20T07:37:05.540023168Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-39a","depends_on_id":"bd-1wz","type":"blocks","created_at":"2026-02-20T07:37:11.596212456Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-39a","depends_on_id":"bd-24du","type":"blocks","created_at":"2026-02-20T07:37:06.289533878Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-39a","depends_on_id":"bd-253o","type":"blocks","created_at":"2026-02-20T07:37:06.043103837Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-39a","depends_on_id":"bd-293y","type":"blocks","created_at":"2026-02-20T07:37:05.371611762Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-39a","depends_on_id":"bd-2ozr","type":"blocks","created_at":"2026-02-20T07:37:05.792612622Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-39a","depends_on_id":"bd-2yvw","type":"blocks","created_at":"2026-02-20T07:37:05.873914251Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-39a","depends_on_id":"bd-2zip","type":"blocks","created_at":"2026-02-20T07:37:06.208110201Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-39a","depends_on_id":"bd-32p","type":"blocks","created_at":"2026-02-20T07:37:11.635592238Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-39a","depends_on_id":"bd-3aqy","type":"blocks","created_at":"2026-02-20T07:37:05.454103307Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-39a","depends_on_id":"bd-3gwi","type":"blocks","created_at":"2026-02-20T07:37:05.956512235Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-39a","depends_on_id":"bd-3hr2","type":"blocks","created_at":"2026-02-20T07:48:19.686800741Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-39a","depends_on_id":"bd-3ps8","type":"blocks","created_at":"2026-02-20T07:37:05.710130284Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-39a","depends_on_id":"bd-cda","type":"blocks","created_at":"2026-02-20T07:37:09.779371902Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-39a","depends_on_id":"bd-ukh7","type":"blocks","created_at":"2026-02-20T07:37:05.623215900Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-39ga","title":"[10.21] Define canonical `BehavioralGenome` schema and version-lineage contract for extension phenotypes.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.21 — Behavioral Phenotype Evolution Tracker Execution Track (9O)\n\nWhy This Exists:\nBPET longitudinal phenotype intelligence track for pre-compromise trajectory detection and integration with DGIS/ATC/migration/economic policy.\n\nTask Objective:\nDefine canonical `BehavioralGenome` schema and version-lineage contract for extension phenotypes.\n\nAcceptance Criteria:\n- Schema encodes capability usage, dependency reach, API-surface traits, resource/network envelopes, complexity signals, maintainer/build events, and provenance bindings; serialization is deterministic and signed.\n\nExpected Artifacts:\n- `docs/specs/bpet_behavioral_genome_schema.md`, `spec/bpet_behavioral_genome_v1.json`, `artifacts/10.21/bpet_genome_schema_vectors.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_21/bd-39ga/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_21/bd-39ga/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.21] Define canonical `BehavioralGenome` schema and version-lineage contract for extension phenotypes.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.21] Define canonical `BehavioralGenome` schema and version-lineage contract for extension phenotypes.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.21] Define canonical `BehavioralGenome` schema and version-lineage contract for extension phenotypes.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.21] Define canonical `BehavioralGenome` schema and version-lineage contract for extension phenotypes.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.21] Define canonical `BehavioralGenome` schema and version-lineage contract for extension phenotypes.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- Schema encodes capability usage, dependency reach, API-surface traits, resource/network envelopes, complexity signals, maintainer/build events, and provenance bindings; serialization is deterministic and signed.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:37:07.690649218Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:23.837548010Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-21","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-39ga","depends_on_id":"bd-1wz","type":"blocks","created_at":"2026-02-20T07:46:35.470819834Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-39ga","depends_on_id":"bd-39a","type":"blocks","created_at":"2026-02-20T07:46:35.516070424Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-39ga","depends_on_id":"bd-cda","type":"blocks","created_at":"2026-02-20T07:46:35.560633625Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-39ga","depends_on_id":"bd-ybe","type":"blocks","created_at":"2026-02-20T07:46:35.609054219Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-3a3q","title":"[10.14] Implement anytime-valid guardrail monitor set for security/durability-critical budgets.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.14 — FrankenSQLite Deep-Mined Expansion Execution Track (9J)\n\nWhy This Exists:\nFrankenSQLite deep-mined control integrity track: evidence ledgers, proofs, epochs, remote effects, markers/MMR, and deterministic fault labs.\n\nTask Objective:\nImplement anytime-valid guardrail monitor set for security/durability-critical budgets.\n\nAcceptance Criteria:\n- Guardrails are always-on for critical budgets; monitor outputs remain valid under optional stopping; alert thresholds are policy-configurable.\n\nExpected Artifacts:\n- `docs/specs/anytime_valid_guardrails.md`, `tests/conformance/anytime_guardrail_monitors.rs`, `artifacts/10.14/guardrail_monitor_telemetry.csv`.\n\n- Machine-readable verification artifact at `artifacts/section_10_14/bd-3a3q/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_14/bd-3a3q/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.14] Implement anytime-valid guardrail monitor set for security/durability-critical budgets.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.14] Implement anytime-valid guardrail monitor set for security/durability-critical budgets.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.14] Implement anytime-valid guardrail monitor set for security/durability-critical budgets.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.14] Implement anytime-valid guardrail monitor set for security/durability-critical budgets.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.14] Implement anytime-valid guardrail monitor set for security/durability-critical budgets.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"Guardrails are always-on for critical budgets; monitor outputs remain valid under optional stopping; alert thresholds are policy-configurable.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:36:55.712438394Z","created_by":"ubuntu","updated_at":"2026-02-20T15:44:11.223955466Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-14","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-3a3q","depends_on_id":"bd-bq4p","type":"blocks","created_at":"2026-02-20T07:43:14.512302031Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-3agp","title":"[13] Concrete target gate: >=3x migration velocity","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 13\n\nTask Objective:\nBuild KPI gate for migration velocity improvement threshold >=3x.\n\nExecution Requirements:\n- Make this requirement machine-verifiable and release-gated where applicable.\n- Keep behavior self-documenting so future contributors do not need to re-open the master plan.\n\nTesting & Logging Requirements:\n- Unit tests for rule/contract logic and error conditions.\n- Integration/E2E tests for workflow-level enforcement.\n- Structured logs with stable codes and trace IDs.\n- Reproducible artifacts that prove contract satisfaction.\n\nAcceptance Criteria:\n- Success and failure invariants for [13] Concrete target gate: >=3x migration velocity are explicitly quantified and machine-verifiable.\n- Determinism requirements for [13] Concrete target gate: >=3x migration velocity are validated across repeated runs and adversarial perturbations.\n\n\nExpected Artifacts:\n- Machine-readable verification artifact with explicit canonical path under artifacts/section_13/bd-3agp/verification_evidence.json, suitable for CI/release gating.\n- Human-readable verification summary with explicit canonical path under artifacts/section_13/bd-3agp/verification_summary.md, linking implementation intent to measured validation outcomes.\n\nTask-Specific Clarification:\n- The implementation must deliver the exact capability named in the title, with no scope dilution and no silent feature omission.\n- Validation artifacts must include capability-specific thresholds, pass/fail criteria, and reproducible evidence bundles tied to this bead ID.\n- Program/section verification gates must be able to consume this bead's outputs without manual interpretation.\n\nWhy This Improves User Outcomes:\n- \"[13] Concrete target gate: >=3x migration velocity\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[13] Concrete target gate: >=3x migration velocity\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"1. Migration velocity is measured as: (time to migrate a representative project cohort with franken_node tools) / (time to migrate the same cohort manually or with baseline tools).\n2. The representative cohort includes >= 10 projects spanning: Express.js app, Fastify app, Next.js app, CLI tool, library package, worker service, WebSocket server, monorepo, project with native addons (expected partial), project with custom build pipeline.\n3. franken_node migration tools achieve >= 3x velocity improvement: if manual migration takes T hours, tooled migration takes <= T/3 hours.\n4. Velocity is measured end-to-end: from initial analysis to first passing test suite on franken_node.\n5. Each cohort project's migration is documented with: start time, end time, manual intervention points, blockers encountered.\n6. CI runs the velocity benchmark on at least 3 cohort projects per release.\n7. Evidence artifact: migration_velocity_report.json with per-project timings and overall velocity ratio.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:39:34.958919372Z","created_by":"ubuntu","updated_at":"2026-02-20T15:21:15.815621130Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-13","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-3agp","depends_on_id":"bd-28sz","type":"blocks","created_at":"2026-02-20T07:43:25.576288252Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-3aqy","title":"[10.19] Define canonical federated signal schema for anomaly/trust/revocation/quarantine intelligence.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.19 — Adversarial Trust Commons Execution Track (9M)\n\nWhy This Exists:\nATC federated intelligence track for privacy-preserving cross-deployment threat learning, robust aggregation, and verifier-backed trust metrics.\n\nTask Objective:\nDefine canonical federated signal schema for anomaly/trust/revocation/quarantine intelligence.\n\nAcceptance Criteria:\n- Schema covers required signal classes with stable typing, provenance fields, confidence semantics, and expiry windows; schema validation is enforced in CI.\n\nExpected Artifacts:\n- `docs/specs/atc_signal_schema.md`, `spec/atc_signal_schema_v1.json`, `artifacts/10.19/atc_signal_vectors.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_19/bd-3aqy/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_19/bd-3aqy/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.19] Define canonical federated signal schema for anomaly/trust/revocation/quarantine intelligence.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.19] Define canonical federated signal schema for anomaly/trust/revocation/quarantine intelligence.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.19] Define canonical federated signal schema for anomaly/trust/revocation/quarantine intelligence.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.19] Define canonical federated signal schema for anomaly/trust/revocation/quarantine intelligence.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.19] Define canonical federated signal schema for anomaly/trust/revocation/quarantine intelligence.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- Schema covers required signal classes with stable typing, provenance fields, confidence semantics, and expiry windows; schema validation is enforced in CI.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:37:05.416432328Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:24.067303105Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-19","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-3aqy","depends_on_id":"bd-293y","type":"blocks","created_at":"2026-02-20T07:43:19.528898390Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-3b8m","title":"[10.13] Implement anti-amplification response bounds for retrieval/sync traffic and test with adversarial traffic harness.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.13 — FCP Deep-Mined Expansion Execution Track (9I)\n\nWhy This Exists:\nDeep connector/provider contract track: lifecycle FSMs, conformance harnesses, fencing, sandboxing, revocation freshness, and protocol hardening.\n\nTask Objective:\nImplement anti-amplification response bounds for retrieval/sync traffic and test with adversarial traffic harness.\n\nAcceptance Criteria:\n- Response payloads never exceed request-declared bounds under adversarial inputs; unauthenticated limits are stricter and enforced; harness reproduces attacks deterministically.\n\nExpected Artifacts:\n- `tests/security/anti_amplification_harness.rs`, `docs/specs/anti_amplification_rules.md`, `artifacts/10.13/anti_amplification_test_results.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_13/bd-3b8m/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_13/bd-3b8m/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.13] Implement anti-amplification response bounds for retrieval/sync traffic and test with adversarial traffic harness.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.13] Implement anti-amplification response bounds for retrieval/sync traffic and test with adversarial traffic harness.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.13] Implement anti-amplification response bounds for retrieval/sync traffic and test with adversarial traffic harness.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.13] Implement anti-amplification response bounds for retrieval/sync traffic and test with adversarial traffic harness.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.13] Implement anti-amplification response bounds for retrieval/sync traffic and test with adversarial traffic harness.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","status":"closed","priority":1,"issue_type":"task","assignee":"CrimsonCrane","created_at":"2026-02-20T07:36:54.003652591Z","created_by":"ubuntu","updated_at":"2026-02-20T12:48:56.769978383Z","closed_at":"2026-02-20T12:48:56.769950862Z","close_reason":"done","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-13","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-3b8m","depends_on_id":"bd-2k74","type":"blocks","created_at":"2026-02-20T07:43:13.601557508Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-3c2","title":"[10.12] Implement verifier-economy SDK with independent validation workflows.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.12 — Frontier Programs Execution Track (9H)\n\nWhy This Exists:\nFrontier program execution turning migration singularity, trust fabric, verifier economy, and operator intelligence into production flow.\n\nTask Objective:\nImplement verifier-economy SDK with independent validation workflows.\n\nAcceptance Criteria:\n- Implement with explicit success/failure invariants and deterministic behavior under normal, edge, and fault scenarios.\n- Ensure outcomes are verifiable via automated tests and reproducible artifact outputs.\n\nExpected Artifacts:\n- Section-owned design/spec artifact at `docs/specs/section_10_12/bd-3c2_contract.md`, capturing decision rationale, invariants, and interface boundaries.\n- Machine-readable verification artifact at `artifacts/section_10_12/bd-3c2/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_12/bd-3c2/verification_summary.md` linking implementation intent to measured outcomes.\n\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.12] Implement verifier-economy SDK with independent validation workflows.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.12] Implement verifier-economy SDK with independent validation workflows.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.12] Implement verifier-economy SDK with independent validation workflows.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.12] Implement verifier-economy SDK with independent validation workflows.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.12] Implement verifier-economy SDK with independent validation workflows.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"1. Define a VerifierSDK module providing: (a) verify_migration_artifact(artifact_json: &str) -> VerificationResult that validates a MigrationSingularityArtifact (from bd-3hm) without access to the source system, (b) verify_rollback_receipt(receipt_json: &str, public_key: &[u8]) -> VerificationResult that checks receipt signature and deadline, (c) verify_release_gate(manifest_json: &str) -> VerificationResult that validates a ReleaseGateManifest (from bd-1hd).\n2. Define VerificationResult as a struct: (a) verdict (PASS, FAIL, INCONCLUSIVE), (b) checked_fields (list of {field_name, check, pass/fail}), (c) verifier_version (SDK semver), (d) verification_timestamp, (e) details (human-readable summary).\n3. The SDK MUST be usable as a standalone library with zero runtime dependencies on the franken_node system. It should depend only on cryptographic primitives and JSON parsing.\n4. Implement schema validation: the SDK MUST reject artifacts whose schema_version it does not recognize, returning INCONCLUSIVE with a message indicating the required SDK version.\n5. Implement independent hash verification: the SDK MUST recompute all hashes (migration_plan_hash, state fingerprints) from the artifact's embedded data and compare against the declared values. Any mismatch produces FAIL.\n6. Implement signature verification: the SDK MUST verify all signatures in the artifact using the provided public keys. Support Ed25519 signatures at minimum.\n7. Provide a CLI wrapper: `franken-verify <artifact.json> [--public-key <key.pem>]` that prints the VerificationResult as JSON to stdout and exits with code 0 (PASS), 1 (FAIL), or 2 (INCONCLUSIVE).\n8. Unit tests: (a) valid artifact passes, (b) tampered hash fails, (c) invalid signature fails, (d) unknown schema version returns INCONCLUSIVE, (e) missing required field returns FAIL, (f) CLI exit codes match verdict.\n9. Provide example artifacts in fixtures/verifier_sdk/ with known-good and known-bad samples for third-party testing.\n10. Verification: scripts/check_verifier_sdk.py --json, artifacts at artifacts/section_10_12/bd-3c2/.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:36:51.075158591Z","created_by":"ubuntu","updated_at":"2026-02-20T15:40:12.599065615Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-12","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-3c2","depends_on_id":"bd-5si","type":"blocks","created_at":"2026-02-20T07:43:12.055387055Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-3cbi","title":"[10.21] Integrate BPET risk into economic trust layer and operator copilot recommendation engine.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.21 — Behavioral Phenotype Evolution Tracker Execution Track (9O)\n\nWhy This Exists:\nBPET longitudinal phenotype intelligence track for pre-compromise trajectory detection and integration with DGIS/ATC/migration/economic policy.\n\nTask Objective:\nIntegrate BPET risk into economic trust layer and operator copilot recommendation engine.\n\nAcceptance Criteria:\n- Economic models price trajectory-derived compromise propensity and intervention ROI; operator guidance includes historical motif matches and mitigation playbooks.\n\nExpected Artifacts:\n- `src/security/bpet/economic_integration.rs`, `src/ops/bpet_operator_copilot.rs`, `artifacts/10.21/bpet_economic_guidance_report.csv`.\n\n- Machine-readable verification artifact at `artifacts/section_10_21/bd-3cbi/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_21/bd-3cbi/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.21] Integrate BPET risk into economic trust layer and operator copilot recommendation engine.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.21] Integrate BPET risk into economic trust layer and operator copilot recommendation engine.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.21] Integrate BPET risk into economic trust layer and operator copilot recommendation engine.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.21] Integrate BPET risk into economic trust layer and operator copilot recommendation engine.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.21] Integrate BPET risk into economic trust layer and operator copilot recommendation engine.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- Economic models price trajectory-derived compromise propensity and intervention ROI; operator guidance includes historical motif matches and mitigation playbooks.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:37:08.711484589Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:24.296920102Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-21","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-3cbi","depends_on_id":"bd-1jpc","type":"blocks","created_at":"2026-02-20T15:01:15.750818267Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3cbi","depends_on_id":"bd-aoq6","type":"blocks","created_at":"2026-02-20T07:43:21.817650344Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-3cm3","title":"[10.13] Implement schema-gated quarantine promotion rules and promotion provenance receipts.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.13 — FCP Deep-Mined Expansion Execution Track (9I)\n\nWhy This Exists:\nDeep connector/provider contract track: lifecycle FSMs, conformance harnesses, fencing, sandboxing, revocation freshness, and protocol hardening.\n\nTask Objective:\nImplement schema-gated quarantine promotion rules and promotion provenance receipts.\n\nAcceptance Criteria:\n- Promotion requires reachability/authenticated request/pin plus schema validation; promotion emits provenance receipt with promotion reason; invalid promotions fail closed.\n\nExpected Artifacts:\n- `docs/specs/quarantine_promotion_rules.md`, `tests/security/quarantine_promotion_gate.rs`, `artifacts/10.13/quarantine_promotion_receipts.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_13/bd-3cm3/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_13/bd-3cm3/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.13] Implement schema-gated quarantine promotion rules and promotion provenance receipts.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.13] Implement schema-gated quarantine promotion rules and promotion provenance receipts.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.13] Implement schema-gated quarantine promotion rules and promotion provenance receipts.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.13] Implement schema-gated quarantine promotion rules and promotion provenance receipts.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.13] Implement schema-gated quarantine promotion rules and promotion provenance receipts.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","status":"closed","priority":1,"issue_type":"task","assignee":"CrimsonCrane","created_at":"2026-02-20T07:36:54.171128726Z","created_by":"ubuntu","updated_at":"2026-02-20T12:54:59.637303286Z","closed_at":"2026-02-20T12:54:59.637274472Z","close_reason":"done","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-13","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-3cm3","depends_on_id":"bd-2eun","type":"blocks","created_at":"2026-02-20T07:43:13.684421630Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-3cpa","title":"[13] Concrete target gate: >=10x compromise reduction","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 13\n\nTask Objective:\nBuild KPI gate for host-compromise reduction threshold >=10x under adversarial campaigns.\n\nExecution Requirements:\n- Make this requirement machine-verifiable and release-gated where applicable.\n- Keep behavior self-documenting so future contributors do not need to re-open the master plan.\n\nTesting & Logging Requirements:\n- Unit tests for rule/contract logic and error conditions.\n- Integration/E2E tests for workflow-level enforcement.\n- Structured logs with stable codes and trace IDs.\n- Reproducible artifacts that prove contract satisfaction.\n\nAcceptance Criteria:\n- Success and failure invariants for [13] Concrete target gate: >=10x compromise reduction are explicitly quantified and machine-verifiable.\n- Determinism requirements for [13] Concrete target gate: >=10x compromise reduction are validated across repeated runs and adversarial perturbations.\n\n\nExpected Artifacts:\n- Machine-readable verification artifact with explicit canonical path under artifacts/section_13/bd-3cpa/verification_evidence.json, suitable for CI/release gating.\n- Human-readable verification summary with explicit canonical path under artifacts/section_13/bd-3cpa/verification_summary.md, linking implementation intent to measured validation outcomes.\n\nTask-Specific Clarification:\n- The implementation must deliver the exact capability named in the title, with no scope dilution and no silent feature omission.\n- Validation artifacts must include capability-specific thresholds, pass/fail criteria, and reproducible evidence bundles tied to this bead ID.\n- Program/section verification gates must be able to consume this bead's outputs without manual interpretation.\n\nWhy This Improves User Outcomes:\n- \"[13] Concrete target gate: >=10x compromise reduction\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[13] Concrete target gate: >=10x compromise reduction\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"1. Host-compromise reduction is measured by comparing: (successful compromises in hardened franken_node) vs (successful compromises in unhardened baseline) under identical attack campaigns.\n2. Attack campaign includes >= 20 distinct attack vectors: RCE via dependency, prototype pollution, path traversal, SSRF, deserialization, supply-chain injection, privilege escalation, sandbox escape, memory corruption, etc.\n3. franken_node achieves >= 10x reduction: if baseline is compromised by N attacks, franken_node is compromised by <= N/10.\n4. Each attack vector is documented with: attack description, baseline outcome (compromised/not), franken_node outcome (compromised/not), mitigation that blocked it.\n5. The attack campaign is reproducible: scripted attacks that can be rerun on any version.\n6. At least 3 attack vectors must demonstrate containment (attack detected and isolated, not just prevented).\n7. Evidence artifact: compromise_reduction_report.json with per-attack results and overall reduction ratio.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:39:35.043905043Z","created_by":"ubuntu","updated_at":"2026-02-20T15:21:27.797871831Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-13","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-3cpa","depends_on_id":"bd-3agp","type":"blocks","created_at":"2026-02-20T07:43:25.620145926Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-3cs3","title":"[10.14] Implement epoch-scoped key derivation for trust artifact authentication.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.14 — FrankenSQLite Deep-Mined Expansion Execution Track (9J)\n\nWhy This Exists:\nFrankenSQLite deep-mined control integrity track: evidence ledgers, proofs, epochs, remote effects, markers/MMR, and deterministic fault labs.\n\nTask Objective:\nImplement epoch-scoped key derivation for trust artifact authentication.\n\nAcceptance Criteria:\n- Authentication key derivation binds to epoch and domain; cross-epoch key reuse is impossible by construction; verification vectors are published.\n\nExpected Artifacts:\n- `src/security/epoch_scoped_keys.rs`, `tests/conformance/epoch_key_derivation.rs`, `artifacts/10.14/epoch_key_vectors.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_14/bd-3cs3/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_14/bd-3cs3/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.14] Implement epoch-scoped key derivation for trust artifact authentication.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.14] Implement epoch-scoped key derivation for trust artifact authentication.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.14] Implement epoch-scoped key derivation for trust artifact authentication.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.14] Implement epoch-scoped key derivation for trust artifact authentication.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.14] Implement epoch-scoped key derivation for trust artifact authentication.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"Authentication key derivation binds to epoch and domain; cross-epoch key reuse is impossible by construction; verification vectors are published.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:36:58.302630425Z","created_by":"ubuntu","updated_at":"2026-02-20T15:44:04.549509066Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-14","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-3cs3","depends_on_id":"bd-2xv8","type":"blocks","created_at":"2026-02-20T07:43:15.851020132Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-3dn","title":"[10.3] Build rollout planner (`shadow -> canary -> ramp -> default`) per project.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.3 — Migration System\n\nWhy This Exists:\nMigration autopilot pipeline from audit to rollout, designed to collapse migration friction with deterministic confidence and replayability.\n\nTask Objective:\nBuild rollout planner (`shadow -> canary -> ramp -> default`) per project.\n\nAcceptance Criteria:\n- Implement with explicit success/failure invariants and deterministic behavior under normal, edge, and fault scenarios.\n- Ensure outcomes are verifiable via automated tests and reproducible artifact outputs.\n\nExpected Artifacts:\n- Section-owned design/spec artifact at `docs/specs/section_10_3/bd-3dn_contract.md`, capturing decision rationale, invariants, and interface boundaries.\n- Machine-readable verification artifact at `artifacts/section_10_3/bd-3dn/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_3/bd-3dn/verification_summary.md` linking implementation intent to measured outcomes.\n\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.3] Build rollout planner (`shadow -> canary -> ramp -> default`) per project.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.3] Build rollout planner (`shadow -> canary -> ramp -> default`) per project.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.3] Build rollout planner (`shadow -> canary -> ramp -> default`) per project.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.3] Build rollout planner (`shadow -> canary -> ramp -> default`) per project.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.3] Build rollout planner (`shadow -> canary -> ramp -> default`) per project.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","status":"closed","priority":1,"issue_type":"task","assignee":"CrimsonCrane","created_at":"2026-02-20T07:36:45.113759296Z","created_by":"ubuntu","updated_at":"2026-02-20T10:16:34.652745740Z","closed_at":"2026-02-20T10:16:34.652721064Z","close_reason":"done","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-3","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-3dn","depends_on_id":"bd-2st","type":"blocks","created_at":"2026-02-20T07:43:22.190282530Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-3e74","title":"[13] Success criterion: benchmark/verifier external usage","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 13\n\nTask Objective:\nTrack and enforce external usage targets for benchmark and verifier standards.\n\nExecution Requirements:\n- Make this requirement machine-verifiable and release-gated where applicable.\n- Keep behavior self-documenting so future contributors do not need to re-open the master plan.\n\nTesting & Logging Requirements:\n- Unit tests for rule/contract logic and error conditions.\n- Integration/E2E tests for workflow-level enforcement.\n- Structured logs with stable codes and trace IDs.\n- Reproducible artifacts that prove contract satisfaction.\n\nAcceptance Criteria:\n- Success and failure invariants for [13] Success criterion: benchmark/verifier external usage are explicitly quantified and machine-verifiable.\n- Determinism requirements for [13] Success criterion: benchmark/verifier external usage are validated across repeated runs and adversarial perturbations.\n\n\nExpected Artifacts:\n- Machine-readable verification artifact with explicit canonical path under artifacts/section_13/bd-3e74/verification_evidence.json, suitable for CI/release gating.\n- Human-readable verification summary with explicit canonical path under artifacts/section_13/bd-3e74/verification_summary.md, linking implementation intent to measured validation outcomes.\n\nTask-Specific Clarification:\n- The implementation must deliver the exact capability named in the title, with no scope dilution and no silent feature omission.\n- Validation artifacts must include capability-specific thresholds, pass/fail criteria, and reproducible evidence bundles tied to this bead ID.\n- Program/section verification gates must be able to consume this bead's outputs without manual interpretation.\n\nWhy This Improves User Outcomes:\n- \"[13] Success criterion: benchmark/verifier external usage\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[13] Success criterion: benchmark/verifier external usage\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"1. Published benchmark suite is used by >= 3 external projects or organizations (tracked via download/citation metrics).\n2. Published verifier toolkit is used by >= 2 external parties for independent validation (tracked via usage reports).\n3. Benchmark results are cited in >= 1 external publication, blog post, or conference presentation.\n4. Benchmark and verifier are packaged for easy external consumption: npm package, Docker image, or standalone binary.\n5. External usage is tracked via: (a) npm download counts, (b) Docker pull counts, (c) GitHub stars/forks on benchmark repo, (d) citation tracking.\n6. Documentation includes 'getting started' guide for external users that enables first benchmark run in <= 15 minutes.\n7. Evidence: external_usage_report.json with download counts, known external users, and citation list.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:39:34.752176035Z","created_by":"ubuntu","updated_at":"2026-02-20T15:23:17.432118837Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-13","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-3e74","depends_on_id":"bd-1xao","type":"blocks","created_at":"2026-02-20T07:43:25.487730766Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-3en","title":"[10.13] Build connector protocol conformance harness and block registry publication on failures.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.13 — FCP Deep-Mined Expansion Execution Track (9I)\n\nWhy This Exists:\nDeep connector/provider contract track: lifecycle FSMs, conformance harnesses, fencing, sandboxing, revocation freshness, and protocol hardening.\n\nTask Objective:\nBuild connector protocol conformance harness and block registry publication on failures.\n\nAcceptance Criteria:\n- CI gate fails publication for non-conformant connectors; harness emits deterministic pass/fail reasons; bypass requires explicit policy override artifact.\n\nExpected Artifacts:\n- `tests/conformance/connector_protocol_harness.rs`, `.github/workflows/connector-conformance.yml`, `artifacts/10.13/publication_gate_evidence.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_13/bd-3en/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_13/bd-3en/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.13] Build connector protocol conformance harness and block registry publication on failures.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.13] Build connector protocol conformance harness and block registry publication on failures.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.13] Build connector protocol conformance harness and block registry publication on failures.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.13] Build connector protocol conformance harness and block registry publication on failures.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.13] Build connector protocol conformance harness and block registry publication on failures.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","status":"closed","priority":1,"issue_type":"task","assignee":"CrimsonCrane","created_at":"2026-02-20T07:36:51.637471661Z","created_by":"ubuntu","updated_at":"2026-02-20T10:45:02.089794576Z","closed_at":"2026-02-20T10:45:02.089769249Z","close_reason":"done","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-13","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-3en","depends_on_id":"bd-1h6","type":"blocks","created_at":"2026-02-20T07:43:12.356825845Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-3enl","title":"[10.3] Section-wide verification gate: comprehensive unit+e2e+logging","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.3\n\nTask Objective:\nCreate a hard section completion gate that verifies all implemented behavior in this section with comprehensive unit tests, integration/e2e scripts, and detailed structured logging evidence.\n\nAcceptance Criteria:\n- Section test matrix covers happy-path, edge-case, and adversarial/error-path scenarios for all section deliverables.\n- E2E scripts execute representative end-user workflows and policy/control-plane transitions for this section.\n- Structured logs include stable event/error codes, trace correlation IDs, and enough context for deterministic replay triage.\n- Verification report is deterministic and machine-readable for CI/release gating.\n\nExpected Artifacts:\n- Section-level test matrix and coverage summary artifact.\n- E2E script suite with pass/fail outputs and reproducible fixtures/seeds.\n- Structured log validation report and traceability bundle.\n- Gate verdict artifact consumable by release automation.\n\n- Machine-readable verification artifact at `artifacts/section_10_3/bd-3enl/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_3/bd-3enl/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests must validate contracts, invariants, and failure semantics.\n- E2E tests must validate cross-component behavior from user/operator entrypoints to persisted effects.\n- Logging must support root-cause analysis without hidden context requirements.\n\nTask-Specific Clarification:\n- For \"[10.3] Section-wide verification gate: comprehensive unit+e2e+logging\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.3] Section-wide verification gate: comprehensive unit+e2e+logging\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.3] Section-wide verification gate: comprehensive unit+e2e+logging\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.3] Section-wide verification gate: comprehensive unit+e2e+logging\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.3] Section-wide verification gate: comprehensive unit+e2e+logging\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","status":"closed","priority":1,"issue_type":"task","assignee":"CrimsonCrane","created_at":"2026-02-20T07:48:22.811975525Z","created_by":"ubuntu","updated_at":"2026-02-20T10:23:05.394460058Z","closed_at":"2026-02-20T10:23:05.394434400Z","close_reason":"done","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-3","test-obligations","verification-gate"],"dependencies":[{"issue_id":"bd-3enl","depends_on_id":"bd-12f","type":"blocks","created_at":"2026-02-20T07:48:23.006448591Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3enl","depends_on_id":"bd-1dpd","type":"blocks","created_at":"2026-02-20T08:24:25.309475159Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3enl","depends_on_id":"bd-2a0","type":"blocks","created_at":"2026-02-20T07:48:23.263782169Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3enl","depends_on_id":"bd-2ew","type":"blocks","created_at":"2026-02-20T07:48:23.153016291Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3enl","depends_on_id":"bd-2st","type":"blocks","created_at":"2026-02-20T07:48:23.103783062Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3enl","depends_on_id":"bd-2twu","type":"blocks","created_at":"2026-02-20T08:20:50.967786989Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3enl","depends_on_id":"bd-33x","type":"blocks","created_at":"2026-02-20T07:48:23.206554850Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3enl","depends_on_id":"bd-3dn","type":"blocks","created_at":"2026-02-20T07:48:23.053801569Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3enl","depends_on_id":"bd-3f9","type":"blocks","created_at":"2026-02-20T07:48:22.909400214Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3enl","depends_on_id":"bd-hg1","type":"blocks","created_at":"2026-02-20T07:48:22.957592705Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-3epz","title":"[10.14] Section-wide verification gate: comprehensive unit+e2e+logging","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.14\n\nTask Objective:\nCreate a hard section completion gate that verifies all implemented behavior in this section with comprehensive unit tests, integration/e2e scripts, and detailed structured logging evidence.\n\nAcceptance Criteria:\n- Section test matrix covers happy-path, edge-case, and adversarial/error-path scenarios for all section deliverables.\n- E2E scripts execute representative end-user workflows and policy/control-plane transitions for this section.\n- Structured logs include stable event/error codes, trace correlation IDs, and enough context for deterministic replay triage.\n- Verification report is deterministic and machine-readable for CI/release gating.\n\nExpected Artifacts:\n- Section-level test matrix and coverage summary artifact.\n- E2E script suite with pass/fail outputs and reproducible fixtures/seeds.\n- Structured log validation report and traceability bundle.\n- Gate verdict artifact consumable by release automation.\n\n- Machine-readable verification artifact at `artifacts/section_10_14/bd-3epz/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_14/bd-3epz/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests must validate contracts, invariants, and failure semantics.\n- E2E tests must validate cross-component behavior from user/operator entrypoints to persisted effects.\n- Logging must support root-cause analysis without hidden context requirements.\n\nTask-Specific Clarification:\n- For \"[10.14] Section-wide verification gate: comprehensive unit+e2e+logging\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.14] Section-wide verification gate: comprehensive unit+e2e+logging\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.14] Section-wide verification gate: comprehensive unit+e2e+logging\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.14] Section-wide verification gate: comprehensive unit+e2e+logging\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.14] Section-wide verification gate: comprehensive unit+e2e+logging\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"Section test matrix covers happy-path, edge-case, and adversarial/error-path scenarios for all section deliverables.; E2E scripts execute representative end-user workflows and policy/control-plane transitions for this section.; Structured logs include stable event/error codes, trace correlation IDs, and enough context for deterministic replay triage.; Verification report is deterministic and machine-readable for CI/release gating.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:48:11.517555268Z","created_by":"ubuntu","updated_at":"2026-02-20T15:44:01.562913438Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-14","test-obligations","verification-gate"],"dependencies":[{"issue_id":"bd-3epz","depends_on_id":"bd-126h","type":"blocks","created_at":"2026-02-20T07:48:12.099669987Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3epz","depends_on_id":"bd-129f","type":"blocks","created_at":"2026-02-20T07:48:12.050677055Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3epz","depends_on_id":"bd-12n3","type":"blocks","created_at":"2026-02-20T07:48:12.579463687Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3epz","depends_on_id":"bd-15u3","type":"blocks","created_at":"2026-02-20T07:48:13.726723938Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3epz","depends_on_id":"bd-18ud","type":"blocks","created_at":"2026-02-20T07:48:12.844617560Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3epz","depends_on_id":"bd-1ayu","type":"blocks","created_at":"2026-02-20T07:48:13.537978771Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3epz","depends_on_id":"bd-1dar","type":"blocks","created_at":"2026-02-20T07:48:11.954977660Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3epz","depends_on_id":"bd-1daz","type":"blocks","created_at":"2026-02-20T07:48:13.483134591Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3epz","depends_on_id":"bd-1dpd","type":"blocks","created_at":"2026-02-20T08:24:26.552106678Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3epz","depends_on_id":"bd-1fck","type":"blocks","created_at":"2026-02-20T07:48:12.778348751Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3epz","depends_on_id":"bd-1fp4","type":"blocks","created_at":"2026-02-20T07:48:13.432440680Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3epz","depends_on_id":"bd-1iyx","type":"blocks","created_at":"2026-02-20T07:48:13.091380138Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3epz","depends_on_id":"bd-1l62","type":"blocks","created_at":"2026-02-20T07:48:13.336980962Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3epz","depends_on_id":"bd-1nfu","type":"blocks","created_at":"2026-02-20T07:48:12.674028840Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3epz","depends_on_id":"bd-1oof","type":"blocks","created_at":"2026-02-20T07:48:14.022270479Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3epz","depends_on_id":"bd-1ru2","type":"blocks","created_at":"2026-02-20T07:48:12.724543917Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3epz","depends_on_id":"bd-1vsr","type":"blocks","created_at":"2026-02-20T07:48:12.147581655Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3epz","depends_on_id":"bd-1zym","type":"blocks","created_at":"2026-02-20T07:48:13.585081732Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3epz","depends_on_id":"bd-206h","type":"blocks","created_at":"2026-02-20T07:48:12.531769845Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3epz","depends_on_id":"bd-20uo","type":"blocks","created_at":"2026-02-20T07:48:13.289068563Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3epz","depends_on_id":"bd-22yy","type":"blocks","created_at":"2026-02-20T07:48:11.658851089Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3epz","depends_on_id":"bd-2573","type":"blocks","created_at":"2026-02-20T07:48:13.044507204Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3epz","depends_on_id":"bd-25nl","type":"blocks","created_at":"2026-02-20T07:48:11.855103519Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3epz","depends_on_id":"bd-27o2","type":"blocks","created_at":"2026-02-20T07:48:12.950567006Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3epz","depends_on_id":"bd-2808","type":"blocks","created_at":"2026-02-20T07:48:11.806344072Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3epz","depends_on_id":"bd-29r6","type":"blocks","created_at":"2026-02-20T07:48:13.142600498Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3epz","depends_on_id":"bd-29yx","type":"blocks","created_at":"2026-02-20T07:48:13.241977493Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3epz","depends_on_id":"bd-2e73","type":"blocks","created_at":"2026-02-20T07:48:14.118909774Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3epz","depends_on_id":"bd-2igi","type":"blocks","created_at":"2026-02-20T07:48:13.774165601Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3epz","depends_on_id":"bd-2ona","type":"blocks","created_at":"2026-02-20T07:48:13.974737346Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3epz","depends_on_id":"bd-2qqu","type":"blocks","created_at":"2026-02-20T07:48:11.756050698Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3epz","depends_on_id":"bd-2twu","type":"blocks","created_at":"2026-02-20T08:20:52.427491455Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3epz","depends_on_id":"bd-2wsm","type":"blocks","created_at":"2026-02-20T07:48:12.203158600Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3epz","depends_on_id":"bd-2xv8","type":"blocks","created_at":"2026-02-20T07:48:12.308091603Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3epz","depends_on_id":"bd-3a3q","type":"blocks","created_at":"2026-02-20T07:48:13.820935352Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3epz","depends_on_id":"bd-3cs3","type":"blocks","created_at":"2026-02-20T07:48:12.253010762Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3epz","depends_on_id":"bd-3hdv","type":"blocks","created_at":"2026-02-20T07:48:12.365237861Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3epz","depends_on_id":"bd-3i6c","type":"blocks","created_at":"2026-02-20T07:48:11.613358106Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3epz","depends_on_id":"bd-3ort","type":"blocks","created_at":"2026-02-20T07:48:13.190861787Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3epz","depends_on_id":"bd-3rya","type":"blocks","created_at":"2026-02-20T07:48:13.632148927Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3epz","depends_on_id":"bd-876n","type":"blocks","created_at":"2026-02-20T07:48:11.707461478Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3epz","depends_on_id":"bd-8tvs","type":"blocks","created_at":"2026-02-20T07:48:12.998070203Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3epz","depends_on_id":"bd-ac83","type":"blocks","created_at":"2026-02-20T07:48:12.626672606Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3epz","depends_on_id":"bd-b9b6","type":"blocks","created_at":"2026-02-20T07:48:13.384860049Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3epz","depends_on_id":"bd-bq4p","type":"blocks","created_at":"2026-02-20T07:48:13.881264508Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3epz","depends_on_id":"bd-mwvn","type":"blocks","created_at":"2026-02-20T07:48:13.680901782Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3epz","depends_on_id":"bd-nupr","type":"blocks","created_at":"2026-02-20T07:48:14.168391136Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3epz","depends_on_id":"bd-nwhn","type":"blocks","created_at":"2026-02-20T07:48:11.902054718Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3epz","depends_on_id":"bd-okqy","type":"blocks","created_at":"2026-02-20T07:48:12.903638970Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3epz","depends_on_id":"bd-oolt","type":"blocks","created_at":"2026-02-20T07:48:14.068854233Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3epz","depends_on_id":"bd-qlc6","type":"blocks","created_at":"2026-02-20T07:48:12.414930826Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3epz","depends_on_id":"bd-sddz","type":"blocks","created_at":"2026-02-20T07:48:13.928230394Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3epz","depends_on_id":"bd-v4l0","type":"blocks","created_at":"2026-02-20T07:48:12.473044486Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3epz","depends_on_id":"bd-xwk5","type":"blocks","created_at":"2026-02-20T07:48:12.003363050Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-3ex","title":"[10.7] Add verifier CLI conformance contract tests.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.7 — Conformance + Verification\n\nWhy This Exists:\nConformance and verification evidence stack for compatibility, trust protocols, fuzzing, and external reproducibility.\n\nTask Objective:\nAdd verifier CLI conformance contract tests.\n\nAcceptance Criteria:\n- Implement with explicit success/failure invariants and deterministic behavior under normal, edge, and fault scenarios.\n- Ensure outcomes are verifiable via automated tests and reproducible artifact outputs.\n\nExpected Artifacts:\n- Section-owned design/spec artifact at `docs/specs/section_10_7/bd-3ex_contract.md`, capturing decision rationale, invariants, and interface boundaries.\n- Machine-readable verification artifact at `artifacts/section_10_7/bd-3ex/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_7/bd-3ex/verification_summary.md` linking implementation intent to measured outcomes.\n\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.7] Add verifier CLI conformance contract tests.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.7] Add verifier CLI conformance contract tests.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.7] Add verifier CLI conformance contract tests.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.7] Add verifier CLI conformance contract tests.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.7] Add verifier CLI conformance contract tests.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"1. Verifier CLI exposes at least: verify-module, verify-migration, verify-compatibility, and verify-corpus subcommands.\n2. Each subcommand has a conformance contract defined in a spec document under docs/specs/ specifying inputs, outputs, exit codes, and error formats.\n3. Contract tests exercise every specified input/output combination including edge cases and error paths.\n4. Tests validate that CLI output conforms to the documented JSON schema (no undocumented fields, no missing required fields).\n5. Exit codes follow a documented taxonomy: 0=pass, 1=fail, 2=error, 3=skipped.\n6. Per Section 3.2 capability #10 (public verifier toolkit): CLI is usable by an external party with no internal knowledge — contract tests verify this by running in an isolated environment with no access to internal state.\n7. Contract tests are generated from the spec documents (not hand-written) to ensure spec and tests stay in sync.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:36:47.589413741Z","created_by":"ubuntu","updated_at":"2026-02-20T15:17:26.215095079Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-7","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-3ex","depends_on_id":"bd-1u4","type":"blocks","created_at":"2026-02-20T07:43:23.618772843Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-3f9","title":"[10.3] Build deterministic migration failure replay tooling.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.3 — Migration System\n\nWhy This Exists:\nMigration autopilot pipeline from audit to rollout, designed to collapse migration friction with deterministic confidence and replayability.\n\nTask Objective:\nBuild deterministic migration failure replay tooling.\n\nAcceptance Criteria:\n- Implement with explicit success/failure invariants and deterministic behavior under normal, edge, and fault scenarios.\n- Ensure outcomes are verifiable via automated tests and reproducible artifact outputs.\n\nExpected Artifacts:\n- Section-owned design/spec artifact at `docs/specs/section_10_3/bd-3f9_contract.md`, capturing decision rationale, invariants, and interface boundaries.\n- Machine-readable verification artifact at `artifacts/section_10_3/bd-3f9/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_3/bd-3f9/verification_summary.md` linking implementation intent to measured outcomes.\n\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.3] Build deterministic migration failure replay tooling.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.3] Build deterministic migration failure replay tooling.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.3] Build deterministic migration failure replay tooling.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.3] Build deterministic migration failure replay tooling.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.3] Build deterministic migration failure replay tooling.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","status":"closed","priority":1,"issue_type":"task","assignee":"CrimsonCrane","created_at":"2026-02-20T07:36:45.346743011Z","created_by":"ubuntu","updated_at":"2026-02-20T10:21:45.798113045Z","closed_at":"2026-02-20T10:21:45.798088439Z","close_reason":"done","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-3","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-3f9","depends_on_id":"bd-hg1","type":"blocks","created_at":"2026-02-20T07:43:22.321503315Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-3f91","title":"Epic: Lease Service + Execution Planner [10.13e]","description":"- type: epic","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-20T07:47:58.072163029Z","updated_at":"2026-02-20T07:49:21.181692969Z","closed_at":"2026-02-20T07:49:21.181674655Z","close_reason":"Superseded by canonical detailed master-plan graph (bd-33v) with full 10.N-10.21 and 11-16 coverage, explicit dependencies, and per-section verification gates.","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-3fo","title":"[PLAN 10.0] Top 10 Initiative Tracking","description":"Section: 10.0 — Top 10 Initiative Tracking\n\nStrategic Context:\nTop-10 initiative tracking layer that ensures category-defining capabilities are delivered as a complete system, not isolated features.\n\nExecution Requirements:\n- Preserve all scoped capabilities from the canonical plan.\n- Keep contracts self-contained so future contributors can execute without reopening the master plan.\n- Require explicit testing strategy (unit + integration/e2e) and structured logging/telemetry for every child bead.\n- Require artifact-backed validation for performance, security, and correctness claims.\n\nDependency Semantics:\n- This epic is blocked by its child implementation beads.\n- Cross-epic dependencies encode strategic sequencing and canonical ownership boundaries.\n\n## Success Criteria\n- All child beads for this section are completed with acceptance artifacts attached and no unresolved blockers.\n- Section-level verification gate for comprehensive unit tests, integration/e2e workflows, and detailed structured logging evidence is green.\n- Scope-to-plan traceability is explicit, with no feature loss versus the canonical plan section.\n\n## Optimization Notes\n- User-Outcome Lens: \"[PLAN 10.0] Top 10 Initiative Tracking\" must improve operator confidence, safety posture, and deterministic recovery behavior under both normal and adversarial conditions.\n- Cross-Section Coordination: child beads must encode integration assumptions explicitly to avoid local optimizations that degrade system-wide correctness.\n- Verification Non-Negotiable: completion requires reproducible unit/integration/E2E evidence and structured logs suitable for independent replay.\n- Scope Protection: any simplification must preserve canonical-plan feature intent and be justified with explicit tradeoff documentation.","status":"open","priority":1,"issue_type":"epic","created_at":"2026-02-20T07:36:40.215374799Z","created_by":"ubuntu","updated_at":"2026-02-20T08:16:43.404296376Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-0"],"dependencies":[{"issue_id":"bd-3fo","depends_on_id":"bd-1hf","type":"blocks","created_at":"2026-02-20T07:37:12.221401584Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3fo","depends_on_id":"bd-1nf","type":"blocks","created_at":"2026-02-20T07:36:43.079963183Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3fo","depends_on_id":"bd-1ow","type":"blocks","created_at":"2026-02-20T07:37:11.867966377Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3fo","depends_on_id":"bd-1qp","type":"blocks","created_at":"2026-02-20T07:36:42.521695479Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3fo","depends_on_id":"bd-1ta","type":"blocks","created_at":"2026-02-20T07:37:12.340046742Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3fo","depends_on_id":"bd-1u9","type":"blocks","created_at":"2026-02-20T07:37:12.067810643Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3fo","depends_on_id":"bd-1wz","type":"blocks","created_at":"2026-02-20T07:37:12.519035922Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3fo","depends_on_id":"bd-1xg","type":"blocks","created_at":"2026-02-20T07:37:11.989087818Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3fo","depends_on_id":"bd-20a","type":"blocks","created_at":"2026-02-20T07:37:12.028202556Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3fo","depends_on_id":"bd-20z","type":"blocks","created_at":"2026-02-20T07:37:12.260081623Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3fo","depends_on_id":"bd-229","type":"blocks","created_at":"2026-02-20T07:37:11.949951780Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3fo","depends_on_id":"bd-26k","type":"blocks","created_at":"2026-02-20T07:37:12.183548386Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3fo","depends_on_id":"bd-2ac","type":"blocks","created_at":"2026-02-20T07:36:42.999829460Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3fo","depends_on_id":"bd-2de","type":"blocks","created_at":"2026-02-20T07:36:42.600501940Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3fo","depends_on_id":"bd-2g0","type":"blocks","created_at":"2026-02-20T07:36:43.164646441Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3fo","depends_on_id":"bd-32p","type":"blocks","created_at":"2026-02-20T07:37:12.558528684Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3fo","depends_on_id":"bd-37i","type":"blocks","created_at":"2026-02-20T07:37:12.675325580Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3fo","depends_on_id":"bd-39a","type":"blocks","created_at":"2026-02-20T07:37:12.597436407Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3fo","depends_on_id":"bd-3il","type":"blocks","created_at":"2026-02-20T07:37:11.911697915Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3fo","depends_on_id":"bd-3qo","type":"blocks","created_at":"2026-02-20T07:37:12.416970617Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3fo","depends_on_id":"bd-3qsp","type":"blocks","created_at":"2026-02-20T07:48:05.895248058Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3fo","depends_on_id":"bd-3rc","type":"blocks","created_at":"2026-02-20T07:37:12.106806771Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3fo","depends_on_id":"bd-5rh","type":"blocks","created_at":"2026-02-20T07:37:12.378255974Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3fo","depends_on_id":"bd-c4f","type":"blocks","created_at":"2026-02-20T07:37:12.145428631Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3fo","depends_on_id":"bd-cda","type":"blocks","created_at":"2026-02-20T07:37:09.037682421Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3fo","depends_on_id":"bd-go4","type":"blocks","created_at":"2026-02-20T07:37:12.301336487Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3fo","depends_on_id":"bd-khy","type":"blocks","created_at":"2026-02-20T07:36:43.244272449Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3fo","depends_on_id":"bd-mwf","type":"blocks","created_at":"2026-02-20T07:36:42.840729637Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3fo","depends_on_id":"bd-n71","type":"blocks","created_at":"2026-02-20T07:37:12.456495840Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3fo","depends_on_id":"bd-uo4","type":"blocks","created_at":"2026-02-20T07:36:42.762488900Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3fo","depends_on_id":"bd-y4g","type":"blocks","created_at":"2026-02-20T07:36:42.681380220Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3fo","depends_on_id":"bd-ybe","type":"blocks","created_at":"2026-02-20T07:37:12.636396016Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3fo","depends_on_id":"bd-yqz","type":"blocks","created_at":"2026-02-20T07:36:42.919101499Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-3fr6","title":"Epic: Migration System [10.3]","description":"- type: epic","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-20T07:47:58.072163029Z","updated_at":"2026-02-20T07:49:21.101468746Z","closed_at":"2026-02-20T07:49:21.101451594Z","close_reason":"Superseded by canonical detailed master-plan graph (bd-33v) with full 10.N-10.21 and 11-16 coverage, explicit dependencies, and per-section verification gates.","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-3g4k","title":"[10.18] Implement hash-chained receipt stream with periodic commitment checkpoints.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.18 — Verifiable Execution Fabric Execution Track (9L)\n\nWhy This Exists:\nVEF track for proof-carrying runtime compliance: receipt chains, commitment checkpoints, proof generation/verification, and claim gating.\n\nTask Objective:\nImplement hash-chained receipt stream with periodic commitment checkpoints.\n\nAcceptance Criteria:\n- Receipt stream is append-only with deterministic chain linkage; checkpoint commitments are reproducible; tamper detection is fail-closed.\n\nExpected Artifacts:\n- `src/trust/vef_receipt_chain.rs`, `tests/conformance/vef_receipt_chain_integrity.rs`, `artifacts/10.18/vef_receipt_commitment_log.jsonl`.\n\n- Machine-readable verification artifact at `artifacts/section_10_18/bd-3g4k/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_18/bd-3g4k/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.18] Implement hash-chained receipt stream with periodic commitment checkpoints.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.18] Implement hash-chained receipt stream with periodic commitment checkpoints.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.18] Implement hash-chained receipt stream with periodic commitment checkpoints.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.18] Implement hash-chained receipt stream with periodic commitment checkpoints.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.18] Implement hash-chained receipt stream with periodic commitment checkpoints.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- Receipt stream is append-only with deterministic chain linkage; checkpoint commitments are reproducible; tamper detection is fail-closed.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:37:04.375699004Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:57.117043373Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-18","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-3g4k","depends_on_id":"bd-p73r","type":"blocks","created_at":"2026-02-20T07:43:19.008310781Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-3ghc","title":"Epic: Asupersync Remote + Evidence Integration [10.15c]","description":"- type: epic","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-20T07:47:58.072163029Z","updated_at":"2026-02-20T07:49:21.267153425Z","closed_at":"2026-02-20T07:49:21.267132776Z","close_reason":"Superseded by canonical detailed master-plan graph (bd-33v) with full 10.N-10.21 and 11-16 coverage, explicit dependencies, and per-section verification gates.","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-3gnh","title":"[10.15] Add observability dashboards for region health, obligation health, lane pressure, and cancel latency.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.15 — Asupersync-First Integration Execution Track (8.4-8.6)\n\nWhy This Exists:\nAsupersync-first control-plane migration track enforcing Cx-first, region ownership, cancellation correctness, and protocol-grade verification gates.\n\nTask Objective:\nAdd observability dashboards for region health, obligation health, lane pressure, and cancel latency.\n\nAcceptance Criteria:\n- Dashboards expose core runtime health invariants with alert thresholds; metrics are mapped to runbook actions.\n\nExpected Artifacts:\n- `docs/observability/asupersync_control_dashboards.md`, `artifacts/10.15/dashboard_snapshot.json`, `artifacts/10.15/alert_policy_map.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_15/bd-3gnh/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_15/bd-3gnh/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.15] Add observability dashboards for region health, obligation health, lane pressure, and cancel latency.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.15] Add observability dashboards for region health, obligation health, lane pressure, and cancel latency.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.15] Add observability dashboards for region health, obligation health, lane pressure, and cancel latency.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.15] Add observability dashboards for region health, obligation health, lane pressure, and cancel latency.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.15] Add observability dashboards for region health, obligation health, lane pressure, and cancel latency.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- Dashboards expose core runtime health invariants with alert thresholds; metrics are mapped to runbook actions.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:37:01.118361043Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:49.664428703Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-15","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-3gnh","depends_on_id":"bd-h93z","type":"blocks","created_at":"2026-02-20T07:43:17.308443869Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-3go4","title":"[10.18] Integrate VEF coverage and proof-validity metrics into claim compiler and public trust scoreboard.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.18 — Verifiable Execution Fabric Execution Track (9L)\n\nWhy This Exists:\nVEF track for proof-carrying runtime compliance: receipt chains, commitment checkpoints, proof generation/verification, and claim gating.\n\nTask Objective:\nIntegrate VEF coverage and proof-validity metrics into claim compiler and public trust scoreboard.\n\nAcceptance Criteria:\n- Claim compiler can require VEF-backed evidence for security/compliance claims; scoreboard publishes VEF coverage/validity stats with signed evidence links.\n\nExpected Artifacts:\n- `docs/specs/vef_claim_integration.md`, `tests/conformance/vef_claim_gate.rs`, `artifacts/10.18/vef_claim_coverage_snapshot.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_18/bd-3go4/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_18/bd-3go4/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.18] Integrate VEF coverage and proof-validity metrics into claim compiler and public trust scoreboard.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.18] Integrate VEF coverage and proof-validity metrics into claim compiler and public trust scoreboard.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.18] Integrate VEF coverage and proof-validity metrics into claim compiler and public trust scoreboard.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.18] Integrate VEF coverage and proof-validity metrics into claim compiler and public trust scoreboard.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.18] Integrate VEF coverage and proof-validity metrics into claim compiler and public trust scoreboard.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- Claim compiler can require VEF-backed evidence for security/compliance claims; scoreboard publishes VEF coverage/validity stats with signed evidence links.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:37:04.954326332Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:55.377347987Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-18","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-3go4","depends_on_id":"bd-3pds","type":"blocks","created_at":"2026-02-20T07:43:19.303548222Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-3gwi","title":"[10.19] Implement contribution-weighted intelligence access policy and reciprocity controls.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.19 — Adversarial Trust Commons Execution Track (9M)\n\nWhy This Exists:\nATC federated intelligence track for privacy-preserving cross-deployment threat learning, robust aggregation, and verifier-backed trust metrics.\n\nTask Objective:\nImplement contribution-weighted intelligence access policy and reciprocity controls.\n\nAcceptance Criteria:\n- Intelligence access tiers map to measured contribution quality/quantity by policy; free-rider limits and exception paths are explicit and auditable.\n\nExpected Artifacts:\n- `docs/specs/atc_reciprocity_policy.md`, `tests/conformance/atc_reciprocity_enforcement.rs`, `artifacts/10.19/atc_reciprocity_matrix.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_19/bd-3gwi/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_19/bd-3gwi/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.19] Implement contribution-weighted intelligence access policy and reciprocity controls.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.19] Implement contribution-weighted intelligence access policy and reciprocity controls.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.19] Implement contribution-weighted intelligence access policy and reciprocity controls.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.19] Implement contribution-weighted intelligence access policy and reciprocity controls.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.19] Implement contribution-weighted intelligence access policy and reciprocity controls.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- Intelligence access tiers map to measured contribution quality/quantity by policy; free-rider limits and exception paths are explicit and auditable.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:37:05.919149500Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:24.519072581Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-19","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-3gwi","depends_on_id":"bd-2yvw","type":"blocks","created_at":"2026-02-20T07:43:19.786560678Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-3h1g","title":"[14] Publish benchmark specs/harness/datasets/scoring formulas","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 14\n\nTask Objective:\nPublish full benchmark package and scoring semantics for public reproducibility.\n\nExecution Requirements:\n- Make this requirement machine-verifiable and release-gated where applicable.\n- Keep behavior self-documenting so future contributors do not need to re-open the master plan.\n\nTesting & Logging Requirements:\n- Unit tests for rule/contract logic and error conditions.\n- Integration/E2E tests for workflow-level enforcement.\n- Structured logs with stable codes and trace IDs.\n- Reproducible artifacts that prove contract satisfaction.\n\nAcceptance Criteria:\n- Success and failure invariants for [14] Publish benchmark specs/harness/datasets/scoring formulas are explicitly quantified and machine-verifiable.\n- Determinism requirements for [14] Publish benchmark specs/harness/datasets/scoring formulas are validated across repeated runs and adversarial perturbations.\n\n\nExpected Artifacts:\n- Machine-readable verification artifact with explicit canonical path under artifacts/section_14/bd-3h1g/verification_evidence.json, suitable for CI/release gating.\n- Human-readable verification summary with explicit canonical path under artifacts/section_14/bd-3h1g/verification_summary.md, linking implementation intent to measured validation outcomes.\n\nTask-Specific Clarification:\n- The implementation must deliver the exact capability named in the title, with no scope dilution and no silent feature omission.\n- Validation artifacts must include capability-specific thresholds, pass/fail criteria, and reproducible evidence bundles tied to this bead ID.\n- Program/section verification gates must be able to consume this bead's outputs without manual interpretation.\n\nWhy This Improves User Outcomes:\n- \"[14] Publish benchmark specs/harness/datasets/scoring formulas\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[14] Publish benchmark specs/harness/datasets/scoring formulas\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"1. Benchmark specification document published covering: scope, methodology, metrics, scoring formulas, and interpretation guide.\n2. Benchmark harness is open-source, installable via npm or cargo, and runs on Linux/macOS/Windows.\n3. Benchmark datasets are versioned, hosted publicly, and include: (a) API compatibility corpus, (b) performance workloads (throughput, latency, cold start), (c) security attack scenarios.\n4. Scoring formulas are transparent: each metric has a defined formula, input sources, normalization method, and aggregation into overall score.\n5. Harness produces machine-readable output (JSON) and human-readable report (Markdown).\n6. Benchmark is reproducible: same harness + same dataset + same system produces results within 5% variance.\n7. Publication checklist: spec reviewed by >= 2 external reviewers, harness CI-tested on 3 platforms, datasets validated for completeness.\n8. Evidence: benchmark_publication_checklist.json with per-item status.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:39:35.301199420Z","created_by":"ubuntu","updated_at":"2026-02-20T16:08:37.463156629Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-14","self-contained","test-obligations"]}
{"id":"bd-3h63","title":"[10.15] Add saga wrappers with deterministic compensations for multi-step remote+local workflows.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.15 — Asupersync-First Integration Execution Track (8.4-8.6)\n\nWhy This Exists:\nAsupersync-first control-plane migration track enforcing Cx-first, region ownership, cancellation correctness, and protocol-grade verification gates.\n\nTask Objective:\nAdd saga wrappers with deterministic compensations for multi-step remote+local workflows.\n\nAcceptance Criteria:\n- Cancellation/crash at any step leaves equivalent \"never happened\" state or committed terminal state; compensation traces are replay-stable.\n\nExpected Artifacts:\n- `docs/specs/control_sagas.md`, `tests/integration/control_saga_compensation.rs`, `artifacts/10.15/control_saga_traces.jsonl`.\n\n- Machine-readable verification artifact at `artifacts/section_10_15/bd-3h63/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_15/bd-3h63/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.15] Add saga wrappers with deterministic compensations for multi-step remote+local workflows.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.15] Add saga wrappers with deterministic compensations for multi-step remote+local workflows.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.15] Add saga wrappers with deterministic compensations for multi-step remote+local workflows.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.15] Add saga wrappers with deterministic compensations for multi-step remote+local workflows.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.15] Add saga wrappers with deterministic compensations for multi-step remote+local workflows.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- Cancellation/crash at any step leaves equivalent \"never happened\" state or committed terminal state; compensation traces are replay-stable.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:37:00.301222545Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:51.917584317Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-15","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-3h63","depends_on_id":"bd-12n3","type":"blocks","created_at":"2026-02-20T14:59:48.113662257Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3h63","depends_on_id":"bd-1cwp","type":"blocks","created_at":"2026-02-20T07:43:16.881318361Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3h63","depends_on_id":"bd-ac83","type":"blocks","created_at":"2026-02-20T14:59:47.982183828Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-3hdv","title":"[10.14] Define monotonic control epoch in canonical manifest state.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.14 — FrankenSQLite Deep-Mined Expansion Execution Track (9J)\n\nWhy This Exists:\nFrankenSQLite deep-mined control integrity track: evidence ledgers, proofs, epochs, remote effects, markers/MMR, and deterministic fault labs.\n\nTask Objective:\nDefine monotonic control epoch in canonical manifest state.\n\nAcceptance Criteria:\n- Epoch value is monotonic and durable; regressions are rejected; epoch changes produce signed control events.\n\nExpected Artifacts:\n- `docs/specs/control_epoch_contract.md`, `tests/conformance/control_epoch_monotonicity.rs`, `artifacts/10.14/control_epoch_history.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_14/bd-3hdv/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_14/bd-3hdv/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.14] Define monotonic control epoch in canonical manifest state.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.14] Define monotonic control epoch in canonical manifest state.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.14] Define monotonic control epoch in canonical manifest state.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.14] Define monotonic control epoch in canonical manifest state.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.14] Define monotonic control epoch in canonical manifest state.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"Epoch value is monotonic and durable; regressions are rejected; epoch changes produce signed control events.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:36:58.142004330Z","created_by":"ubuntu","updated_at":"2026-02-20T15:44:04.972327885Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-14","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-3hdv","depends_on_id":"bd-qlc6","type":"blocks","created_at":"2026-02-20T07:43:15.761119074Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-3he","title":"[10.11] Implement supervision tree with restart budgets and escalation policies.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.11 — FrankenSQLite-Inspired Runtime Systems Integration Track\n\nWhy This Exists:\nFrankenSQLite-inspired systems integration of capabilities, cancellation protocol, obligations, deterministic labs, and anti-entropy.\n\nTask Objective:\nImplement supervision tree with restart budgets and escalation policies.\n\nAcceptance Criteria:\n- Implement with explicit success/failure invariants and deterministic behavior under normal, edge, and fault scenarios.\n- Ensure outcomes are verifiable via automated tests and reproducible artifact outputs.\n\nExpected Artifacts:\n- Section-owned design/spec artifact at `docs/specs/section_10_11/bd-3he_contract.md`, capturing decision rationale, invariants, and interface boundaries.\n- Machine-readable verification artifact at `artifacts/section_10_11/bd-3he/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_11/bd-3he/verification_summary.md` linking implementation intent to measured outcomes.\n\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.11] Implement supervision tree with restart budgets and escalation policies.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.11] Implement supervision tree with restart budgets and escalation policies.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.11] Implement supervision tree with restart budgets and escalation policies.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.11] Implement supervision tree with restart budgets and escalation policies.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.11] Implement supervision tree with restart budgets and escalation policies.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"AC for bd-3he:\n1. A SupervisionTree structure models parent-child relationships between supervised actors/tasks, where each node has a configurable RestartBudget (max_restarts: u32, window: Duration).\n2. When a child fails, the supervisor applies the restart policy: if restarts remaining in the current window > 0, restart the child and decrement the budget; if budget is exhausted, escalate to the parent supervisor.\n3. Escalation policies are configurable per node: RestartChild (default), RestartAllChildren (one-for-all), EscalateToParent, and ShutdownSubtree.\n4. The root supervisor has no parent; budget exhaustion at the root triggers a controlled system shutdown with SUPERVISION_ROOT_EXHAUSTED event and a full tree status dump.\n5. Restart budgets use a sliding window (not fixed intervals): the window tracks the timestamp of each restart and expires old entries, so bursts are correctly detected.\n6. Each supervisor node exposes metrics: restart_count (counter), active_children (gauge), budget_remaining (gauge), and escalation_count (counter).\n7. The supervision tree integrates with the cancellation protocol (bd-7om): shutting down a subtree sends cancel -> drain -> finalize to all children in reverse dependency order (leaves first, then parents).\n8. Unit tests verify: (a) child restart within budget succeeds, (b) budget exhaustion triggers escalation, (c) one-for-all policy restarts all siblings, (d) root exhaustion triggers shutdown, (e) sliding window correctly expires old restarts, (f) subtree shutdown follows cancel -> drain -> finalize order.\n9. Structured log events: CHILD_STARTED / CHILD_FAILED / CHILD_RESTARTED / BUDGET_EXHAUSTED / ESCALATION_TRIGGERED / SUBTREE_SHUTDOWN with supervisor path and child ID.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:36:50.140473702Z","created_by":"ubuntu","updated_at":"2026-02-20T15:18:22.856460145Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-11","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-3he","depends_on_id":"bd-2ah","type":"blocks","created_at":"2026-02-20T07:43:11.578915532Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-3hm","title":"[10.12] Define migration singularity artifact contract and verifier format.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.12 — Frontier Programs Execution Track (9H)\n\nWhy This Exists:\nFrontier program execution turning migration singularity, trust fabric, verifier economy, and operator intelligence into production flow.\n\nTask Objective:\nDefine migration singularity artifact contract and verifier format.\n\nAcceptance Criteria:\n- Implement with explicit success/failure invariants and deterministic behavior under normal, edge, and fault scenarios.\n- Ensure outcomes are verifiable via automated tests and reproducible artifact outputs.\n\nExpected Artifacts:\n- Section-owned design/spec artifact at `docs/specs/section_10_12/bd-3hm_contract.md`, capturing decision rationale, invariants, and interface boundaries.\n- Machine-readable verification artifact at `artifacts/section_10_12/bd-3hm/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_12/bd-3hm/verification_summary.md` linking implementation intent to measured outcomes.\n\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.12] Define migration singularity artifact contract and verifier format.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.12] Define migration singularity artifact contract and verifier format.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.12] Define migration singularity artifact contract and verifier format.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.12] Define migration singularity artifact contract and verifier format.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.12] Define migration singularity artifact contract and verifier format.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"1. Define a MigrationSingularityArtifact struct containing: (a) artifact_id (TrustObjectId with unique domain tag MIGRATION or reuse POLICY), (b) source_system_fingerprint (hash of the pre-migration system state), (c) target_system_fingerprint (hash of the expected post-migration state), (d) migration_plan_hash (SHA-256 of the canonical-serialized migration plan), (e) rollback_receipt (a signed proof that the migration can be reversed), (f) precondition_checks (list of {check_name, pass/fail, evidence_hash}), (g) postcondition_checks (same structure), (h) created_at, (i) signer_key_id.\n2. Define a VerifierFormat spec: the artifact MUST be serializable to a self-contained JSON document that an independent verifier can validate without access to the source system. The JSON schema MUST be versioned (schema_version field) and published in docs/specs/section_10_12/migration_artifact_schema.json.\n3. Implement MigrationSingularityArtifact::validate_structure() that checks: (a) all required fields are present, (b) artifact_id is well-formed, (c) at least one precondition and one postcondition check exist, (d) rollback_receipt is parseable and signature-verifiable.\n4. Implement a rollback receipt format: RollbackReceipt containing (a) original_artifact_id, (b) rollback_plan_hash, (c) rollback_deadline (UTC timestamp after which rollback is no longer guaranteed), (d) signer_key_id, (e) signature. The receipt MUST be verifiable using the signer's public key from the key-role registry (bd-364).\n5. Implement schema evolution rules: (a) new fields may be added as optional, (b) existing required fields MUST NOT be removed, (c) field types MUST NOT change. Provide a schema_compatible(old_version, new_version) check.\n6. Unit tests: (a) valid artifact construction and serialization, (b) missing required field rejection, (c) rollback receipt signature verification, (d) schema compatibility check for additive change, (e) schema compatibility check rejects breaking change, (f) round-trip serialize/deserialize identity.\n7. Golden fixture: a complete migration artifact with rollback receipt in vectors/migration_singularity_artifact.json.\n8. Verification: scripts/check_migration_artifact.py --json, artifacts at artifacts/section_10_12/bd-3hm/.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:36:50.834582916Z","created_by":"ubuntu","updated_at":"2026-02-20T15:39:14.411931004Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-12","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-3hm","depends_on_id":"bd-1wz","type":"blocks","created_at":"2026-02-20T07:46:32.054913239Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3hm","depends_on_id":"bd-1xg","type":"blocks","created_at":"2026-02-20T07:46:32.116003832Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3hm","depends_on_id":"bd-20a","type":"blocks","created_at":"2026-02-20T07:46:32.182601201Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3hm","depends_on_id":"bd-229","type":"blocks","created_at":"2026-02-20T07:46:32.261976220Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3hm","depends_on_id":"bd-cda","type":"blocks","created_at":"2026-02-20T07:46:32.322273695Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-3hr2","title":"[10.19] Section-wide verification gate: comprehensive unit+e2e+logging","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.19\n\nTask Objective:\nCreate a hard section completion gate that verifies all implemented behavior in this section with comprehensive unit tests, integration/e2e scripts, and detailed structured logging evidence.\n\nAcceptance Criteria:\n- Section test matrix covers happy-path, edge-case, and adversarial/error-path scenarios for all section deliverables.\n- E2E scripts execute representative end-user workflows and policy/control-plane transitions for this section.\n- Structured logs include stable event/error codes, trace correlation IDs, and enough context for deterministic replay triage.\n- Verification report is deterministic and machine-readable for CI/release gating.\n\nExpected Artifacts:\n- Section-level test matrix and coverage summary artifact.\n- E2E script suite with pass/fail outputs and reproducible fixtures/seeds.\n- Structured log validation report and traceability bundle.\n- Gate verdict artifact consumable by release automation.\n\n- Machine-readable verification artifact at `artifacts/section_10_19/bd-3hr2/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_19/bd-3hr2/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests must validate contracts, invariants, and failure semantics.\n- E2E tests must validate cross-component behavior from user/operator entrypoints to persisted effects.\n- Logging must support root-cause analysis without hidden context requirements.\n\nTask-Specific Clarification:\n- For \"[10.19] Section-wide verification gate: comprehensive unit+e2e+logging\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.19] Section-wide verification gate: comprehensive unit+e2e+logging\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.19] Section-wide verification gate: comprehensive unit+e2e+logging\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.19] Section-wide verification gate: comprehensive unit+e2e+logging\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.19] Section-wide verification gate: comprehensive unit+e2e+logging\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- Section test matrix covers happy-path, edge-case, and adversarial/error-path scenarios for all section deliverables.\n- E2E scripts execute representative end-user workflows and policy/control-plane transitions for this section.\n- Structured logs include stable event/error codes, trace correlation IDs, and enough context for deterministic replay triage.\n- Verification report is deterministic and machine-readable for CI/release gating.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:48:18.906875449Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:24.751612699Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-19","test-obligations","verification-gate"],"dependencies":[{"issue_id":"bd-3hr2","depends_on_id":"bd-11rz","type":"blocks","created_at":"2026-02-20T07:48:19.020748614Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3hr2","depends_on_id":"bd-1dpd","type":"blocks","created_at":"2026-02-20T08:24:25.877635349Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3hr2","depends_on_id":"bd-1eot","type":"blocks","created_at":"2026-02-20T07:48:19.166917882Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3hr2","depends_on_id":"bd-1hj3","type":"blocks","created_at":"2026-02-20T07:48:19.511872298Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3hr2","depends_on_id":"bd-24du","type":"blocks","created_at":"2026-02-20T07:48:19.069739152Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3hr2","depends_on_id":"bd-253o","type":"blocks","created_at":"2026-02-20T07:48:19.217751683Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3hr2","depends_on_id":"bd-293y","type":"blocks","created_at":"2026-02-20T07:48:19.639611058Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3hr2","depends_on_id":"bd-2ozr","type":"blocks","created_at":"2026-02-20T07:48:19.360949867Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3hr2","depends_on_id":"bd-2twu","type":"blocks","created_at":"2026-02-20T08:20:51.636842036Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3hr2","depends_on_id":"bd-2yvw","type":"blocks","created_at":"2026-02-20T07:48:19.312954673Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3hr2","depends_on_id":"bd-2zip","type":"blocks","created_at":"2026-02-20T07:48:19.118664658Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3hr2","depends_on_id":"bd-3aqy","type":"blocks","created_at":"2026-02-20T07:48:19.592815869Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3hr2","depends_on_id":"bd-3gwi","type":"blocks","created_at":"2026-02-20T07:48:19.265546934Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3hr2","depends_on_id":"bd-3ps8","type":"blocks","created_at":"2026-02-20T07:48:19.408224588Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3hr2","depends_on_id":"bd-ukh7","type":"blocks","created_at":"2026-02-20T07:48:19.455939690Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-3hw","title":"[10.11] Integrate canonical remote idempotency + saga semantics (from `10.14`) for multi-step workflows.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.11 — FrankenSQLite-Inspired Runtime Systems Integration Track\n\nWhy This Exists:\nFrankenSQLite-inspired systems integration of capabilities, cancellation protocol, obligations, deterministic labs, and anti-entropy.\n\nTask Objective:\nIntegrate canonical remote idempotency + saga semantics (from `10.14`) for multi-step workflows.\n\nAcceptance Criteria:\n- Implement with explicit success/failure invariants and deterministic behavior under normal, edge, and fault scenarios.\n- Ensure outcomes are verifiable via automated tests and reproducible artifact outputs.\n\nExpected Artifacts:\n- Section-owned design/spec artifact at `docs/specs/section_10_11/bd-3hw_contract.md`, capturing decision rationale, invariants, and interface boundaries.\n- Machine-readable verification artifact at `artifacts/section_10_11/bd-3hw/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_11/bd-3hw/verification_summary.md` linking implementation intent to measured outcomes.\n\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.11] Integrate canonical remote idempotency + saga semantics (from `10.14`) for multi-step workflows.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.11] Integrate canonical remote idempotency + saga semantics (from `10.14`) for multi-step workflows.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.11] Integrate canonical remote idempotency + saga semantics (from `10.14`) for multi-step workflows.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.11] Integrate canonical remote idempotency + saga semantics (from `10.14`) for multi-step workflows.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.11] Integrate canonical remote idempotency + saga semantics (from `10.14`) for multi-step workflows.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"AC for bd-3hw:\n1. Integrate the canonical remote idempotency model from 10.14: every remote-effect operation derives an IdempotencyKey from (request_bytes, epoch_id) using a deterministic hash; replayed requests with matching key+payload return the cached outcome without re-execution.\n2. An IdempotencyStore trait provides: lookup(key) -> Option<CachedOutcome>, insert(key, payload_hash, outcome), and expire(older_than: Duration). The store rejects key reuse with a different payload_hash via IDEMPOTENCY_CONFLICT error.\n3. Saga semantics: multi-step workflows are modeled as a Saga<S> with a sequence of Steps, each having a forward action and a compensating action. If step N fails, compensations for steps N-1..0 are executed in reverse order.\n4. The saga coordinator persists step completion state so that crash recovery resumes from the last completed step (forward) or the current compensation step (backward); this integrates with the checkpoint contract (bd-93k).\n5. Compensation actions are idempotent: re-executing a compensation for an already-compensated step is a no-op (verified by idempotency key).\n6. Saga execution is epoch-bound (bd-2gr): a saga started in epoch N that is still in-flight when epoch N+1 activates is either drained to completion or compensated, depending on configurable policy (drain_on_epoch_change vs compensate_on_epoch_change).\n7. Unit tests verify: (a) idempotent replay returns cached outcome, (b) payload mismatch on same key returns IDEMPOTENCY_CONFLICT, (c) saga forward path completes all steps, (d) saga failure at step 3 of 5 compensates steps 2,1,0 in order, (e) crash recovery resumes saga from persisted state, (f) compensation idempotency (double-compensate is no-op).\n8. Integration test: a 5-step saga with injected failure at step 3 demonstrates full compensation and verified resource release.\n9. Structured log events: IDEMPOTENCY_HIT / IDEMPOTENCY_MISS / IDEMPOTENCY_CONFLICT / SAGA_STEP_FORWARD / SAGA_STEP_COMPENSATE / SAGA_COMPLETED / SAGA_COMPENSATED with saga_id, step_index, idempotency_key, and epoch_id.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:36:50.553299304Z","created_by":"ubuntu","updated_at":"2026-02-20T15:19:24.168170557Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-11","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-3hw","depends_on_id":"bd-12n3","type":"blocks","created_at":"2026-02-20T15:00:18.646602108Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3hw","depends_on_id":"bd-206h","type":"blocks","created_at":"2026-02-20T15:00:18.834054666Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3hw","depends_on_id":"bd-2gr","type":"blocks","created_at":"2026-02-20T07:43:11.789571212Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-3i6c","title":"[10.14] Add conformance suite for ledger determinism, idempotency, epoch validity, and marker/MMR proof correctness.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.14 — FrankenSQLite Deep-Mined Expansion Execution Track (9J)\n\nWhy This Exists:\nFrankenSQLite deep-mined control integrity track: evidence ledgers, proofs, epochs, remote effects, markers/MMR, and deterministic fault labs.\n\nTask Objective:\nAdd conformance suite for ledger determinism, idempotency, epoch validity, and marker/MMR proof correctness.\n\nAcceptance Criteria:\n- Suite includes normative fixtures for all four domains; suite is required for release profile claim; failures map to stable conformance IDs.\n\nExpected Artifacts:\n- `tests/conformance/fsqlite_inspired_suite.rs`, `fixtures/conformance/fsqlite_inspired/*`, `artifacts/10.14/fsqlite_inspired_conformance_report.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_14/bd-3i6c/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_14/bd-3i6c/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.14] Add conformance suite for ledger determinism, idempotency, epoch validity, and marker/MMR proof correctness.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.14] Add conformance suite for ledger determinism, idempotency, epoch validity, and marker/MMR proof correctness.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.14] Add conformance suite for ledger determinism, idempotency, epoch validity, and marker/MMR proof correctness.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.14] Add conformance suite for ledger determinism, idempotency, epoch validity, and marker/MMR proof correctness.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.14] Add conformance suite for ledger determinism, idempotency, epoch validity, and marker/MMR proof correctness.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"Suite includes normative fixtures for all four domains; suite is required for release profile claim; failures map to stable conformance IDs.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:36:59.393612417Z","created_by":"ubuntu","updated_at":"2026-02-20T15:44:01.776119119Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-14","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-3i6c","depends_on_id":"bd-22yy","type":"blocks","created_at":"2026-02-20T07:43:16.400324425Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-3i9o","title":"[10.13] Implement provenance/attestation policy gates (required attestation types, minimum build assurance, trusted builders).","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.13 — FCP Deep-Mined Expansion Execution Track (9I)\n\nWhy This Exists:\nDeep connector/provider contract track: lifecycle FSMs, conformance harnesses, fencing, sandboxing, revocation freshness, and protocol hardening.\n\nTask Objective:\nImplement provenance/attestation policy gates (required attestation types, minimum build assurance, trusted builders).\n\nAcceptance Criteria:\n- Policy engine enforces required attestations and builder trust constraints; non-compliant artifacts are blocked pre-activation; gate results are signed.\n\nExpected Artifacts:\n- `docs/specs/provenance_policy.md`, `tests/security/attestation_gate.rs`, `artifacts/10.13/provenance_gate_decisions.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_13/bd-3i9o/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_13/bd-3i9o/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.13] Implement provenance/attestation policy gates (required attestation types, minimum build assurance, trusted builders).\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.13] Implement provenance/attestation policy gates (required attestation types, minimum build assurance, trusted builders).\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.13] Implement provenance/attestation policy gates (required attestation types, minimum build assurance, trusted builders).\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.13] Implement provenance/attestation policy gates (required attestation types, minimum build assurance, trusted builders).\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.13] Implement provenance/attestation policy gates (required attestation types, minimum build assurance, trusted builders).\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","status":"closed","priority":1,"issue_type":"task","assignee":"CrimsonCrane","created_at":"2026-02-20T07:36:52.780708056Z","created_by":"ubuntu","updated_at":"2026-02-20T11:46:42.246827311Z","closed_at":"2026-02-20T11:46:42.246798919Z","close_reason":"done","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-13","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-3i9o","depends_on_id":"bd-1z9s","type":"blocks","created_at":"2026-02-20T07:43:12.970190878Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-3id1","title":"[16] Contribution: external red-team and independent evaluations","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 16\n\nTask Objective:\nPublish external red-team and independent evaluation reports.\n\nExecution Requirements:\n- Make this requirement machine-verifiable and release-gated where applicable.\n- Keep behavior self-documenting so future contributors do not need to re-open the master plan.\n\nTesting & Logging Requirements:\n- Unit tests for rule/contract logic and error conditions.\n- Integration/E2E tests for workflow-level enforcement.\n- Structured logs with stable codes and trace IDs.\n- Reproducible artifacts that prove contract satisfaction.\n\nAcceptance Criteria:\n- Success and failure invariants for [16] Contribution: external red-team and independent evaluations are explicitly quantified and machine-verifiable.\n- Determinism requirements for [16] Contribution: external red-team and independent evaluations are validated across repeated runs and adversarial perturbations.\n\n\nExpected Artifacts:\n- Machine-readable verification artifact with explicit canonical path under artifacts/section_16/bd-3id1/verification_evidence.json, suitable for CI/release gating.\n- Human-readable verification summary with explicit canonical path under artifacts/section_16/bd-3id1/verification_summary.md, linking implementation intent to measured validation outcomes.\n\nTask-Specific Clarification:\n- The implementation must deliver the exact capability named in the title, with no scope dilution and no silent feature omission.\n- Validation artifacts must include capability-specific thresholds, pass/fail criteria, and reproducible evidence bundles tied to this bead ID.\n- Program/section verification gates must be able to consume this bead's outputs without manual interpretation.\n\nWhy This Improves User Outcomes:\n- \"[16] Contribution: external red-team and independent evaluations\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[16] Contribution: external red-team and independent evaluations\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"1. At least 2 external red-team exercises conducted by independent security firms or research groups.\n2. Each red-team engagement includes: (a) defined scope (which subsystems are in-scope), (b) rules of engagement, (c) findings report with severity ratings (critical/high/medium/low/informational), (d) remediation timeline for each finding, (e) re-test verification after remediation.\n3. At least 1 independent evaluation (non-red-team) assessing: trust system correctness, compatibility claim validity, or benchmark methodology soundness.\n4. All critical and high findings are remediated within 30 days; medium within 90 days.\n5. Red-team reports are published (with responsible disclosure timeline if needed) including: findings summary, methodology, and franken_node's response.\n6. Independent evaluations are published with evaluator's permission.\n7. Findings from red-team and evaluations are tracked as beads and closed when remediated.\n8. Evidence: external_evaluation_registry.json with per-engagement: evaluator, scope, finding count by severity, remediation status, and publication URL.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:39:37.044915395Z","created_by":"ubuntu","updated_at":"2026-02-20T15:28:33.756811169Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-16","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-3id1","depends_on_id":"bd-nbh7","type":"blocks","created_at":"2026-02-20T07:43:26.680501950Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-3il","title":"[PLAN 10.2] Compatibility Core","description":"Section: 10.2 — Compatibility Core\n\nStrategic Context:\nCompatibility core as strategic wedge: policy-visible behavior, divergence receipts, L1/L2 lockstep, and spec-first fixture governance.\n\nExecution Requirements:\n- Preserve all scoped capabilities from the canonical plan.\n- Keep contracts self-contained so future contributors can execute without reopening the master plan.\n- Require explicit testing strategy (unit + integration/e2e) and structured logging/telemetry for every child bead.\n- Require artifact-backed validation for performance, security, and correctness claims.\n\nDependency Semantics:\n- This epic is blocked by its child implementation beads.\n- Cross-epic dependencies encode strategic sequencing and canonical ownership boundaries.\n\n## Success Criteria\n- All child beads for this section are completed with acceptance artifacts attached and no unresolved blockers.\n- Section-level verification gate for comprehensive unit tests, integration/e2e workflows, and detailed structured logging evidence is green.\n- Scope-to-plan traceability is explicit, with no feature loss versus the canonical plan section.\n\n## Optimization Notes\n- User-Outcome Lens: \"[PLAN 10.2] Compatibility Core\" must improve operator confidence, safety posture, and deterministic recovery behavior under both normal and adversarial conditions.\n- Cross-Section Coordination: child beads must encode integration assumptions explicitly to avoid local optimizations that degrade system-wide correctness.\n- Verification Non-Negotiable: completion requires reproducible unit/integration/E2E evidence and structured logs suitable for independent replay.\n- Scope Protection: any simplification must preserve canonical-plan feature intent and be justified with explicit tradeoff documentation.","status":"closed","priority":2,"issue_type":"epic","created_at":"2026-02-20T07:36:40.377571480Z","created_by":"ubuntu","updated_at":"2026-02-20T10:05:27.181170544Z","closed_at":"2026-02-20T10:05:27.181144235Z","close_reason":"done","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-2"],"dependencies":[{"issue_id":"bd-3il","depends_on_id":"bd-1ck","type":"blocks","created_at":"2026-02-20T07:36:44.438983595Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3il","depends_on_id":"bd-1ow","type":"blocks","created_at":"2026-02-20T07:37:09.893838928Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3il","depends_on_id":"bd-1z3","type":"blocks","created_at":"2026-02-20T07:36:44.198729738Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3il","depends_on_id":"bd-23ys","type":"blocks","created_at":"2026-02-20T07:48:20.504504177Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3il","depends_on_id":"bd-240","type":"blocks","created_at":"2026-02-20T07:36:44.519440841Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3il","depends_on_id":"bd-2hs","type":"blocks","created_at":"2026-02-20T07:36:44.598252001Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3il","depends_on_id":"bd-2kf","type":"blocks","created_at":"2026-02-20T07:36:44.116856715Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3il","depends_on_id":"bd-2qf","type":"blocks","created_at":"2026-02-20T07:36:43.954455543Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3il","depends_on_id":"bd-2vi","type":"blocks","created_at":"2026-02-20T07:36:44.276333539Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3il","depends_on_id":"bd-2wz","type":"blocks","created_at":"2026-02-20T07:36:43.872334648Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3il","depends_on_id":"bd-32v","type":"blocks","created_at":"2026-02-20T07:36:44.355131936Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3il","depends_on_id":"bd-38l","type":"blocks","created_at":"2026-02-20T07:36:44.034546618Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3il","depends_on_id":"bd-7mt","type":"blocks","created_at":"2026-02-20T07:36:44.755766771Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3il","depends_on_id":"bd-80g","type":"blocks","created_at":"2026-02-20T07:36:44.677334126Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3il","depends_on_id":"bd-cda","type":"blocks","created_at":"2026-02-20T07:37:09.114585838Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-3j4","title":"[10.12] Implement end-to-end migration singularity pipeline for pilot cohorts.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.12 — Frontier Programs Execution Track (9H)\n\nWhy This Exists:\nFrontier program execution turning migration singularity, trust fabric, verifier economy, and operator intelligence into production flow.\n\nTask Objective:\nImplement end-to-end migration singularity pipeline for pilot cohorts.\n\nAcceptance Criteria:\n- Implement with explicit success/failure invariants and deterministic behavior under normal, edge, and fault scenarios.\n- Ensure outcomes are verifiable via automated tests and reproducible artifact outputs.\n\nExpected Artifacts:\n- Section-owned design/spec artifact at `docs/specs/section_10_12/bd-3j4_contract.md`, capturing decision rationale, invariants, and interface boundaries.\n- Machine-readable verification artifact at `artifacts/section_10_12/bd-3j4/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_12/bd-3j4/verification_summary.md` linking implementation intent to measured outcomes.\n\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.12] Implement end-to-end migration singularity pipeline for pilot cohorts.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.12] Implement end-to-end migration singularity pipeline for pilot cohorts.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.12] Implement end-to-end migration singularity pipeline for pilot cohorts.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.12] Implement end-to-end migration singularity pipeline for pilot cohorts.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.12] Implement end-to-end migration singularity pipeline for pilot cohorts.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"1. Implement a MigrationSingularityPipeline that orchestrates the full lifecycle: (a) plan_generation: accept a source system descriptor and produce a machine-checked migration plan, (b) precondition_evaluation: run all precondition checks and collect evidence, (c) execution: apply migration steps with progress tracking, (d) postcondition_evaluation: run all postcondition checks, (e) artifact_emission: produce a MigrationSingularityArtifact (from bd-3hm) with all evidence, (f) rollback_readiness: generate and attach a RollbackReceipt.\n2. Implement pilot cohort management: define a PilotCohort struct with (a) cohort_id, (b) member_count (1-100 for pilot), (c) migration_artifact_ids (one per member), (d) cohort_status (PENDING, IN_PROGRESS, COMPLETED, ROLLED_BACK), (e) started_at, completed_at.\n3. Implement cohort-level rollback: if any member migration fails postcondition checks, the entire cohort MUST be rolled back. Track per-member rollback status. Provide a cohort_rollback(cohort_id) function that invokes rollback for all members.\n4. Implement progress telemetry: emit structured events for each pipeline stage transition (plan_generated, preconditions_passed, executing, postconditions_passed, artifact_emitted, rolled_back) with cohort_id, member_id, duration_ms, and trace correlation ID.\n5. Implement idempotency: re-running the pipeline for an already-completed member (same source fingerprint and plan hash) MUST return the existing artifact rather than re-executing. Detect via the idempotency store from 10.14.\n6. Implement a dry-run mode: execute all stages except the actual migration execution step, producing a DryRunReport with predicted outcome, estimated duration, and identified risks.\n7. Unit tests: (a) full pipeline happy path for a single member, (b) precondition failure aborts before execution, (c) postcondition failure triggers rollback, (d) cohort rollback on partial failure, (e) idempotent re-run returns cached artifact, (f) dry-run mode produces report without side effects.\n8. Integration test: simulate a 5-member pilot cohort, inject one failure, verify cohort-level rollback and telemetry.\n9. Verification: scripts/check_migration_pipeline.py --json, artifacts at artifacts/section_10_12/bd-3j4/.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:36:50.916052848Z","created_by":"ubuntu","updated_at":"2026-02-20T15:39:33.739624922Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-12","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-3j4","depends_on_id":"bd-3hm","type":"blocks","created_at":"2026-02-20T07:43:11.969194895Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-3jc1","title":"[12] Risk control: migration friction persistence","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 12\n\nTask Objective:\nImplement migration autopilot and confidence reporting guardrails to prevent persistent migration friction.\n\nExecution Requirements:\n- Make this requirement machine-verifiable and release-gated where applicable.\n- Keep behavior self-documenting so future contributors do not need to re-open the master plan.\n\nTesting & Logging Requirements:\n- Unit tests for rule/contract logic and error conditions.\n- Integration/E2E tests for workflow-level enforcement.\n- Structured logs with stable codes and trace IDs.\n- Reproducible artifacts that prove contract satisfaction.\n\nAcceptance Criteria:\n- Success and failure invariants for [12] Risk control: migration friction persistence are explicitly quantified and machine-verifiable.\n- Determinism requirements for [12] Risk control: migration friction persistence are validated across repeated runs and adversarial perturbations.\n\n\nExpected Artifacts:\n- Machine-readable verification artifact with explicit canonical path under artifacts/section_12/bd-3jc1/verification_evidence.json, suitable for CI/release gating.\n- Human-readable verification summary with explicit canonical path under artifacts/section_12/bd-3jc1/verification_summary.md, linking implementation intent to measured validation outcomes.\n\nTask-Specific Clarification:\n- The implementation must deliver the exact capability named in the title, with no scope dilution and no silent feature omission.\n- Validation artifacts must include capability-specific thresholds, pass/fail criteria, and reproducible evidence bundles tied to this bead ID.\n- Program/section verification gates must be able to consume this bead's outputs without manual interpretation.\n\nWhy This Improves User Outcomes:\n- \"[12] Risk control: migration friction persistence\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[12] Risk control: migration friction persistence\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"RISK: Migration friction persistence — migration from Node.js/Bun remains painful despite tooling, discouraging adoption.\nIMPACT: Low adoption rates, failed migrations returning to original runtime, negative community perception.\nCOUNTERMEASURES:\n  (a) Migration autopilot: automated tool that handles >= 80% of migration steps without manual intervention.\n  (b) Confidence reporting: migration tool produces a confidence score (0-100) with specific blockers listed.\n  (c) Incremental migration: support running mixed-mode (partial migration) so users are not forced into all-or-nothing.\nVERIFICATION:\n  1. Migration autopilot successfully migrates >= 80% of steps in a representative 10-project cohort without manual intervention.\n  2. Confidence report is generated for every migration attempt, with score and ranked blocker list.\n  3. Confidence score correlates with actual migration success: score >= 80 predicts success >= 90% of the time.\n  4. Mixed-mode operation demonstrated: partially migrated project runs correctly with both runtimes active.\nTEST SCENARIOS:\n  - Scenario A: Run autopilot on Express.js starter app; verify fully automated migration with confidence >= 90.\n  - Scenario B: Run autopilot on project with native C++ addons; verify confidence score < 50 and blockers list includes 'native addon'.\n  - Scenario C: Run mixed-mode on a project with 50% migrated modules; verify both migrated and unmigrated modules function correctly.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:39:33.501591325Z","created_by":"ubuntu","updated_at":"2026-02-20T15:18:30.329786774Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-12","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-3jc1","depends_on_id":"bd-kiqr","type":"blocks","created_at":"2026-02-20T07:43:24.863920726Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-3k6h","title":"E2E Test Scripts + Logging Infrastructure","description":"- type: task","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-20T07:47:58.072163029Z","updated_at":"2026-02-20T07:49:21.333563548Z","closed_at":"2026-02-20T07:49:21.333541487Z","close_reason":"Superseded by canonical detailed master-plan graph (bd-33v) with full 10.N-10.21 and 11-16 coverage, explicit dependencies, and per-section verification gates.","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-3k9t","title":"[BOOTSTRAP] Implement foundation e2e scripts with structured log bundles","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md (Bootstrap integration quality overlay for Sections 10.0–10.5)\nSection: BOOTSTRAP (Foundation E2E and structured logging)\n\nTask Objective:\nImplement bootstrap E2E script suite that exercises command, config, and transplant workflows end-to-end with rich structured logging and reproducible evidence bundles.\n\nAcceptance Criteria:\n- E2E suite covers representative user/operator journeys (`init`, `run`, `doctor`, transplant integrity checks).\n- Scripts emit deterministic machine-readable pass/fail summaries and attach replay inputs.\n- Logs include stable event/error codes, stage markers, and trace-correlation IDs across the full flow.\n\nExpected Artifacts:\n- Bootstrap E2E script suite and execution harness docs.\n- Evidence bundle format containing command outputs, logs, and replay fixtures.\n- CI integration note for running suite in gated pipelines.\n\n- Machine-readable verification artifact at `artifacts/section_bootstrap/bd-3k9t/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_bootstrap/bd-3k9t/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for script helpers/parsers where applicable.\n- E2E self-check runs against fixture environments (clean + degraded + drifted states).\n- Detailed structured logs with per-stage timestamps and failure taxonomy.\n\nTask-Specific Clarification:\n- For \"[BOOTSTRAP] Implement foundation e2e scripts with structured log bundles\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[BOOTSTRAP] Implement foundation e2e scripts with structured log bundles\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[BOOTSTRAP] Implement foundation e2e scripts with structured log bundles\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[BOOTSTRAP] Implement foundation e2e scripts with structured log bundles\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[BOOTSTRAP] Implement foundation e2e scripts with structured log bundles\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T08:03:10.391869457Z","created_by":"ubuntu","updated_at":"2026-02-20T08:46:08.372682252Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["bootstrap","e2e","logging","verification"],"dependencies":[{"issue_id":"bd-3k9t","depends_on_id":"bd-1dpd","type":"blocks","created_at":"2026-02-20T08:24:22.946868179Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3k9t","depends_on_id":"bd-1pk","type":"blocks","created_at":"2026-02-20T08:03:11.274964953Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3k9t","depends_on_id":"bd-1qz","type":"blocks","created_at":"2026-02-20T08:03:11.387735624Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3k9t","depends_on_id":"bd-29q","type":"blocks","created_at":"2026-02-20T08:03:11.647306751Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3k9t","depends_on_id":"bd-2lb","type":"blocks","created_at":"2026-02-20T08:03:10.773258145Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3k9t","depends_on_id":"bd-2nd","type":"blocks","created_at":"2026-02-20T08:03:11.793987344Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3k9t","depends_on_id":"bd-2twu","type":"blocks","created_at":"2026-02-20T08:20:48.131253791Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3k9t","depends_on_id":"bd-32e","type":"blocks","created_at":"2026-02-20T08:03:11.149658132Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3k9t","depends_on_id":"bd-3vk","type":"blocks","created_at":"2026-02-20T08:03:10.905798220Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3k9t","depends_on_id":"bd-7rt","type":"blocks","created_at":"2026-02-20T08:03:11.514369948Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3k9t","depends_on_id":"bd-jvzc","type":"blocks","created_at":"2026-02-20T08:03:10.638125612Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3k9t","depends_on_id":"bd-n9r","type":"blocks","created_at":"2026-02-20T08:03:11.026067868Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-3kn","title":"[10.6] Add packaging profiles for local/dev/enterprise deployments.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.6 — Performance + Packaging\n\nWhy This Exists:\nPerformance and packaging reliability gates: benchmark rigor, latency targets, release integrity, and deterministic rollback bundles.\n\nTask Objective:\nAdd packaging profiles for local/dev/enterprise deployments.\n\nAcceptance Criteria:\n- Implement with explicit success/failure invariants and deterministic behavior under normal, edge, and fault scenarios.\n- Ensure outcomes are verifiable via automated tests and reproducible artifact outputs.\n\nExpected Artifacts:\n- Section-owned design/spec artifact at `docs/specs/section_10_6/bd-3kn_contract.md`, capturing decision rationale, invariants, and interface boundaries.\n- Machine-readable verification artifact at `artifacts/section_10_6/bd-3kn/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_6/bd-3kn/verification_summary.md` linking implementation intent to measured outcomes.\n\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.6] Add packaging profiles for local/dev/enterprise deployments.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.6] Add packaging profiles for local/dev/enterprise deployments.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.6] Add packaging profiles for local/dev/enterprise deployments.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.6] Add packaging profiles for local/dev/enterprise deployments.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.6] Add packaging profiles for local/dev/enterprise deployments.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"1. At least three packaging profiles are defined: local (dev laptop), dev (CI/staging), and enterprise (production/air-gapped).\n2. Each profile is specified in a declarative config file (TOML or JSON) listing included binaries, feature flags, default configs, and resource limits.\n3. Local profile produces a minimal binary with debug symbols and hot-reload support.\n4. Enterprise profile produces a hardened binary with stripped symbols, static linking where possible, and no dev-only dependencies.\n5. A single build command (e.g., cargo build --profile <name> or scripts/package.sh <name>) produces the correct artifact for each profile.\n6. Each profile's output artifact is checksummed (SHA-256) and the checksum is recorded in the build manifest.\n7. Profile selection is documented in a packaging guide under docs/ with a comparison matrix of what each profile includes/excludes.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:36:47.017498866Z","created_by":"ubuntu","updated_at":"2026-02-20T15:15:47.082709055Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-6","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-3kn","depends_on_id":"bd-2q5","type":"blocks","created_at":"2026-02-20T07:43:23.293600138Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-3ku8","title":"[10.17] Define and enforce capability-carrying extension artifact format.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.17 — Radical Expansion Execution Track (9K)\n\nWhy This Exists:\nRadical expansion track for proof-carrying speculation, Bayesian adversary control, time-travel replay, ZK attestations, and claim compiler systems.\n\nTask Objective:\nDefine and enforce capability-carrying extension artifact format.\n\nAcceptance Criteria:\n- Artifact admission fails closed on missing/invalid capability contracts; runtime enforcement matches admitted capability envelope without drift.\n\nExpected Artifacts:\n- `docs/specs/capability_artifact_format.md`, `src/extensions/artifact_contract.rs`, `tests/conformance/capability_artifact_admission.rs`, `artifacts/10.17/capability_artifact_vectors.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_17/bd-3ku8/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_17/bd-3ku8/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.17] Define and enforce capability-carrying extension artifact format.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.17] Define and enforce capability-carrying extension artifact format.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.17] Define and enforce capability-carrying extension artifact format.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.17] Define and enforce capability-carrying extension artifact format.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.17] Define and enforce capability-carrying extension artifact format.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- Artifact admission fails closed on missing/invalid capability contracts; runtime enforcement matches admitted capability envelope without drift.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:37:03.182308178Z","created_by":"ubuntu","updated_at":"2026-02-20T15:46:00.380398370Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-17","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-3ku8","depends_on_id":"bd-1xbc","type":"blocks","created_at":"2026-02-20T07:43:18.391173150Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-3l2p","title":"[10.17] Ship intent-aware remote effects firewall for extension-originated traffic.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.17 — Radical Expansion Execution Track (9K)\n\nWhy This Exists:\nRadical expansion track for proof-carrying speculation, Bayesian adversary control, time-travel replay, ZK attestations, and claim compiler systems.\n\nTask Objective:\nShip intent-aware remote effects firewall for extension-originated traffic.\n\nAcceptance Criteria:\n- Requests receive stable intent classification and policy verdicts; risky intent categories trigger challenge/simulate/deny/quarantine pathways with deterministic receipts.\n\nExpected Artifacts:\n- `src/security/intent_firewall.rs`, `docs/specs/intent_effects_policy.md`, `tests/security/intent_firewall_conformance.rs`, `artifacts/10.17/intent_firewall_eval_report.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_17/bd-3l2p/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_17/bd-3l2p/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.17] Ship intent-aware remote effects firewall for extension-originated traffic.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.17] Ship intent-aware remote effects firewall for extension-originated traffic.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.17] Ship intent-aware remote effects firewall for extension-originated traffic.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.17] Ship intent-aware remote effects firewall for extension-originated traffic.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.17] Ship intent-aware remote effects firewall for extension-originated traffic.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- Requests receive stable intent classification and policy verdicts; risky intent categories trigger challenge/simulate/deny/quarantine pathways with deterministic receipts.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:37:03.680391608Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:59.097319509Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-17","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-3l2p","depends_on_id":"bd-21fo","type":"blocks","created_at":"2026-02-20T07:43:18.644614327Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-3l8d","title":"[11] Contract field: benchmark and correctness artifacts","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 11\n\nTask Objective:\nRequire benchmark and correctness artifacts before merge for all major subsystem changes.\n\nExecution Requirements:\n- Make this requirement machine-verifiable and release-gated where applicable.\n- Keep behavior self-documenting so future contributors do not need to re-open the master plan.\n\nTesting & Logging Requirements:\n- Unit tests for rule/contract logic and error conditions.\n- Integration/E2E tests for workflow-level enforcement.\n- Structured logs with stable codes and trace IDs.\n- Reproducible artifacts that prove contract satisfaction.\n\nAcceptance Criteria:\n- Success and failure invariants for [11] Contract field: benchmark and correctness artifacts are explicitly quantified and machine-verifiable.\n- Determinism requirements for [11] Contract field: benchmark and correctness artifacts are validated across repeated runs and adversarial perturbations.\n\n\nExpected Artifacts:\n- Machine-readable verification artifact with explicit canonical path under artifacts/section_11/bd-3l8d/verification_evidence.json, suitable for CI/release gating.\n- Human-readable verification summary with explicit canonical path under artifacts/section_11/bd-3l8d/verification_summary.md, linking implementation intent to measured validation outcomes.\n\nTask-Specific Clarification:\n- The implementation must deliver the exact capability named in the title, with no scope dilution and no silent feature omission.\n- Validation artifacts must include capability-specific thresholds, pass/fail criteria, and reproducible evidence bundles tied to this bead ID.\n- Program/section verification gates must be able to consume this bead's outputs without manual interpretation.\n\nWhy This Improves User Outcomes:\n- \"[11] Contract field: benchmark and correctness artifacts\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[11] Contract field: benchmark and correctness artifacts\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"1. Every evidence contract includes benchmark and correctness artifacts: (a) benchmark results with metric names, values, and baseline comparisons, (b) correctness proof artifacts (test results, formal verification outputs, or fuzzing coverage reports).\n2. Benchmark artifacts must include: metric name, unit, measured value, baseline value, delta, and whether delta is within acceptable bounds.\n3. Correctness artifacts must include: test suite name, pass/fail counts, coverage percentage, and links to raw test output files.\n4. All artifacts must be persisted under artifacts/section_N/bd-XXX/ with stable filenames.\n5. CI rejects contracts where benchmark section references zero metrics or correctness section references zero test suites.\n6. Unit test: contract with both benchmark table and correctness references passes; contract missing either section fails.\n7. Artifact files referenced in the contract must actually exist at the specified paths (CI checks file existence).","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:39:33.071851427Z","created_by":"ubuntu","updated_at":"2026-02-20T15:16:59.628277804Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-11","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-3l8d","depends_on_id":"bd-nglx","type":"blocks","created_at":"2026-02-20T07:43:24.604980107Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-3lh","title":"[10.6] Add cold-start and p99 latency gates for core workflows.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.6 — Performance + Packaging\n\nWhy This Exists:\nPerformance and packaging reliability gates: benchmark rigor, latency targets, release integrity, and deterministic rollback bundles.\n\nTask Objective:\nAdd cold-start and p99 latency gates for core workflows.\n\nAcceptance Criteria:\n- Implement with explicit success/failure invariants and deterministic behavior under normal, edge, and fault scenarios.\n- Ensure outcomes are verifiable via automated tests and reproducible artifact outputs.\n\nExpected Artifacts:\n- Section-owned design/spec artifact at `docs/specs/section_10_6/bd-3lh_contract.md`, capturing decision rationale, invariants, and interface boundaries.\n- Machine-readable verification artifact at `artifacts/section_10_6/bd-3lh/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_6/bd-3lh/verification_summary.md` linking implementation intent to measured outcomes.\n\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.6] Add cold-start and p99 latency gates for core workflows.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.6] Add cold-start and p99 latency gates for core workflows.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.6] Add cold-start and p99 latency gates for core workflows.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.6] Add cold-start and p99 latency gates for core workflows.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.6] Add cold-start and p99 latency gates for core workflows.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"1. Cold-start gate: franken_node process must reach 'ready' state within a defined SLA threshold (documented in spec), measured from exec to first successful health-check response.\n2. p99 latency gate: core workflows (module-load, require-resolve, compatibility-shim dispatch) must each have a p99 latency ceiling defined in a TOML/JSON config file.\n3. CI pipeline enforces gates: build fails if cold-start or any p99 ceiling is exceeded.\n4. Measurement harness runs at least 1000 iterations per workflow to produce statistically significant tail-latency numbers.\n5. Results include tail-latency notes per Section 7 doctrine: p99, p99.9, and max with jitter analysis.\n6. Before/after comparison table is generated automatically when baselines change.\n7. Gate thresholds are parameterized per deployment profile (local/dev/enterprise) so each tier has appropriate ceilings.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:36:46.779051685Z","created_by":"ubuntu","updated_at":"2026-02-20T15:15:14.202422680Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-6","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-3lh","depends_on_id":"bd-k4s","type":"blocks","created_at":"2026-02-20T07:43:23.163199060Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-3lzk","title":"[10.18] Add release gate requiring VEF-backed evidence for designated high-impact security and compliance claims.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.18 — Verifiable Execution Fabric Execution Track (9L)\n\nWhy This Exists:\nVEF track for proof-carrying runtime compliance: receipt chains, commitment checkpoints, proof generation/verification, and claim gating.\n\nTask Objective:\nAdd release gate requiring VEF-backed evidence for designated high-impact security and compliance claims.\n\nAcceptance Criteria:\n- Release pipeline blocks designated claims without VEF evidence coverage; gate output is machine-readable, signed, and externally verifiable.\n\nExpected Artifacts:\n- `.github/workflows/vef-claim-gate.yml`, `docs/conformance/vef_release_claim_gate.md`, `artifacts/10.18/vef_release_gate_report.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_18/bd-3lzk/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_18/bd-3lzk/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.18] Add release gate requiring VEF-backed evidence for designated high-impact security and compliance claims.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.18] Add release gate requiring VEF-backed evidence for designated high-impact security and compliance claims.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.18] Add release gate requiring VEF-backed evidence for designated high-impact security and compliance claims.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.18] Add release gate requiring VEF-backed evidence for designated high-impact security and compliance claims.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.18] Add release gate requiring VEF-backed evidence for designated high-impact security and compliance claims.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- Release pipeline blocks designated claims without VEF evidence coverage; gate output is machine-readable, signed, and externally verifiable.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:37:05.201133996Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:54.669832233Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-18","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-3lzk","depends_on_id":"bd-ufk5","type":"blocks","created_at":"2026-02-20T07:43:19.430443981Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-3m6","title":"[10.8] Implement disaster-recovery drills for control-plane failures.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.8 — Operational Readiness\n\nWhy This Exists:\nOperational readiness and fleet safety posture: control APIs, observability contracts, safe-mode operations, and disaster drills.\n\nTask Objective:\nImplement disaster-recovery drills for control-plane failures.\n\nAcceptance Criteria:\n- Implement with explicit success/failure invariants and deterministic behavior under normal, edge, and fault scenarios.\n- Ensure outcomes are verifiable via automated tests and reproducible artifact outputs.\n\nExpected Artifacts:\n- Section-owned design/spec artifact at `docs/specs/section_10_8/bd-3m6_contract.md`, capturing decision rationale, invariants, and interface boundaries.\n- Machine-readable verification artifact at `artifacts/section_10_8/bd-3m6/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_8/bd-3m6/verification_summary.md` linking implementation intent to measured outcomes.\n\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.8] Implement disaster-recovery drills for control-plane failures.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.8] Implement disaster-recovery drills for control-plane failures.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.8] Implement disaster-recovery drills for control-plane failures.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.8] Implement disaster-recovery drills for control-plane failures.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.8] Implement disaster-recovery drills for control-plane failures.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"1. DR drill covers at minimum: complete control-plane failure, network partition between fleet segments, loss of trust-anchor store, and simultaneous quarantine of >50% of fleet.\n2. Each drill has a written scenario document specifying: preconditions, injected failure, expected system behavior, success criteria, and maximum allowable recovery time.\n3. Drills are executable via automation scripts (scripts/dr_drill_*.sh) that inject failures into a test environment and measure recovery.\n4. Recovery verification is automated: scripts assert that the system returns to a defined healthy state within the time ceiling.\n5. Drill results are captured in a structured JSON report with: scenario ID, start time, recovery time, success/failure status, and any deviations from expected behavior.\n6. At least one drill validates the anti-entropy reconciliation from the fleet control API (cross-reference bd-tg2).\n7. Drill cadence is documented: drills must run at least once per release cycle, with results archived under artifacts/.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:36:48.206127362Z","created_by":"ubuntu","updated_at":"2026-02-20T15:19:15.273767009Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-8","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-3m6","depends_on_id":"bd-nr4","type":"blocks","created_at":"2026-02-20T07:43:23.942011366Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-3mj9","title":"[15] Pillar: enterprise governance integrations","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 15\n\nTask Objective:\nImplement enterprise policy/audit/compliance integration pillar.\n\nExecution Requirements:\n- Make this requirement machine-verifiable and release-gated where applicable.\n- Keep behavior self-documenting so future contributors do not need to re-open the master plan.\n\nTesting & Logging Requirements:\n- Unit tests for rule/contract logic and error conditions.\n- Integration/E2E tests for workflow-level enforcement.\n- Structured logs with stable codes and trace IDs.\n- Reproducible artifacts that prove contract satisfaction.\n\nAcceptance Criteria:\n- Success and failure invariants for [15] Pillar: enterprise governance integrations are explicitly quantified and machine-verifiable.\n- Determinism requirements for [15] Pillar: enterprise governance integrations are validated across repeated runs and adversarial perturbations.\n\n\nExpected Artifacts:\n- Machine-readable verification artifact with explicit canonical path under artifacts/section_15/bd-3mj9/verification_evidence.json, suitable for CI/release gating.\n- Human-readable verification summary with explicit canonical path under artifacts/section_15/bd-3mj9/verification_summary.md, linking implementation intent to measured validation outcomes.\n\nTask-Specific Clarification:\n- The implementation must deliver the exact capability named in the title, with no scope dilution and no silent feature omission.\n- Validation artifacts must include capability-specific thresholds, pass/fail criteria, and reproducible evidence bundles tied to this bead ID.\n- Program/section verification gates must be able to consume this bead's outputs without manual interpretation.\n\nWhy This Improves User Outcomes:\n- \"[15] Pillar: enterprise governance integrations\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[15] Pillar: enterprise governance integrations\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"1. Enterprise governance integration supports >= 3 enterprise platforms: (a) LDAP/Active Directory for identity, (b) SIEM integration (Splunk, ELK, or equivalent) for security event forwarding, (c) policy engine integration (OPA or equivalent) for custom trust policies.\n2. Each integration has: (a) configuration guide, (b) authentication/authorization flow documented, (c) data format specification, (d) test suite validating the integration.\n3. SIEM integration: all security-relevant events (trust decisions, containment actions, revocations) are forwarded in CEF or equivalent standard format.\n4. Policy engine integration: custom policies can override default trust decisions with audit trail.\n5. SSO support: enterprise users authenticate via SAML/OIDC without creating separate credentials.\n6. Compliance reporting: generate reports compatible with SOC2, ISO27001, or equivalent frameworks.\n7. Enterprise integration test suite passes against mock enterprise services in CI.\n8. Evidence: enterprise_integration_status.json with per-platform integration status and test results.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:39:36.353660538Z","created_by":"ubuntu","updated_at":"2026-02-20T15:26:23.932273023Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-15","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-3mj9","depends_on_id":"bd-wpck","type":"blocks","created_at":"2026-02-20T07:43:26.298478993Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-3n2u","title":"[10.13] Publish formal schema spec files and golden vectors for serialization, signatures, and control-channel frames.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.13 — FCP Deep-Mined Expansion Execution Track (9I)\n\nWhy This Exists:\nDeep connector/provider contract track: lifecycle FSMs, conformance harnesses, fencing, sandboxing, revocation freshness, and protocol hardening.\n\nTask Objective:\nPublish formal schema spec files and golden vectors for serialization, signatures, and control-channel frames.\n\nAcceptance Criteria:\n- Normative schema files and golden vectors are versioned and release-published; verification CLI passes full vector suite; vector changes require explicit changelog entry.\n\nExpected Artifacts:\n- `spec/FNODE_TRUST_SCHEMA_V1.cddl`, `vectors/fnode_trust_vectors_v1.json`, `artifacts/10.13/vector_verification_report.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_13/bd-3n2u/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_13/bd-3n2u/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.13] Publish formal schema spec files and golden vectors for serialization, signatures, and control-channel frames.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.13] Publish formal schema spec files and golden vectors for serialization, signatures, and control-channel frames.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.13] Publish formal schema spec files and golden vectors for serialization, signatures, and control-channel frames.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.13] Publish formal schema spec files and golden vectors for serialization, signatures, and control-channel frames.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.13] Publish formal schema spec files and golden vectors for serialization, signatures, and control-channel frames.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","status":"closed","priority":1,"issue_type":"task","assignee":"CrimsonCrane","created_at":"2026-02-20T07:36:55.059574888Z","created_by":"ubuntu","updated_at":"2026-02-20T14:55:48.209691291Z","closed_at":"2026-02-20T14:55:48.209665232Z","close_reason":"done","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-13","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-3n2u","depends_on_id":"bd-29ct","type":"blocks","created_at":"2026-02-20T07:43:14.149707100Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-3n58","title":"[10.13] Add domain-separated interface-hash verification and admission failure telemetry.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.13 — FCP Deep-Mined Expansion Execution Track (9I)\n\nWhy This Exists:\nDeep connector/provider contract track: lifecycle FSMs, conformance harnesses, fencing, sandboxing, revocation freshness, and protocol hardening.\n\nTask Objective:\nAdd domain-separated interface-hash verification and admission failure telemetry.\n\nAcceptance Criteria:\n- Interface hash uses domain-separated derivation; invalid hashes block admission; telemetry exposes rejection code distribution.\n\nExpected Artifacts:\n- `src/security/interface_hash.rs`, `tests/conformance/interface_hash_verification.rs`, `artifacts/10.13/interface_hash_rejection_metrics.csv`.\n\n- Machine-readable verification artifact at `artifacts/section_10_13/bd-3n58/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_13/bd-3n58/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.13] Add domain-separated interface-hash verification and admission failure telemetry.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.13] Add domain-separated interface-hash verification and admission failure telemetry.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.13] Add domain-separated interface-hash verification and admission failure telemetry.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.13] Add domain-separated interface-hash verification and admission failure telemetry.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.13] Add domain-separated interface-hash verification and admission failure telemetry.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","status":"closed","priority":1,"issue_type":"task","assignee":"CrimsonCrane","created_at":"2026-02-20T07:36:52.535107430Z","created_by":"ubuntu","updated_at":"2026-02-20T11:35:56.503105126Z","closed_at":"2026-02-20T11:35:56.503078356Z","close_reason":"done","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-13","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-3n58","depends_on_id":"bd-17mb","type":"blocks","created_at":"2026-02-20T07:43:12.846096877Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-3ndj","title":"[10.16] Define `fastapi_rust` control-plane service integration contract.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.16 — Adjacent Substrate Integration Execution Track (8.7)\n\nWhy This Exists:\nAdjacent substrate integration track to enforce deep composition with frankentui, frankensqlite, sqlmodel_rust, and fastapi_rust.\n\nTask Objective:\nDefine `fastapi_rust` control-plane service integration contract.\n\nAcceptance Criteria:\n- Contract defines endpoint lifecycle, auth/policy hooks, error contract mapping, and observability requirements.\n\nExpected Artifacts:\n- `docs/specs/fastapi_rust_integration_contract.md`, `artifacts/10.16/fastapi_contract_checklist.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_16/bd-3ndj/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_16/bd-3ndj/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.16] Define `fastapi_rust` control-plane service integration contract.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.16] Define `fastapi_rust` control-plane service integration contract.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.16] Define `fastapi_rust` control-plane service integration contract.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.16] Define `fastapi_rust` control-plane service integration contract.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.16] Define `fastapi_rust` control-plane service integration contract.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- Contract defines endpoint lifecycle, auth/policy hooks, error contract mapping, and observability requirements.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:37:02.348772938Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:46.278888718Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-16","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-3ndj","depends_on_id":"bd-1v65","type":"blocks","created_at":"2026-02-20T07:43:17.962147873Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-3nr","title":"[10.5] Implement degraded-mode policy behavior with mandatory audit events.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.5 — Security + Policy Product Surfaces\n\nWhy This Exists:\nSecurity and policy product surfaces: decision receipts, incident replay, expected-loss policying, and auditable degraded-mode behavior.\n\nTask Objective:\nImplement degraded-mode policy behavior with mandatory audit events.\n\nAcceptance Criteria:\n- Implement with explicit success/failure invariants and deterministic behavior under normal, edge, and fault scenarios.\n- Ensure outcomes are verifiable via automated tests and reproducible artifact outputs.\n\nExpected Artifacts:\n- Section-owned design/spec artifact at `docs/specs/section_10_5/bd-3nr_contract.md`, capturing decision rationale, invariants, and interface boundaries.\n- Machine-readable verification artifact at `artifacts/section_10_5/bd-3nr/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_5/bd-3nr/verification_summary.md` linking implementation intent to measured outcomes.\n\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.5] Implement degraded-mode policy behavior with mandatory audit events.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.5] Implement degraded-mode policy behavior with mandatory audit events.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.5] Implement degraded-mode policy behavior with mandatory audit events.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.5] Implement degraded-mode policy behavior with mandatory audit events.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.5] Implement degraded-mode policy behavior with mandatory audit events.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"1. Define a DegradedModePolicy struct containing: mode_name (string), trigger_conditions (Vec<TriggerCondition>), permitted_actions (HashSet<String>), denied_actions (HashSet<String>), mandatory_audit_events (Vec<AuditEventSpec>), and auto_recovery_criteria (Vec<RecoveryCriterion>).\n2. TriggerCondition is an enum with variants: HealthGateFailed(gate_name: String), CapabilityUnavailable(capability_id: String), ErrorRateExceeded { threshold: f64, window_secs: u64 }, and ManualActivation(operator_id: String).\n3. When degraded mode activates, the system must emit a structured DegradedModeEntered audit event containing: timestamp, mode_name, triggering_condition, active_policy_version, and list of denied_actions. This event must be emitted before any action processing resumes.\n4. Every action attempted during degraded mode must produce a DegradedModeActionAudit event containing: timestamp, action_name, actor, permitted (bool), and if denied, the denial_reason referencing the specific denied_actions entry.\n5. Mandatory audit events defined in mandatory_audit_events must fire at configurable intervals (default: every 60s) while degraded mode is active; missing a mandatory event must trigger an alert (separate AuditEventMissed event).\n6. Recovery: when all auto_recovery_criteria are met, emit a DegradedModeExited event and restore normal policy. Recovery must require all criteria satisfied for a stabilization_window (default 300s) before exiting.\n7. Verification: scripts/check_degraded_mode.py --json simulates mode entry, action denial, mandatory audit ticks, and recovery; asserts correct event ordering and completeness; unit tests in tests/test_check_degraded_mode.py cover each trigger variant, the denied-action path, the missed-audit alert, and the stabilization window; evidence in artifacts/section_10_5/bd-3nr/.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:36:46.543807640Z","created_by":"ubuntu","updated_at":"2026-02-20T15:16:11.387047031Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-5","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-3nr","depends_on_id":"bd-33b","type":"blocks","created_at":"2026-02-20T07:43:23.019580574Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-3o6","title":"[10.8] Adopt canonical structured observability + stable error taxonomy contracts (from `10.13`) across operational surfaces.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.8 — Operational Readiness\n\nWhy This Exists:\nOperational readiness and fleet safety posture: control APIs, observability contracts, safe-mode operations, and disaster drills.\n\nTask Objective:\nAdopt canonical structured observability + stable error taxonomy contracts (from `10.13`) across operational surfaces.\n\nAcceptance Criteria:\n- Implement with explicit success/failure invariants and deterministic behavior under normal, edge, and fault scenarios.\n- Ensure outcomes are verifiable via automated tests and reproducible artifact outputs.\n\nExpected Artifacts:\n- Section-owned design/spec artifact at `docs/specs/section_10_8/bd-3o6_contract.md`, capturing decision rationale, invariants, and interface boundaries.\n- Machine-readable verification artifact at `artifacts/section_10_8/bd-3o6/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_8/bd-3o6/verification_summary.md` linking implementation intent to measured outcomes.\n\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.8] Adopt canonical structured observability + stable error taxonomy contracts (from `10.13`) across operational surfaces.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.8] Adopt canonical structured observability + stable error taxonomy contracts (from `10.13`) across operational surfaces.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.8] Adopt canonical structured observability + stable error taxonomy contracts (from `10.13`) across operational surfaces.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.8] Adopt canonical structured observability + stable error taxonomy contracts (from `10.13`) across operational surfaces.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.8] Adopt canonical structured observability + stable error taxonomy contracts (from `10.13`) across operational surfaces.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"1. All log output uses structured format (JSON lines) with mandatory fields: timestamp, level, component, event_type, and correlation_id.\n2. Error taxonomy defines a stable, versioned catalog of error codes organized by domain (connectivity, compatibility, migration, trust, fleet).\n3. Each error code has: unique identifier, severity level, human-readable description, suggested remediation, and a stability guarantee (codes are never reused or silently changed).\n4. Observability contracts from 10.13 (telemetry namespace, trace context) are adopted and all emitted metrics/traces conform to those schemas.\n5. Log schema and error taxonomy are published as JSON Schema files under spec/ for external tooling consumption.\n6. Breaking changes to the error taxonomy require a semver-major bump and a migration note.\n7. Integration test verifies that every code path that produces an error emits a cataloged error code — uncataloged errors cause test failure.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:36:47.864218865Z","created_by":"ubuntu","updated_at":"2026-02-20T15:18:14.689925825Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-8","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-3o6","depends_on_id":"bd-1ugy","type":"blocks","created_at":"2026-02-20T15:00:23.655745001Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3o6","depends_on_id":"bd-novi","type":"blocks","created_at":"2026-02-20T15:00:23.475314471Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3o6","depends_on_id":"bd-tg2","type":"blocks","created_at":"2026-02-20T07:43:23.764046341Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-3ohj","title":"[BOOTSTRAP] Foundation verification gate: comprehensive unit+e2e+logging","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md (Bootstrap integration quality overlay)\nSection: BOOTSTRAP (Foundation verification overlay)\n\nTask Objective:\nCreate a hard bootstrap completion gate requiring comprehensive unit/integration/E2E validation and detailed structured logging evidence before bootstrap epic closure.\n\nAcceptance Criteria:\n- Gate consumes matrix coverage, E2E outcomes, baseline check artifacts, and docs-navigation validation.\n- Gate fails closed on missing evidence, unstable logs, or nondeterministic outcomes.\n- Gate outputs deterministic machine-readable verdict consumable by downstream planning/release automation.\n\nExpected Artifacts:\n- Bootstrap gate policy contract and verdict schema.\n- Gate pass/fail artifact samples with remediation guidance.\n- Traceability report linking each bootstrap bead to verification evidence.\n\n- Machine-readable verification artifact at `artifacts/section_bootstrap/bd-3ohj/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_bootstrap/bd-3ohj/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for gate aggregation/evaluation logic.\n- E2E tests for gate behavior under green, partial, and failing evidence sets.\n- Structured gate logs with explicit failing dimension tags and trace correlation IDs.\n\nTask-Specific Clarification:\n- For \"[BOOTSTRAP] Foundation verification gate: comprehensive unit+e2e+logging\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[BOOTSTRAP] Foundation verification gate: comprehensive unit+e2e+logging\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[BOOTSTRAP] Foundation verification gate: comprehensive unit+e2e+logging\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[BOOTSTRAP] Foundation verification gate: comprehensive unit+e2e+logging\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[BOOTSTRAP] Foundation verification gate: comprehensive unit+e2e+logging\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T08:03:10.519600884Z","created_by":"ubuntu","updated_at":"2026-02-20T08:46:08.183091660Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["bootstrap","test-obligations","verification-gate"],"dependencies":[{"issue_id":"bd-3ohj","depends_on_id":"bd-1dpd","type":"blocks","created_at":"2026-02-20T08:24:23.078691855Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3ohj","depends_on_id":"bd-2a3","type":"blocks","created_at":"2026-02-20T08:03:12.074478046Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3ohj","depends_on_id":"bd-2twu","type":"blocks","created_at":"2026-02-20T08:20:48.304308367Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3ohj","depends_on_id":"bd-3k9t","type":"blocks","created_at":"2026-02-20T08:03:11.943618042Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-3ort","title":"[10.14] Add proof-presence requirement for quarantine promotion in high-assurance modes.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.14 — FrankenSQLite Deep-Mined Expansion Execution Track (9J)\n\nWhy This Exists:\nFrankenSQLite deep-mined control integrity track: evidence ledgers, proofs, epochs, remote effects, markers/MMR, and deterministic fault labs.\n\nTask Objective:\nAdd proof-presence requirement for quarantine promotion in high-assurance modes.\n\nAcceptance Criteria:\n- High-assurance mode promotion fails without required proof bundle; mode toggle is policy-controlled; conformance covers both assurance modes.\n\nExpected Artifacts:\n- `tests/conformance/high_assurance_quarantine_promotion.rs`, `docs/specs/high_assurance_promotion.md`, `artifacts/10.14/high_assurance_promotion_matrix.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_14/bd-3ort/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_14/bd-3ort/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.14] Add proof-presence requirement for quarantine promotion in high-assurance modes.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.14] Add proof-presence requirement for quarantine promotion in high-assurance modes.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.14] Add proof-presence requirement for quarantine promotion in high-assurance modes.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.14] Add proof-presence requirement for quarantine promotion in high-assurance modes.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.14] Add proof-presence requirement for quarantine promotion in high-assurance modes.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"High-assurance mode promotion fails without required proof bundle; mode toggle is policy-controlled; conformance covers both assurance modes.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:36:56.803588168Z","created_by":"ubuntu","updated_at":"2026-02-20T15:44:08.411947262Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-14","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-3ort","depends_on_id":"bd-29yx","type":"blocks","created_at":"2026-02-20T07:43:15.064629734Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-3p74","title":"Epic: Radical Expansion - Time-Travel + Artifacts [10.17b]","description":"- type: epic","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-20T07:47:58.072163029Z","updated_at":"2026-02-20T07:49:21.289235835Z","closed_at":"2026-02-20T07:49:21.289215857Z","close_reason":"Superseded by canonical detailed master-plan graph (bd-33v) with full 10.N-10.21 and 11-16 coverage, explicit dependencies, and per-section verification gates.","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-3p9n","title":"[10.6] Section-wide verification gate: comprehensive unit+e2e+logging","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.6\n\nTask Objective:\nCreate a hard section completion gate that verifies all implemented behavior in this section with comprehensive unit tests, integration/e2e scripts, and detailed structured logging evidence.\n\nAcceptance Criteria:\n- Section test matrix covers happy-path, edge-case, and adversarial/error-path scenarios for all section deliverables.\n- E2E scripts execute representative end-user workflows and policy/control-plane transitions for this section.\n- Structured logs include stable event/error codes, trace correlation IDs, and enough context for deterministic replay triage.\n- Verification report is deterministic and machine-readable for CI/release gating.\n\nExpected Artifacts:\n- Section-level test matrix and coverage summary artifact.\n- E2E script suite with pass/fail outputs and reproducible fixtures/seeds.\n- Structured log validation report and traceability bundle.\n- Gate verdict artifact consumable by release automation.\n\n- Machine-readable verification artifact at `artifacts/section_10_6/bd-3p9n/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_6/bd-3p9n/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests must validate contracts, invariants, and failure semantics.\n- E2E tests must validate cross-component behavior from user/operator entrypoints to persisted effects.\n- Logging must support root-cause analysis without hidden context requirements.\n\nTask-Specific Clarification:\n- For \"[10.6] Section-wide verification gate: comprehensive unit+e2e+logging\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.6] Section-wide verification gate: comprehensive unit+e2e+logging\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.6] Section-wide verification gate: comprehensive unit+e2e+logging\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.6] Section-wide verification gate: comprehensive unit+e2e+logging\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.6] Section-wide verification gate: comprehensive unit+e2e+logging\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"1. Section 10.6 gate aggregates pass/fail status from all sibling beads (bd-k4s, bd-3lh, bd-38m, bd-2q5, bd-3kn, bd-2pw, bd-3q9).\n2. Gate script (scripts/check_section_10_6_gate.py) runs all section verification scripts and produces a unified JSON report.\n3. Gate fails if any sibling bead's verification evidence is missing or shows a failure.\n4. Unit tests cover gate logic: all-pass, single-fail, and missing-evidence scenarios.\n5. Gate produces a section-level summary under artifacts/ with per-bead status, timestamps, and links to individual evidence files.\n6. E2E logging: gate execution emits structured log lines for each sub-check with bead ID, result, and duration.\n7. Gate is idempotent: running it twice in succession with no changes produces identical output.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:48:24.783780697Z","created_by":"ubuntu","updated_at":"2026-02-20T15:16:24.462716885Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-6","test-obligations","verification-gate"],"dependencies":[{"issue_id":"bd-3p9n","depends_on_id":"bd-1dpd","type":"blocks","created_at":"2026-02-20T08:24:24.876702944Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3p9n","depends_on_id":"bd-2pw","type":"blocks","created_at":"2026-02-20T07:48:24.933749843Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3p9n","depends_on_id":"bd-2q5","type":"blocks","created_at":"2026-02-20T07:48:25.029904196Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3p9n","depends_on_id":"bd-2twu","type":"blocks","created_at":"2026-02-20T08:20:50.468307824Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3p9n","depends_on_id":"bd-38m","type":"blocks","created_at":"2026-02-20T07:48:25.078010626Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3p9n","depends_on_id":"bd-3kn","type":"blocks","created_at":"2026-02-20T07:48:24.981114262Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3p9n","depends_on_id":"bd-3lh","type":"blocks","created_at":"2026-02-20T07:48:25.126851335Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3p9n","depends_on_id":"bd-3q9","type":"blocks","created_at":"2026-02-20T07:48:24.885587438Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3p9n","depends_on_id":"bd-k4s","type":"blocks","created_at":"2026-02-20T07:48:25.175550019Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-3pds","title":"[10.18] Integrate VEF evidence into verifier SDK replay capsules and external verification APIs.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.18 — Verifiable Execution Fabric Execution Track (9L)\n\nWhy This Exists:\nVEF track for proof-carrying runtime compliance: receipt chains, commitment checkpoints, proof generation/verification, and claim gating.\n\nTask Objective:\nIntegrate VEF evidence into verifier SDK replay capsules and external verification APIs.\n\nAcceptance Criteria:\n- Replay capsules include receipt commitments, proof references, and verifier-friendly validation metadata; external verifiers can independently validate VEF claims.\n\nExpected Artifacts:\n- `docs/specs/vef_capsule_extension.md`, `tests/conformance/vef_verifier_sdk_integration.rs`, `artifacts/10.18/vef_external_verification_report.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_18/bd-3pds/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_18/bd-3pds/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.18] Integrate VEF evidence into verifier SDK replay capsules and external verification APIs.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.18] Integrate VEF evidence into verifier SDK replay capsules and external verification APIs.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.18] Integrate VEF evidence into verifier SDK replay capsules and external verification APIs.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.18] Integrate VEF evidence into verifier SDK replay capsules and external verification APIs.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.18] Integrate VEF evidence into verifier SDK replay capsules and external verification APIs.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- Replay capsules include receipt commitments, proof references, and verifier-friendly validation metadata; external verifiers can independently validate VEF claims.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:37:04.872225515Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:55.576627997Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-18","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-3pds","depends_on_id":"bd-4jh9","type":"blocks","created_at":"2026-02-20T07:43:19.259144130Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-3po7","title":"[10.20] Section-wide verification gate: comprehensive unit+e2e+logging","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.20\n\nTask Objective:\nCreate a hard section completion gate that verifies all implemented behavior in this section with comprehensive unit tests, integration/e2e scripts, and detailed structured logging evidence.\n\nAcceptance Criteria:\n- Section test matrix covers happy-path, edge-case, and adversarial/error-path scenarios for all section deliverables.\n- E2E scripts execute representative end-user workflows and policy/control-plane transitions for this section.\n- Structured logs include stable event/error codes, trace correlation IDs, and enough context for deterministic replay triage.\n- Verification report is deterministic and machine-readable for CI/release gating.\n\nExpected Artifacts:\n- Section-level test matrix and coverage summary artifact.\n- E2E script suite with pass/fail outputs and reproducible fixtures/seeds.\n- Structured log validation report and traceability bundle.\n- Gate verdict artifact consumable by release automation.\n\n- Machine-readable verification artifact at `artifacts/section_10_20/bd-3po7/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_20/bd-3po7/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests must validate contracts, invariants, and failure semantics.\n- E2E tests must validate cross-component behavior from user/operator entrypoints to persisted effects.\n- Logging must support root-cause analysis without hidden context requirements.\n\nTask-Specific Clarification:\n- For \"[10.20] Section-wide verification gate: comprehensive unit+e2e+logging\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.20] Section-wide verification gate: comprehensive unit+e2e+logging\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.20] Section-wide verification gate: comprehensive unit+e2e+logging\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.20] Section-wide verification gate: comprehensive unit+e2e+logging\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.20] Section-wide verification gate: comprehensive unit+e2e+logging\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- Section test matrix covers happy-path, edge-case, and adversarial/error-path scenarios for all section deliverables.\n- E2E scripts execute representative end-user workflows and policy/control-plane transitions for this section.\n- Structured logs include stable event/error codes, trace correlation IDs, and enough context for deterministic replay triage.\n- Verification report is deterministic and machine-readable for CI/release gating.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:48:20.709409404Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:24.980353011Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-20","test-obligations","verification-gate"],"dependencies":[{"issue_id":"bd-3po7","depends_on_id":"bd-19k2","type":"blocks","created_at":"2026-02-20T07:48:21.061016901Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3po7","depends_on_id":"bd-1dpd","type":"blocks","created_at":"2026-02-20T08:24:25.599914748Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3po7","depends_on_id":"bd-1f8v","type":"blocks","created_at":"2026-02-20T07:48:21.003099437Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3po7","depends_on_id":"bd-1q38","type":"blocks","created_at":"2026-02-20T07:48:21.355393153Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3po7","depends_on_id":"bd-1tnu","type":"blocks","created_at":"2026-02-20T07:48:21.252698508Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3po7","depends_on_id":"bd-2bj4","type":"blocks","created_at":"2026-02-20T07:48:21.501526153Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3po7","depends_on_id":"bd-2d17","type":"blocks","created_at":"2026-02-20T07:48:20.947378384Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3po7","depends_on_id":"bd-2fid","type":"blocks","created_at":"2026-02-20T07:48:21.299719187Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3po7","depends_on_id":"bd-2jns","type":"blocks","created_at":"2026-02-20T07:48:21.404396414Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3po7","depends_on_id":"bd-2twu","type":"blocks","created_at":"2026-02-20T08:20:51.305266418Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3po7","depends_on_id":"bd-2wod","type":"blocks","created_at":"2026-02-20T07:48:21.155362746Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3po7","depends_on_id":"bd-351r","type":"blocks","created_at":"2026-02-20T07:48:21.108297404Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3po7","depends_on_id":"bd-38yt","type":"blocks","created_at":"2026-02-20T07:48:20.834483641Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3po7","depends_on_id":"bd-b541","type":"blocks","created_at":"2026-02-20T07:48:21.550562296Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3po7","depends_on_id":"bd-c97l","type":"blocks","created_at":"2026-02-20T07:48:21.202861935Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3po7","depends_on_id":"bd-cclm","type":"blocks","created_at":"2026-02-20T07:48:20.894532395Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3po7","depends_on_id":"bd-t89w","type":"blocks","created_at":"2026-02-20T07:48:21.452341534Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-3ps8","title":"[10.19] Implement mergeable sketch system for scalable ecosystem pattern sharing.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.19 — Adversarial Trust Commons Execution Track (9M)\n\nWhy This Exists:\nATC federated intelligence track for privacy-preserving cross-deployment threat learning, robust aggregation, and verifier-backed trust metrics.\n\nTask Objective:\nImplement mergeable sketch system for scalable ecosystem pattern sharing.\n\nAcceptance Criteria:\n- Sketch merge semantics are deterministic and bounded-error; bandwidth and compute costs stay within configured budgets under large participant counts.\n\nExpected Artifacts:\n- `src/federation/atc_sketches.rs`, `tests/perf/atc_sketch_scaling.rs`, `artifacts/10.19/atc_sketch_accuracy_report.csv`.\n\n- Machine-readable verification artifact at `artifacts/section_10_19/bd-3ps8/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_19/bd-3ps8/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.19] Implement mergeable sketch system for scalable ecosystem pattern sharing.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.19] Implement mergeable sketch system for scalable ecosystem pattern sharing.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.19] Implement mergeable sketch system for scalable ecosystem pattern sharing.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.19] Implement mergeable sketch system for scalable ecosystem pattern sharing.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.19] Implement mergeable sketch system for scalable ecosystem pattern sharing.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- Sketch merge semantics are deterministic and bounded-error; bandwidth and compute costs stay within configured budgets under large participant counts.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:37:05.669165059Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:25.223453010Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-19","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-3ps8","depends_on_id":"bd-ukh7","type":"blocks","created_at":"2026-02-20T07:43:19.660915157Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-3ptu","title":"[10.18] Add adversarial test suite for receipt tampering, proof replay, stale-policy proofs, and commitment mismatch.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.18 — Verifiable Execution Fabric Execution Track (9L)\n\nWhy This Exists:\nVEF track for proof-carrying runtime compliance: receipt chains, commitment checkpoints, proof generation/verification, and claim gating.\n\nTask Objective:\nAdd adversarial test suite for receipt tampering, proof replay, stale-policy proofs, and commitment mismatch.\n\nAcceptance Criteria:\n- Adversarial scenarios are deterministic and fail closed; mismatch classes map to stable error codes and remediation hints.\n\nExpected Artifacts:\n- `tests/security/vef_adversarial_suite.rs`, `docs/security/vef_adversarial_testing.md`, `artifacts/10.18/vef_adversarial_results.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_18/bd-3ptu/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_18/bd-3ptu/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.18] Add adversarial test suite for receipt tampering, proof replay, stale-policy proofs, and commitment mismatch.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.18] Add adversarial test suite for receipt tampering, proof replay, stale-policy proofs, and commitment mismatch.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.18] Add adversarial test suite for receipt tampering, proof replay, stale-policy proofs, and commitment mismatch.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.18] Add adversarial test suite for receipt tampering, proof replay, stale-policy proofs, and commitment mismatch.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.18] Add adversarial test suite for receipt tampering, proof replay, stale-policy proofs, and commitment mismatch.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- Adversarial scenarios are deterministic and fail closed; mismatch classes map to stable error codes and remediation hints.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:37:05.036498944Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:55.151065768Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-18","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-3ptu","depends_on_id":"bd-3go4","type":"blocks","created_at":"2026-02-20T07:43:19.346263718Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-3q9","title":"[10.6] Add release rollback bundles with deterministic restore checks.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.6 — Performance + Packaging\n\nWhy This Exists:\nPerformance and packaging reliability gates: benchmark rigor, latency targets, release integrity, and deterministic rollback bundles.\n\nTask Objective:\nAdd release rollback bundles with deterministic restore checks.\n\nAcceptance Criteria:\n- Implement with explicit success/failure invariants and deterministic behavior under normal, edge, and fault scenarios.\n- Ensure outcomes are verifiable via automated tests and reproducible artifact outputs.\n\nExpected Artifacts:\n- Section-owned design/spec artifact at `docs/specs/section_10_6/bd-3q9_contract.md`, capturing decision rationale, invariants, and interface boundaries.\n- Machine-readable verification artifact at `artifacts/section_10_6/bd-3q9/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_6/bd-3q9/verification_summary.md` linking implementation intent to measured outcomes.\n\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.6] Add release rollback bundles with deterministic restore checks.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.6] Add release rollback bundles with deterministic restore checks.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.6] Add release rollback bundles with deterministic restore checks.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.6] Add release rollback bundles with deterministic restore checks.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.6] Add release rollback bundles with deterministic restore checks.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"1. Rollback bundle is a self-contained archive containing the previous release binary, its config, migration state snapshot, and a restore manifest.\n2. Deterministic restore: applying a rollback bundle to a clean environment produces a byte-identical state to the pre-upgrade state (verified by checksum comparison).\n3. Restore check script (scripts/verify_rollback.sh) validates bundle integrity, applies it to a temp environment, and confirms deterministic restoration.\n4. Rollback bundles are generated automatically during every release build and stored alongside release artifacts.\n5. Bundle includes a compatibility proof: a record of which versions it can safely roll back from/to.\n6. Restore procedure completes within a defined time ceiling (documented in spec) for the standard deployment size.\n7. CI pipeline includes a rollback-and-verify integration test that upgrades, then rolls back, then asserts state equivalence.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:36:47.183210313Z","created_by":"ubuntu","updated_at":"2026-02-20T15:16:11.814348414Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-6","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-3q9","depends_on_id":"bd-2pw","type":"blocks","created_at":"2026-02-20T07:43:23.379124345Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-3qo","title":"[PLAN 10.15] Asupersync-First Integration Execution Track (8.4-8.6)","description":"Section: 10.15 — Asupersync-First Integration Execution Track (8.4-8.6)\n\nStrategic Context:\nAsupersync-first control-plane migration track enforcing Cx-first, region ownership, cancellation correctness, and protocol-grade verification gates.\n\nExecution Requirements:\n- Preserve all scoped capabilities from the canonical plan.\n- Keep contracts self-contained so future contributors can execute without reopening the master plan.\n- Require explicit testing strategy (unit + integration/e2e) and structured logging/telemetry for every child bead.\n- Require artifact-backed validation for performance, security, and correctness claims.\n\nDependency Semantics:\n- This epic is blocked by its child implementation beads.\n- Cross-epic dependencies encode strategic sequencing and canonical ownership boundaries.\n\n## Success Criteria\n- All child beads for this section are completed with acceptance artifacts attached and no unresolved blockers.\n- Section-level verification gate for comprehensive unit tests, integration/e2e workflows, and detailed structured logging evidence is green.\n- Scope-to-plan traceability is explicit, with no feature loss versus the canonical plan section.\n\n## Optimization Notes\n- User-Outcome Lens: \"[PLAN 10.15] Asupersync-First Integration Execution Track (8.4-8.6)\" must improve operator confidence, safety posture, and deterministic recovery behavior under both normal and adversarial conditions.\n- Cross-Section Coordination: child beads must encode integration assumptions explicitly to avoid local optimizations that degrade system-wide correctness.\n- Verification Non-Negotiable: completion requires reproducible unit/integration/E2E evidence and structured logs suitable for independent replay.\n- Scope Protection: any simplification must preserve canonical-plan feature intent and be justified with explicit tradeoff documentation.","status":"open","priority":1,"issue_type":"epic","created_at":"2026-02-20T07:36:41.453506694Z","created_by":"ubuntu","updated_at":"2026-02-20T08:16:40.108162887Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-15"],"dependencies":[{"issue_id":"bd-3qo","depends_on_id":"bd-145n","type":"blocks","created_at":"2026-02-20T07:37:00.746589551Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3qo","depends_on_id":"bd-15j6","type":"blocks","created_at":"2026-02-20T07:37:00.585278490Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3qo","depends_on_id":"bd-181w","type":"blocks","created_at":"2026-02-20T07:37:00.421192691Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3qo","depends_on_id":"bd-1cs7","type":"blocks","created_at":"2026-02-20T07:36:59.928358869Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3qo","depends_on_id":"bd-1cwp","type":"blocks","created_at":"2026-02-20T07:37:00.257980619Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3qo","depends_on_id":"bd-1f8m","type":"blocks","created_at":"2026-02-20T07:37:01.238015361Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3qo","depends_on_id":"bd-1hbw","type":"blocks","created_at":"2026-02-20T07:37:00.502995994Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3qo","depends_on_id":"bd-1id0","type":"blocks","created_at":"2026-02-20T07:36:59.511565245Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3qo","depends_on_id":"bd-1n5p","type":"blocks","created_at":"2026-02-20T07:37:00.009686516Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3qo","depends_on_id":"bd-1ow","type":"blocks","created_at":"2026-02-20T07:37:11.087554779Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3qo","depends_on_id":"bd-1xwz","type":"blocks","created_at":"2026-02-20T07:37:01.401126034Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3qo","depends_on_id":"bd-20eg","type":"blocks","created_at":"2026-02-20T07:48:15.670063999Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3qo","depends_on_id":"bd-2177","type":"blocks","created_at":"2026-02-20T07:36:59.599731671Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3qo","depends_on_id":"bd-25oa","type":"blocks","created_at":"2026-02-20T07:37:00.992189165Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3qo","depends_on_id":"bd-2g6r","type":"blocks","created_at":"2026-02-20T07:36:59.682462893Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3qo","depends_on_id":"bd-2h2s","type":"blocks","created_at":"2026-02-20T07:37:01.319393552Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3qo","depends_on_id":"bd-2tdi","type":"blocks","created_at":"2026-02-20T07:36:59.846593025Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3qo","depends_on_id":"bd-3014","type":"blocks","created_at":"2026-02-20T07:37:00.175342100Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3qo","depends_on_id":"bd-33kj","type":"blocks","created_at":"2026-02-20T07:37:01.482583323Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3qo","depends_on_id":"bd-3gnh","type":"blocks","created_at":"2026-02-20T07:37:01.155642186Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3qo","depends_on_id":"bd-3h63","type":"blocks","created_at":"2026-02-20T07:37:00.338797355Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3qo","depends_on_id":"bd-3tpg","type":"blocks","created_at":"2026-02-20T07:37:00.828209183Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3qo","depends_on_id":"bd-3u6o","type":"blocks","created_at":"2026-02-20T07:37:00.909187610Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3qo","depends_on_id":"bd-5rh","type":"blocks","created_at":"2026-02-20T07:37:11.126045505Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3qo","depends_on_id":"bd-721z","type":"blocks","created_at":"2026-02-20T07:36:59.766480300Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3qo","depends_on_id":"bd-cda","type":"blocks","created_at":"2026-02-20T07:37:09.623066235Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3qo","depends_on_id":"bd-cuut","type":"blocks","created_at":"2026-02-20T07:37:00.093553323Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3qo","depends_on_id":"bd-h93z","type":"blocks","created_at":"2026-02-20T07:37:01.072709589Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3qo","depends_on_id":"bd-tyr2","type":"blocks","created_at":"2026-02-20T07:37:00.665876499Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-3qsp","title":"[10.0] Section-wide verification gate: comprehensive unit+e2e+logging","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.0\n\nTask Objective:\nCreate a hard section completion gate that verifies all implemented behavior in this section with comprehensive unit tests, integration/e2e scripts, and detailed structured logging evidence.\n\nAcceptance Criteria:\n- Section test matrix covers happy-path, edge-case, and adversarial/error-path scenarios for all section deliverables.\n- E2E scripts execute representative end-user workflows and policy/control-plane transitions for this section.\n- Structured logs include stable event/error codes, trace correlation IDs, and enough context for deterministic replay triage.\n- Verification report is deterministic and machine-readable for CI/release gating.\n\nExpected Artifacts:\n- Section-level test matrix and coverage summary artifact.\n- E2E script suite with pass/fail outputs and reproducible fixtures/seeds.\n- Structured log validation report and traceability bundle.\n- Gate verdict artifact consumable by release automation.\n\n- Machine-readable verification artifact at `artifacts/section_10_0/bd-3qsp/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_0/bd-3qsp/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests must validate contracts, invariants, and failure semantics.\n- E2E tests must validate cross-component behavior from user/operator entrypoints to persisted effects.\n- Logging must support root-cause analysis without hidden context requirements.\n\nTask-Specific Clarification:\n- For \"[10.0] Section-wide verification gate: comprehensive unit+e2e+logging\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.0] Section-wide verification gate: comprehensive unit+e2e+logging\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.0] Section-wide verification gate: comprehensive unit+e2e+logging\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.0] Section-wide verification gate: comprehensive unit+e2e+logging\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.0] Section-wide verification gate: comprehensive unit+e2e+logging\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:48:05.309065965Z","created_by":"ubuntu","updated_at":"2026-02-20T08:43:53.562426330Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-0","test-obligations","verification-gate"],"dependencies":[{"issue_id":"bd-3qsp","depends_on_id":"bd-1dpd","type":"blocks","created_at":"2026-02-20T08:24:27.368025603Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3qsp","depends_on_id":"bd-1nf","type":"blocks","created_at":"2026-02-20T07:48:05.499625522Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3qsp","depends_on_id":"bd-1qp","type":"blocks","created_at":"2026-02-20T07:48:05.843287579Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3qsp","depends_on_id":"bd-2ac","type":"blocks","created_at":"2026-02-20T07:48:05.546095194Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3qsp","depends_on_id":"bd-2de","type":"blocks","created_at":"2026-02-20T07:48:05.793624600Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3qsp","depends_on_id":"bd-2g0","type":"blocks","created_at":"2026-02-20T07:48:05.453113871Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3qsp","depends_on_id":"bd-2twu","type":"blocks","created_at":"2026-02-20T08:20:53.412645689Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3qsp","depends_on_id":"bd-khy","type":"blocks","created_at":"2026-02-20T07:48:05.405752829Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3qsp","depends_on_id":"bd-mwf","type":"blocks","created_at":"2026-02-20T07:48:05.644826295Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3qsp","depends_on_id":"bd-uo4","type":"blocks","created_at":"2026-02-20T07:48:05.694144253Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3qsp","depends_on_id":"bd-y4g","type":"blocks","created_at":"2026-02-20T07:48:05.744199643Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3qsp","depends_on_id":"bd-yqz","type":"blocks","created_at":"2026-02-20T07:48:05.594045694Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-3rai","title":"[10.21] Implement signed lineage graph builder linking versions, maintainers, dependency graph deltas, and build pipeline transitions.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.21 — Behavioral Phenotype Evolution Tracker Execution Track (9O)\n\nWhy This Exists:\nBPET longitudinal phenotype intelligence track for pre-compromise trajectory detection and integration with DGIS/ATC/migration/economic policy.\n\nTask Objective:\nImplement signed lineage graph builder linking versions, maintainers, dependency graph deltas, and build pipeline transitions.\n\nAcceptance Criteria:\n- Lineage graph is replayable and tamper-evident; version ancestry, handoff events, and dependency pivot points are queryable with stable identifiers.\n\nExpected Artifacts:\n- `src/security/bpet/lineage_graph.rs`, `docs/specs/bpet_lineage_contract.md`, `artifacts/10.21/bpet_lineage_snapshot.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_21/bd-3rai/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_21/bd-3rai/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.21] Implement signed lineage graph builder linking versions, maintainers, dependency graph deltas, and build pipeline transitions.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.21] Implement signed lineage graph builder linking versions, maintainers, dependency graph deltas, and build pipeline transitions.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.21] Implement signed lineage graph builder linking versions, maintainers, dependency graph deltas, and build pipeline transitions.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.21] Implement signed lineage graph builder linking versions, maintainers, dependency graph deltas, and build pipeline transitions.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.21] Implement signed lineage graph builder linking versions, maintainers, dependency graph deltas, and build pipeline transitions.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- Lineage graph is replayable and tamper-evident; version ancestry, handoff events, and dependency pivot points are queryable with stable identifiers.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:37:07.857879515Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:25.468835955Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-21","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-3rai","depends_on_id":"bd-2xgs","type":"blocks","created_at":"2026-02-20T07:43:21.343268691Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-3rc","title":"[PLAN 10.7] Conformance + Verification","description":"Section: 10.7 — Conformance + Verification\n\nStrategic Context:\nConformance and verification evidence stack for compatibility, trust protocols, fuzzing, and external reproducibility.\n\nExecution Requirements:\n- Preserve all scoped capabilities from the canonical plan.\n- Keep contracts self-contained so future contributors can execute without reopening the master plan.\n- Require explicit testing strategy (unit + integration/e2e) and structured logging/telemetry for every child bead.\n- Require artifact-backed validation for performance, security, and correctness claims.\n\nDependency Semantics:\n- This epic is blocked by its child implementation beads.\n- Cross-epic dependencies encode strategic sequencing and canonical ownership boundaries.\n\n## Success Criteria\n- All child beads for this section are completed with acceptance artifacts attached and no unresolved blockers.\n- Section-level verification gate for comprehensive unit tests, integration/e2e workflows, and detailed structured logging evidence is green.\n- Scope-to-plan traceability is explicit, with no feature loss versus the canonical plan section.\n\n## Optimization Notes\n- User-Outcome Lens: \"[PLAN 10.7] Conformance + Verification\" must improve operator confidence, safety posture, and deterministic recovery behavior under both normal and adversarial conditions.\n- Cross-Section Coordination: child beads must encode integration assumptions explicitly to avoid local optimizations that degrade system-wide correctness.\n- Verification Non-Negotiable: completion requires reproducible unit/integration/E2E evidence and structured logs suitable for independent replay.\n- Scope Protection: any simplification must preserve canonical-plan feature intent and be justified with explicit tradeoff documentation.","status":"open","priority":2,"issue_type":"epic","created_at":"2026-02-20T07:36:40.788808523Z","created_by":"ubuntu","updated_at":"2026-02-20T08:16:48.822854764Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-7"],"dependencies":[{"issue_id":"bd-3rc","depends_on_id":"bd-1rwq","type":"blocks","created_at":"2026-02-20T07:48:25.814626403Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3rc","depends_on_id":"bd-1ta","type":"blocks","created_at":"2026-02-20T07:37:10.356942993Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3rc","depends_on_id":"bd-1u4","type":"blocks","created_at":"2026-02-20T07:36:47.543636392Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3rc","depends_on_id":"bd-1ul","type":"blocks","created_at":"2026-02-20T07:36:47.464082679Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3rc","depends_on_id":"bd-229","type":"blocks","created_at":"2026-02-20T07:37:10.318911362Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3rc","depends_on_id":"bd-2ja","type":"blocks","created_at":"2026-02-20T07:36:47.301407958Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3rc","depends_on_id":"bd-2pu","type":"blocks","created_at":"2026-02-20T07:36:47.706582098Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3rc","depends_on_id":"bd-3ex","type":"blocks","created_at":"2026-02-20T07:36:47.627010682Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3rc","depends_on_id":"bd-3il","type":"blocks","created_at":"2026-02-20T07:37:10.280281627Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3rc","depends_on_id":"bd-5rh","type":"blocks","created_at":"2026-02-20T07:37:10.395352628Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3rc","depends_on_id":"bd-cda","type":"blocks","created_at":"2026-02-20T07:37:09.309377883Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3rc","depends_on_id":"bd-s6y","type":"blocks","created_at":"2026-02-20T07:36:47.381263934Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-3rp","title":"Build CLI scaffold with clap for franken-node binary","status":"closed","priority":1,"issue_type":"task","assignee":"CoralReef","created_at":"2026-02-20T07:29:16.130665777Z","created_by":"ubuntu","updated_at":"2026-02-20T07:32:07.416297382Z","closed_at":"2026-02-20T07:32:07.416275331Z","close_reason":"CLI scaffold implemented: 10 top-level commands (init, run, migrate, verify, trust, fleet, incident, registry, bench, doctor) with full argument parsing via clap derive. All subcommands match README CLI reference. Compiles clean, clippy clean, fmt clean.","source_repo":".","compaction_level":0,"original_size":0,"labels":["cli","foundation"]}
{"id":"bd-3rya","title":"[10.14] Implement monotonic hardening mode state machine with one-way escalation semantics.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.14 — FrankenSQLite Deep-Mined Expansion Execution Track (9J)\n\nWhy This Exists:\nFrankenSQLite deep-mined control integrity track: evidence ledgers, proofs, epochs, remote effects, markers/MMR, and deterministic fault labs.\n\nTask Objective:\nImplement monotonic hardening mode state machine with one-way escalation semantics.\n\nAcceptance Criteria:\n- Hardening transitions are monotonic unless explicit governance rollback artifact is present; state transitions are durable and replayable; illegal regressions are rejected.\n\nExpected Artifacts:\n- `src/policy/hardening_state_machine.rs`, `tests/security/monotonic_hardening.rs`, `artifacts/10.14/hardening_state_history.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_14/bd-3rya/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_14/bd-3rya/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.14] Implement monotonic hardening mode state machine with one-way escalation semantics.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.14] Implement monotonic hardening mode state machine with one-way escalation semantics.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.14] Implement monotonic hardening mode state machine with one-way escalation semantics.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.14] Implement monotonic hardening mode state machine with one-way escalation semantics.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.14] Implement monotonic hardening mode state machine with one-way escalation semantics.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"Hardening transitions are monotonic unless explicit governance rollback artifact is present; state transitions are durable and replayable; illegal regressions are rejected.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:36:56.036380415Z","created_by":"ubuntu","updated_at":"2026-02-20T15:44:10.371371081Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-14","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-3rya","depends_on_id":"bd-mwvn","type":"blocks","created_at":"2026-02-20T07:43:14.680927020Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-3se1","title":"[11] Contract field: change summary","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 11 — Evidence And Decision Contracts (Mandatory)\nContract Field: 1 of 8 — Change Summary\n\nWhy This Exists:\nSection 11 establishes mandatory evidence contracts for every major subsystem proposal. The 8 required fields are: (1) change summary, (2) compatibility and threat evidence, (3) EV score and tier, (4) expected-loss model, (5) fallback trigger, (6) rollout wedge, (7) rollback command, (8) benchmark and correctness artifacts. The enforcement rule is: NO CONTRACT, NO MERGE. This bead covers field #1: the change summary requirement.\n\nTask Objective:\nImplement the change summary contract requirement: every major subsystem proposal must include a concise, structured change summary with scope, affected contracts, and operational impact.\n\nDetailed Acceptance Criteria:\n1. Change summary template defined with required fields: scope (affected modules/APIs), affected contracts (which beads/specifications this changes), operational impact (what operators need to know), risk delta (how this changes the risk profile).\n2. Template is machine-parseable (structured YAML/TOML/JSON in PR description or companion file).\n3. CI gate enforces presence and completeness of change summary on PRs touching subsystem code.\n4. Change summary links to relevant section beads and contract documents for traceability.\n5. Summary includes backward-compatibility assessment: does this change any existing contracts?\n6. Summary includes forward-compatibility note: does this change enable or block future planned work?\n\nKey Dependencies:\n- Depends on all execution tracks (10.0-10.21) for enforcement — contracts must be applied to real changes.\n- This bead is a prerequisite for all other Section 11 contract fields.\n- The no-contract-no-merge gate (bd-2ut3) depends on all 8 contract field beads.\n\nExpected Artifacts:\n- docs/templates/change_summary_template.md — structured template.\n- CI gate configuration for contract enforcement.\n- Example change summary from a representative subsystem change.\n- artifacts/section_11/bd-3se1/verification_evidence.json\n\nTesting and Logging Requirements:\n- Unit tests: template schema validation (valid/invalid change summaries).\n- Integration tests: CI gate blocks PRs with missing/incomplete change summaries.\n- E2E tests: full PR workflow with change summary -> CI gate -> merge.\n- Structured logs: CONTRACT_CHANGE_SUMMARY_VALIDATED, CONTRACT_MISSING, CONTRACT_INCOMPLETE with PR metadata and trace IDs.","acceptance_criteria":"1. Every proposal/PR includes a structured change-summary field in the evidence contract header.\n2. The change summary must contain: (a) one-line intent statement, (b) list of affected subsystems/modules, (c) surface area delta (new APIs, removed APIs, changed signatures), (d) dependency changes if any.\n3. A CI lint rejects any proposal missing the change-summary field or any of its sub-fields.\n4. Unit test: a mock proposal with all fields present passes validation; one missing any sub-field fails.\n5. The change summary is machine-parseable (JSON or YAML front-matter) so downstream tooling can consume it.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:39:32.476069866Z","created_by":"ubuntu","updated_at":"2026-02-20T16:07:09.152633341Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-11","self-contained","test-obligations"]}
{"id":"bd-3t08","title":"[10.17] Section-wide verification gate: comprehensive unit+e2e+logging","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.17\n\nTask Objective:\nCreate a hard section completion gate that verifies all implemented behavior in this section with comprehensive unit tests, integration/e2e scripts, and detailed structured logging evidence.\n\nAcceptance Criteria:\n- Section test matrix covers happy-path, edge-case, and adversarial/error-path scenarios for all section deliverables.\n- E2E scripts execute representative end-user workflows and policy/control-plane transitions for this section.\n- Structured logs include stable event/error codes, trace correlation IDs, and enough context for deterministic replay triage.\n- Verification report is deterministic and machine-readable for CI/release gating.\n\nExpected Artifacts:\n- Section-level test matrix and coverage summary artifact.\n- E2E script suite with pass/fail outputs and reproducible fixtures/seeds.\n- Structured log validation report and traceability bundle.\n- Gate verdict artifact consumable by release automation.\n\n- Machine-readable verification artifact at `artifacts/section_10_17/bd-3t08/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_17/bd-3t08/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests must validate contracts, invariants, and failure semantics.\n- E2E tests must validate cross-component behavior from user/operator entrypoints to persisted effects.\n- Logging must support root-cause analysis without hidden context requirements.\n\nTask-Specific Clarification:\n- For \"[10.17] Section-wide verification gate: comprehensive unit+e2e+logging\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.17] Section-wide verification gate: comprehensive unit+e2e+logging\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.17] Section-wide verification gate: comprehensive unit+e2e+logging\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.17] Section-wide verification gate: comprehensive unit+e2e+logging\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.17] Section-wide verification gate: comprehensive unit+e2e+logging\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:48:16.943916897Z","created_by":"ubuntu","updated_at":"2026-02-20T08:43:51.425912183Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-17","test-obligations","verification-gate"],"dependencies":[{"issue_id":"bd-3t08","depends_on_id":"bd-1dpd","type":"blocks","created_at":"2026-02-20T08:24:26.149551545Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3t08","depends_on_id":"bd-1nl1","type":"blocks","created_at":"2026-02-20T07:48:17.740999805Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3t08","depends_on_id":"bd-1xbc","type":"blocks","created_at":"2026-02-20T07:48:17.644349328Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3t08","depends_on_id":"bd-21fo","type":"blocks","created_at":"2026-02-20T07:48:17.334312960Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3t08","depends_on_id":"bd-26mk","type":"blocks","created_at":"2026-02-20T07:48:17.388792190Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3t08","depends_on_id":"bd-274s","type":"blocks","created_at":"2026-02-20T07:48:17.693220864Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3t08","depends_on_id":"bd-2iyk","type":"blocks","created_at":"2026-02-20T07:48:17.235791188Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3t08","depends_on_id":"bd-2kd9","type":"blocks","created_at":"2026-02-20T07:48:17.041981697Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3t08","depends_on_id":"bd-2o8b","type":"blocks","created_at":"2026-02-20T07:48:17.139438656Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3t08","depends_on_id":"bd-2twu","type":"blocks","created_at":"2026-02-20T08:20:51.947807078Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3t08","depends_on_id":"bd-383z","type":"blocks","created_at":"2026-02-20T07:48:17.089793810Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3t08","depends_on_id":"bd-3ku8","type":"blocks","created_at":"2026-02-20T07:48:17.595255839Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3t08","depends_on_id":"bd-3l2p","type":"blocks","created_at":"2026-02-20T07:48:17.286109428Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3t08","depends_on_id":"bd-al8i","type":"blocks","created_at":"2026-02-20T07:48:17.439502851Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3t08","depends_on_id":"bd-gad3","type":"blocks","created_at":"2026-02-20T07:48:17.546454985Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3t08","depends_on_id":"bd-kcg9","type":"blocks","created_at":"2026-02-20T07:48:17.494071919Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3t08","depends_on_id":"bd-nbwo","type":"blocks","created_at":"2026-02-20T07:48:17.187204082Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-3tpg","title":"[10.15] Enforce canonical all-point cancellation injection gate (from `10.14`) for critical control workflows.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.15 — Asupersync-First Integration Execution Track (8.4-8.6)\n\nWhy This Exists:\nAsupersync-first control-plane migration track enforcing Cx-first, region ownership, cancellation correctness, and protocol-grade verification gates.\n\nTask Objective:\nEnforce canonical all-point cancellation injection gate (from `10.14`) for critical control workflows.\n\nAcceptance Criteria:\n- Canonical cancellation injection runs on every critical protocol flow; no obligation leaks, no half-commit outcomes, no quiescence violations.\n\nExpected Artifacts:\n- `tests/lab/control_cancellation_injection.rs`, `artifacts/10.15/control_cancel_injection_report.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_15/bd-3tpg/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_15/bd-3tpg/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.15] Enforce canonical all-point cancellation injection gate (from `10.14`) for critical control workflows.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.15] Enforce canonical all-point cancellation injection gate (from `10.14`) for critical control workflows.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.15] Enforce canonical all-point cancellation injection gate (from `10.14`) for critical control workflows.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.15] Enforce canonical all-point cancellation injection gate (from `10.14`) for critical control workflows.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.15] Enforce canonical all-point cancellation injection gate (from `10.14`) for critical control workflows.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- Canonical cancellation injection runs on every critical protocol flow; no obligation leaks, no half-commit outcomes, no quiescence violations.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:37:00.790939581Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:50.577014015Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-15","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-3tpg","depends_on_id":"bd-145n","type":"blocks","created_at":"2026-02-20T07:43:17.139054567Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3tpg","depends_on_id":"bd-876n","type":"blocks","created_at":"2026-02-20T14:59:37.895649831Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-3tzl","title":"[10.13] Add bounded parser/resource-accounting guardrails on control-channel frame decode.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.13 — FCP Deep-Mined Expansion Execution Track (9I)\n\nWhy This Exists:\nDeep connector/provider contract track: lifecycle FSMs, conformance harnesses, fencing, sandboxing, revocation freshness, and protocol hardening.\n\nTask Objective:\nAdd bounded parser/resource-accounting guardrails on control-channel frame decode.\n\nAcceptance Criteria:\n- Decode path enforces byte/CPU/allocation ceilings; oversized/malformed frames fail fast; parse budgets are reflected in telemetry.\n\nExpected Artifacts:\n- `docs/specs/control_channel_parser_limits.md`, `tests/security/parser_budget_guardrails.rs`, `artifacts/10.13/parser_guardrail_metrics.csv`.\n\n- Machine-readable verification artifact at `artifacts/section_10_13/bd-3tzl/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_13/bd-3tzl/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.13] Add bounded parser/resource-accounting guardrails on control-channel frame decode.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.13] Add bounded parser/resource-accounting guardrails on control-channel frame decode.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.13] Add bounded parser/resource-accounting guardrails on control-channel frame decode.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.13] Add bounded parser/resource-accounting guardrails on control-channel frame decode.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.13] Add bounded parser/resource-accounting guardrails on control-channel frame decode.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","status":"closed","priority":1,"issue_type":"task","assignee":"CrimsonCrane","created_at":"2026-02-20T07:36:54.496150518Z","created_by":"ubuntu","updated_at":"2026-02-20T13:12:05.795600879Z","closed_at":"2026-02-20T13:12:05.795572466Z","close_reason":"done","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-13","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-3tzl","depends_on_id":"bd-v97o","type":"blocks","created_at":"2026-02-20T07:43:13.853864652Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-3u2o","title":"[10.16] Add substrate conformance gate in CI to block non-compliant feature merges.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.16 — Adjacent Substrate Integration Execution Track (8.7)\n\nWhy This Exists:\nAdjacent substrate integration track to enforce deep composition with frankentui, frankensqlite, sqlmodel_rust, and fastapi_rust.\n\nTask Objective:\nAdd substrate conformance gate in CI to block non-compliant feature merges.\n\nAcceptance Criteria:\n- CI detects relevant-feature noncompliance with substrate policy; failures include remediation hints and waiver path.\n\nExpected Artifacts:\n- `.github/workflows/adjacent-substrate-gate.yml`, `tests/conformance/adjacent_substrate_gate.rs`, `artifacts/10.16/adjacent_substrate_gate_report.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_16/bd-3u2o/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_16/bd-3u2o/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.16] Add substrate conformance gate in CI to block non-compliant feature merges.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.16] Add substrate conformance gate in CI to block non-compliant feature merges.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.16] Add substrate conformance gate in CI to block non-compliant feature merges.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.16] Add substrate conformance gate in CI to block non-compliant feature merges.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.16] Add substrate conformance gate in CI to block non-compliant feature merges.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- CI detects relevant-feature noncompliance with substrate policy; failures include remediation hints and waiver path.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:37:02.600606433Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:45.608127690Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-16","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-3u2o","depends_on_id":"bd-8l9k","type":"blocks","created_at":"2026-02-20T07:43:18.087162109Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-3u4","title":"[10.11] Implement BOCPD regime detector for workload/incident stream shifts.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.11 — FrankenSQLite-Inspired Runtime Systems Integration Track\n\nWhy This Exists:\nFrankenSQLite-inspired systems integration of capabilities, cancellation protocol, obligations, deterministic labs, and anti-entropy.\n\nTask Objective:\nImplement BOCPD regime detector for workload/incident stream shifts.\n\nAcceptance Criteria:\n- Implement with explicit success/failure invariants and deterministic behavior under normal, edge, and fault scenarios.\n- Ensure outcomes are verifiable via automated tests and reproducible artifact outputs.\n\nExpected Artifacts:\n- Section-owned design/spec artifact at `docs/specs/section_10_11/bd-3u4_contract.md`, capturing decision rationale, invariants, and interface boundaries.\n- Machine-readable verification artifact at `artifacts/section_10_11/bd-3u4/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_11/bd-3u4/verification_summary.md` linking implementation intent to measured outcomes.\n\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.11] Implement BOCPD regime detector for workload/incident stream shifts.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.11] Implement BOCPD regime detector for workload/incident stream shifts.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.11] Implement BOCPD regime detector for workload/incident stream shifts.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.11] Implement BOCPD regime detector for workload/incident stream shifts.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.11] Implement BOCPD regime detector for workload/incident stream shifts.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"AC for bd-3u4:\n1. Implement a BOCPD (Bayesian Online Changepoint Detection) regime detector that processes streaming workload metrics and incident event streams to detect distributional shifts (regime changes) in real time.\n2. The detector maintains a run-length distribution P(r_t | x_{1:t}) updated incrementally with each new observation; the underlying predictive model uses a conjugate-exponential hazard function with configurable prior parameters (hazard_lambda, prior_mean, prior_variance).\n3. A regime change is signaled when the posterior probability of run-length r=0 (new regime) exceeds a configurable threshold (default: 0.5); the signal includes the estimated changepoint timestamp, confidence score, and pre/post regime summary statistics.\n4. The detector supports multiple concurrent streams (e.g., request_rate, error_rate, latency_p99) with independent run-length distributions; a meta-detector can fuse per-stream signals into a joint regime-change verdict.\n5. Detection latency is bounded: the detector must signal a regime change within K observations of the true changepoint (K configurable, default: 10) on synthetic step-function and ramp-function test signals.\n6. Memory is bounded: the run-length distribution is truncated at a configurable max_run_length (default: 500) to prevent unbounded growth; truncation error is logged as BOCPD_TRUNCATION_WARNING when the tail probability exceeds 1e-4.\n7. Unit tests verify: (a) step-function changepoint detected within K observations, (b) ramp-function changepoint detected within 2K observations, (c) stationary stream produces no false positives over 10,000 observations, (d) truncation at max_run_length does not cause missed detections on standard test signals, (e) multi-stream fusion correctly requires majority agreement.\n8. Deterministic lab runtime (bd-2ko) scenario fixtures exercise: sudden load spike, gradual degradation, and oscillating workload patterns.\n9. Structured log events: BOCPD_REGIME_CHANGE / BOCPD_OBSERVATION / BOCPD_TRUNCATION_WARNING with stream_id, run_length, posterior_probability, and trace correlation ID.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:36:50.306945145Z","created_by":"ubuntu","updated_at":"2026-02-20T15:18:48.734995981Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-11","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-3u4","depends_on_id":"bd-2ko","type":"blocks","created_at":"2026-02-20T07:43:11.661955822Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-3u6o","title":"[10.15] Enforce canonical virtual transport fault harness (from `10.14`) for distributed control protocols.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.15 — Asupersync-First Integration Execution Track (8.4-8.6)\n\nWhy This Exists:\nAsupersync-first control-plane migration track enforcing Cx-first, region ownership, cancellation correctness, and protocol-grade verification gates.\n\nTask Objective:\nEnforce canonical virtual transport fault harness (from `10.14`) for distributed control protocols.\n\nAcceptance Criteria:\n- Canonical harness scenarios are deterministic by seed, adopted by control-plane gates, and reproduce distributed protocol decisions and failures.\n\nExpected Artifacts:\n- `tests/harness/control_virtual_transport_faults.rs`, `docs/testing/control_virtual_transport_faults.md`, `artifacts/10.15/control_fault_harness_summary.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_15/bd-3u6o/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_15/bd-3u6o/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.15] Enforce canonical virtual transport fault harness (from `10.14`) for distributed control protocols.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.15] Enforce canonical virtual transport fault harness (from `10.14`) for distributed control protocols.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.15] Enforce canonical virtual transport fault harness (from `10.14`) for distributed control protocols.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.15] Enforce canonical virtual transport fault harness (from `10.14`) for distributed control protocols.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.15] Enforce canonical virtual transport fault harness (from `10.14`) for distributed control protocols.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- Canonical harness scenarios are deterministic by seed, adopted by control-plane gates, and reproduce distributed protocol decisions and failures.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:37:00.871954887Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:50.347028278Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-15","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-3u6o","depends_on_id":"bd-2qqu","type":"blocks","created_at":"2026-02-20T14:59:45.738976001Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3u6o","depends_on_id":"bd-3tpg","type":"blocks","created_at":"2026-02-20T07:43:17.182366785Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-3ua7","title":"[10.13] Implement sandbox profile system (`strict`, `strict_plus`, `moderate`, `permissive`) with policy compiler.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.13 — FCP Deep-Mined Expansion Execution Track (9I)\n\nWhy This Exists:\nDeep connector/provider contract track: lifecycle FSMs, conformance harnesses, fencing, sandboxing, revocation freshness, and protocol hardening.\n\nTask Objective:\nImplement sandbox profile system (`strict`, `strict_plus`, `moderate`, `permissive`) with policy compiler.\n\nAcceptance Criteria:\n- Profile compiler emits enforceable low-level policy for each tier; profile downgrade attempts are blocked by policy; profile selection is auditable.\n\nExpected Artifacts:\n- `src/security/sandbox_policy_compiler.rs`, `docs/specs/sandbox_profiles.md`, `artifacts/10.13/sandbox_profile_compiler_output.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_13/bd-3ua7/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_13/bd-3ua7/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.13] Implement sandbox profile system (`strict`, `strict_plus`, `moderate`, `permissive`) with policy compiler.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.13] Implement sandbox profile system (`strict`, `strict_plus`, `moderate`, `permissive`) with policy compiler.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.13] Implement sandbox profile system (`strict`, `strict_plus`, `moderate`, `permissive`) with policy compiler.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.13] Implement sandbox profile system (`strict`, `strict_plus`, `moderate`, `permissive`) with policy compiler.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.13] Implement sandbox profile system (`strict`, `strict_plus`, `moderate`, `permissive`) with policy compiler.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","status":"closed","priority":1,"issue_type":"task","assignee":"CrimsonCrane","created_at":"2026-02-20T07:36:52.120604764Z","created_by":"ubuntu","updated_at":"2026-02-20T11:12:22.101895921Z","closed_at":"2026-02-20T11:12:22.101868630Z","close_reason":"done","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-13","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-3ua7","depends_on_id":"bd-b44","type":"blocks","created_at":"2026-02-20T07:43:12.610690751Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-3uoo","title":"[10.13] Section-wide verification gate: comprehensive unit+e2e+logging","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.13\n\nTask Objective:\nCreate a hard section completion gate that verifies all implemented behavior in this section with comprehensive unit tests, integration/e2e scripts, and detailed structured logging evidence.\n\nAcceptance Criteria:\n- Section test matrix covers happy-path, edge-case, and adversarial/error-path scenarios for all section deliverables.\n- E2E scripts execute representative end-user workflows and policy/control-plane transitions for this section.\n- Structured logs include stable event/error codes, trace correlation IDs, and enough context for deterministic replay triage.\n- Verification report is deterministic and machine-readable for CI/release gating.\n\nExpected Artifacts:\n- Section-level test matrix and coverage summary artifact.\n- E2E script suite with pass/fail outputs and reproducible fixtures/seeds.\n- Structured log validation report and traceability bundle.\n- Gate verdict artifact consumable by release automation.\n\n- Machine-readable verification artifact at `artifacts/section_10_13/bd-3uoo/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_13/bd-3uoo/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests must validate contracts, invariants, and failure semantics.\n- E2E tests must validate cross-component behavior from user/operator entrypoints to persisted effects.\n- Logging must support root-cause analysis without hidden context requirements.\n\nTask-Specific Clarification:\n- For \"[10.13] Section-wide verification gate: comprehensive unit+e2e+logging\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.13] Section-wide verification gate: comprehensive unit+e2e+logging\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.13] Section-wide verification gate: comprehensive unit+e2e+logging\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.13] Section-wide verification gate: comprehensive unit+e2e+logging\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.13] Section-wide verification gate: comprehensive unit+e2e+logging\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","status":"closed","priority":1,"issue_type":"task","assignee":"CrimsonCrane","created_at":"2026-02-20T07:48:09.057548812Z","created_by":"ubuntu","updated_at":"2026-02-20T14:58:09.613392242Z","closed_at":"2026-02-20T14:58:09.613366023Z","close_reason":"done","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-13","test-obligations","verification-gate"],"dependencies":[{"issue_id":"bd-3uoo","depends_on_id":"bd-12h8","type":"blocks","created_at":"2026-02-20T07:48:09.579670911Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3uoo","depends_on_id":"bd-17mb","type":"blocks","created_at":"2026-02-20T07:48:10.671119018Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3uoo","depends_on_id":"bd-18o","type":"blocks","created_at":"2026-02-20T07:48:11.122058666Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3uoo","depends_on_id":"bd-19u","type":"blocks","created_at":"2026-02-20T07:48:11.001470785Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3uoo","depends_on_id":"bd-1cm","type":"blocks","created_at":"2026-02-20T07:48:11.070824520Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3uoo","depends_on_id":"bd-1d7n","type":"blocks","created_at":"2026-02-20T07:48:10.436300577Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3uoo","depends_on_id":"bd-1dpd","type":"blocks","created_at":"2026-02-20T08:24:26.684476571Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3uoo","depends_on_id":"bd-1gnb","type":"blocks","created_at":"2026-02-20T07:48:09.348117250Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3uoo","depends_on_id":"bd-1h6","type":"blocks","created_at":"2026-02-20T07:48:11.215188585Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3uoo","depends_on_id":"bd-1m8r","type":"blocks","created_at":"2026-02-20T07:48:10.281551108Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3uoo","depends_on_id":"bd-1nk5","type":"blocks","created_at":"2026-02-20T07:48:10.717897355Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3uoo","depends_on_id":"bd-1p2b","type":"blocks","created_at":"2026-02-20T07:48:09.625556565Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3uoo","depends_on_id":"bd-1rk","type":"blocks","created_at":"2026-02-20T07:48:11.262083399Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3uoo","depends_on_id":"bd-1ugy","type":"blocks","created_at":"2026-02-20T07:48:09.439289924Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3uoo","depends_on_id":"bd-1vvs","type":"blocks","created_at":"2026-02-20T07:48:10.812923075Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3uoo","depends_on_id":"bd-1z9s","type":"blocks","created_at":"2026-02-20T07:48:10.529322585Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3uoo","depends_on_id":"bd-24s","type":"blocks","created_at":"2026-02-20T07:48:10.950663333Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3uoo","depends_on_id":"bd-29ct","type":"blocks","created_at":"2026-02-20T07:48:09.203505744Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3uoo","depends_on_id":"bd-29w6","type":"blocks","created_at":"2026-02-20T07:48:09.913344775Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3uoo","depends_on_id":"bd-2eun","type":"blocks","created_at":"2026-02-20T07:48:09.718720057Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3uoo","depends_on_id":"bd-2gh","type":"blocks","created_at":"2026-02-20T07:48:11.309242986Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3uoo","depends_on_id":"bd-2k74","type":"blocks","created_at":"2026-02-20T07:48:09.813875579Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3uoo","depends_on_id":"bd-2m2b","type":"blocks","created_at":"2026-02-20T07:48:10.766822721Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3uoo","depends_on_id":"bd-2t5u","type":"blocks","created_at":"2026-02-20T07:48:09.959896239Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3uoo","depends_on_id":"bd-2twu","type":"blocks","created_at":"2026-02-20T08:20:52.585437456Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3uoo","depends_on_id":"bd-2vs4","type":"blocks","created_at":"2026-02-20T07:48:10.144899037Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3uoo","depends_on_id":"bd-2yc4","type":"blocks","created_at":"2026-02-20T07:48:10.388793993Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3uoo","depends_on_id":"bd-35by","type":"blocks","created_at":"2026-02-20T07:48:09.251232357Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3uoo","depends_on_id":"bd-35q1","type":"blocks","created_at":"2026-02-20T07:48:10.574614183Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3uoo","depends_on_id":"bd-3b8m","type":"blocks","created_at":"2026-02-20T07:48:09.767184805Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3uoo","depends_on_id":"bd-3cm3","type":"blocks","created_at":"2026-02-20T07:48:09.671808401Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3uoo","depends_on_id":"bd-3en","type":"blocks","created_at":"2026-02-20T07:48:11.167972443Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3uoo","depends_on_id":"bd-3i9o","type":"blocks","created_at":"2026-02-20T07:48:10.483292972Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3uoo","depends_on_id":"bd-3n2u","type":"blocks","created_at":"2026-02-20T07:48:09.157882057Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3uoo","depends_on_id":"bd-3n58","type":"blocks","created_at":"2026-02-20T07:48:10.622826671Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3uoo","depends_on_id":"bd-3tzl","type":"blocks","created_at":"2026-02-20T07:48:09.487619811Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3uoo","depends_on_id":"bd-3ua7","type":"blocks","created_at":"2026-02-20T07:48:10.858573291Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3uoo","depends_on_id":"bd-8uvb","type":"blocks","created_at":"2026-02-20T07:48:10.099431451Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3uoo","depends_on_id":"bd-8vby","type":"blocks","created_at":"2026-02-20T07:48:10.053066884Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3uoo","depends_on_id":"bd-91gg","type":"blocks","created_at":"2026-02-20T07:48:09.860890276Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3uoo","depends_on_id":"bd-b44","type":"blocks","created_at":"2026-02-20T07:48:10.904491536Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3uoo","depends_on_id":"bd-bq6y","type":"blocks","created_at":"2026-02-20T07:48:10.190145049Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3uoo","depends_on_id":"bd-ck2h","type":"blocks","created_at":"2026-02-20T07:48:09.299046223Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3uoo","depends_on_id":"bd-jxgt","type":"blocks","created_at":"2026-02-20T07:48:10.005938485Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3uoo","depends_on_id":"bd-novi","type":"blocks","created_at":"2026-02-20T07:48:09.393705110Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3uoo","depends_on_id":"bd-v97o","type":"blocks","created_at":"2026-02-20T07:48:09.534477596Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3uoo","depends_on_id":"bd-w0jq","type":"blocks","created_at":"2026-02-20T07:48:10.235406481Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-3uoo","depends_on_id":"bd-y7lu","type":"blocks","created_at":"2026-02-20T07:48:10.328102442Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-3v8f","title":"[11] Contract field: fallback trigger","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 11\n\nTask Objective:\nRequire deterministic fallback trigger contract for each major subsystem change.\n\nExecution Requirements:\n- Make this requirement machine-verifiable and release-gated where applicable.\n- Keep behavior self-documenting so future contributors do not need to re-open the master plan.\n\nTesting & Logging Requirements:\n- Unit tests for rule/contract logic and error conditions.\n- Integration/E2E tests for workflow-level enforcement.\n- Structured logs with stable codes and trace IDs.\n- Reproducible artifacts that prove contract satisfaction.\n\nAcceptance Criteria:\n- Success and failure invariants for [11] Contract field: fallback trigger are explicitly quantified and machine-verifiable.\n- Determinism requirements for [11] Contract field: fallback trigger are validated across repeated runs and adversarial perturbations.\n\n\nExpected Artifacts:\n- Machine-readable verification artifact with explicit canonical path under artifacts/section_11/bd-3v8f/verification_evidence.json, suitable for CI/release gating.\n- Human-readable verification summary with explicit canonical path under artifacts/section_11/bd-3v8f/verification_summary.md, linking implementation intent to measured validation outcomes.\n\nTask-Specific Clarification:\n- The implementation must deliver the exact capability named in the title, with no scope dilution and no silent feature omission.\n- Validation artifacts must include capability-specific thresholds, pass/fail criteria, and reproducible evidence bundles tied to this bead ID.\n- Program/section verification gates must be able to consume this bead's outputs without manual interpretation.\n\nWhy This Improves User Outcomes:\n- \"[11] Contract field: fallback trigger\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[11] Contract field: fallback trigger\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"1. Every evidence contract specifies a fallback trigger: a concrete, measurable condition that activates the rollback path.\n2. Trigger must be expressed as a threshold on an observable metric (e.g., error rate > 5%, p99 latency > 200ms, compatibility pass rate < 90%).\n3. The trigger must specify: (a) metric name and source, (b) threshold value, (c) evaluation window (e.g., 5-minute rolling), (d) minimum sample size before trigger is armed.\n4. CI rejects contracts where fallback trigger is missing, uses vague language ('if things go wrong'), or lacks numeric threshold.\n5. Unit test: trigger with all four sub-fields passes; trigger missing threshold or evaluation window fails.\n6. Integration test: a simulated metric breach activates the fallback trigger and logs the activation event.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:39:32.819252135Z","created_by":"ubuntu","updated_at":"2026-02-20T15:16:28.198320212Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-11","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-3v8f","depends_on_id":"bd-2fpj","type":"blocks","created_at":"2026-02-20T07:43:24.465521890Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-3v8g","title":"[14] Version benchmark standards with migration guidance","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 14\n\nTask Objective:\nVersion standards and provide explicit migration guidance between standard revisions.\n\nExecution Requirements:\n- Make this requirement machine-verifiable and release-gated where applicable.\n- Keep behavior self-documenting so future contributors do not need to re-open the master plan.\n\nTesting & Logging Requirements:\n- Unit tests for rule/contract logic and error conditions.\n- Integration/E2E tests for workflow-level enforcement.\n- Structured logs with stable codes and trace IDs.\n- Reproducible artifacts that prove contract satisfaction.\n\nAcceptance Criteria:\n- Success and failure invariants for [14] Version benchmark standards with migration guidance are explicitly quantified and machine-verifiable.\n- Determinism requirements for [14] Version benchmark standards with migration guidance are validated across repeated runs and adversarial perturbations.\n\n\nExpected Artifacts:\n- Machine-readable verification artifact with explicit canonical path under artifacts/section_14/bd-3v8g/verification_evidence.json, suitable for CI/release gating.\n- Human-readable verification summary with explicit canonical path under artifacts/section_14/bd-3v8g/verification_summary.md, linking implementation intent to measured validation outcomes.\n\nTask-Specific Clarification:\n- The implementation must deliver the exact capability named in the title, with no scope dilution and no silent feature omission.\n- Validation artifacts must include capability-specific thresholds, pass/fail criteria, and reproducible evidence bundles tied to this bead ID.\n- Program/section verification gates must be able to consume this bead's outputs without manual interpretation.\n\nWhy This Improves User Outcomes:\n- \"[14] Version benchmark standards with migration guidance\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[14] Version benchmark standards with migration guidance\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"1. Benchmark standards follow semantic versioning (major.minor.patch) with clear compatibility guarantees.\n2. Each major version includes migration guidance: what changed, how to update benchmark configurations, and how to compare results across versions.\n3. Version changelog documents: added/removed/changed metrics, formula modifications, dataset updates, and scoring changes.\n4. Backward compatibility: minor versions can compare results with previous minor versions of the same major version.\n5. Deprecation policy: metrics or scoring formulas are deprecated with >= 1 major version warning before removal.\n6. Migration scripts exist to convert benchmark results from version N to version N+1 format.\n7. Version compatibility matrix published: which benchmark versions work with which franken_node versions.\n8. Evidence: benchmark_version_registry.json with version history, migration guide links, and compatibility matrix.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:39:35.557107936Z","created_by":"ubuntu","updated_at":"2026-02-20T15:24:15.578544310Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-14","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-3v8g","depends_on_id":"bd-yz3t","type":"blocks","created_at":"2026-02-20T07:43:25.893331096Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-3v9l","title":"[10.21] Add performance budgets and release claim gates for predictive pre-compromise trajectory assertions.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.21 — Behavioral Phenotype Evolution Tracker Execution Track (9O)\n\nWhy This Exists:\nBPET longitudinal phenotype intelligence track for pre-compromise trajectory detection and integration with DGIS/ATC/migration/economic policy.\n\nTask Objective:\nAdd performance budgets and release claim gates for predictive pre-compromise trajectory assertions.\n\nAcceptance Criteria:\n- BPET scoring latency and storage overhead meet p95/p99 budgets; release claims about predictive detection are blocked without signed calibration/provenance artifacts.\n\nExpected Artifacts:\n- `tests/perf/bpet_budget_gate.rs`, `.github/workflows/bpet-claim-gate.yml`, `artifacts/10.21/bpet_release_gate_report.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_21/bd-3v9l/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_21/bd-3v9l/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.21] Add performance budgets and release claim gates for predictive pre-compromise trajectory assertions.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.21] Add performance budgets and release claim gates for predictive pre-compromise trajectory assertions.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.21] Add performance budgets and release claim gates for predictive pre-compromise trajectory assertions.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.21] Add performance budgets and release claim gates for predictive pre-compromise trajectory assertions.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.21] Add performance budgets and release claim gates for predictive pre-compromise trajectory assertions.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- BPET scoring latency and storage overhead meet p95/p99 budgets; release claims about predictive detection are blocked without signed calibration/provenance artifacts.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:37:08.961628016Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:25.701318245Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-21","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-3v9l","depends_on_id":"bd-1naf","type":"blocks","created_at":"2026-02-20T07:43:21.952571420Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-3vk","title":"Implement CLI scaffold for franken-node runtime commands","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md (Bootstrap bridge for Sections 10.0–10.5 command surfaces)\nSection: BOOTSTRAP (CLI command-family scaffold bridge)\n\nBootstrap Context:\nThis bead expands the minimal CLI from `bd-2lb` into a complete runtime command-family skeleton while preserving non-duplicative ownership and deterministic behavior.\n\nTask Objective:\nImplement full command-family scaffold (`init`, `run`, `migrate`, `verify`, `trust`, `incident`, `doctor`) with explicit handlers/stubs and stable output contracts.\n\nIn Scope:\n- Full subcommand registration and deterministic argument validation.\n- Handler routing for each command family, with deterministic stub responses where business logic is not yet implemented.\n- Consistent command-level output/error envelope format for future policy/evidence hooks.\n\nOut of Scope:\n- Re-implementing `run`/`doctor` internals already delivered in `bd-2lb`.\n- Deep feature logic for each command family (tracked in downstream beads).\n\nAcceptance Criteria:\n- Every target command family appears in CLI help and routes to a deterministic handler path.\n- Stubbed commands emit stable, machine-readable placeholder output with explicit TODO ownership references.\n- No behavioral regression in `run`/`doctor` paths introduced by surface expansion.\n\nExpected Artifacts:\n- Command-surface matrix mapping commands to handlers and owning downstream beads.\n- Golden CLI help and routing fixtures.\n- Compatibility note describing migration from bootstrap-only to full command scaffold.\n\n- Machine-readable verification artifact at `artifacts/section_bootstrap/bd-3vk/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_bootstrap/bd-3vk/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for subcommand registration and parse coverage across all command families.\n- Integration tests for handler routing and deterministic placeholder responses.\n- E2E script coverage of representative end-user command sequences across all families.\n- Structured per-command logs with stable command IDs, phase markers, and trace correlation fields.\n\nTask-Specific Clarification:\n- For \"Implement CLI scaffold for franken-node runtime commands\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"Implement CLI scaffold for franken-node runtime commands\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"Implement CLI scaffold for franken-node runtime commands\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"Implement CLI scaffold for franken-node runtime commands\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"Implement CLI scaffold for franken-node runtime commands\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","notes":"Legacy bridge task mapped to plan compatibility/CLI stream; sequenced behind bd-2lb to avoid duplicate implementation overlap.","status":"closed","priority":1,"issue_type":"task","assignee":"OrangeAnchor","created_at":"2026-02-20T07:26:07.680355016Z","created_by":"ubuntu","updated_at":"2026-02-20T13:08:57.452775409Z","closed_at":"2026-02-20T13:08:57.452731157Z","close_reason":"done","closed_by_session":"CoralReef","source_repo":".","compaction_level":0,"original_size":0,"labels":["cli","runtime"],"dependencies":[{"issue_id":"bd-3vk","depends_on_id":"bd-2lb","type":"blocks","created_at":"2026-02-20T07:44:42.107689663Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-3vm","title":"[10.11] Add ambient-authority audit gate for product security-critical modules.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.11 — FrankenSQLite-Inspired Runtime Systems Integration Track\n\nWhy This Exists:\nFrankenSQLite-inspired systems integration of capabilities, cancellation protocol, obligations, deterministic labs, and anti-entropy.\n\nTask Objective:\nAdd ambient-authority audit gate for product security-critical modules.\n\nAcceptance Criteria:\n- Implement with explicit success/failure invariants and deterministic behavior under normal, edge, and fault scenarios.\n- Ensure outcomes are verifiable via automated tests and reproducible artifact outputs.\n\nExpected Artifacts:\n- Section-owned design/spec artifact at `docs/specs/section_10_11/bd-3vm_contract.md`, capturing decision rationale, invariants, and interface boundaries.\n- Machine-readable verification artifact at `artifacts/section_10_11/bd-3vm/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_11/bd-3vm/verification_summary.md` linking implementation intent to measured outcomes.\n\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.11] Add ambient-authority audit gate for product security-critical modules.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.11] Add ambient-authority audit gate for product security-critical modules.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.11] Add ambient-authority audit gate for product security-critical modules.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.11] Add ambient-authority audit gate for product security-critical modules.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.11] Add ambient-authority audit gate for product security-critical modules.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"AC for bd-3vm:\n1. A static-analysis or init-time audit gate scans all product security-critical modules and flags any use of ambient authority (global mutable state, unscoped file/network access, raw syscalls not routed through a CxHandle).\n2. The gate produces a machine-readable AuditReport JSON listing every ambient-authority site found, with module path, line number, and violation category.\n3. The gate returns exit code 0 (pass) only when zero ambient-authority violations exist; any violation returns exit code 1 with structured error output.\n4. CI integrates the gate as a mandatory pre-merge check; PRs introducing new ambient authority are blocked until a CxHandle refactor or an explicit exception annotation is added.\n5. Exception annotations (e.g., #[allow_ambient(reason = \"...\")]) are tracked in the audit report and require review sign-off; the total exception count is emitted as a metric.\n6. Unit tests verify: (a) a clean module passes the gate, (b) a module with raw std::fs::read (no CxHandle) fails, (c) an annotated exception is reported but does not fail the gate, (d) removing a CxHandle wrapper from a previously-clean call causes regression failure.\n7. Structured log events use stable codes AMBIENT_AUDIT_PASS / AMBIENT_AUDIT_VIOLATION / AMBIENT_AUDIT_EXCEPTION with module path context.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:36:49.744255694Z","created_by":"ubuntu","updated_at":"2026-02-20T15:17:59.323725586Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-11","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-3vm","depends_on_id":"bd-cvt","type":"blocks","created_at":"2026-02-20T07:43:11.367817499Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-4jh9","title":"[10.18] Implement degraded-mode policy for proof lag/outage (`restricted`, `quarantine`, `halt`) with explicit SLOs.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.18 — Verifiable Execution Fabric Execution Track (9L)\n\nWhy This Exists:\nVEF track for proof-carrying runtime compliance: receipt chains, commitment checkpoints, proof generation/verification, and claim gating.\n\nTask Objective:\nImplement degraded-mode policy for proof lag/outage (`restricted`, `quarantine`, `halt`) with explicit SLOs.\n\nAcceptance Criteria:\n- Proof pipeline lag/outage triggers deterministic degraded mode by policy tier; mode transitions emit mandatory audit events and recovery receipts.\n\nExpected Artifacts:\n- `docs/specs/vef_degraded_mode_policy.md`, `tests/security/vef_degraded_mode_transitions.rs`, `artifacts/10.18/vef_degraded_mode_events.jsonl`.\n\n- Machine-readable verification artifact at `artifacts/section_10_18/bd-4jh9/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_18/bd-4jh9/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.18] Implement degraded-mode policy for proof lag/outage (`restricted`, `quarantine`, `halt`) with explicit SLOs.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.18] Implement degraded-mode policy for proof lag/outage (`restricted`, `quarantine`, `halt`) with explicit SLOs.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.18] Implement degraded-mode policy for proof lag/outage (`restricted`, `quarantine`, `halt`) with explicit SLOs.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.18] Implement degraded-mode policy for proof lag/outage (`restricted`, `quarantine`, `halt`) with explicit SLOs.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.18] Implement degraded-mode policy for proof lag/outage (`restricted`, `quarantine`, `halt`) with explicit SLOs.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- Proof pipeline lag/outage triggers deterministic degraded mode by policy tier; mode transitions emit mandatory audit events and recovery receipts.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:37:04.790616914Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:55.829328005Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-18","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-4jh9","depends_on_id":"bd-8qlj","type":"blocks","created_at":"2026-02-20T07:43:19.217046034Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-4ou","title":"[PLAN 11] Evidence And Decision Contracts","description":"Section 11 codification epic. Every major subsystem must ship change summary, threat/compat evidence, EV tiering, expected-loss model, fallback trigger, rollout wedge, rollback command, and benchmark/correctness artifacts. No contract, no merge.\n\n## Success Criteria\n- All child beads for this section are completed with acceptance artifacts attached and no unresolved blockers.\n- Section-level verification gate for comprehensive unit tests, integration/e2e workflows, and detailed structured logging evidence is green.\n- Scope-to-plan traceability is explicit, with no feature loss versus the canonical plan section.\n\n## Optimization Notes\n- User-Outcome Lens: \"[PLAN 11] Evidence And Decision Contracts\" must improve real operator and end-user reliability, explainability, and time-to-safe-outcome under both normal and degraded conditions.\n- Cross-Section Coordination: this epic's child beads must explicitly encode integration expectations with neighboring sections to prevent local optimizations that break global behavior.\n- Verification Non-Negotiable: completion requires deterministic unit coverage, integration/E2E replay evidence, and structured logs sufficient for independent third-party reproduction and triage.\n- Scope Protection: any proposed simplification must prove feature parity against plan intent and document tradeoffs explicitly; silent scope reduction is forbidden.","status":"open","priority":1,"issue_type":"epic","created_at":"2026-02-20T07:36:42.021201087Z","created_by":"ubuntu","updated_at":"2026-02-20T08:12:48.085724528Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-11"],"dependencies":[{"issue_id":"bd-4ou","depends_on_id":"bd-1hf","type":"blocks","created_at":"2026-02-20T07:38:34.250357758Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-4ou","depends_on_id":"bd-1jmq","type":"blocks","created_at":"2026-02-20T07:39:32.689946661Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-4ou","depends_on_id":"bd-1ow","type":"blocks","created_at":"2026-02-20T07:38:33.862941846Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-4ou","depends_on_id":"bd-1ta","type":"blocks","created_at":"2026-02-20T07:38:34.378934506Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-4ou","depends_on_id":"bd-1u9","type":"blocks","created_at":"2026-02-20T07:38:34.073268017Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-4ou","depends_on_id":"bd-1wz","type":"blocks","created_at":"2026-02-20T07:38:34.555391699Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-4ou","depends_on_id":"bd-1xg","type":"blocks","created_at":"2026-02-20T07:38:33.992324625Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-4ou","depends_on_id":"bd-20a","type":"blocks","created_at":"2026-02-20T07:38:34.033061445Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-4ou","depends_on_id":"bd-20z","type":"blocks","created_at":"2026-02-20T07:38:34.293242839Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-4ou","depends_on_id":"bd-229","type":"blocks","created_at":"2026-02-20T07:38:33.951183813Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-4ou","depends_on_id":"bd-26k","type":"blocks","created_at":"2026-02-20T07:38:34.204005308Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-4ou","depends_on_id":"bd-2fpj","type":"blocks","created_at":"2026-02-20T07:39:32.774414577Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-4ou","depends_on_id":"bd-2ut3","type":"blocks","created_at":"2026-02-20T07:39:33.195957557Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-4ou","depends_on_id":"bd-2ymp","type":"blocks","created_at":"2026-02-20T07:39:32.943331225Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-4ou","depends_on_id":"bd-32p","type":"blocks","created_at":"2026-02-20T07:38:34.598840290Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-4ou","depends_on_id":"bd-36wa","type":"blocks","created_at":"2026-02-20T07:39:32.604423719Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-4ou","depends_on_id":"bd-37i","type":"blocks","created_at":"2026-02-20T07:38:34.726688450Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-4ou","depends_on_id":"bd-39a","type":"blocks","created_at":"2026-02-20T07:38:34.641587755Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-4ou","depends_on_id":"bd-3fo","type":"blocks","created_at":"2026-02-20T07:38:33.820883124Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-4ou","depends_on_id":"bd-3il","type":"blocks","created_at":"2026-02-20T07:38:33.906443706Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-4ou","depends_on_id":"bd-3l8d","type":"blocks","created_at":"2026-02-20T07:39:33.111697057Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-4ou","depends_on_id":"bd-3qo","type":"blocks","created_at":"2026-02-20T07:38:34.465887772Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-4ou","depends_on_id":"bd-3rc","type":"blocks","created_at":"2026-02-20T07:38:34.117390473Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-4ou","depends_on_id":"bd-3se1","type":"blocks","created_at":"2026-02-20T07:39:32.519718871Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-4ou","depends_on_id":"bd-3v8f","type":"blocks","created_at":"2026-02-20T07:39:32.858939821Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-4ou","depends_on_id":"bd-5rh","type":"blocks","created_at":"2026-02-20T07:38:34.423399830Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-4ou","depends_on_id":"bd-c4f","type":"blocks","created_at":"2026-02-20T07:38:34.161121339Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-4ou","depends_on_id":"bd-c781","type":"blocks","created_at":"2026-02-20T07:48:27.939791388Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-4ou","depends_on_id":"bd-go4","type":"blocks","created_at":"2026-02-20T07:38:34.336288179Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-4ou","depends_on_id":"bd-n71","type":"blocks","created_at":"2026-02-20T07:38:34.511864762Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-4ou","depends_on_id":"bd-nglx","type":"blocks","created_at":"2026-02-20T07:39:33.028007430Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-4ou","depends_on_id":"bd-ybe","type":"blocks","created_at":"2026-02-20T07:38:34.684929376Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-4skb","title":"Epic: Behavioral Phenotype Evolution Tracker (BPET) [10.21]","description":"- type: epic","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-20T07:47:58.072163029Z","updated_at":"2026-02-20T07:49:21.322442785Z","closed_at":"2026-02-20T07:49:21.322424401Z","close_reason":"Superseded by canonical detailed master-plan graph (bd-33v) with full 10.N-10.21 and 11-16 coverage, explicit dependencies, and per-section verification gates.","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-4yv","title":"[10.1] Add reproducibility contract templates (`env.json`, `manifest.json`, `repro.lock`).","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.1 — Charter + Split Governance\n\nWhy This Exists:\nProgram charter and governance baseline: split contracts, reproducibility, and anti-regression rules for strategic integrity.\n\nTask Objective:\nAdd reproducibility contract templates (`env.json`, `manifest.json`, `repro.lock`).\n\nAcceptance Criteria:\n- Implement with explicit success/failure invariants and deterministic behavior under normal, edge, and fault scenarios.\n- Ensure outcomes are verifiable via automated tests and reproducible artifact outputs.\n\nExpected Artifacts:\n- Section-owned design/spec artifact at `docs/specs/section_10_1/bd-4yv_contract.md`, capturing decision rationale, invariants, and interface boundaries.\n- Machine-readable verification artifact at `artifacts/section_10_1/bd-4yv/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_1/bd-4yv/verification_summary.md` linking implementation intent to measured outcomes.\n\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.1] Add reproducibility contract templates (`env.json`, `manifest.json`, `repro.lock`).\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.1] Add reproducibility contract templates (`env.json`, `manifest.json`, `repro.lock`).\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.1] Add reproducibility contract templates (`env.json`, `manifest.json`, `repro.lock`).\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.1] Add reproducibility contract templates (`env.json`, `manifest.json`, `repro.lock`).\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.1] Add reproducibility contract templates (`env.json`, `manifest.json`, `repro.lock`).\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","status":"closed","priority":1,"issue_type":"task","assignee":"CrimsonCrane","created_at":"2026-02-20T07:36:43.525939936Z","created_by":"ubuntu","updated_at":"2026-02-20T09:16:10.283235333Z","closed_at":"2026-02-20T09:16:10.283207021Z","close_reason":"done","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-1","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-4yv","depends_on_id":"bd-2zz","type":"blocks","created_at":"2026-02-20T07:43:10.659397831Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-5rh","title":"[PLAN 10.14] FrankenSQLite Deep-Mined Expansion Execution Track (9J)","description":"Section: 10.14 — FrankenSQLite Deep-Mined Expansion Execution Track (9J)\n\nStrategic Context:\nFrankenSQLite deep-mined control integrity track: evidence ledgers, proofs, epochs, remote effects, markers/MMR, and deterministic fault labs.\n\nExecution Requirements:\n- Preserve all scoped capabilities from the canonical plan.\n- Keep contracts self-contained so future contributors can execute without reopening the master plan.\n- Require explicit testing strategy (unit + integration/e2e) and structured logging/telemetry for every child bead.\n- Require artifact-backed validation for performance, security, and correctness claims.\n\nDependency Semantics:\n- This epic is blocked by its child implementation beads.\n- Cross-epic dependencies encode strategic sequencing and canonical ownership boundaries.\n\n## Success Criteria\n- All child beads for this section are completed with acceptance artifacts attached and no unresolved blockers.\n- Section-level verification gate for comprehensive unit tests, integration/e2e workflows, and detailed structured logging evidence is green.\n- Scope-to-plan traceability is explicit, with no feature loss versus the canonical plan section.\n\n## Optimization Notes\n- User-Outcome Lens: \"[PLAN 10.14] FrankenSQLite Deep-Mined Expansion Execution Track (9J)\" must improve operator confidence, safety posture, and deterministic recovery behavior under both normal and adversarial conditions.\n- Cross-Section Coordination: child beads must encode integration assumptions explicitly to avoid local optimizations that degrade system-wide correctness.\n- Verification Non-Negotiable: completion requires reproducible unit/integration/E2E evidence and structured logs suitable for independent replay.\n- Scope Protection: any simplification must preserve canonical-plan feature intent and be justified with explicit tradeoff documentation.","status":"open","priority":2,"issue_type":"epic","created_at":"2026-02-20T07:36:41.367896930Z","created_by":"ubuntu","updated_at":"2026-02-20T16:05:56.282378187Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-14"],"dependencies":[{"issue_id":"bd-5rh","depends_on_id":"bd-126h","type":"blocks","created_at":"2026-02-20T07:36:58.584272274Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-5rh","depends_on_id":"bd-129f","type":"blocks","created_at":"2026-02-20T07:36:58.664252462Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-5rh","depends_on_id":"bd-12n3","type":"blocks","created_at":"2026-02-20T07:36:57.849114510Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-5rh","depends_on_id":"bd-15u3","type":"blocks","created_at":"2026-02-20T07:36:55.911410566Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-5rh","depends_on_id":"bd-18ud","type":"blocks","created_at":"2026-02-20T07:36:57.443831206Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-5rh","depends_on_id":"bd-1ayu","type":"blocks","created_at":"2026-02-20T07:36:56.256022438Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-5rh","depends_on_id":"bd-1dar","type":"blocks","created_at":"2026-02-20T07:36:58.830555140Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-5rh","depends_on_id":"bd-1daz","type":"blocks","created_at":"2026-02-20T07:36:56.336425843Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-5rh","depends_on_id":"bd-1fck","type":"blocks","created_at":"2026-02-20T07:36:57.524529972Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-5rh","depends_on_id":"bd-1fp4","type":"blocks","created_at":"2026-02-20T07:36:56.418318804Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-5rh","depends_on_id":"bd-1iyx","type":"blocks","created_at":"2026-02-20T07:36:57.007491124Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-5rh","depends_on_id":"bd-1l62","type":"blocks","created_at":"2026-02-20T07:36:56.581499457Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-5rh","depends_on_id":"bd-1nfu","type":"blocks","created_at":"2026-02-20T07:36:57.687319648Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-5rh","depends_on_id":"bd-1oof","type":"blocks","created_at":"2026-02-20T07:36:55.424301086Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-5rh","depends_on_id":"bd-1ru2","type":"blocks","created_at":"2026-02-20T07:36:57.606828969Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-5rh","depends_on_id":"bd-1ta","type":"blocks","created_at":"2026-02-20T07:37:11.049606534Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-5rh","depends_on_id":"bd-1vsr","type":"blocks","created_at":"2026-02-20T07:36:58.502941391Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-5rh","depends_on_id":"bd-1zym","type":"blocks","created_at":"2026-02-20T07:36:56.174814453Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-5rh","depends_on_id":"bd-206h","type":"blocks","created_at":"2026-02-20T07:36:57.929921317Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-5rh","depends_on_id":"bd-20uo","type":"blocks","created_at":"2026-02-20T07:36:56.662081255Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-5rh","depends_on_id":"bd-22yy","type":"blocks","created_at":"2026-02-20T07:36:59.348957639Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-5rh","depends_on_id":"bd-2573","type":"blocks","created_at":"2026-02-20T07:36:57.095910962Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-5rh","depends_on_id":"bd-25nl","type":"blocks","created_at":"2026-02-20T07:36:58.992656193Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-5rh","depends_on_id":"bd-27o2","type":"blocks","created_at":"2026-02-20T07:36:57.259914508Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-5rh","depends_on_id":"bd-2808","type":"blocks","created_at":"2026-02-20T07:36:59.098862682Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-5rh","depends_on_id":"bd-29r6","type":"blocks","created_at":"2026-02-20T07:36:56.926619145Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-5rh","depends_on_id":"bd-29yx","type":"blocks","created_at":"2026-02-20T07:36:56.745473859Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-5rh","depends_on_id":"bd-2e73","type":"blocks","created_at":"2026-02-20T07:36:55.259894609Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-5rh","depends_on_id":"bd-2igi","type":"blocks","created_at":"2026-02-20T07:36:55.830081325Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-5rh","depends_on_id":"bd-2ona","type":"blocks","created_at":"2026-02-20T07:36:55.506408025Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-5rh","depends_on_id":"bd-2qqu","type":"blocks","created_at":"2026-02-20T07:36:59.183045588Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-5rh","depends_on_id":"bd-2wsm","type":"blocks","created_at":"2026-02-20T07:36:58.421016370Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-5rh","depends_on_id":"bd-2xv8","type":"blocks","created_at":"2026-02-20T07:36:58.258507198Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-5rh","depends_on_id":"bd-3a3q","type":"blocks","created_at":"2026-02-20T07:36:55.748889100Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-5rh","depends_on_id":"bd-3cs3","type":"blocks","created_at":"2026-02-20T07:36:58.339724430Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-5rh","depends_on_id":"bd-3epz","type":"blocks","created_at":"2026-02-20T07:48:14.216064370Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-5rh","depends_on_id":"bd-3hdv","type":"blocks","created_at":"2026-02-20T07:36:58.178437884Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-5rh","depends_on_id":"bd-3i6c","type":"blocks","created_at":"2026-02-20T07:36:59.429744529Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-5rh","depends_on_id":"bd-3ort","type":"blocks","created_at":"2026-02-20T07:36:56.846304565Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-5rh","depends_on_id":"bd-3rya","type":"blocks","created_at":"2026-02-20T07:36:56.087182583Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-5rh","depends_on_id":"bd-876n","type":"blocks","created_at":"2026-02-20T07:36:59.268237132Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-5rh","depends_on_id":"bd-8tvs","type":"blocks","created_at":"2026-02-20T07:36:57.177752907Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-5rh","depends_on_id":"bd-ac83","type":"blocks","created_at":"2026-02-20T07:36:57.768811311Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-5rh","depends_on_id":"bd-b9b6","type":"blocks","created_at":"2026-02-20T07:36:56.500384807Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-5rh","depends_on_id":"bd-bq4p","type":"blocks","created_at":"2026-02-20T07:36:55.668220139Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-5rh","depends_on_id":"bd-cda","type":"blocks","created_at":"2026-02-20T07:37:09.585164496Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-5rh","depends_on_id":"bd-mwvn","type":"blocks","created_at":"2026-02-20T07:36:55.992250224Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-5rh","depends_on_id":"bd-nupr","type":"blocks","created_at":"2026-02-20T07:36:55.177813869Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-5rh","depends_on_id":"bd-nwhn","type":"blocks","created_at":"2026-02-20T07:36:58.911575656Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-5rh","depends_on_id":"bd-okqy","type":"blocks","created_at":"2026-02-20T07:36:57.359502148Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-5rh","depends_on_id":"bd-oolt","type":"blocks","created_at":"2026-02-20T07:36:55.342190951Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-5rh","depends_on_id":"bd-qlc6","type":"blocks","created_at":"2026-02-20T07:36:58.098545019Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-5rh","depends_on_id":"bd-sddz","type":"blocks","created_at":"2026-02-20T07:36:55.586773089Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-5rh","depends_on_id":"bd-v4l0","type":"blocks","created_at":"2026-02-20T07:36:58.017343276Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-5rh","depends_on_id":"bd-xwk5","type":"blocks","created_at":"2026-02-20T07:36:58.748174161Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-5si","title":"[10.12] Implement trust fabric convergence protocol and degraded-mode semantics.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.12 — Frontier Programs Execution Track (9H)\n\nWhy This Exists:\nFrontier program execution turning migration singularity, trust fabric, verifier economy, and operator intelligence into production flow.\n\nTask Objective:\nImplement trust fabric convergence protocol and degraded-mode semantics.\n\nAcceptance Criteria:\n- Implement with explicit success/failure invariants and deterministic behavior under normal, edge, and fault scenarios.\n- Ensure outcomes are verifiable via automated tests and reproducible artifact outputs.\n\nExpected Artifacts:\n- Section-owned design/spec artifact at `docs/specs/section_10_12/bd-5si_contract.md`, capturing decision rationale, invariants, and interface boundaries.\n- Machine-readable verification artifact at `artifacts/section_10_12/bd-5si/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_12/bd-5si/verification_summary.md` linking implementation intent to measured outcomes.\n\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.12] Implement trust fabric convergence protocol and degraded-mode semantics.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.12] Implement trust fabric convergence protocol and degraded-mode semantics.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.12] Implement trust fabric convergence protocol and degraded-mode semantics.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.12] Implement trust fabric convergence protocol and degraded-mode semantics.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.12] Implement trust fabric convergence protocol and degraded-mode semantics.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"1. Define a TrustFabricState enum: CONVERGED (all nodes agree on trust state), DEGRADED (some nodes have stale or missing trust artifacts), PARTITIONED (one or more nodes are unreachable and their trust state is unknown), DIVERGED (conflicting trust states detected, requires manual resolution).\n2. Implement a TrustFabricConvergenceProtocol with: (a) announce(node_id, trust_state_vector) to broadcast a node's current trust state, (b) merge(local_state, remote_state) -> MergeResult that produces a merged trust state or identifies conflicts, (c) evaluate_fabric_health() -> TrustFabricState based on all known node states.\n3. Define convergence criteria: the fabric is CONVERGED when all active nodes report the same trust_state_hash within a configurable convergence_window (default 30s). Nodes that have not announced within the window are classified as STALE.\n4. Implement degraded-mode semantics: when the fabric is DEGRADED, (a) read operations proceed with a staleness warning attached to responses, (b) write operations (token issuance, key binding, policy changes) are blocked unless an override flag force_degraded=true is provided, (c) DANGEROUS actions (from bd-2sx risk tiers) are unconditionally blocked in DEGRADED mode.\n5. Implement partition detection: if a node has not announced for > 3x convergence_window, classify it as PARTITIONED. Emit a CRITICAL structured log event with the partitioned node list.\n6. Implement divergence resolution: when merge() detects conflicting trust states, produce a DivergenceReport containing (a) conflicting node IDs, (b) their respective trust_state_hashes, (c) the specific trust objects that differ. Do NOT auto-resolve; require operator intervention.\n7. Implement health metrics: expose fabric_convergence_ratio (converged_nodes / total_nodes), fabric_state, time_since_last_full_convergence, and stale_node_count.\n8. Unit tests: (a) two nodes converge, (b) one node stale => DEGRADED, (c) one node partitioned => PARTITIONED, (d) conflicting states => DIVERGED, (e) degraded-mode write blocking, (f) degraded-mode read with warning, (g) DANGEROUS action blocked in DEGRADED.\n9. Integration test: simulate a 5-node fabric, partition one node, verify state transitions and metric updates.\n10. Verification: scripts/check_trust_fabric.py --json, artifacts at artifacts/section_10_12/bd-5si/.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:36:50.995452214Z","created_by":"ubuntu","updated_at":"2026-02-20T15:39:53.631601777Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-12","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-5si","depends_on_id":"bd-3j4","type":"blocks","created_at":"2026-02-20T07:43:12.013896771Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-5y9q","title":"Epic: Workspace + Build Infrastructure","description":"- type: task","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-20T07:47:58.072163029Z","updated_at":"2026-02-20T07:49:21.071277203Z","closed_at":"2026-02-20T07:49:21.071253589Z","close_reason":"Superseded by canonical detailed master-plan graph (bd-33v) with full 10.N-10.21 and 11-16 coverage, explicit dependencies, and per-section verification gates.","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-721z","title":"[10.15] Add ambient-authority audit gate for control-plane modules.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.15 — Asupersync-First Integration Execution Track (8.4-8.6)\n\nWhy This Exists:\nAsupersync-first control-plane migration track enforcing Cx-first, region ownership, cancellation correctness, and protocol-grade verification gates.\n\nTask Objective:\nAdd ambient-authority audit gate for control-plane modules.\n\nAcceptance Criteria:\n- Ambient network/spawn/time effects in restricted modules fail CI; allowlist is explicit and signed.\n\nExpected Artifacts:\n- `tools/lints/ambient_authority_gate.rs`, `docs/specs/ambient_authority_policy.md`, `artifacts/10.15/ambient_authority_findings.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_15/bd-721z/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_15/bd-721z/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.15] Add ambient-authority audit gate for control-plane modules.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.15] Add ambient-authority audit gate for control-plane modules.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.15] Add ambient-authority audit gate for control-plane modules.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.15] Add ambient-authority audit gate for control-plane modules.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.15] Add ambient-authority audit gate for control-plane modules.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- Ambient network/spawn/time effects in restricted modules fail CI; allowlist is explicit and signed.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:36:59.726628519Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:53.651822264Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-15","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-721z","depends_on_id":"bd-2g6r","type":"blocks","created_at":"2026-02-20T07:43:16.581383091Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-7mt","title":"[10.2] Add CI gate: compatibility implementations must cite spec section + fixture IDs; missing references fail review gates.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.2 — Compatibility Core\n\nWhy This Exists:\nCompatibility core as strategic wedge: policy-visible behavior, divergence receipts, L1/L2 lockstep, and spec-first fixture governance.\n\nTask Objective:\nAdd CI gate: compatibility implementations must cite spec section + fixture IDs; missing references fail review gates.\n\nAcceptance Criteria:\n- Implement with explicit success/failure invariants and deterministic behavior under normal, edge, and fault scenarios.\n- Ensure outcomes are verifiable via automated tests and reproducible artifact outputs.\n\nExpected Artifacts:\n- Section-owned design/spec artifact at `docs/specs/section_10_2/bd-7mt_contract.md`, capturing decision rationale, invariants, and interface boundaries.\n- Machine-readable verification artifact at `artifacts/section_10_2/bd-7mt/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_2/bd-7mt/verification_summary.md` linking implementation intent to measured outcomes.\n\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.2] Add CI gate: compatibility implementations must cite spec section + fixture IDs; missing references fail review gates.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.2] Add CI gate: compatibility implementations must cite spec section + fixture IDs; missing references fail review gates.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.2] Add CI gate: compatibility implementations must cite spec section + fixture IDs; missing references fail review gates.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.2] Add CI gate: compatibility implementations must cite spec section + fixture IDs; missing references fail review gates.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.2] Add CI gate: compatibility implementations must cite spec section + fixture IDs; missing references fail review gates.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","status":"closed","priority":1,"issue_type":"task","assignee":"CrimsonCrane","created_at":"2026-02-20T07:36:44.719663372Z","created_by":"ubuntu","updated_at":"2026-02-20T10:03:25.554310012Z","closed_at":"2026-02-20T10:03:25.554283553Z","close_reason":"done","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-2","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-7mt","depends_on_id":"bd-80g","type":"blocks","created_at":"2026-02-20T07:43:20.518881424Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-7om","title":"[10.11] Adopt canonical cancel -> drain -> finalize protocol contracts (from `10.15`) for product services.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.11 — FrankenSQLite-Inspired Runtime Systems Integration Track\n\nWhy This Exists:\nFrankenSQLite-inspired systems integration of capabilities, cancellation protocol, obligations, deterministic labs, and anti-entropy.\n\nTask Objective:\nAdopt canonical cancel -> drain -> finalize protocol contracts (from `10.15`) for product services.\n\nAcceptance Criteria:\n- Implement with explicit success/failure invariants and deterministic behavior under normal, edge, and fault scenarios.\n- Ensure outcomes are verifiable via automated tests and reproducible artifact outputs.\n\nExpected Artifacts:\n- Section-owned design/spec artifact at `docs/specs/section_10_11/bd-7om_contract.md`, capturing decision rationale, invariants, and interface boundaries.\n- Machine-readable verification artifact at `artifacts/section_10_11/bd-7om/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_11/bd-7om/verification_summary.md` linking implementation intent to measured outcomes.\n\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.11] Adopt canonical cancel -> drain -> finalize protocol contracts (from `10.15`) for product services.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.11] Adopt canonical cancel -> drain -> finalize protocol contracts (from `10.15`) for product services.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.11] Adopt canonical cancel -> drain -> finalize protocol contracts (from `10.15`) for product services.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.11] Adopt canonical cancel -> drain -> finalize protocol contracts (from `10.15`) for product services.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.11] Adopt canonical cancel -> drain -> finalize protocol contracts (from `10.15`) for product services.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"AC for bd-7om:\n1. All product services adopt the canonical three-phase cancellation protocol from 10.15: Cancel (signal intent) -> Drain (complete in-flight work, reject new work) -> Finalize (release resources, emit completion evidence).\n2. A CancellationProtocol trait is defined with methods: cancel(), drain(timeout: Duration) -> DrainOutcome, finalize() -> FinalizeReport.\n3. State transitions are strictly ordered: Idle -> Cancelled -> Draining -> Finalized. Any out-of-order transition attempt returns Err with stable code CANCEL_PROTOCOL_VIOLATION.\n4. Drain has a configurable timeout; if in-flight work does not complete within the timeout, drain returns DrainOutcome::TimedOut with a list of still-active work items, and finalize force-drops them with a CANCEL_FORCE_DROP log event.\n5. Double-cancel is idempotent (no error, no state change beyond first cancel).\n6. Every service implementing CancellationProtocol emits structured telemetry: CANCEL_SIGNAL_RECEIVED, DRAIN_STARTED, DRAIN_COMPLETED / DRAIN_TIMED_OUT, FINALIZE_COMPLETED with trace correlation IDs and elapsed-time measurements.\n7. Unit tests verify: (a) happy-path cancel -> drain -> finalize completes cleanly, (b) drain timeout triggers forced finalization, (c) out-of-order transition is rejected, (d) double-cancel is idempotent, (e) new work submitted during drain phase is rejected with WORK_REJECTED_DRAINING.\n8. Integration test: a multi-service orchestration cancels all services concurrently and verifies total drain time is bounded by the maximum individual drain timeout (parallel drain, not serial).","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:36:49.901866673Z","created_by":"ubuntu","updated_at":"2026-02-20T15:18:11.212445621Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-11","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-7om","depends_on_id":"bd-1cs7","type":"blocks","created_at":"2026-02-20T15:00:17.548435204Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-7om","depends_on_id":"bd-93k","type":"blocks","created_at":"2026-02-20T07:43:11.454634042Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-7rt","title":"Generate transplant hash lockfile for tamper detection","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md (Bootstrap bridge for integrity/provenance controls)\n\nTask Objective:\nGenerate a deterministic transplant hash lockfile (`sha256`/equivalent) for restored snapshot assets and define verification semantics used by CI and drift tooling.\n\nIn Scope:\n- Deterministic hash computation and canonical ordering rules.\n- Lockfile format contract including algorithm, path normalization, and metadata fields.\n- Verification command/flow that compares current snapshot state against lockfile.\n\nAcceptance Criteria:\n- Equivalent snapshot inputs always produce byte-identical lockfile outputs.\n- Verification flow reliably detects additions, deletions, and content mutations.\n- Lockfile output is consumable by downstream drift workflow (`bd-29q`) and CI checks.\n\nExpected Artifacts:\n- Lockfile format specification and generation procedure.\n- Golden lockfile fixtures for known snapshot states.\n- Verification report format for CI/release evidence.\n\nTesting & Logging Requirements:\n- Unit tests for hash generation, ordering, and path-normalization edge cases.\n- Integration tests covering positive/negative verification scenarios.\n- E2E tests for restore -> lockfile -> verification workflow.\n- Structured logs with hashed-file counts, mismatch categories, and trace IDs.\n\nTask-Specific Clarification:\n- For \"Generate transplant hash lockfile for tamper detection\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"Generate transplant hash lockfile for tamper detection\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"Generate transplant hash lockfile for tamper detection\" must support deterministic replay and root-cause triage without hidden context.","notes":"Legacy transplant lockfile task retained; now explicitly sequenced after bd-1qz to avoid orphan lockfile generation.","status":"closed","priority":1,"issue_type":"task","assignee":"ubuntu","created_at":"2026-02-20T07:26:02.917369250Z","created_by":"ubuntu","updated_at":"2026-02-20T08:11:40.703967519Z","closed_at":"2026-02-20T08:11:40.703863445Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["integrity","transplant"],"dependencies":[{"issue_id":"bd-7rt","depends_on_id":"bd-1qz","type":"blocks","created_at":"2026-02-20T07:44:42.162279998Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-80g","title":"[10.2] Build prioritized Node/Bun reference capture programs and fixture corpora per API band (CLI/process/fs/network/module/tooling).","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.2 — Compatibility Core\n\nWhy This Exists:\nCompatibility core as strategic wedge: policy-visible behavior, divergence receipts, L1/L2 lockstep, and spec-first fixture governance.\n\nTask Objective:\nBuild prioritized Node/Bun reference capture programs and fixture corpora per API band (CLI/process/fs/network/module/tooling).\n\nAcceptance Criteria:\n- Implement with explicit success/failure invariants and deterministic behavior under normal, edge, and fault scenarios.\n- Ensure outcomes are verifiable via automated tests and reproducible artifact outputs.\n\nExpected Artifacts:\n- Section-owned design/spec artifact at `docs/specs/section_10_2/bd-80g_contract.md`, capturing decision rationale, invariants, and interface boundaries.\n- Machine-readable verification artifact at `artifacts/section_10_2/bd-80g/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_2/bd-80g/verification_summary.md` linking implementation intent to measured outcomes.\n\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.2] Build prioritized Node/Bun reference capture programs and fixture corpora per API band (CLI/process/fs/network/module/tooling).\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.2] Build prioritized Node/Bun reference capture programs and fixture corpora per API band (CLI/process/fs/network/module/tooling).\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.2] Build prioritized Node/Bun reference capture programs and fixture corpora per API band (CLI/process/fs/network/module/tooling).\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.2] Build prioritized Node/Bun reference capture programs and fixture corpora per API band (CLI/process/fs/network/module/tooling).\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.2] Build prioritized Node/Bun reference capture programs and fixture corpora per API band (CLI/process/fs/network/module/tooling).\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","status":"closed","priority":1,"issue_type":"task","assignee":"CrimsonCrane","created_at":"2026-02-20T07:36:44.641054328Z","created_by":"ubuntu","updated_at":"2026-02-20T10:00:58.376678667Z","closed_at":"2026-02-20T10:00:58.376653841Z","close_reason":"done","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-2","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-80g","depends_on_id":"bd-2hs","type":"blocks","created_at":"2026-02-20T07:43:20.475881267Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-876n","title":"[10.14] Add cancellation injection at all await points for critical control workflows in lab tests.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.14 — FrankenSQLite Deep-Mined Expansion Execution Track (9J)\n\nWhy This Exists:\nFrankenSQLite deep-mined control integrity track: evidence ledgers, proofs, epochs, remote effects, markers/MMR, and deterministic fault labs.\n\nTask Objective:\nAdd cancellation injection at all await points for critical control workflows in lab tests.\n\nAcceptance Criteria:\n- Critical workflows are instrumented for all-point cancellation injection; leak-free and half-commit-free invariants hold under injected cancellations.\n\nExpected Artifacts:\n- `tests/lab/cancellation_injection_control_workflows.rs`, `docs/testing/cancel_injection_matrix.md`, `artifacts/10.14/cancel_injection_report.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_14/bd-876n/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_14/bd-876n/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.14] Add cancellation injection at all await points for critical control workflows in lab tests.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.14] Add cancellation injection at all await points for critical control workflows in lab tests.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.14] Add cancellation injection at all await points for critical control workflows in lab tests.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.14] Add cancellation injection at all await points for critical control workflows in lab tests.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.14] Add cancellation injection at all await points for critical control workflows in lab tests.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"Critical workflows are instrumented for all-point cancellation injection; leak-free and half-commit-free invariants hold under injected cancellations.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:36:59.227759656Z","created_by":"ubuntu","updated_at":"2026-02-20T15:44:02.199832831Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-14","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-876n","depends_on_id":"bd-2qqu","type":"blocks","created_at":"2026-02-20T07:43:16.316132570Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-8h8m","title":"Epic: Lab + Verification Infrastructure [10.14h]","description":"- type: epic","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-20T07:47:58.072163029Z","updated_at":"2026-02-20T07:49:21.250401734Z","closed_at":"2026-02-20T07:49:21.250384001Z","close_reason":"Superseded by canonical detailed master-plan graph (bd-33v) with full 10.N-10.21 and 11-16 coverage, explicit dependencies, and per-section verification gates.","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-8l9k","title":"[10.16] Add cross-substrate contract tests validating end-to-end behavior (`frankentui` -> service -> persistence).","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.16 — Adjacent Substrate Integration Execution Track (8.7)\n\nWhy This Exists:\nAdjacent substrate integration track to enforce deep composition with frankentui, frankensqlite, sqlmodel_rust, and fastapi_rust.\n\nTask Objective:\nAdd cross-substrate contract tests validating end-to-end behavior (`frankentui` -> service -> persistence).\n\nAcceptance Criteria:\n- End-to-end tests cover representative operator flows and replay determinism; failure includes cross-layer trace.\n\nExpected Artifacts:\n- `tests/e2e/adjacent_substrate_flow.rs`, `artifacts/10.16/adjacent_substrate_e2e_report.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_16/bd-8l9k/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_16/bd-8l9k/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.16] Add cross-substrate contract tests validating end-to-end behavior (`frankentui` -> service -> persistence).\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.16] Add cross-substrate contract tests validating end-to-end behavior (`frankentui` -> service -> persistence).\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.16] Add cross-substrate contract tests validating end-to-end behavior (`frankentui` -> service -> persistence).\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.16] Add cross-substrate contract tests validating end-to-end behavior (`frankentui` -> service -> persistence).\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.16] Add cross-substrate contract tests validating end-to-end behavior (`frankentui` -> service -> persistence).\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- End-to-end tests cover representative operator flows and replay determinism; failure includes cross-layer trace.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:37:02.512563237Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:45.832321130Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-16","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-8l9k","depends_on_id":"bd-2f5l","type":"blocks","created_at":"2026-02-20T07:43:18.045632301Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-8qlj","title":"[10.18] Integrate VEF verification state into high-risk control transitions and action authorization.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.18 — Verifiable Execution Fabric Execution Track (9L)\n\nWhy This Exists:\nVEF track for proof-carrying runtime compliance: receipt chains, commitment checkpoints, proof generation/verification, and claim gating.\n\nTask Objective:\nIntegrate VEF verification state into high-risk control transitions and action authorization.\n\nAcceptance Criteria:\n- High-risk actions require configured VEF verification state; policy can enforce strict/graded modes; gate decisions are auditable and replayable.\n\nExpected Artifacts:\n- `docs/integration/vef_control_plane_integration.md`, `tests/integration/vef_high_risk_action_gating.rs`, `artifacts/10.18/vef_control_gate_decisions.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_18/bd-8qlj/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_18/bd-8qlj/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.18] Integrate VEF verification state into high-risk control transitions and action authorization.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.18] Integrate VEF verification state into high-risk control transitions and action authorization.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.18] Integrate VEF verification state into high-risk control transitions and action authorization.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.18] Integrate VEF verification state into high-risk control transitions and action authorization.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.18] Integrate VEF verification state into high-risk control transitions and action authorization.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- High-risk actions require configured VEF verification state; policy can enforce strict/graded modes; gate decisions are auditable and replayable.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:37:04.708319971Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:56.028230401Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-18","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-8qlj","depends_on_id":"bd-1o4v","type":"blocks","created_at":"2026-02-20T07:43:19.175032765Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-8tvs","title":"[10.14] Implement per-class symbol-size/overhead/fetch policy with benchmark-derived defaults.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.14 — FrankenSQLite Deep-Mined Expansion Execution Track (9J)\n\nWhy This Exists:\nFrankenSQLite deep-mined control integrity track: evidence ledgers, proofs, epochs, remote effects, markers/MMR, and deterministic fault labs.\n\nTask Objective:\nImplement per-class symbol-size/overhead/fetch policy with benchmark-derived defaults.\n\nAcceptance Criteria:\n- Policy engine applies class-specific defaults at runtime; defaults are justified by benchmark data; policy override path is audited.\n\nExpected Artifacts:\n- `src/policy/object_class_tuning.rs`, `benchmarks/object_class_tuning/*`, `artifacts/10.14/object_class_policy_report.csv`.\n\n- Machine-readable verification artifact at `artifacts/section_10_14/bd-8tvs/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_14/bd-8tvs/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.14] Implement per-class symbol-size/overhead/fetch policy with benchmark-derived defaults.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.14] Implement per-class symbol-size/overhead/fetch policy with benchmark-derived defaults.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.14] Implement per-class symbol-size/overhead/fetch policy with benchmark-derived defaults.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.14] Implement per-class symbol-size/overhead/fetch policy with benchmark-derived defaults.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.14] Implement per-class symbol-size/overhead/fetch policy with benchmark-derived defaults.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"Policy engine applies class-specific defaults at runtime; defaults are justified by benchmark data; policy override path is audited.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:36:57.139699366Z","created_by":"ubuntu","updated_at":"2026-02-20T15:44:07.556386758Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-14","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-8tvs","depends_on_id":"bd-2573","type":"blocks","created_at":"2026-02-20T07:43:15.232335331Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-8uvb","title":"[10.13] Implement overlapping-lease conflict policy and deterministic fork handling logs.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.13 — FCP Deep-Mined Expansion Execution Track (9I)\n\nWhy This Exists:\nDeep connector/provider contract track: lifecycle FSMs, conformance harnesses, fencing, sandboxing, revocation freshness, and protocol hardening.\n\nTask Objective:\nImplement overlapping-lease conflict policy and deterministic fork handling logs.\n\nAcceptance Criteria:\n- Overlapping lease conflicts resolve via documented deterministic rule; dangerous conflicts halt and alert; fork logs contain reproducible evidence.\n\nExpected Artifacts:\n- `docs/specs/lease_conflict_policy.md`, `tests/integration/overlapping_lease_conflicts.rs`, `artifacts/10.13/lease_fork_log_samples.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_13/bd-8uvb/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_13/bd-8uvb/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.13] Implement overlapping-lease conflict policy and deterministic fork handling logs.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.13] Implement overlapping-lease conflict policy and deterministic fork handling logs.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.13] Implement overlapping-lease conflict policy and deterministic fork handling logs.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.13] Implement overlapping-lease conflict policy and deterministic fork handling logs.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.13] Implement overlapping-lease conflict policy and deterministic fork handling logs.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","status":"closed","priority":1,"issue_type":"task","assignee":"CrimsonCrane","created_at":"2026-02-20T07:36:53.435407011Z","created_by":"ubuntu","updated_at":"2026-02-20T12:22:09.970492099Z","closed_at":"2026-02-20T12:22:09.970467493Z","close_reason":"done","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-13","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-8uvb","depends_on_id":"bd-2vs4","type":"blocks","created_at":"2026-02-20T07:43:13.309101118Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-8vby","title":"[10.13] Implement device profile registry and placement policy schema for execution targeting.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.13 — FCP Deep-Mined Expansion Execution Track (9I)\n\nWhy This Exists:\nDeep connector/provider contract track: lifecycle FSMs, conformance harnesses, fencing, sandboxing, revocation freshness, and protocol hardening.\n\nTask Objective:\nImplement device profile registry and placement policy schema for execution targeting.\n\nAcceptance Criteria:\n- Device profiles have validated schema and freshness checks; placement policies reject invalid constraints; policy evaluation is deterministic.\n\nExpected Artifacts:\n- `docs/specs/device_profile_schema.md`, `tests/conformance/placement_policy_schema.rs`, `artifacts/10.13/device_profile_examples.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_13/bd-8vby/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_13/bd-8vby/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.13] Implement device profile registry and placement policy schema for execution targeting.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.13] Implement device profile registry and placement policy schema for execution targeting.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.13] Implement device profile registry and placement policy schema for execution targeting.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.13] Implement device profile registry and placement policy schema for execution targeting.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.13] Implement device profile registry and placement policy schema for execution targeting.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","status":"closed","priority":1,"issue_type":"task","assignee":"CrimsonCrane","created_at":"2026-02-20T07:36:53.517398144Z","created_by":"ubuntu","updated_at":"2026-02-20T12:25:55.036302890Z","closed_at":"2026-02-20T12:25:55.036274818Z","close_reason":"done","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-13","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-8vby","depends_on_id":"bd-8uvb","type":"blocks","created_at":"2026-02-20T07:43:13.350198230Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-91gg","title":"[10.13] Implement background repair controller with bounded work-per-cycle and fairness controls.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.13 — FCP Deep-Mined Expansion Execution Track (9I)\n\nWhy This Exists:\nDeep connector/provider contract track: lifecycle FSMs, conformance harnesses, fencing, sandboxing, revocation freshness, and protocol hardening.\n\nTask Objective:\nImplement background repair controller with bounded work-per-cycle and fairness controls.\n\nAcceptance Criteria:\n- Repair loop respects per-cycle work caps and fairness constraints; no tenant starvation under synthetic load; controller decisions are auditable.\n\nExpected Artifacts:\n- `src/repair/background_repair_controller.rs`, `tests/perf/repair_fairness.rs`, `artifacts/10.13/repair_cycle_telemetry.csv`.\n\n- Machine-readable verification artifact at `artifacts/section_10_13/bd-91gg/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_13/bd-91gg/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.13] Implement background repair controller with bounded work-per-cycle and fairness controls.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.13] Implement background repair controller with bounded work-per-cycle and fairness controls.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.13] Implement background repair controller with bounded work-per-cycle and fairness controls.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.13] Implement background repair controller with bounded work-per-cycle and fairness controls.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.13] Implement background repair controller with bounded work-per-cycle and fairness controls.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","status":"closed","priority":1,"issue_type":"task","assignee":"CrimsonCrane","created_at":"2026-02-20T07:36:53.843418486Z","created_by":"ubuntu","updated_at":"2026-02-20T12:41:27.513000782Z","closed_at":"2026-02-20T12:41:27.512973661Z","close_reason":"done","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-13","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-91gg","depends_on_id":"bd-29w6","type":"blocks","created_at":"2026-02-20T07:43:13.516444147Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-93k","title":"[10.11] Add checkpoint-placement contract in all long orchestration loops.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.11 — FrankenSQLite-Inspired Runtime Systems Integration Track\n\nWhy This Exists:\nFrankenSQLite-inspired systems integration of capabilities, cancellation protocol, obligations, deterministic labs, and anti-entropy.\n\nTask Objective:\nAdd checkpoint-placement contract in all long orchestration loops.\n\nAcceptance Criteria:\n- Implement with explicit success/failure invariants and deterministic behavior under normal, edge, and fault scenarios.\n- Ensure outcomes are verifiable via automated tests and reproducible artifact outputs.\n\nExpected Artifacts:\n- Section-owned design/spec artifact at `docs/specs/section_10_11/bd-93k_contract.md`, capturing decision rationale, invariants, and interface boundaries.\n- Machine-readable verification artifact at `artifacts/section_10_11/bd-93k/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_11/bd-93k/verification_summary.md` linking implementation intent to measured outcomes.\n\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.11] Add checkpoint-placement contract in all long orchestration loops.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.11] Add checkpoint-placement contract in all long orchestration loops.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.11] Add checkpoint-placement contract in all long orchestration loops.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.11] Add checkpoint-placement contract in all long orchestration loops.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.11] Add checkpoint-placement contract in all long orchestration loops.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"AC for bd-93k:\n1. Every long orchestration loop (defined as any loop that may execute more than N iterations or exceed T wall-clock seconds, where N and T are configurable) must contain at least one checkpoint call that persists recoverable state.\n2. A CheckpointContract trait is defined with methods: save_checkpoint(state) -> CheckpointId, restore_checkpoint(id) -> State, and list_checkpoints() -> Vec<CheckpointMeta>.\n3. A compile-time or lint-time contract checker verifies that all orchestration loops annotated with #[long_orchestration] contain at least one checkpoint call; missing checkpoints cause a build warning (or error in strict mode).\n4. Checkpoints are idempotent: calling save_checkpoint with identical state produces the same CheckpointId (content-addressed).\n5. On crash recovery, the orchestration loop resumes from the latest valid checkpoint rather than restarting from scratch; a test demonstrates this by injecting a panic mid-loop and verifying resumed iteration count.\n6. Checkpoint storage is pluggable (in-memory for tests, persistent for production) via a CheckpointBackend trait.\n7. Unit tests verify: (a) checkpoint save/restore round-trip, (b) idempotent checkpoint ID stability, (c) loop resumption after simulated crash, (d) missing-checkpoint lint fires on unannotated loop.\n8. Structured log events use stable codes CHECKPOINT_SAVE / CHECKPOINT_RESTORE / CHECKPOINT_MISSING with loop identifier and iteration count context.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:36:49.822962089Z","created_by":"ubuntu","updated_at":"2026-02-20T15:18:05.202000980Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-11","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-93k","depends_on_id":"bd-3vm","type":"blocks","created_at":"2026-02-20T07:43:11.409939991Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-9is","title":"[10.9] Build autonomous adversarial campaign runner with continuous updates.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.9 — Moonshot Disruption Track\n\nWhy This Exists:\nMoonshot disruption track for public benchmark leadership, adversarial campaigns, verifier economy, and category-shift reporting.\n\nTask Objective:\nBuild autonomous adversarial campaign runner with continuous updates.\n\nAcceptance Criteria:\n- Implement with explicit success/failure invariants and deterministic behavior under normal, edge, and fault scenarios.\n- Ensure outcomes are verifiable via automated tests and reproducible artifact outputs.\n\nExpected Artifacts:\n- Section-owned design/spec artifact at `docs/specs/section_10_9/bd-9is_contract.md`, capturing decision rationale, invariants, and interface boundaries.\n- Machine-readable verification artifact at `artifacts/section_10_9/bd-9is/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_9/bd-9is/verification_summary.md` linking implementation intent to measured outcomes.\n\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.9] Build autonomous adversarial campaign runner with continuous updates.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.9] Build autonomous adversarial campaign runner with continuous updates.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.9] Build autonomous adversarial campaign runner with continuous updates.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.9] Build autonomous adversarial campaign runner with continuous updates.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.9] Build autonomous adversarial campaign runner with continuous updates.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"1. Adversarial campaign runner continuously generates and executes attack scenarios against franken_node: malformed inputs, privilege escalation attempts, resource exhaustion, timing attacks, and supply-chain injection simulations.\n2. Runner updates its attack corpus automatically by ingesting new CVEs, fuzzer findings, and adversarial patterns from configured feeds.\n3. Campaign runs on a schedule (at least daily in CI) and produces a structured JSON report with: scenarios executed, passes, failures, new findings, and severity classifications.\n4. Any new finding is automatically filed as a bead with severity tag and linked to the campaign run that discovered it.\n5. Runner supports pluggable attack generators: new attack categories can be added via a documented interface without modifying the runner core.\n6. Per Section 9F moonshot bets: runner tracks attacker-ROI metrics — estimated cost-to-attack vs. cost-to-defend for each scenario.\n7. Historical trend data is persisted and a regression detector alerts when previously-passing scenarios begin failing.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:36:48.365808717Z","created_by":"ubuntu","updated_at":"2026-02-20T15:19:52.727101806Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-9","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-9is","depends_on_id":"bd-f5d","type":"blocks","created_at":"2026-02-20T07:43:24.044512521Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-ac83","title":"[10.14] Implement named remote computation registry and reject unknown computation identifiers.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.14 — FrankenSQLite Deep-Mined Expansion Execution Track (9J)\n\nWhy This Exists:\nFrankenSQLite deep-mined control integrity track: evidence ledgers, proofs, epochs, remote effects, markers/MMR, and deterministic fault labs.\n\nTask Objective:\nImplement named remote computation registry and reject unknown computation identifiers.\n\nAcceptance Criteria:\n- Remote execution accepts only registered computation names; unknown or malformed names are rejected with stable codes; registry is versioned.\n\nExpected Artifacts:\n- `src/remote/computation_registry.rs`, `tests/conformance/remote_name_registry.rs`, `artifacts/10.14/remote_registry_catalog.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_14/bd-ac83/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_14/bd-ac83/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.14] Implement named remote computation registry and reject unknown computation identifiers.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.14] Implement named remote computation registry and reject unknown computation identifiers.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.14] Implement named remote computation registry and reject unknown computation identifiers.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.14] Implement named remote computation registry and reject unknown computation identifiers.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.14] Implement named remote computation registry and reject unknown computation identifiers.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"Remote execution accepts only registered computation names; unknown or malformed names are rejected with stable codes; registry is versioned.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:36:57.731532743Z","created_by":"ubuntu","updated_at":"2026-02-20T15:44:06.037402580Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-14","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-ac83","depends_on_id":"bd-1nfu","type":"blocks","created_at":"2026-02-20T07:43:15.527702593Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-al8i","title":"[10.17] Implement L2 engine-boundary N-version semantic oracle across franken_engine and reference runtimes.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.17 — Radical Expansion Execution Track (9K)\n\nWhy This Exists:\nRadical expansion track for proof-carrying speculation, Bayesian adversary control, time-travel replay, ZK attestations, and claim compiler systems.\n\nTask Objective:\nImplement L2 engine-boundary N-version semantic oracle across franken_engine and reference runtimes.\n\nAcceptance Criteria:\n- Differential harness classifies boundary divergences by risk tier and blocks release on high-risk unresolved deltas; low-risk deltas require explicit policy receipts and link back to L1 product-oracle results.\n\nExpected Artifacts:\n- `tests/oracle/n_version_semantic_oracle.rs`, `docs/testing/semantic_oracle_policy.md`, `artifacts/10.17/semantic_oracle_divergence_matrix.csv`.\n\n- Machine-readable verification artifact at `artifacts/section_10_17/bd-al8i/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_17/bd-al8i/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.17] Implement L2 engine-boundary N-version semantic oracle across franken_engine and reference runtimes.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.17] Implement L2 engine-boundary N-version semantic oracle across franken_engine and reference runtimes.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.17] Implement L2 engine-boundary N-version semantic oracle across franken_engine and reference runtimes.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.17] Implement L2 engine-boundary N-version semantic oracle across franken_engine and reference runtimes.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.17] Implement L2 engine-boundary N-version semantic oracle across franken_engine and reference runtimes.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- Differential harness classifies boundary divergences by risk tier and blocks release on high-risk unresolved deltas; low-risk deltas require explicit policy receipts and link back to L1 product-oracle results.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:37:03.433918277Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:59.739854822Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-17","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-al8i","depends_on_id":"bd-kcg9","type":"blocks","created_at":"2026-02-20T07:43:18.519351208Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-aoq6","title":"[10.21] Integrate evolution stability scoring into migration autopilot dependency admission and rollback gates.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.21 — Behavioral Phenotype Evolution Tracker Execution Track (9O)\n\nWhy This Exists:\nBPET longitudinal phenotype intelligence track for pre-compromise trajectory detection and integration with DGIS/ATC/migration/economic policy.\n\nTask Objective:\nIntegrate evolution stability scoring into migration autopilot dependency admission and rollback gates.\n\nAcceptance Criteria:\n- Migration planner includes trajectory-stability constraints; upgrades crossing risk thresholds require additional evidence or staged rollout with automated fallback plans.\n\nExpected Artifacts:\n- `src/migration/bpet_migration_gate.rs`, `tests/integration/bpet_migration_stability_gate.rs`, `artifacts/10.21/bpet_migration_gate_results.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_21/bd-aoq6/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_21/bd-aoq6/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.21] Integrate evolution stability scoring into migration autopilot dependency admission and rollback gates.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.21] Integrate evolution stability scoring into migration autopilot dependency admission and rollback gates.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.21] Integrate evolution stability scoring into migration autopilot dependency admission and rollback gates.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.21] Integrate evolution stability scoring into migration autopilot dependency admission and rollback gates.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.21] Integrate evolution stability scoring into migration autopilot dependency admission and rollback gates.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- Migration planner includes trajectory-stability constraints; upgrades crossing risk thresholds require additional evidence or staged rollout with automated fallback plans.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:37:08.627241090Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:25.931119926Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-21","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-aoq6","depends_on_id":"bd-1jpc","type":"blocks","created_at":"2026-02-20T15:01:15.980176224Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-aoq6","depends_on_id":"bd-2zo1","type":"blocks","created_at":"2026-02-20T07:43:21.773050558Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-b44","title":"[10.13] Add state schema version contracts and deterministic migration hint execution checks.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.13 — FCP Deep-Mined Expansion Execution Track (9I)\n\nWhy This Exists:\nDeep connector/provider contract track: lifecycle FSMs, conformance harnesses, fencing, sandboxing, revocation freshness, and protocol hardening.\n\nTask Objective:\nAdd state schema version contracts and deterministic migration hint execution checks.\n\nAcceptance Criteria:\n- Version transitions require declared migration path; migrations are idempotent and replay-stable; failed migrations rollback cleanly.\n\nExpected Artifacts:\n- `docs/specs/state_schema_migrations.md`, `tests/integration/state_migration_contract.rs`, `artifacts/10.13/state_migration_receipts.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_13/bd-b44/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_13/bd-b44/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.13] Add state schema version contracts and deterministic migration hint execution checks.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.13] Add state schema version contracts and deterministic migration hint execution checks.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.13] Add state schema version contracts and deterministic migration hint execution checks.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.13] Add state schema version contracts and deterministic migration hint execution checks.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.13] Add state schema version contracts and deterministic migration hint execution checks.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","status":"closed","priority":1,"issue_type":"task","assignee":"CrimsonCrane","created_at":"2026-02-20T07:36:52.041101645Z","created_by":"ubuntu","updated_at":"2026-02-20T11:07:38.066236989Z","closed_at":"2026-02-20T11:07:38.066211973Z","close_reason":"done","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-13","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-b44","depends_on_id":"bd-24s","type":"blocks","created_at":"2026-02-20T07:43:12.569358060Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-b541","title":"[10.20] Define canonical dependency/topology graph schema covering packages, extensions, publishers, maintainers, and transitive edge semantics.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.20 — Dependency Graph Immune System Execution Track (9N)\n\nWhy This Exists:\nDGIS topological immune system track for dependency contagion modeling, choke-point immunization, and graph-aware containment economics.\n\nTask Objective:\nDefine canonical dependency/topology graph schema covering packages, extensions, publishers, maintainers, and transitive edge semantics.\n\nAcceptance Criteria:\n- Schema captures runtime/build/provenance edge types, trust metadata, update cadence, and policy annotations; identical inputs yield hash-stable graph serialization and signed snapshots.\n\nExpected Artifacts:\n- `docs/specs/dgis_graph_schema.md`, `spec/dgis_graph_schema_v1.json`, `artifacts/10.20/dgis_graph_schema_vectors.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_20/bd-b541/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_20/bd-b541/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.20] Define canonical dependency/topology graph schema covering packages, extensions, publishers, maintainers, and transitive edge semantics.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.20] Define canonical dependency/topology graph schema covering packages, extensions, publishers, maintainers, and transitive edge semantics.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.20] Define canonical dependency/topology graph schema covering packages, extensions, publishers, maintainers, and transitive edge semantics.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.20] Define canonical dependency/topology graph schema covering packages, extensions, publishers, maintainers, and transitive edge semantics.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.20] Define canonical dependency/topology graph schema covering packages, extensions, publishers, maintainers, and transitive edge semantics.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- Schema captures runtime/build/provenance edge types, trust metadata, update cadence, and policy annotations; identical inputs yield hash-stable graph serialization and signed snapshots.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:37:06.418562507Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:26.154166219Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-20","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-b541","depends_on_id":"bd-1wz","type":"blocks","created_at":"2026-02-20T07:46:35.183993121Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-b541","depends_on_id":"bd-39a","type":"blocks","created_at":"2026-02-20T07:46:35.230039473Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-b541","depends_on_id":"bd-cda","type":"blocks","created_at":"2026-02-20T07:46:35.274404895Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-b9b6","title":"[10.14] Emit \"durability contract violated\" diagnostic bundles when hardening cannot restore verifiability.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.14 — FrankenSQLite Deep-Mined Expansion Execution Track (9J)\n\nWhy This Exists:\nFrankenSQLite deep-mined control integrity track: evidence ledgers, proofs, epochs, remote effects, markers/MMR, and deterministic fault labs.\n\nTask Objective:\nEmit \"durability contract violated\" diagnostic bundles when hardening cannot restore verifiability.\n\nAcceptance Criteria:\n- Violation bundles include causal event sequence, failed artifacts, and proof context; bundle generation is deterministic; gating operations are halted per policy.\n\nExpected Artifacts:\n- `docs/runbooks/durability_contract_violated.md`, `tests/integration/durability_violation_bundle.rs`, `artifacts/10.14/durability_violation_bundle_example.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_14/bd-b9b6/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_14/bd-b9b6/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.14] Emit \"durability contract violated\" diagnostic bundles when hardening cannot restore verifiability.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.14] Emit \"durability contract violated\" diagnostic bundles when hardening cannot restore verifiability.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.14] Emit \"durability contract violated\" diagnostic bundles when hardening cannot restore verifiability.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.14] Emit \"durability contract violated\" diagnostic bundles when hardening cannot restore verifiability.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.14] Emit \"durability contract violated\" diagnostic bundles when hardening cannot restore verifiability.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"Violation bundles include causal event sequence, failed artifacts, and proof context; bundle generation is deterministic; gating operations are halted per policy.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:36:56.463373737Z","created_by":"ubuntu","updated_at":"2026-02-20T15:44:09.278537903Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-14","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-b9b6","depends_on_id":"bd-1fp4","type":"blocks","created_at":"2026-02-20T07:43:14.894298187Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-bq4p","title":"[10.14] Implement controller boundary checks rejecting any attempted correctness-semantic mutation.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.14 — FrankenSQLite Deep-Mined Expansion Execution Track (9J)\n\nWhy This Exists:\nFrankenSQLite deep-mined control integrity track: evidence ledgers, proofs, epochs, remote effects, markers/MMR, and deterministic fault labs.\n\nTask Objective:\nImplement controller boundary checks rejecting any attempted correctness-semantic mutation.\n\nAcceptance Criteria:\n- Boundary checks run pre-apply for every policy proposal; violation attempts return stable error class; audit trail records rejected mutation intent.\n\nExpected Artifacts:\n- `src/policy/controller_boundary_checks.rs`, `tests/security/controller_mutation_rejection.rs`, `artifacts/10.14/controller_boundary_rejections.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_14/bd-bq4p/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_14/bd-bq4p/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.14] Implement controller boundary checks rejecting any attempted correctness-semantic mutation.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.14] Implement controller boundary checks rejecting any attempted correctness-semantic mutation.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.14] Implement controller boundary checks rejecting any attempted correctness-semantic mutation.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.14] Implement controller boundary checks rejecting any attempted correctness-semantic mutation.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.14] Implement controller boundary checks rejecting any attempted correctness-semantic mutation.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"Boundary checks run pre-apply for every policy proposal; violation attempts return stable error class; audit trail records rejected mutation intent.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:36:55.629743289Z","created_by":"ubuntu","updated_at":"2026-02-20T15:44:11.455822653Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-14","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-bq4p","depends_on_id":"bd-sddz","type":"blocks","created_at":"2026-02-20T07:43:14.470559086Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-bq6y","title":"[10.13] Implement generic lease service for operation execution, state writes, and migration handoff.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.13 — FCP Deep-Mined Expansion Execution Track (9I)\n\nWhy This Exists:\nDeep connector/provider contract track: lifecycle FSMs, conformance harnesses, fencing, sandboxing, revocation freshness, and protocol hardening.\n\nTask Objective:\nImplement generic lease service for operation execution, state writes, and migration handoff.\n\nAcceptance Criteria:\n- Lease API supports all required purposes with shared semantics; lease expiry and renewal behavior is deterministic; stale lease usage is rejected.\n\nExpected Artifacts:\n- `src/control_plane/lease_service.rs`, `docs/specs/generic_leases.md`, `artifacts/10.13/lease_service_contract.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_13/bd-bq6y/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_13/bd-bq6y/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.13] Implement generic lease service for operation execution, state writes, and migration handoff.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.13] Implement generic lease service for operation execution, state writes, and migration handoff.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.13] Implement generic lease service for operation execution, state writes, and migration handoff.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.13] Implement generic lease service for operation execution, state writes, and migration handoff.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.13] Implement generic lease service for operation execution, state writes, and migration handoff.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","status":"closed","priority":1,"issue_type":"task","assignee":"CrimsonCrane","created_at":"2026-02-20T07:36:53.275390171Z","created_by":"ubuntu","updated_at":"2026-02-20T12:11:47.261333863Z","closed_at":"2026-02-20T12:11:47.261308806Z","close_reason":"done","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-13","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-bq6y","depends_on_id":"bd-w0jq","type":"blocks","created_at":"2026-02-20T07:43:13.225997189Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-bt82","title":"[10.16] Define `sqlmodel_rust` usage policy and typed model boundaries.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.16 — Adjacent Substrate Integration Execution Track (8.7)\n\nWhy This Exists:\nAdjacent substrate integration track to enforce deep composition with frankentui, frankensqlite, sqlmodel_rust, and fastapi_rust.\n\nTask Objective:\nDefine `sqlmodel_rust` usage policy and typed model boundaries.\n\nAcceptance Criteria:\n- Policy defines where typed models are mandatory vs optional; model ownership and codegen/versioning expectations are explicit.\n\nExpected Artifacts:\n- `docs/specs/sqlmodel_rust_usage_policy.md`, `artifacts/10.16/sqlmodel_policy_matrix.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_16/bd-bt82/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_16/bd-bt82/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.16] Define `sqlmodel_rust` usage policy and typed model boundaries.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.16] Define `sqlmodel_rust` usage policy and typed model boundaries.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.16] Define `sqlmodel_rust` usage policy and typed model boundaries.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.16] Define `sqlmodel_rust` usage policy and typed model boundaries.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.16] Define `sqlmodel_rust` usage policy and typed model boundaries.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- Policy defines where typed models are mandatory vs optional; model ownership and codegen/versioning expectations are explicit.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:37:02.185287076Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:46.734950949Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-16","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-bt82","depends_on_id":"bd-26ux","type":"blocks","created_at":"2026-02-20T07:43:17.879116159Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-c1ri","title":"Epic: Control Channel + Telemetry [10.13g]","description":"- type: epic","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-20T07:47:58.072163029Z","updated_at":"2026-02-20T07:49:21.192901846Z","closed_at":"2026-02-20T07:49:21.192884895Z","close_reason":"Superseded by canonical detailed master-plan graph (bd-33v) with full 10.N-10.21 and 11-16 coverage, explicit dependencies, and per-section verification gates.","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-c4f","title":"[PLAN 10.8] Operational Readiness","description":"Section: 10.8 — Operational Readiness\n\nStrategic Context:\nOperational readiness and fleet safety posture: control APIs, observability contracts, safe-mode operations, and disaster drills.\n\nExecution Requirements:\n- Preserve all scoped capabilities from the canonical plan.\n- Keep contracts self-contained so future contributors can execute without reopening the master plan.\n- Require explicit testing strategy (unit + integration/e2e) and structured logging/telemetry for every child bead.\n- Require artifact-backed validation for performance, security, and correctness claims.\n\nDependency Semantics:\n- This epic is blocked by its child implementation beads.\n- Cross-epic dependencies encode strategic sequencing and canonical ownership boundaries.\n\n## Success Criteria\n- All child beads for this section are completed with acceptance artifacts attached and no unresolved blockers.\n- Section-level verification gate for comprehensive unit tests, integration/e2e workflows, and detailed structured logging evidence is green.\n- Scope-to-plan traceability is explicit, with no feature loss versus the canonical plan section.\n\n## Optimization Notes\n- User-Outcome Lens: \"[PLAN 10.8] Operational Readiness\" must improve operator confidence, safety posture, and deterministic recovery behavior under both normal and adversarial conditions.\n- Cross-Section Coordination: child beads must encode integration assumptions explicitly to avoid local optimizations that degrade system-wide correctness.\n- Verification Non-Negotiable: completion requires reproducible unit/integration/E2E evidence and structured logs suitable for independent replay.\n- Scope Protection: any simplification must preserve canonical-plan feature intent and be justified with explicit tradeoff documentation.","status":"open","priority":2,"issue_type":"epic","created_at":"2026-02-20T07:36:40.869070676Z","created_by":"ubuntu","updated_at":"2026-02-20T08:16:48.401705139Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-8"],"dependencies":[{"issue_id":"bd-c4f","depends_on_id":"bd-1fi2","type":"blocks","created_at":"2026-02-20T07:48:26.408839126Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-c4f","depends_on_id":"bd-1hf","type":"blocks","created_at":"2026-02-20T07:37:10.473264242Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-c4f","depends_on_id":"bd-1ta","type":"blocks","created_at":"2026-02-20T07:37:10.512039328Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-c4f","depends_on_id":"bd-20a","type":"blocks","created_at":"2026-02-20T07:37:10.433812366Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-c4f","depends_on_id":"bd-3m6","type":"blocks","created_at":"2026-02-20T07:36:48.244705350Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-c4f","depends_on_id":"bd-3o6","type":"blocks","created_at":"2026-02-20T07:36:47.903942117Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-c4f","depends_on_id":"bd-cda","type":"blocks","created_at":"2026-02-20T07:37:09.347462613Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-c4f","depends_on_id":"bd-f2y","type":"blocks","created_at":"2026-02-20T07:36:48.062724949Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-c4f","depends_on_id":"bd-k6o","type":"blocks","created_at":"2026-02-20T07:36:47.984291001Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-c4f","depends_on_id":"bd-nr4","type":"blocks","created_at":"2026-02-20T07:36:48.163231450Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-c4f","depends_on_id":"bd-tg2","type":"blocks","created_at":"2026-02-20T07:36:47.787141765Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-c781","title":"[11] Section-wide verification gate: comprehensive unit+e2e+logging","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 11\n\nTask Objective:\nCreate a hard section completion gate that verifies all implemented behavior in this section with comprehensive unit tests, integration/e2e scripts, and detailed structured logging evidence.\n\nAcceptance Criteria:\n- Section test matrix covers happy-path, edge-case, and adversarial/error-path scenarios for all section deliverables.\n- E2E scripts execute representative end-user workflows and policy/control-plane transitions for this section.\n- Structured logs include stable event/error codes, trace correlation IDs, and enough context for deterministic replay triage.\n- Verification report is deterministic and machine-readable for CI/release gating.\n\nExpected Artifacts:\n- Section-level test matrix and coverage summary artifact.\n- E2E script suite with pass/fail outputs and reproducible fixtures/seeds.\n- Structured log validation report and traceability bundle.\n- Gate verdict artifact consumable by release automation.\n\n- Machine-readable verification artifact at `artifacts/section_11/bd-c781/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_11/bd-c781/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests must validate contracts, invariants, and failure semantics.\n- E2E tests must validate cross-component behavior from user/operator entrypoints to persisted effects.\n- Logging must support root-cause analysis without hidden context requirements.\n\nTask-Specific Clarification:\n- For \"[11] Section-wide verification gate: comprehensive unit+e2e+logging\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[11] Section-wide verification gate: comprehensive unit+e2e+logging\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[11] Section-wide verification gate: comprehensive unit+e2e+logging\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[11] Section-wide verification gate: comprehensive unit+e2e+logging\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[11] Section-wide verification gate: comprehensive unit+e2e+logging\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"1. Section 11 verification gate runs all section-11 check scripts and confirms 100% pass rate.\n2. Gate validates: (a) every contract field check script exists and passes self-test, (b) every contract field has unit tests that pass, (c) integration test demonstrates end-to-end contract validation on a sample PR.\n3. Evidence artifacts for all section-11 beads are present under artifacts/section_11/.\n4. Logging covers: gate start/end timestamps, per-check pass/fail, overall verdict.\n5. Gate produces a section_11_verification_summary.md with pass/fail matrix for all sub-beads.\n6. The gate itself has a unit test verifying it correctly aggregates sub-check results.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:48:27.383018037Z","created_by":"ubuntu","updated_at":"2026-02-20T15:17:26.990000734Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-11","test-obligations","verification-gate"],"dependencies":[{"issue_id":"bd-c781","depends_on_id":"bd-1dpd","type":"blocks","created_at":"2026-02-20T08:24:24.173598144Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-c781","depends_on_id":"bd-1jmq","type":"blocks","created_at":"2026-02-20T07:48:27.780026176Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-c781","depends_on_id":"bd-2fpj","type":"blocks","created_at":"2026-02-20T07:48:27.731249838Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-c781","depends_on_id":"bd-2twu","type":"blocks","created_at":"2026-02-20T08:20:49.636723874Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-c781","depends_on_id":"bd-2ut3","type":"blocks","created_at":"2026-02-20T07:48:27.481438841Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-c781","depends_on_id":"bd-2ymp","type":"blocks","created_at":"2026-02-20T07:48:27.631507492Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-c781","depends_on_id":"bd-36wa","type":"blocks","created_at":"2026-02-20T07:48:27.831121033Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-c781","depends_on_id":"bd-3l8d","type":"blocks","created_at":"2026-02-20T07:48:27.530747802Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-c781","depends_on_id":"bd-3se1","type":"blocks","created_at":"2026-02-20T07:48:27.882729136Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-c781","depends_on_id":"bd-3v8f","type":"blocks","created_at":"2026-02-20T07:48:27.682492504Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-c781","depends_on_id":"bd-nglx","type":"blocks","created_at":"2026-02-20T07:48:27.582602815Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-c97l","title":"[10.20] Integrate DGIS topological context into trust cards, adversary graph posterior updates, and extension risk UI.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.20 — Dependency Graph Immune System Execution Track (9N)\n\nWhy This Exists:\nDGIS topological immune system track for dependency contagion modeling, choke-point immunization, and graph-aware containment economics.\n\nTask Objective:\nIntegrate DGIS topological context into trust cards, adversary graph posterior updates, and extension risk UI.\n\nAcceptance Criteria:\n- Risk surfaces show node-level topological blast-radius context and delta impact from planned updates; posterior scoring incorporates topology features with explicit attribution.\n\nExpected Artifacts:\n- `src/security/dgis/risk_surface_integration.rs`, `tests/integration/dgis_trust_card_integration.rs`, `artifacts/10.20/dgis_risk_ui_snapshot.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_20/bd-c97l/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_20/bd-c97l/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.20] Integrate DGIS topological context into trust cards, adversary graph posterior updates, and extension risk UI.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.20] Integrate DGIS topological context into trust cards, adversary graph posterior updates, and extension risk UI.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.20] Integrate DGIS topological context into trust cards, adversary graph posterior updates, and extension risk UI.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.20] Integrate DGIS topological context into trust cards, adversary graph posterior updates, and extension risk UI.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.20] Integrate DGIS topological context into trust cards, adversary graph posterior updates, and extension risk UI.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- Risk surfaces show node-level topological blast-radius context and delta impact from planned updates; posterior scoring incorporates topology features with explicit attribution.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:37:06.997270565Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:26.414762112Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-20","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-c97l","depends_on_id":"bd-1tnu","type":"blocks","created_at":"2026-02-20T07:43:20.887845429Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-cclm","title":"[10.20] Add adversarial validation suite (graph poisoning, edge-obfuscation, fake-low-risk pivots, delayed activation) with fail-closed semantics.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.20 — Dependency Graph Immune System Execution Track (9N)\n\nWhy This Exists:\nDGIS topological immune system track for dependency contagion modeling, choke-point immunization, and graph-aware containment economics.\n\nTask Objective:\nAdd adversarial validation suite (graph poisoning, edge-obfuscation, fake-low-risk pivots, delayed activation) with fail-closed semantics.\n\nAcceptance Criteria:\n- Adversarial campaigns are encoded as deterministic fixtures; DGIS detects or bounds damage within defined limits; bypass attempts emit stable error classes and remediation hints.\n\nExpected Artifacts:\n- `tests/security/dgis_adversarial_suite.rs`, `docs/security/dgis_attack_playbook.md`, `artifacts/10.20/dgis_adversarial_results.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_20/bd-cclm/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_20/bd-cclm/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.20] Add adversarial validation suite (graph poisoning, edge-obfuscation, fake-low-risk pivots, delayed activation) with fail-closed semantics.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.20] Add adversarial validation suite (graph poisoning, edge-obfuscation, fake-low-risk pivots, delayed activation) with fail-closed semantics.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.20] Add adversarial validation suite (graph poisoning, edge-obfuscation, fake-low-risk pivots, delayed activation) with fail-closed semantics.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.20] Add adversarial validation suite (graph poisoning, edge-obfuscation, fake-low-risk pivots, delayed activation) with fail-closed semantics.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.20] Add adversarial validation suite (graph poisoning, edge-obfuscation, fake-low-risk pivots, delayed activation) with fail-closed semantics.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- Adversarial campaigns are encoded as deterministic fixtures; DGIS detects or bounds damage within defined limits; bypass attempts emit stable error classes and remediation hints.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:37:07.527097073Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:26.645246886Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-20","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-cclm","depends_on_id":"bd-2d17","type":"blocks","created_at":"2026-02-20T07:43:21.150941047Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-cda","title":"[PLAN 10.N] Execution Normalization Contract (No Duplicate Implementations)","description":"Section: 10.N — Execution Normalization Contract (No Duplicate Implementations)\n\nStrategic Context:\nExecution normalization to prevent duplicate implementations, enforce canonical ownership, and keep cross-track integration coherent.\n\nExecution Requirements:\n- Preserve all scoped capabilities from the canonical plan.\n- Keep contracts self-contained so future contributors can execute without reopening the master plan.\n- Require explicit testing strategy (unit + integration/e2e) and structured logging/telemetry for every child bead.\n- Require artifact-backed validation for performance, security, and correctness claims.\n\nDependency Semantics:\n- This epic is blocked by its child implementation beads.\n- Cross-epic dependencies encode strategic sequencing and canonical ownership boundaries.\n\n## Success Criteria\n- All child beads for this section are completed with acceptance artifacts attached and no unresolved blockers.\n- Section-level verification gate for comprehensive unit tests, integration/e2e workflows, and detailed structured logging evidence is green.\n- Scope-to-plan traceability is explicit, with no feature loss versus the canonical plan section.\n\n## Optimization Notes\n- User-Outcome Lens: \"[PLAN 10.N] Execution Normalization Contract (No Duplicate Implementations)\" must improve operator confidence, safety posture, and deterministic recovery behavior under both normal and adversarial conditions.\n- Cross-Section Coordination: child beads must encode integration assumptions explicitly to avoid local optimizations that degrade system-wide correctness.\n- Verification Non-Negotiable: completion requires reproducible unit/integration/E2E evidence and structured logs suitable for independent replay.\n- Scope Protection: any simplification must preserve canonical-plan feature intent and be justified with explicit tradeoff documentation.","status":"closed","priority":1,"issue_type":"epic","created_at":"2026-02-20T07:36:40.132488047Z","created_by":"ubuntu","updated_at":"2026-02-20T08:41:50.891275800Z","closed_at":"2026-02-20T08:41:50.891190381Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-N"],"dependencies":[{"issue_id":"bd-cda","depends_on_id":"bd-1neb","type":"blocks","created_at":"2026-02-20T07:48:27.220550663Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-cda","depends_on_id":"bd-1oyt","type":"blocks","created_at":"2026-02-20T07:50:04.664351830Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-cda","depends_on_id":"bd-1v2c","type":"blocks","created_at":"2026-02-20T07:50:04.758779969Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-cda","depends_on_id":"bd-2yhs","type":"blocks","created_at":"2026-02-20T07:50:04.569309366Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-cda","depends_on_id":"bd-zxk8","type":"blocks","created_at":"2026-02-20T07:50:04.448172801Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-ck2h","title":"[10.13] Define MVP vs Full conformance profile matrix and publication claim rules.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.13 — FCP Deep-Mined Expansion Execution Track (9I)\n\nWhy This Exists:\nDeep connector/provider contract track: lifecycle FSMs, conformance harnesses, fencing, sandboxing, revocation freshness, and protocol hardening.\n\nTask Objective:\nDefine MVP vs Full conformance profile matrix and publication claim rules.\n\nAcceptance Criteria:\n- Profile matrix maps required capabilities to claim language; publication metadata is generated from measured profile results; unsupported claims are blocked.\n\nExpected Artifacts:\n- `docs/conformance/profile_matrix.md`, `tests/conformance/profile_claim_gate.rs`, `artifacts/10.13/profile_claim_report.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_13/bd-ck2h/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_13/bd-ck2h/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.13] Define MVP vs Full conformance profile matrix and publication claim rules.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.13] Define MVP vs Full conformance profile matrix and publication claim rules.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.13] Define MVP vs Full conformance profile matrix and publication claim rules.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.13] Define MVP vs Full conformance profile matrix and publication claim rules.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.13] Define MVP vs Full conformance profile matrix and publication claim rules.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","status":"closed","priority":1,"issue_type":"task","assignee":"CrimsonCrane","created_at":"2026-02-20T07:36:54.818421576Z","created_by":"ubuntu","updated_at":"2026-02-20T13:29:24.402952603Z","closed_at":"2026-02-20T13:29:24.402923880Z","close_reason":"done","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-13","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-ck2h","depends_on_id":"bd-1gnb","type":"blocks","created_at":"2026-02-20T07:43:14.020689699Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-cuut","title":"[10.15] Define lane mapping policy for control-plane workloads (Cancel/Timed/Ready).","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.15 — Asupersync-First Integration Execution Track (8.4-8.6)\n\nWhy This Exists:\nAsupersync-first control-plane migration track enforcing Cx-first, region ownership, cancellation correctness, and protocol-grade verification gates.\n\nTask Objective:\nDefine lane mapping policy for control-plane workloads (Cancel/Timed/Ready).\n\nAcceptance Criteria:\n- Every control task class has lane assignment and budget policy; starvation checks are automated.\n\nExpected Artifacts:\n- `docs/specs/control_lane_mapping.md`, `tests/conformance/control_lane_policy.rs`, `artifacts/10.15/lane_starvation_metrics.csv`.\n\n- Machine-readable verification artifact at `artifacts/section_10_15/bd-cuut/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_15/bd-cuut/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.15] Define lane mapping policy for control-plane workloads (Cancel/Timed/Ready).\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.15] Define lane mapping policy for control-plane workloads (Cancel/Timed/Ready).\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.15] Define lane mapping policy for control-plane workloads (Cancel/Timed/Ready).\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.15] Define lane mapping policy for control-plane workloads (Cancel/Timed/Ready).\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.15] Define lane mapping policy for control-plane workloads (Cancel/Timed/Ready).\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- Every control task class has lane assignment and budget policy; starvation checks are automated.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:37:00.053329409Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:52.634470539Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-15","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-cuut","depends_on_id":"bd-1n5p","type":"blocks","created_at":"2026-02-20T07:43:16.755041935Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-cuut","depends_on_id":"bd-qlc6","type":"blocks","created_at":"2026-02-20T14:59:48.249813942Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-cv49","title":"[15] Adoption target: published security/ops improvement case studies","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 15\n\nTask Objective:\nDeliver deterministic migration validation and publish measurable security/ops case studies.\n\nExecution Requirements:\n- Make this requirement machine-verifiable and release-gated where applicable.\n- Keep behavior self-documenting so future contributors do not need to re-open the master plan.\n\nTesting & Logging Requirements:\n- Unit tests for rule/contract logic and error conditions.\n- Integration/E2E tests for workflow-level enforcement.\n- Structured logs with stable codes and trace IDs.\n- Reproducible artifacts that prove contract satisfaction.\n\nAcceptance Criteria:\n- Success and failure invariants for [15] Adoption target: published security/ops improvement case studies are explicitly quantified and machine-verifiable.\n- Determinism requirements for [15] Adoption target: published security/ops improvement case studies are validated across repeated runs and adversarial perturbations.\n\n\nExpected Artifacts:\n- Machine-readable verification artifact with explicit canonical path under artifacts/section_15/bd-cv49/verification_evidence.json, suitable for CI/release gating.\n- Human-readable verification summary with explicit canonical path under artifacts/section_15/bd-cv49/verification_summary.md, linking implementation intent to measured validation outcomes.\n\nTask-Specific Clarification:\n- The implementation must deliver the exact capability named in the title, with no scope dilution and no silent feature omission.\n- Validation artifacts must include capability-specific thresholds, pass/fail criteria, and reproducible evidence bundles tied to this bead ID.\n- Program/section verification gates must be able to consume this bead's outputs without manual interpretation.\n\nWhy This Improves User Outcomes:\n- \"[15] Adoption target: published security/ops improvement case studies\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[15] Adoption target: published security/ops improvement case studies\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"1. At least 3 case studies published documenting real-world security and operational improvements from adopting franken_node.\n2. Each case study includes: (a) organization context (size, industry, anonymized if needed), (b) pre-adoption security posture metrics, (c) post-adoption security posture metrics, (d) operational improvements (incident response time, deployment frequency, etc.), (e) migration effort and timeline, (f) lessons learned and recommendations.\n3. Quantitative improvements documented: at least 2 case studies show measurable security improvement (e.g., X% reduction in vulnerabilities, Y% faster incident containment).\n4. Case studies are reviewed by the featured organization before publication.\n5. Case studies are published on project website and submitted to at least 1 industry publication or conference.\n6. Case study template exists for partners to self-author with editorial support.\n7. Evidence: case_study_registry.json with per-study: title, organization type, key metrics, publication status, and URL.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:39:36.696204017Z","created_by":"ubuntu","updated_at":"2026-02-20T15:27:30.435957516Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-15","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-cv49","depends_on_id":"bd-elog","type":"blocks","created_at":"2026-02-20T07:43:26.472641055Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-cvt","title":"[10.11] Define capability profiles for product subsystems and enforce narrowing.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.11 — FrankenSQLite-Inspired Runtime Systems Integration Track\n\nWhy This Exists:\nFrankenSQLite-inspired systems integration of capabilities, cancellation protocol, obligations, deterministic labs, and anti-entropy.\n\nTask Objective:\nDefine capability profiles for product subsystems and enforce narrowing.\n\nAcceptance Criteria:\n- Implement with explicit success/failure invariants and deterministic behavior under normal, edge, and fault scenarios.\n- Ensure outcomes are verifiable via automated tests and reproducible artifact outputs.\n\nExpected Artifacts:\n- Section-owned design/spec artifact at `docs/specs/section_10_11/bd-cvt_contract.md`, capturing decision rationale, invariants, and interface boundaries.\n- Machine-readable verification artifact at `artifacts/section_10_11/bd-cvt/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_11/bd-cvt/verification_summary.md` linking implementation intent to measured outcomes.\n\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.11] Define capability profiles for product subsystems and enforce narrowing.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.11] Define capability profiles for product subsystems and enforce narrowing.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.11] Define capability profiles for product subsystems and enforce narrowing.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.11] Define capability profiles for product subsystems and enforce narrowing.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.11] Define capability profiles for product subsystems and enforce narrowing.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"AC for bd-cvt:\n1. Every product subsystem declares a CapabilityProfile enum listing exactly the capabilities it requires (e.g., FileRead, NetConnect, CryptoSign); profiles are defined in a central registry module.\n2. A compile-time or init-time narrowing gate enforces that a subsystem cannot acquire capabilities outside its declared profile; attempts to exceed the profile panic or return Err with a stable CAPABILITY_VIOLATION error code.\n3. Profile narrowing is monotonic: once a subsystem drops a capability, it cannot re-acquire it within the same process lifetime.\n4. A deny-by-default policy applies: subsystems start with an empty capability set and explicitly request each capability via a typed CxHandle (capability-context-first API pattern from Section 9G).\n5. The capability registry exposes a machine-readable JSON manifest listing every subsystem and its granted capability set, suitable for offline audit.\n6. Unit tests verify: (a) subsystem within profile succeeds, (b) subsystem exceeding profile is rejected, (c) monotonic narrowing prevents re-acquisition, (d) empty-profile subsystem cannot perform any privileged operation.\n7. Integration test demonstrates two subsystems with disjoint profiles running concurrently without cross-contamination.\n8. Structured log events use stable code CAPABILITY_GRANT / CAPABILITY_DENY / CAPABILITY_NARROW with trace correlation IDs.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:36:49.664148019Z","created_by":"ubuntu","updated_at":"2026-02-20T15:17:43.675461432Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-11","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-cvt","depends_on_id":"bd-3qo","type":"blocks","created_at":"2026-02-20T07:46:31.606158050Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-cvt","depends_on_id":"bd-5rh","type":"blocks","created_at":"2026-02-20T07:46:31.751296865Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-cvt","depends_on_id":"bd-cda","type":"blocks","created_at":"2026-02-20T07:46:31.811317014Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-e5cz","title":"[16] Output contract: externally replicated high-impact claims","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 16\n\nTask Objective:\nDeliver externally replicated high-impact claims.\n\nExecution Requirements:\n- Make this requirement machine-verifiable and release-gated where applicable.\n- Keep behavior self-documenting so future contributors do not need to re-open the master plan.\n\nTesting & Logging Requirements:\n- Unit tests for rule/contract logic and error conditions.\n- Integration/E2E tests for workflow-level enforcement.\n- Structured logs with stable codes and trace IDs.\n- Reproducible artifacts that prove contract satisfaction.\n\nAcceptance Criteria:\n- Success and failure invariants for [16] Output contract: externally replicated high-impact claims are explicitly quantified and machine-verifiable.\n- Determinism requirements for [16] Output contract: externally replicated high-impact claims are validated across repeated runs and adversarial perturbations.\n\n\nExpected Artifacts:\n- Machine-readable verification artifact with explicit canonical path under artifacts/section_16/bd-e5cz/verification_evidence.json, suitable for CI/release gating.\n- Human-readable verification summary with explicit canonical path under artifacts/section_16/bd-e5cz/verification_summary.md, linking implementation intent to measured validation outcomes.\n\nTask-Specific Clarification:\n- The implementation must deliver the exact capability named in the title, with no scope dilution and no silent feature omission.\n- Validation artifacts must include capability-specific thresholds, pass/fail criteria, and reproducible evidence bundles tied to this bead ID.\n- Program/section verification gates must be able to consume this bead's outputs without manual interpretation.\n\nWhy This Improves User Outcomes:\n- \"[16] Output contract: externally replicated high-impact claims\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[16] Output contract: externally replicated high-impact claims\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"1. At least 3 high-impact claims are identified for external replication: (a) >= 95% compatibility corpus pass rate, (b) >= 10x host-compromise reduction, (c) >= 3x migration velocity improvement.\n2. Each claim has a replication kit: (a) precise claim statement with measurement methodology, (b) all data/tools needed to replicate, (c) step-by-step replication instructions, (d) expected results with acceptable variance bounds (within 10%).\n3. At least 2 claims have been replicated by independent external parties (different from the project team).\n4. Replication results are published alongside original claims with: replicator identity, methodology notes, results, and delta from original.\n5. Discrepancies > 10% between original and replicated results trigger investigation and published explanation.\n6. Replication kits are tested in CI to ensure they remain functional as the project evolves.\n7. Evidence: replication_results.json with per-claim: claim statement, original result, replicator, replicated result, delta, and investigation notes if applicable.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:39:37.303012227Z","created_by":"ubuntu","updated_at":"2026-02-20T15:29:10.247328185Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-16","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-e5cz","depends_on_id":"bd-1sgr","type":"blocks","created_at":"2026-02-20T07:43:26.813544107Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-elog","title":"[15] Adoption target: automation-first safe-extension onboarding","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 15\n\nTask Objective:\nDeliver friction-minimized onboarding from install to first safe extension with deterministic validation.\n\nExecution Requirements:\n- Make this requirement machine-verifiable and release-gated where applicable.\n- Keep behavior self-documenting so future contributors do not need to re-open the master plan.\n\nTesting & Logging Requirements:\n- Unit tests for rule/contract logic and error conditions.\n- Integration/E2E tests for workflow-level enforcement.\n- Structured logs with stable codes and trace IDs.\n- Reproducible artifacts that prove contract satisfaction.\n\nAcceptance Criteria:\n- Success and failure invariants for [15] Adoption target: automation-first safe-extension onboarding are explicitly quantified and machine-verifiable.\n- Determinism requirements for [15] Adoption target: automation-first safe-extension onboarding are validated across repeated runs and adversarial perturbations.\n\n\nExpected Artifacts:\n- Machine-readable verification artifact with explicit canonical path under artifacts/section_15/bd-elog/verification_evidence.json, suitable for CI/release gating.\n- Human-readable verification summary with explicit canonical path under artifacts/section_15/bd-elog/verification_summary.md, linking implementation intent to measured validation outcomes.\n\nTask-Specific Clarification:\n- The implementation must deliver the exact capability named in the title, with no scope dilution and no silent feature omission.\n- Validation artifacts must include capability-specific thresholds, pass/fail criteria, and reproducible evidence bundles tied to this bead ID.\n- Program/section verification gates must be able to consume this bead's outputs without manual interpretation.\n\nWhy This Improves User Outcomes:\n- \"[15] Adoption target: automation-first safe-extension onboarding\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[15] Adoption target: automation-first safe-extension onboarding\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"1. First safe extension onboarding pathway exists: from 'I have an idea' to 'signed, published, running in production' with minimal friction.\n2. Onboarding is automation-first: (a) project scaffold generator ('npx create-franken-extension'), (b) automatic signing setup integrated into publish workflow, (c) automated compatibility and security checks pre-publish, (d) one-command publish to signed registry.\n3. Total time from scaffold to published signed extension <= 30 minutes for a simple extension.\n4. Onboarding produces a 'safety report' for the extension: compatibility score, security scan results, trust requirements.\n5. Documentation: step-by-step tutorial with estimated time per step.\n6. CI test: scaffold, build, sign, and publish a test extension end-to-end; verify it appears in registry and is installable.\n7. Onboarding error messages are actionable: each failure includes 'what went wrong' and 'how to fix it'.\n8. Evidence: extension_onboarding_timing.json with per-step timings for the CI test run.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:39:36.611525969Z","created_by":"ubuntu","updated_at":"2026-02-20T15:27:05.117955447Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-15","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-elog","depends_on_id":"bd-31tg","type":"blocks","created_at":"2026-02-20T07:43:26.428914866Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-evb9","title":"Epic: Performance + Packaging [10.6]","description":"- type: epic","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-20T07:47:58.072163029Z","updated_at":"2026-02-20T07:49:21.118764591Z","closed_at":"2026-02-20T07:49:21.118746537Z","close_reason":"Superseded by canonical detailed master-plan graph (bd-33v) with full 10.N-10.21 and 11-16 coverage, explicit dependencies, and per-section verification gates.","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-f2y","title":"[10.8] Implement incident bundle retention and export policy.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.8 — Operational Readiness\n\nWhy This Exists:\nOperational readiness and fleet safety posture: control APIs, observability contracts, safe-mode operations, and disaster drills.\n\nTask Objective:\nImplement incident bundle retention and export policy.\n\nAcceptance Criteria:\n- Implement with explicit success/failure invariants and deterministic behavior under normal, edge, and fault scenarios.\n- Ensure outcomes are verifiable via automated tests and reproducible artifact outputs.\n\nExpected Artifacts:\n- Section-owned design/spec artifact at `docs/specs/section_10_8/bd-f2y_contract.md`, capturing decision rationale, invariants, and interface boundaries.\n- Machine-readable verification artifact at `artifacts/section_10_8/bd-f2y/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_8/bd-f2y/verification_summary.md` linking implementation intent to measured outcomes.\n\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.8] Implement incident bundle retention and export policy.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.8] Implement incident bundle retention and export policy.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.8] Implement incident bundle retention and export policy.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.8] Implement incident bundle retention and export policy.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.8] Implement incident bundle retention and export policy.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"1. Incident bundles are self-contained archives containing: logs, metrics snapshot, configuration state, error context, and timeline of events for a specific incident window.\n2. Retention policy is configurable: minimum retention period, maximum storage budget, and automatic expiry/rotation.\n3. Export policy supports at least two formats: compressed archive (tar.gz) for offline analysis and structured JSON stream for ingestion by external SIEM/observability tools.\n4. Bundles are integrity-protected: each bundle includes a SHA-256 checksum and an optional signature for chain-of-custody verification.\n5. Retention policy enforcement is automated: expired bundles are cleaned up without operator intervention, with a log entry for each deletion.\n6. A CLI command (e.g., franken-node incident export <incident-id>) produces the export artifact.\n7. Integration test creates an incident bundle, applies retention policy to expire it, and verifies cleanup occurred correctly.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:36:48.026309178Z","created_by":"ubuntu","updated_at":"2026-02-20T15:18:41.677921379Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-8","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-f2y","depends_on_id":"bd-k6o","type":"blocks","created_at":"2026-02-20T07:43:23.852819218Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-f5d","title":"[10.9] Build public Node/Bun/franken_node benchmark campaign infrastructure.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.9 — Moonshot Disruption Track\n\nWhy This Exists:\nMoonshot disruption track for public benchmark leadership, adversarial campaigns, verifier economy, and category-shift reporting.\n\nTask Objective:\nBuild public Node/Bun/franken_node benchmark campaign infrastructure.\n\nAcceptance Criteria:\n- Implement with explicit success/failure invariants and deterministic behavior under normal, edge, and fault scenarios.\n- Ensure outcomes are verifiable via automated tests and reproducible artifact outputs.\n\nExpected Artifacts:\n- Section-owned design/spec artifact at `docs/specs/section_10_9/bd-f5d_contract.md`, capturing decision rationale, invariants, and interface boundaries.\n- Machine-readable verification artifact at `artifacts/section_10_9/bd-f5d/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_9/bd-f5d/verification_summary.md` linking implementation intent to measured outcomes.\n\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.9] Build public Node/Bun/franken_node benchmark campaign infrastructure.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.9] Build public Node/Bun/franken_node benchmark campaign infrastructure.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.9] Build public Node/Bun/franken_node benchmark campaign infrastructure.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.9] Build public Node/Bun/franken_node benchmark campaign infrastructure.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.9] Build public Node/Bun/franken_node benchmark campaign infrastructure.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"1. Benchmark campaign compares Node.js, Bun, and franken_node across at least 10 real-world workloads: HTTP server throughput, module loading, cold start, JSON processing, file I/O, child process spawning, stream throughput, crypto operations, URL parsing, and compatibility-shim overhead.\n2. Campaign infrastructure produces reproducible results: all benchmarks run in containerized environments with pinned runtime versions and identical hardware profiles.\n3. Results are published as a structured JSON dataset with per-benchmark, per-runtime mean/median/p95/p99 latency and throughput numbers.\n4. Campaign includes a comparative visualization generator (HTML or Markdown report) with charts and tables suitable for public consumption.\n5. Per Section 3 category-defining targets: report highlights where franken_node achieves >= 95% Node.js compatibility, >= 3x migration velocity, or >= 10x compromise reduction.\n6. Campaign is re-runnable on new releases with a single command (scripts/run_benchmark_campaign.sh) and automatically diffs against previous results.\n7. Methodology document explains statistical rigor: number of iterations, warm-up policy, outlier handling, and confidence intervals.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:36:48.287999303Z","created_by":"ubuntu","updated_at":"2026-02-20T15:19:39.050773306Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-9","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-f5d","depends_on_id":"bd-1xg","type":"blocks","created_at":"2026-02-20T07:46:37.840224751Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-f5d","depends_on_id":"bd-20a","type":"blocks","created_at":"2026-02-20T07:46:37.895375020Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-f5d","depends_on_id":"bd-229","type":"blocks","created_at":"2026-02-20T07:46:37.943889570Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-f5d","depends_on_id":"bd-3il","type":"blocks","created_at":"2026-02-20T07:46:37.988491682Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-f5d","depends_on_id":"bd-cda","type":"blocks","created_at":"2026-02-20T07:46:38.032583014Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-f7im","title":"Epic: Conformance + Verification [10.7]","description":"- type: epic","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-20T07:47:58.072163029Z","updated_at":"2026-02-20T07:49:21.124358690Z","closed_at":"2026-02-20T07:49:21.124341068Z","close_reason":"Superseded by canonical detailed master-plan graph (bd-33v) with full 10.N-10.21 and 11-16 coverage, explicit dependencies, and per-section verification gates.","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-f955","title":"[16] Contribution: open trust/compatibility specs","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 16\n\nTask Objective:\nPublish open product-layer trust and compatibility specifications.\n\nExecution Requirements:\n- Make this requirement machine-verifiable and release-gated where applicable.\n- Keep behavior self-documenting so future contributors do not need to re-open the master plan.\n\nTesting & Logging Requirements:\n- Unit tests for rule/contract logic and error conditions.\n- Integration/E2E tests for workflow-level enforcement.\n- Structured logs with stable codes and trace IDs.\n- Reproducible artifacts that prove contract satisfaction.\n\nAcceptance Criteria:\n- Success and failure invariants for [16] Contribution: open trust/compatibility specs are explicitly quantified and machine-verifiable.\n- Determinism requirements for [16] Contribution: open trust/compatibility specs are validated across repeated runs and adversarial perturbations.\n\n\nExpected Artifacts:\n- Machine-readable verification artifact with explicit canonical path under artifacts/section_16/bd-f955/verification_evidence.json, suitable for CI/release gating.\n- Human-readable verification summary with explicit canonical path under artifacts/section_16/bd-f955/verification_summary.md, linking implementation intent to measured validation outcomes.\n\nTask-Specific Clarification:\n- The implementation must deliver the exact capability named in the title, with no scope dilution and no silent feature omission.\n- Validation artifacts must include capability-specific thresholds, pass/fail criteria, and reproducible evidence bundles tied to this bead ID.\n- Program/section verification gates must be able to consume this bead's outputs without manual interpretation.\n\nWhy This Improves User Outcomes:\n- \"[16] Contribution: open trust/compatibility specs\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[16] Contribution: open trust/compatibility specs\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"1. Open specifications published for trust primitives: (a) trust signal format and semantics, (b) trust aggregation algorithm (with formal properties: convergence, Byzantine tolerance threshold), (c) trust decision protocol (inputs, outputs, determinism guarantees).\n2. Open specifications published for compatibility primitives: (a) compatibility test case format, (b) lockstep comparison protocol, (c) divergence receipt format and integrity guarantees.\n3. Specifications follow a recognized format (RFC-style or W3C-style) with: abstract, terminology, normative requirements (MUST/SHOULD/MAY), security considerations, and IANA-style registry for extensible fields.\n4. Each specification is versioned with semantic versioning and includes change history.\n5. Specifications are reviewed by >= 2 external domain experts before publication.\n6. Specifications are hosted in a public, version-controlled repository with contribution guidelines.\n7. Reference implementations exist for each specification (in the franken_node codebase) with test suites validating conformance.\n8. Evidence: open_specs_registry.json with per-spec: title, version, review status, reference implementation path, and conformance test pass rate.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:39:36.783733016Z","created_by":"ubuntu","updated_at":"2026-02-20T16:09:35.923547893Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-16","self-contained","test-obligations"]}
{"id":"bd-gad3","title":"[10.17] Ship adaptive multi-rail isolation mesh with hot-elevation policy.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.17 — Radical Expansion Execution Track (9K)\n\nWhy This Exists:\nRadical expansion track for proof-carrying speculation, Bayesian adversary control, time-travel replay, ZK attestations, and claim compiler systems.\n\nTask Objective:\nShip adaptive multi-rail isolation mesh with hot-elevation policy.\n\nAcceptance Criteria:\n- Workloads can be promoted to stricter rails at runtime without losing policy continuity; latency-sensitive trusted workloads remain on high-performance rails within budget.\n\nExpected Artifacts:\n- `docs/architecture/isolation_mesh.md`, `src/security/isolation_rail_router.rs`, `tests/integration/isolation_hot_elevation.rs`, `artifacts/10.17/isolation_mesh_profile_report.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_17/bd-gad3/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_17/bd-gad3/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.17] Ship adaptive multi-rail isolation mesh with hot-elevation policy.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.17] Ship adaptive multi-rail isolation mesh with hot-elevation policy.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.17] Ship adaptive multi-rail isolation mesh with hot-elevation policy.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.17] Ship adaptive multi-rail isolation mesh with hot-elevation policy.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.17] Ship adaptive multi-rail isolation mesh with hot-elevation policy.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- Workloads can be promoted to stricter rails at runtime without losing policy continuity; latency-sensitive trusted workloads remain on high-performance rails within budget.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:37:03.266990043Z","created_by":"ubuntu","updated_at":"2026-02-20T15:46:00.166252804Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-17","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-gad3","depends_on_id":"bd-3ku8","type":"blocks","created_at":"2026-02-20T07:43:18.432602651Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-gldk","title":"Epic: Tiered Trust Storage [10.14e]","description":"- type: epic","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-20T07:47:58.072163029Z","updated_at":"2026-02-20T07:49:21.230815012Z","closed_at":"2026-02-20T07:49:21.230796528Z","close_reason":"Superseded by canonical detailed master-plan graph (bd-33v) with full 10.N-10.21 and 11-16 coverage, explicit dependencies, and per-section verification gates.","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-go4","title":"[PLAN 10.12] Frontier Programs Execution Track (9H)","description":"Section: 10.12 — Frontier Programs Execution Track (9H)\n\nStrategic Context:\nFrontier program execution turning migration singularity, trust fabric, verifier economy, and operator intelligence into production flow.\n\nExecution Requirements:\n- Preserve all scoped capabilities from the canonical plan.\n- Keep contracts self-contained so future contributors can execute without reopening the master plan.\n- Require explicit testing strategy (unit + integration/e2e) and structured logging/telemetry for every child bead.\n- Require artifact-backed validation for performance, security, and correctness claims.\n\nDependency Semantics:\n- This epic is blocked by its child implementation beads.\n- Cross-epic dependencies encode strategic sequencing and canonical ownership boundaries.\n\n## Success Criteria\n- All child beads for this section are completed with acceptance artifacts attached and no unresolved blockers.\n- Section-level verification gate for comprehensive unit tests, integration/e2e workflows, and detailed structured logging evidence is green.\n- Scope-to-plan traceability is explicit, with no feature loss versus the canonical plan section.\n\n## Optimization Notes\n- User-Outcome Lens: \"[PLAN 10.12] Frontier Programs Execution Track (9H)\" must improve operator confidence, safety posture, and deterministic recovery behavior under both normal and adversarial conditions.\n- Cross-Section Coordination: child beads must encode integration assumptions explicitly to avoid local optimizations that degrade system-wide correctness.\n- Verification Non-Negotiable: completion requires reproducible unit/integration/E2E evidence and structured logs suitable for independent replay.\n- Scope Protection: any simplification must preserve canonical-plan feature intent and be justified with explicit tradeoff documentation.","status":"open","priority":2,"issue_type":"epic","created_at":"2026-02-20T07:36:41.196986528Z","created_by":"ubuntu","updated_at":"2026-02-20T08:16:46.688501747Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-12"],"dependencies":[{"issue_id":"bd-go4","depends_on_id":"bd-1d6x","type":"blocks","created_at":"2026-02-20T07:48:08.894422511Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-go4","depends_on_id":"bd-1wz","type":"blocks","created_at":"2026-02-20T07:37:10.973643649Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-go4","depends_on_id":"bd-1xg","type":"blocks","created_at":"2026-02-20T07:37:10.897091667Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-go4","depends_on_id":"bd-20a","type":"blocks","created_at":"2026-02-20T07:37:10.935900927Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-go4","depends_on_id":"bd-229","type":"blocks","created_at":"2026-02-20T07:37:10.858130625Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-go4","depends_on_id":"bd-2aj","type":"blocks","created_at":"2026-02-20T07:36:51.271224289Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-go4","depends_on_id":"bd-3c2","type":"blocks","created_at":"2026-02-20T07:36:51.111605120Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-go4","depends_on_id":"bd-3hm","type":"blocks","created_at":"2026-02-20T07:36:50.871882924Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-go4","depends_on_id":"bd-3j4","type":"blocks","created_at":"2026-02-20T07:36:50.952975423Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-go4","depends_on_id":"bd-5si","type":"blocks","created_at":"2026-02-20T07:36:51.032232654Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-go4","depends_on_id":"bd-cda","type":"blocks","created_at":"2026-02-20T07:37:09.508382185Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-go4","depends_on_id":"bd-n1w","type":"blocks","created_at":"2026-02-20T07:36:51.350685200Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-go4","depends_on_id":"bd-y0v","type":"blocks","created_at":"2026-02-20T07:36:51.191796741Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-h93z","title":"[10.15] Add release gate requiring asupersync-backed conformance on high-impact features.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.15 — Asupersync-First Integration Execution Track (8.4-8.6)\n\nWhy This Exists:\nAsupersync-first control-plane migration track enforcing Cx-first, region ownership, cancellation correctness, and protocol-grade verification gates.\n\nTask Objective:\nAdd release gate requiring asupersync-backed conformance on high-impact features.\n\nAcceptance Criteria:\n- Release pipeline blocks claims/features lacking required conformance artifacts; gate output is machine-readable and signed.\n\nExpected Artifacts:\n- `.github/workflows/asupersync-integration-gate.yml`, `docs/conformance/asupersync_release_gate.md`, `artifacts/10.15/release_gate_report.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_15/bd-h93z/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_15/bd-h93z/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.15] Add release gate requiring asupersync-backed conformance on high-impact features.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.15] Add release gate requiring asupersync-backed conformance on high-impact features.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.15] Add release gate requiring asupersync-backed conformance on high-impact features.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.15] Add release gate requiring asupersync-backed conformance on high-impact features.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.15] Add release gate requiring asupersync-backed conformance on high-impact features.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- Release pipeline blocks claims/features lacking required conformance artifacts; gate output is machine-readable and signed.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:37:01.035150388Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:49.892222294Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-15","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-h93z","depends_on_id":"bd-25oa","type":"blocks","created_at":"2026-02-20T07:43:17.266357244Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-hg1","title":"[10.3] Build one-command migration report export for enterprise review.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.3 — Migration System\n\nWhy This Exists:\nMigration autopilot pipeline from audit to rollout, designed to collapse migration friction with deterministic confidence and replayability.\n\nTask Objective:\nBuild one-command migration report export for enterprise review.\n\nAcceptance Criteria:\n- Implement with explicit success/failure invariants and deterministic behavior under normal, edge, and fault scenarios.\n- Ensure outcomes are verifiable via automated tests and reproducible artifact outputs.\n\nExpected Artifacts:\n- Section-owned design/spec artifact at `docs/specs/section_10_3/bd-hg1_contract.md`, capturing decision rationale, invariants, and interface boundaries.\n- Machine-readable verification artifact at `artifacts/section_10_3/bd-hg1/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_3/bd-hg1/verification_summary.md` linking implementation intent to measured outcomes.\n\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.3] Build one-command migration report export for enterprise review.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.3] Build one-command migration report export for enterprise review.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.3] Build one-command migration report export for enterprise review.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.3] Build one-command migration report export for enterprise review.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.3] Build one-command migration report export for enterprise review.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","status":"closed","priority":1,"issue_type":"task","assignee":"CrimsonCrane","created_at":"2026-02-20T07:36:45.267595003Z","created_by":"ubuntu","updated_at":"2026-02-20T10:20:06.070654409Z","closed_at":"2026-02-20T10:20:06.070629784Z","close_reason":"done","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-3","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-hg1","depends_on_id":"bd-12f","type":"blocks","created_at":"2026-02-20T07:43:22.277603002Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-i8fh","title":"Epic: Activation Pipeline + Revocation [10.13d]","description":"- type: epic","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-20T07:47:58.072163029Z","updated_at":"2026-02-20T07:49:21.176058124Z","closed_at":"2026-02-20T07:49:21.176039930Z","close_reason":"Superseded by canonical detailed master-plan graph (bd-33v) with full 10.N-10.21 and 11-16 coverage, explicit dependencies, and per-section verification gates.","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-jbp1","title":"[14] Metric family: replay determinism and artifact completeness","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 14\n\nTask Objective:\nInstrument replay determinism and artifact completeness metric family.\n\nExecution Requirements:\n- Make this requirement machine-verifiable and release-gated where applicable.\n- Keep behavior self-documenting so future contributors do not need to re-open the master plan.\n\nTesting & Logging Requirements:\n- Unit tests for rule/contract logic and error conditions.\n- Integration/E2E tests for workflow-level enforcement.\n- Structured logs with stable codes and trace IDs.\n- Reproducible artifacts that prove contract satisfaction.\n\nAcceptance Criteria:\n- Success and failure invariants for [14] Metric family: replay determinism and artifact completeness are explicitly quantified and machine-verifiable.\n- Determinism requirements for [14] Metric family: replay determinism and artifact completeness are validated across repeated runs and adversarial perturbations.\n\n\nExpected Artifacts:\n- Machine-readable verification artifact with explicit canonical path under artifacts/section_14/bd-jbp1/verification_evidence.json, suitable for CI/release gating.\n- Human-readable verification summary with explicit canonical path under artifacts/section_14/bd-jbp1/verification_summary.md, linking implementation intent to measured validation outcomes.\n\nTask-Specific Clarification:\n- The implementation must deliver the exact capability named in the title, with no scope dilution and no silent feature omission.\n- Validation artifacts must include capability-specific thresholds, pass/fail criteria, and reproducible evidence bundles tied to this bead ID.\n- Program/section verification gates must be able to consume this bead's outputs without manual interpretation.\n\nWhy This Improves User Outcomes:\n- \"[14] Metric family: replay determinism and artifact completeness\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[14] Metric family: replay determinism and artifact completeness\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"METRIC FAMILY: Replay determinism and artifact completeness.\n1. Metrics measured: (a) determinism rate (% of replays that produce bit-identical output), (b) artifact completeness (% of incident types with full replay artifacts), (c) replay fidelity (% of state transitions correctly reproduced), (d) replay overhead (time to replay vs original execution).\n2. Determinism target: >= 99.9% of replays produce identical output on same inputs.\n3. Artifact completeness target: 100% of high-severity incident types have complete replay artifacts.\n4. Replay fidelity: >= 99% of state transitions reproduced correctly (verified by trace comparison).\n5. Replay overhead: replay takes <= 2x the original execution time.\n6. Measured across: trust decisions, containment actions, migration operations, compatibility checks.\n7. Publication: determinism and completeness metrics in benchmark report with per-category breakdown.\n8. Evidence: replay_determinism_metrics.json with per-category determinism rate, completeness, fidelity, and overhead.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:39:35.900424585Z","created_by":"ubuntu","updated_at":"2026-02-20T15:25:04.600163361Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-14","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-jbp1","depends_on_id":"bd-2a6g","type":"blocks","created_at":"2026-02-20T07:43:26.070265130Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-jjm","title":"[10.10] Enforce product-level adoption of canonical deterministic serialization and signature preimage rules (from `10.13` + `10.14`).","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.10 — FCP-Inspired Hardening + Interop Integration Track\n\nWhy This Exists:\nFCP-inspired hardening/interop contract for IDs, serialization, control-channel auth, revocation freshness, and publication gating.\n\nTask Objective:\nEnforce product-level adoption of canonical deterministic serialization and signature preimage rules (from `10.13` + `10.14`).\n\nAcceptance Criteria:\n- Implement with explicit success/failure invariants and deterministic behavior under normal, edge, and fault scenarios.\n- Ensure outcomes are verifiable via automated tests and reproducible artifact outputs.\n\nExpected Artifacts:\n- Section-owned design/spec artifact at `docs/specs/section_10_10/bd-jjm_contract.md`, capturing decision rationale, invariants, and interface boundaries.\n- Machine-readable verification artifact at `artifacts/section_10_10/bd-jjm/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_10/bd-jjm/verification_summary.md` linking implementation intent to measured outcomes.\n\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.10] Enforce product-level adoption of canonical deterministic serialization and signature preimage rules (from `10.13` + `10.14`).\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.10] Enforce product-level adoption of canonical deterministic serialization and signature preimage rules (from `10.13` + `10.14`).\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.10] Enforce product-level adoption of canonical deterministic serialization and signature preimage rules (from `10.13` + `10.14`).\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.10] Enforce product-level adoption of canonical deterministic serialization and signature preimage rules (from `10.13` + `10.14`).\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.10] Enforce product-level adoption of canonical deterministic serialization and signature preimage rules (from `10.13` + `10.14`).\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"1. Define a CanonicalSerializer trait with a single method `canonical_bytes(&self) -> Vec<u8>` that produces a deterministic byte representation. The canonical form MUST sort map keys lexicographically, use fixed-width integer encoding (big-endian), and omit optional fields that are None (not encode them as null).\n2. Define a SignaturePreimage struct wrapping: (a) a 4-byte context tag identifying the signing context (e.g., POLICY_SIGN, TOKEN_SIGN, RELEASE_SIGN), (b) canonical_bytes of the payload, (c) a 32-byte domain-separation salt unique per context tag. The preimage is the concatenation of these three fields.\n3. Implement CanonicalSerializer for all trust object types defined in bd-1l5 (TrustObjectId), policy checkpoint structs (bd-174), and token chain structs (bd-1r2).\n4. Add a compile-time or test-time check that ensures no trust object type is added to the crate without a corresponding CanonicalSerializer impl (use an inventory pattern or exhaustive test).\n5. Enforce that re-serializing a deserialized object produces byte-identical output (idempotency test) for all implemented types.\n6. Provide at least 3 golden vector fixtures in vectors/canonical_serialization.json containing known inputs and expected byte outputs. Verify these in CI.\n7. Unit tests: (a) deterministic output across multiple serializations, (b) map-key ordering, (c) big-endian integer encoding, (d) preimage domain separation (same payload + different context tag = different preimage), (e) idempotency round-trip.\n8. Integration test: serialize 1000 random instances of each type, verify all produce deterministic output when serialized twice.\n9. Verification script scripts/check_canonical_serialization.py with --json flag, emitting to artifacts/section_10_10/bd-jjm/verification_evidence.json.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:36:48.838214999Z","created_by":"ubuntu","updated_at":"2026-02-20T15:36:16.014221492Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-10","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-jjm","depends_on_id":"bd-1l5","type":"blocks","created_at":"2026-02-20T07:43:10.880271721Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-jjm","depends_on_id":"bd-3n2u","type":"blocks","created_at":"2026-02-20T14:59:53.867505683Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-jvzc","title":"[BOOTSTRAP] Define foundation test matrix + deterministic fixtures (CLI/config/transplant)","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md (Bootstrap integration quality overlay for Sections 10.0–10.5)\nSection: BOOTSTRAP (Foundation test matrix and fixtures)\n\nTask Objective:\nDefine a comprehensive bootstrap test matrix and deterministic fixture contract spanning CLI bootstrap, configuration resolution, transplant integrity, and operator diagnostics.\n\nAcceptance Criteria:\n- Matrix covers happy path, edge cases, and adversarial/error paths for each bootstrap capability family.\n- Fixture contract defines deterministic seeds/inputs/expected outputs and replay expectations.\n- Matrix maps each test family to owning implementation beads and verification gate consumption.\n\nExpected Artifacts:\n- Bootstrap test-matrix document with traceability links to implementation beads.\n- Deterministic fixture catalog and replay instructions.\n- Machine-readable mapping artifact for gate tooling.\n\nTesting & Logging Requirements:\n- Unit tests for any matrix/fixture validators.\n- E2E dry-run validation that matrix entries can be executed in CI order without ambiguity.\n- Structured logs for matrix validation, fixture resolution, and mapping integrity checks.\n\nTask-Specific Clarification:\n- For \"[BOOTSTRAP] Define foundation test matrix + deterministic fixtures (CLI/config/transplant)\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[BOOTSTRAP] Define foundation test matrix + deterministic fixtures (CLI/config/transplant)\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[BOOTSTRAP] Define foundation test matrix + deterministic fixtures (CLI/config/transplant)\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[BOOTSTRAP] Define foundation test matrix + deterministic fixtures (CLI/config/transplant)\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[BOOTSTRAP] Define foundation test matrix + deterministic fixtures (CLI/config/transplant)\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","status":"closed","priority":1,"issue_type":"task","assignee":"ubuntu","created_at":"2026-02-20T08:03:10.278221451Z","created_by":"ubuntu","updated_at":"2026-02-20T08:39:39.046279559Z","closed_at":"2026-02-20T08:39:39.046193930Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["bootstrap","test-obligations","verification"]}
{"id":"bd-jxgt","title":"[10.13] Build execution planner scorer (latency/risk/capability-aware) with deterministic tie-breakers.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.13 — FCP Deep-Mined Expansion Execution Track (9I)\n\nWhy This Exists:\nDeep connector/provider contract track: lifecycle FSMs, conformance harnesses, fencing, sandboxing, revocation freshness, and protocol hardening.\n\nTask Objective:\nBuild execution planner scorer (latency/risk/capability-aware) with deterministic tie-breakers.\n\nAcceptance Criteria:\n- Scorer output is stable for identical inputs; tie-breakers are explicit and tested; planner decisions include explainable factor weights.\n\nExpected Artifacts:\n- `src/planner/execution_scorer.rs`, `tests/integration/execution_planner_determinism.rs`, `artifacts/10.13/planner_decision_explanations.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_13/bd-jxgt/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_13/bd-jxgt/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.13] Build execution planner scorer (latency/risk/capability-aware) with deterministic tie-breakers.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.13] Build execution planner scorer (latency/risk/capability-aware) with deterministic tie-breakers.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.13] Build execution planner scorer (latency/risk/capability-aware) with deterministic tie-breakers.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.13] Build execution planner scorer (latency/risk/capability-aware) with deterministic tie-breakers.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.13] Build execution planner scorer (latency/risk/capability-aware) with deterministic tie-breakers.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","status":"closed","priority":1,"issue_type":"task","assignee":"CrimsonCrane","created_at":"2026-02-20T07:36:53.601124550Z","created_by":"ubuntu","updated_at":"2026-02-20T12:29:26.551814531Z","closed_at":"2026-02-20T12:29:26.551787230Z","close_reason":"done","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-13","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-jxgt","depends_on_id":"bd-8vby","type":"blocks","created_at":"2026-02-20T07:43:13.391829577Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-k4s","title":"[10.6] Build product-level benchmark suite with secure-extension scenarios.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.6 — Performance + Packaging (Item 1 of 7)\nCross-references: 9D global rule, Section 14 benchmark families\n\nWhy This Exists:\nThe product-level benchmark suite validates that franken_node meets performance targets under realistic security-hardened conditions. This is the foundation for all public benchmark claims and the benchmark ownership strategy (10.0 Initiative #10).\n\nTask Objective:\nBuild a comprehensive product-level benchmark suite covering all major workflow categories with secure-extension scenarios (not just vanilla performance).\n\nDetailed Acceptance Criteria:\n1. Benchmark scenarios cover: cold-start latency, p99 tail latency, extension-host overhead with sandbox active, migration scanner throughput, lockstep harness throughput, quarantine propagation latency, trust-card materialization latency.\n2. Secure-extension scenarios: benchmarks run with sandbox enforcement active (not bypassed), measuring realistic overhead.\n3. Deterministic benchmarking: identical inputs produce statistically equivalent results across runs (within confidence intervals).\n4. Benchmark results include confidence intervals and reproducibility metadata per 9C.10.\n5. Results exported in machine-readable format for CI/release gating and public reporting.\n6. Baseline profiling methodology: baseline first, profile top hotspots, one lever per change, validate invariance, re-measure with tail metrics (9D global rule).\n7. All 14 metric families from Section 14 represented: compatibility correctness, performance under hardening, containment latency, replay determinism, migration speed, adversarial resilience.\n\nExpected Artifacts:\n- benchmarks/ directory with harness, scenarios, fixture data, and scoring formulas.\n- CI integration for automated benchmark runs with regression detection.\n- docs/specs/section_10_6/bd-k4s_contract.md\n- artifacts/section_10_6/bd-k4s/verification_evidence.json\n\nTesting and Logging Requirements:\n- Unit tests for benchmark scenario parsing, threshold policy evaluation, and deterministic fixture selection logic.\n- E2E benchmark execution scripts that run representative secure-extension scenarios and emit reproducible result bundles.\n- Benchmark suite self-test: harness produces deterministic results on fixture data.\n- Regression detection: automatic flagging when metrics degrade beyond threshold.\n- Structured logs: BENCHMARK_STARTED, SCENARIO_EXECUTED, METRIC_COMPUTED, REGRESSION_DETECTED with trace IDs and scenario metadata.","acceptance_criteria":"1. Benchmark suite covers at minimum: module-load, require-resolve, extension-hook, and secure-sandbox-spawn scenarios.\n2. Each benchmark produces a structured JSON report with mean, median, p50, p95, p99, and max latency fields.\n3. Suite includes at least 3 secure-extension scenarios (permission-gated import, sandbox cold-start, cross-boundary callback).\n4. Baseline report artifact is persisted under artifacts/ with before/after comparison table per Section 7 performance doctrine.\n5. Profile artifacts (flamegraph or perf-map) are generated for each scenario and stored alongside results.\n6. CI gate fails if any benchmark regresses >5% from the stored baseline without explicit override.\n7. All benchmarks are reproducible on a clean checkout with a single command (e.g., cargo bench or scripts/run_benchmarks.sh).","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:36:46.701147665Z","created_by":"ubuntu","updated_at":"2026-02-20T16:06:02.454062450Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-6","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-k4s","depends_on_id":"bd-20a","type":"blocks","created_at":"2026-02-20T07:46:36.674331390Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-k4s","depends_on_id":"bd-229","type":"blocks","created_at":"2026-02-20T07:46:36.718945745Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-k4s","depends_on_id":"bd-3il","type":"blocks","created_at":"2026-02-20T07:46:36.838506401Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-k4s","depends_on_id":"bd-cda","type":"blocks","created_at":"2026-02-20T07:46:36.883756781Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-k6o","title":"[10.8] Implement deterministic safe-mode startup and operation flags.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.8 — Operational Readiness\n\nWhy This Exists:\nOperational readiness and fleet safety posture: control APIs, observability contracts, safe-mode operations, and disaster drills.\n\nTask Objective:\nImplement deterministic safe-mode startup and operation flags.\n\nAcceptance Criteria:\n- Implement with explicit success/failure invariants and deterministic behavior under normal, edge, and fault scenarios.\n- Ensure outcomes are verifiable via automated tests and reproducible artifact outputs.\n\nExpected Artifacts:\n- Section-owned design/spec artifact at `docs/specs/section_10_8/bd-k6o_contract.md`, capturing decision rationale, invariants, and interface boundaries.\n- Machine-readable verification artifact at `artifacts/section_10_8/bd-k6o/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_8/bd-k6o/verification_summary.md` linking implementation intent to measured outcomes.\n\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.8] Implement deterministic safe-mode startup and operation flags.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.8] Implement deterministic safe-mode startup and operation flags.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.8] Implement deterministic safe-mode startup and operation flags.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.8] Implement deterministic safe-mode startup and operation flags.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.8] Implement deterministic safe-mode startup and operation flags.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"1. Safe-mode startup: when --safe-mode flag is passed (or FRANKEN_SAFE_MODE=1 env var is set), the node starts with a minimal, hardened configuration that disables all non-essential features.\n2. Safe-mode operation is deterministic: given identical inputs, safe-mode produces identical outputs across runs (no randomness, no wall-clock dependencies).\n3. Safe-mode disables: extension loading, network-initiated migrations, auto-update checks, and any feature flagged as experimental.\n4. Safe-mode enables: enhanced logging (debug level), integrity self-checks on startup, and read-only mode for mutable state stores.\n5. A health-check endpoint in safe-mode reports which features are disabled and why.\n6. Transition from safe-mode to normal-mode requires explicit operator action — no automatic escalation.\n7. Integration test verifies safe-mode startup, exercises core workflows, and confirms disabled features are unreachable.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:36:47.947732023Z","created_by":"ubuntu","updated_at":"2026-02-20T15:18:26.275868755Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-8","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-k6o","depends_on_id":"bd-3o6","type":"blocks","created_at":"2026-02-20T07:43:23.808827154Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-ka0n","title":"[14] Metric family: performance under hardening","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 14\n\nTask Objective:\nInstrument p50/p95/p99, cold start, and hardening overhead metric family.\n\nExecution Requirements:\n- Make this requirement machine-verifiable and release-gated where applicable.\n- Keep behavior self-documenting so future contributors do not need to re-open the master plan.\n\nTesting & Logging Requirements:\n- Unit tests for rule/contract logic and error conditions.\n- Integration/E2E tests for workflow-level enforcement.\n- Structured logs with stable codes and trace IDs.\n- Reproducible artifacts that prove contract satisfaction.\n\nAcceptance Criteria:\n- Success and failure invariants for [14] Metric family: performance under hardening are explicitly quantified and machine-verifiable.\n- Determinism requirements for [14] Metric family: performance under hardening are validated across repeated runs and adversarial perturbations.\n\n\nExpected Artifacts:\n- Machine-readable verification artifact with explicit canonical path under artifacts/section_14/bd-ka0n/verification_evidence.json, suitable for CI/release gating.\n- Human-readable verification summary with explicit canonical path under artifacts/section_14/bd-ka0n/verification_summary.md, linking implementation intent to measured validation outcomes.\n\nTask-Specific Clarification:\n- The implementation must deliver the exact capability named in the title, with no scope dilution and no silent feature omission.\n- Validation artifacts must include capability-specific thresholds, pass/fail criteria, and reproducible evidence bundles tied to this bead ID.\n- Program/section verification gates must be able to consume this bead's outputs without manual interpretation.\n\nWhy This Improves User Outcomes:\n- \"[14] Metric family: performance under hardening\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[14] Metric family: performance under hardening\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"METRIC FAMILY: Performance under hardening.\n1. Metrics measured: p50, p95, p99 latency (ms); throughput (requests/sec); cold start time (ms); overhead ratio (hardened/unhardened).\n2. Measured under 3 hardening profiles: permissive (minimal hardening), balanced (recommended), strict (maximum hardening).\n3. Workloads: (a) HTTP request/response (JSON serialization), (b) file I/O (read/write 1MB), (c) crypto operations (AES-256-GCM encrypt/decrypt), (d) stream processing (pipe 10MB through transform), (e) cold start (time to first response).\n4. Overhead gates: balanced profile overhead <= 15% vs unhardened; strict profile overhead documented but not gated.\n5. Cold start gate: balanced profile cold start <= 500ms on reference hardware.\n6. Benchmark is run on defined reference hardware (documented CPU, RAM, OS) for reproducibility.\n7. Publication: all metrics included in benchmark report with statistical confidence intervals (>= 10 runs per workload).\n8. Evidence: performance_under_hardening.json with per-profile, per-workload, per-percentile metrics.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:39:35.727723518Z","created_by":"ubuntu","updated_at":"2026-02-20T15:24:41.205539333Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-14","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-ka0n","depends_on_id":"bd-18ie","type":"blocks","created_at":"2026-02-20T07:43:25.979948238Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-kcg9","title":"[10.17] Add zero-knowledge attestation support for selective compliance verification.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.17 — Radical Expansion Execution Track (9K)\n\nWhy This Exists:\nRadical expansion track for proof-carrying speculation, Bayesian adversary control, time-travel replay, ZK attestations, and claim compiler systems.\n\nTask Objective:\nAdd zero-knowledge attestation support for selective compliance verification.\n\nAcceptance Criteria:\n- Verifiers can validate compliance predicates without privileged disclosure of full private metadata; invalid/forged proofs fail admission.\n\nExpected Artifacts:\n- `docs/specs/zk_attestation_contract.md`, `src/trust/zk_attestation.rs`, `tests/security/zk_attestation_verification.rs`, `artifacts/10.17/zk_attestation_vectors.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_17/bd-kcg9/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_17/bd-kcg9/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.17] Add zero-knowledge attestation support for selective compliance verification.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.17] Add zero-knowledge attestation support for selective compliance verification.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.17] Add zero-knowledge attestation support for selective compliance verification.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.17] Add zero-knowledge attestation support for selective compliance verification.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.17] Add zero-knowledge attestation support for selective compliance verification.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- Verifiers can validate compliance predicates without privileged disclosure of full private metadata; invalid/forged proofs fail admission.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:37:03.348902039Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:59.957333473Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-17","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-kcg9","depends_on_id":"bd-gad3","type":"blocks","created_at":"2026-02-20T07:43:18.477551437Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-khy","title":"[10.0] Implement benchmark + standard ownership stack.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.0 — Top 10 Initiative Tracking (Initiative #10)\nCross-references: 9A.10, 9B.10, 9C.10, 9D.10\n\nWhy This Exists:\nBenchmark and standard ownership is the #10 strategic initiative. It defines and maintains the benchmark and verification standards for secure extension runtime quality, then makes external adoption part of product strategy. Owning the benchmark category means franken_node defines what \"good\" looks like for the industry.\n\nTask Objective:\nBuild the benchmark and standardization ownership stack: define benchmark suites, publish verification standards, create verifier toolkits for independent validation, and establish the category-defining measurement infrastructure.\n\nDetailed Acceptance Criteria:\n1. Public benchmark suite covering: compatibility correctness by API/risk band, performance under hardening, containment/revocation latency, replay determinism, migration speed, adversarial resilience (14 metric families).\n2. Benchmark specs/harness/datasets/scoring formulas published openly with reproducibility guarantees (14).\n3. Verifier toolkit for independent validation of all benchmark claims (14).\n4. Conformance vectors + external verifier contracts to force reproducible claim standards (9B.10).\n5. Statistical rigor: confidence intervals, reproducibility guarantees, verifier receipts for headline claims (9C.10).\n6. Benchmark runner determinism and throughput optimized without weakening rigor (9D.10).\n7. Version benchmark standards with migration guidance for standard evolution (14).\n8. Security and trust co-metrics included alongside performance metrics (14).\n\nKey Dependencies:\n- Depends on all other initiatives for benchmark subject matter.\n- Consumed by 10.9 (Moonshot) for public benchmark campaign infrastructure.\n- Consumed by 10.12 (Frontier) for demo gates with external reproducibility requirements.\n- Consumed by 16 (Scientific Contributions) for reproducible technical reports.\n\nExpected Artifacts:\n- Benchmark suite with harness, datasets, scoring formulas in benchmarks/ directory.\n- Verifier toolkit SDK and CLI.\n- Published benchmark specifications.\n- docs/specs/section_10_0/bd-khy_contract.md\n- artifacts/section_10_0/bd-khy/verification_evidence.json\n\nTesting and Logging Requirements:\n- Unit tests: scoring formula correctness, metric computation, determinism validation.\n- Integration tests: full benchmark run on fixture workloads producing reproducible scores.\n- E2E tests: franken-node bench run CLI producing benchmark report with all metric families.\n- Reproducibility tests: same benchmark inputs produce identical scores across runs.\n- Structured logs: BENCHMARK_STARTED, METRIC_COMPUTED, SCORE_FINALIZED, VERIFIER_RECEIPT_GENERATED with trace IDs and metric breakdown.","acceptance_criteria":"1. Benchmark suite covers all 4 category targets from Section 3: >= 95% compatibility, >= 3x migration velocity, >= 10x compromise reduction, 100% replay coverage.\n2. Each benchmark has: defined methodology, input corpus, measurement procedure, baseline value, target value, and pass/fail threshold.\n3. Benchmark results are reproducible: same input corpus and environment produces results within <= 2% variance across 5 consecutive runs.\n4. Verification standards define: what constitutes passing evidence, required artifact format, minimum test coverage, and review process for each category.\n5. Standard ownership map (10.N cross-reference): each benchmark and standard has a designated canonical owner track; ownership is machine-readable and queryable.\n6. External adoption readiness: benchmark definitions published in standalone format (Markdown + JSON schema) suitable for third-party consumption without internal tooling dependencies.\n7. Regression detection: CI runs benchmark suite on each release candidate; regression beyond threshold triggers release-gate block and owner notification.\n8. Historical tracking: benchmark results stored in append-only time-series; trend visualization available via JSON API (data points: date, version, score, pass/fail).\n9. Cross-initiative validation: benchmark suite validates deliverables from all other 9 initiatives (bd-1qp through bd-2g0); each initiative has >= 1 dedicated benchmark.\n10. Verification evidence includes: benchmark suite execution report, reproducibility variance measurement, standard ownership map snapshot, regression detection test with intentional regression injection.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:36:43.207029086Z","created_by":"ubuntu","updated_at":"2026-02-20T15:36:43.932338003Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-0","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-khy","depends_on_id":"bd-2g0","type":"blocks","created_at":"2026-02-20T07:43:10.478302436Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-khy","depends_on_id":"bd-2ja","type":"blocks","created_at":"2026-02-20T15:01:24.719582173Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-khy","depends_on_id":"bd-3ex","type":"blocks","created_at":"2026-02-20T15:01:24.901907126Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-kiqr","title":"[12] Risk control: trust-system complexity","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 12\n\nTask Objective:\nImplement deterministic replay and degraded-mode contract enforcement for trust-system complexity risk.\n\nExecution Requirements:\n- Make this requirement machine-verifiable and release-gated where applicable.\n- Keep behavior self-documenting so future contributors do not need to re-open the master plan.\n\nTesting & Logging Requirements:\n- Unit tests for rule/contract logic and error conditions.\n- Integration/E2E tests for workflow-level enforcement.\n- Structured logs with stable codes and trace IDs.\n- Reproducible artifacts that prove contract satisfaction.\n\nAcceptance Criteria:\n- Success and failure invariants for [12] Risk control: trust-system complexity are explicitly quantified and machine-verifiable.\n- Determinism requirements for [12] Risk control: trust-system complexity are validated across repeated runs and adversarial perturbations.\n\n\nExpected Artifacts:\n- Machine-readable verification artifact with explicit canonical path under artifacts/section_12/bd-kiqr/verification_evidence.json, suitable for CI/release gating.\n- Human-readable verification summary with explicit canonical path under artifacts/section_12/bd-kiqr/verification_summary.md, linking implementation intent to measured validation outcomes.\n\nTask-Specific Clarification:\n- The implementation must deliver the exact capability named in the title, with no scope dilution and no silent feature omission.\n- Validation artifacts must include capability-specific thresholds, pass/fail criteria, and reproducible evidence bundles tied to this bead ID.\n- Program/section verification gates must be able to consume this bead's outputs without manual interpretation.\n\nWhy This Improves User Outcomes:\n- \"[12] Risk control: trust-system complexity\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[12] Risk control: trust-system complexity\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"RISK: Trust-system complexity — the trust subsystem becomes so complex that reasoning about its behavior is impossible, leading to subtle security gaps.\nIMPACT: Undetectable trust violations, inability to audit trust decisions, security incidents from logic errors in trust evaluation.\nCOUNTERMEASURES:\n  (a) Deterministic replay: every trust decision is replayable from a recorded input state, producing identical output.\n  (b) Degraded-mode contracts: explicit specification of trust-system behavior when components fail (e.g., default-deny, cached decisions with TTL).\n  (c) Trust decision logging: every trust evaluation logs input, decision, reasoning chain, and timestamp.\nVERIFICATION:\n  1. Deterministic replay test: record N trust decisions, replay them, verify bit-identical outputs for >= 99.9% of cases.\n  2. Degraded-mode test: simulate trust-component failure; verify system falls back to specified degraded behavior (not undefined).\n  3. Trust decision audit log is complete — no trust evaluation occurs without a log entry.\n  4. Trust logic has < 500 lines of core decision code (complexity budget).\nTEST SCENARIOS:\n  - Scenario A: Replay 1000 recorded trust decisions; verify 100% deterministic reproduction.\n  - Scenario B: Kill the trust-evaluation service; verify degraded-mode contract activates (default-deny within 1s).\n  - Scenario C: Inject a novel trust input not in training data; verify it is logged and handled by fallback policy.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:39:33.416363092Z","created_by":"ubuntu","updated_at":"2026-02-20T15:18:14.716977030Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-12","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-kiqr","depends_on_id":"bd-38ri","type":"blocks","created_at":"2026-02-20T07:43:24.820420308Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-kwwg","title":"[10.21] Integrate BPET with DGIS for topology-amplified early warning prioritization.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.21 — Behavioral Phenotype Evolution Tracker Execution Track (9O)\n\nWhy This Exists:\nBPET longitudinal phenotype intelligence track for pre-compromise trajectory detection and integration with DGIS/ATC/migration/economic policy.\n\nTask Objective:\nIntegrate BPET with DGIS for topology-amplified early warning prioritization.\n\nAcceptance Criteria:\n- Trajectory anomalies at high-centrality nodes are escalated by policy with explicit expected-loss context; prioritization logic is deterministic and replayable.\n\nExpected Artifacts:\n- `src/security/bpet/dgis_fusion.rs`, `tests/integration/bpet_dgis_priority_escalation.rs`, `artifacts/10.21/bpet_dgis_escalation_report.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_21/bd-kwwg/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_21/bd-kwwg/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.21] Integrate BPET with DGIS for topology-amplified early warning prioritization.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.21] Integrate BPET with DGIS for topology-amplified early warning prioritization.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.21] Integrate BPET with DGIS for topology-amplified early warning prioritization.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.21] Integrate BPET with DGIS for topology-amplified early warning prioritization.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.21] Integrate BPET with DGIS for topology-amplified early warning prioritization.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- Trajectory anomalies at high-centrality nodes are escalated by policy with explicit expected-loss context; prioritization logic is deterministic and replayable.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:37:08.460878340Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:26.872915118Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-21","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-kwwg","depends_on_id":"bd-232t","type":"blocks","created_at":"2026-02-20T07:43:21.676965742Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-kwwg","depends_on_id":"bd-t89w","type":"blocks","created_at":"2026-02-20T15:01:15.323735085Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-kxdz","title":"Epic: Security + Policy Product Surfaces [10.5]","description":"- type: epic","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-20T07:47:58.072163029Z","updated_at":"2026-02-20T07:49:21.113054365Z","closed_at":"2026-02-20T07:49:21.113036612Z","close_reason":"Superseded by canonical detailed master-plan graph (bd-33v) with full 10.N-10.21 and 11-16 coverage, explicit dependencies, and per-section verification gates.","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-lim8","title":"Epic: Control-Plane Execution Migration [10.15b]","description":"- type: epic","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-20T07:47:58.072163029Z","updated_at":"2026-02-20T07:49:21.261623906Z","closed_at":"2026-02-20T07:49:21.261603528Z","close_reason":"Superseded by canonical detailed master-plan graph (bd-33v) with full 10.N-10.21 and 11-16 coverage, explicit dependencies, and per-section verification gates.","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-lus","title":"[10.11] Integrate canonical scheduler lane and global bulkhead policies (from `10.14` + `10.15`) for product operations.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.11 — FrankenSQLite-Inspired Runtime Systems Integration Track\n\nWhy This Exists:\nFrankenSQLite-inspired systems integration of capabilities, cancellation protocol, obligations, deterministic labs, and anti-entropy.\n\nTask Objective:\nIntegrate canonical scheduler lane and global bulkhead policies (from `10.14` + `10.15`) for product operations.\n\nAcceptance Criteria:\n- Implement with explicit success/failure invariants and deterministic behavior under normal, edge, and fault scenarios.\n- Ensure outcomes are verifiable via automated tests and reproducible artifact outputs.\n\nExpected Artifacts:\n- Section-owned design/spec artifact at `docs/specs/section_10_11/bd-lus_contract.md`, capturing decision rationale, invariants, and interface boundaries.\n- Machine-readable verification artifact at `artifacts/section_10_11/bd-lus/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_11/bd-lus/verification_summary.md` linking implementation intent to measured outcomes.\n\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.11] Integrate canonical scheduler lane and global bulkhead policies (from `10.14` + `10.15`) for product operations.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.11] Integrate canonical scheduler lane and global bulkhead policies (from `10.14` + `10.15`) for product operations.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.11] Integrate canonical scheduler lane and global bulkhead policies (from `10.14` + `10.15`) for product operations.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.11] Integrate canonical scheduler lane and global bulkhead policies (from `10.14` + `10.15`) for product operations.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.11] Integrate canonical scheduler lane and global bulkhead policies (from `10.14` + `10.15`) for product operations.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"AC for bd-lus:\n1. Integrate the canonical scheduler lane model from 10.14 + 10.15: all product operations are assigned to one of the defined lanes (e.g., Cancel, Timed, Ready, Background) based on a LanePolicy mapping; operations without an explicit lane assignment default to Background.\n2. Each lane has configurable concurrency limits (max_concurrent), priority weight, and preemption rules; the scheduler respects lane isolation such that a saturated Background lane cannot starve Cancel or Timed lanes.\n3. A global bulkhead enforces a system-wide max_in_flight limit across all lanes; when the global limit is reached, new operations are rejected with BULKHEAD_OVERLOAD error and backpressure signal rather than silently queuing.\n4. Lane configuration is loaded from the same config system (config.rs) and can be updated at runtime via config reload; lane limit changes take effect for newly submitted operations (in-flight operations retain their lane assignment).\n5. Priority ordering within a lane follows: Cancel > Timed > Ready > Background. Operations in the Cancel lane are always scheduled first, ensuring cancellation signals are never starved by application work.\n6. Metrics are exposed per-lane: in_flight (gauge), queued (gauge), completed (counter), rejected (counter), and p99_queue_wait_ms (histogram). Global metrics: total_in_flight (gauge), bulkhead_rejections (counter).\n7. Unit tests verify: (a) operations are assigned to correct lanes per policy, (b) lane concurrency limit is respected, (c) global bulkhead rejects when limit reached, (d) Cancel lane is never starved when Background lane is saturated, (e) runtime config reload updates lane limits for new operations, (f) unknown lane in policy defaults to Background with a warning.\n8. Integration test: simulate 100 concurrent operations across 4 lanes with a global bulkhead of 50 and verify no lane starvation and correct rejection count.\n9. Structured log events: LANE_ASSIGNED / LANE_SATURATED / BULKHEAD_OVERLOAD / LANE_CONFIG_RELOAD with operation_id, lane_name, and current_in_flight counts.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:36:50.637018927Z","created_by":"ubuntu","updated_at":"2026-02-20T15:19:33.861958046Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-11","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-lus","depends_on_id":"bd-3hw","type":"blocks","created_at":"2026-02-20T07:43:11.832104188Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-lus","depends_on_id":"bd-cuut","type":"blocks","created_at":"2026-02-20T15:00:19.396010444Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-lus","depends_on_id":"bd-qlc6","type":"blocks","created_at":"2026-02-20T15:00:19.016005147Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-lus","depends_on_id":"bd-v4l0","type":"blocks","created_at":"2026-02-20T15:00:19.207380051Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-m8p","title":"[10.9] Build verifier economy portal and external attestation publishing flow.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.9 — Moonshot Disruption Track\n\nWhy This Exists:\nMoonshot disruption track for public benchmark leadership, adversarial campaigns, verifier economy, and category-shift reporting.\n\nTask Objective:\nBuild verifier economy portal and external attestation publishing flow.\n\nAcceptance Criteria:\n- Implement with explicit success/failure invariants and deterministic behavior under normal, edge, and fault scenarios.\n- Ensure outcomes are verifiable via automated tests and reproducible artifact outputs.\n\nExpected Artifacts:\n- Section-owned design/spec artifact at `docs/specs/section_10_9/bd-m8p_contract.md`, capturing decision rationale, invariants, and interface boundaries.\n- Machine-readable verification artifact at `artifacts/section_10_9/bd-m8p/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_9/bd-m8p/verification_summary.md` linking implementation intent to measured outcomes.\n\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.9] Build verifier economy portal and external attestation publishing flow.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.9] Build verifier economy portal and external attestation publishing flow.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.9] Build verifier economy portal and external attestation publishing flow.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.9] Build verifier economy portal and external attestation publishing flow.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.9] Build verifier economy portal and external attestation publishing flow.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"1. Verifier economy portal provides a web-accessible interface where external parties can submit artifacts for independent verification and retrieve attestation results.\n2. Attestation publishing flow: verified results are signed, timestamped, and published in a machine-readable format (JSON + optional human-readable summary).\n3. Per Section 3.2 capability #10 (public verifier toolkit): portal is usable without any internal credentials — external verifiers authenticate via a public registration flow.\n4. Each attestation includes: artifact hash, verification method used, result (pass/fail/partial), verifier identity, and a reproducibility pointer (git commit + command to re-run).\n5. Portal tracks attestation history per artifact with a tamper-evident log (append-only, hash-chained entries).\n6. API endpoints support: submit-for-verification, check-status, retrieve-attestation, and list-attestations-for-artifact.\n7. Per Section 9H frontier programs: portal design supports federation — third-party verifier nodes can publish attestations through a documented protocol.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:36:48.524728794Z","created_by":"ubuntu","updated_at":"2026-02-20T15:20:20.270631961Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-9","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-m8p","depends_on_id":"bd-1e0","type":"blocks","created_at":"2026-02-20T07:43:24.135467152Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-mglg","title":"Epic: Compatibility Core [10.2]","description":"- type: epic","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-20T07:47:58.072163029Z","updated_at":"2026-02-20T07:49:21.095746608Z","closed_at":"2026-02-20T07:49:21.095729126Z","close_reason":"Superseded by canonical detailed master-plan graph (bd-33v) with full 10.N-10.21 and 11-16 coverage, explicit dependencies, and per-section verification gates.","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-ml1","title":"[10.4] Implement publisher reputation model with explainable transitions.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.4 — Extension Ecosystem + Registry\n\nWhy This Exists:\nExtension ecosystem and registry trust foundation: signed artifacts, provenance, trust cards, revocation, and quarantine flows.\n\nTask Objective:\nImplement publisher reputation model with explainable transitions.\n\nAcceptance Criteria:\n(See structured acceptance_criteria field for domain-specific criteria.)\n\nExpected Artifacts:\n- Section-owned design/spec artifact at `docs/specs/section_10_4/bd-ml1_contract.md`, capturing decision rationale, invariants, and interface boundaries.\n- Machine-readable verification artifact at `artifacts/section_10_4/bd-ml1/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_4/bd-ml1/verification_summary.md` linking implementation intent to measured outcomes.\n\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.4] Implement publisher reputation model with explainable transitions.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.4] Implement publisher reputation model with explainable transitions.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.4] Implement publisher reputation model with explainable transitions.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.4] Implement publisher reputation model with explainable transitions.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.4] Implement publisher reputation model with explainable transitions.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"1. Publisher reputation is a composite score in range [0.0, 1.0] computed from weighted signals: extension install count and retention (20%), security incident history (30%), attestation chain completeness (15%), behavioral telemetry anomaly rate (15%), community reports (10%), certification level maintenance (10%). 2. Reputation state machine has five levels: Unverified (new publisher, score=0), Provisional (score 0.2-0.5, <90 days history), Established (score 0.5-0.8), Trusted (score >0.8, sustained for >=180 days), Suspended (any level, triggered by security event). 3. Every state transition emits a structured explanation containing: previous_level, new_level, trigger_event, contributing_signals[] (each with signal_name, signal_value, weight, delta_contribution), and counterfactual_actions[] (actions the publisher could take to improve score, per 9C posterior decomposition). 4. Publisher staking integration per 9B: publishers at Trusted level may stake tokens; slashing occurs on verified security incidents proportional to incident severity and affected install base. Staking/slashing events update reputation score immediately. 5. Reputation decay: inactive publishers (no updates in 180 days) decay toward Provisional at rate of 0.01/week; decay is paused during active maintenance periods. 6. Anti-gaming protections: install count signal uses unique-node deduplication; anomaly detection flags sudden install spikes; self-referential dependency chains are excluded from scoring. 7. Reputation is queryable via trust card API (bd-2yh) and CLI: 'franken-node publisher reputation show <publisher-id>' with full signal breakdown. 8. Historical reputation trajectory is stored and queryable for at least 365 days, enabling trend analysis and audit. 9. Reputation changes are propagated to all trust cards referencing the publisher's extensions within one freshness cycle. 10. Structured log events: REPUTATION_TRANSITION with publisher_id, old_level, new_level, explanation_hash, and all contributing signal values.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:36:45.745765563Z","created_by":"ubuntu","updated_at":"2026-02-20T15:18:41.362584191Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-4","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-ml1","depends_on_id":"bd-2yh","type":"blocks","created_at":"2026-02-20T07:43:22.552652865Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-mwf","title":"[10.0] Implement policy-visible compatibility shim system.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.0 — Top 10 Initiative Tracking (Initiative #5)\nCross-references: 9A.5, 9B.5, 9C.5, 9D.5\n\nWhy This Exists:\nPolicy-visible compatibility shims are the #5 strategic initiative. Any behavior shim must be typed, auditable, and policy-gated so operators can choose compatibility level by risk appetite with full traceability. This prevents the common antipattern of hidden compatibility hacks that silently change security or correctness properties.\n\nTask Objective:\nImplement a system where every compatibility shim (code that adapts franken_node behavior to match Node/Bun expectations) is: explicitly typed with metadata, auditable through the divergence ledger, and gated by policy rules that operators control per-profile.\n\nDetailed Acceptance Criteria:\n1. Every shim is registered in the compatibility behavior registry (10.2) with typed metadata: affected API, behavior change description, risk level, and policy gate.\n2. Shim activation is cryptographically constrained and auditable — policy-as-data signatures with attenuation semantics (9B.5).\n3. Non-interference and monotonicity checks encoded as machine-verifiable policy compiler outputs (9C.5).\n4. Policy evaluation path optimized while preserving deterministic rule order (9D.5).\n5. Operators can enable/disable shims per compatibility mode (strict/balanced/legacy-risky) with full audit trail.\n6. Shim activation emits structured audit events consumable by observability stack.\n7. Shim registry supports versioned evolution — shims can be deprecated, superseded, or mandatory.\n\nKey Dependencies:\n- Depends on 10.2 (Compatibility Core) for behavior registry and mode selection.\n- Depends on 10.1 (Charter) for governance rules on what constitutes acceptable shimming.\n- Consumed by 10.5 (Security) for policy-visible compatibility gate APIs.\n- Consumed by 10.7 (Conformance) for verification of shim behavior.\n\nExpected Artifacts:\n- src/conformance/shim_registry.rs — typed shim registration and query.\n- src/conformance/shim_policy.rs — policy evaluation and gate logic.\n- docs/specs/section_10_0/bd-mwf_contract.md\n- artifacts/section_10_0/bd-mwf/verification_evidence.json\n\nTesting and Logging Requirements:\n- Unit tests: shim registration, policy gate evaluation per mode, attenuation semantics, monotonicity checks.\n- Integration tests: shim activation workflow from API call through policy gate to audit event emission.\n- E2E tests: operator configuring compatibility mode and observing different shim activation sets.\n- Structured logs: SHIM_REGISTERED, SHIM_ACTIVATED, SHIM_BLOCKED_BY_POLICY, POLICY_EVALUATED with trace IDs and shim metadata.","acceptance_criteria":"1. Every shim is typed: Rust struct with source API signature, target API signature, behavioral contract, and version applicability range.\n2. Shims are auditable: each shim has a unique ID, creation timestamp, author, review status, and change history in append-only log.\n3. Policy-gated activation: shims only activate when referenced policy rule evaluates to true; default is shim-disabled (deny-by-default).\n4. Shim registry queryable via CLI (`franken-node shim list --format json`) with filtering by status (active/inactive/deprecated), API category, policy gate.\n5. Shim behavioral contracts include: input/output type mapping, side-effect declaration, performance budget (max latency overhead <= 5%), and error propagation semantics.\n6. Compatibility contribution: shim system raises overall compatibility score toward >= 95% category target (Section 3) by bridging identified divergences from the divergence ledger (bd-1qp).\n7. Each shim has unit tests verifying behavioral contract; integration tests verifying policy-gate activation/deactivation.\n8. Shim overhead measurable: runtime telemetry reports per-shim invocation count, latency overhead, and error rate.\n9. Shim deprecation workflow: deprecated shims emit warnings for 2 release cycles before removal; policy can force-disable deprecated shims immediately.\n10. Verification evidence includes: shim registry snapshot, policy-gate test results, performance overhead measurements, compatibility score delta with/without shims.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:36:42.804939462Z","created_by":"ubuntu","updated_at":"2026-02-20T15:35:55.668033836Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-0","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-mwf","depends_on_id":"bd-137","type":"blocks","created_at":"2026-02-20T15:01:23.773763722Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-mwf","depends_on_id":"bd-uo4","type":"blocks","created_at":"2026-02-20T07:43:10.265371610Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-mwvn","title":"[10.14] Add policy action explainer that distinguishes diagnostic confidence from guarantee confidence.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.14 — FrankenSQLite Deep-Mined Expansion Execution Track (9J)\n\nWhy This Exists:\nFrankenSQLite deep-mined control integrity track: evidence ledgers, proofs, epochs, remote effects, markers/MMR, and deterministic fault labs.\n\nTask Objective:\nAdd policy action explainer that distinguishes diagnostic confidence from guarantee confidence.\n\nAcceptance Criteria:\n- Explainer output contains separate sections for heuristic confidence and guarantee confidence; UI/API contracts expose both values; ambiguity-free wording validated.\n\nExpected Artifacts:\n- `docs/specs/policy_explainer_contract.md`, `tests/integration/policy_explainer_output.rs`, `artifacts/10.14/policy_explainer_examples.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_14/bd-mwvn/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_14/bd-mwvn/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.14] Add policy action explainer that distinguishes diagnostic confidence from guarantee confidence.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.14] Add policy action explainer that distinguishes diagnostic confidence from guarantee confidence.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.14] Add policy action explainer that distinguishes diagnostic confidence from guarantee confidence.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.14] Add policy action explainer that distinguishes diagnostic confidence from guarantee confidence.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.14] Add policy action explainer that distinguishes diagnostic confidence from guarantee confidence.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"Explainer output contains separate sections for heuristic confidence and guarantee confidence; UI/API contracts expose both values; ambiguity-free wording validated.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:36:55.955648978Z","created_by":"ubuntu","updated_at":"2026-02-20T15:44:10.585753761Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-14","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-mwvn","depends_on_id":"bd-15u3","type":"blocks","created_at":"2026-02-20T07:43:14.638476928Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-n1w","title":"[10.12] Add frontier demo gates with external reproducibility requirements.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.12 — Frontier Programs Execution Track (9H)\n\nWhy This Exists:\nFrontier program execution turning migration singularity, trust fabric, verifier economy, and operator intelligence into production flow.\n\nTask Objective:\nAdd frontier demo gates with external reproducibility requirements.\n\nAcceptance Criteria:\n- Implement with explicit success/failure invariants and deterministic behavior under normal, edge, and fault scenarios.\n- Ensure outcomes are verifiable via automated tests and reproducible artifact outputs.\n\nExpected Artifacts:\n- Section-owned design/spec artifact at `docs/specs/section_10_12/bd-n1w_contract.md`, capturing decision rationale, invariants, and interface boundaries.\n- Machine-readable verification artifact at `artifacts/section_10_12/bd-n1w/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_12/bd-n1w/verification_summary.md` linking implementation intent to measured outcomes.\n\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.12] Add frontier demo gates with external reproducibility requirements.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.12] Add frontier demo gates with external reproducibility requirements.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.12] Add frontier demo gates with external reproducibility requirements.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.12] Add frontier demo gates with external reproducibility requirements.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.12] Add frontier demo gates with external reproducibility requirements.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"1. Define a FrontierDemoGate struct containing: (a) gate_id, (b) demo_name (one of: MIGRATION_SINGULARITY, TRUST_FABRIC, VERIFIER_ECONOMY, OPERATOR_INTELLIGENCE, ECOSYSTEM_NETWORK), (c) required_artifacts (list of artifact IDs that must exist and pass verification), (d) external_reproducibility_requirements (list of {requirement_name, verification_method, pass/fail}).\n2. Define external reproducibility requirements for each demo: (a) MIGRATION_SINGULARITY: an independent verifier (from bd-3c2 SDK) must successfully validate the migration artifact from a clean environment with no franken_node runtime dependencies. (b) TRUST_FABRIC: a simulated 3-node fabric must converge within 60s from cold start, reproducible on any Linux x86_64 host. (c) VERIFIER_ECONOMY: the verifier CLI must produce identical results when run by three different operators on the same artifact. (d) OPERATOR_INTELLIGENCE: recommendation engine must produce the same top-1 recommendation for a fixed input scenario across 10 runs (determinism). (e) ECOSYSTEM_NETWORK: registry search must return consistent results for the same query within a 5s window.\n3. Implement gate evaluation: evaluate_demo_gate(gate) -> DemoGateResult that: (a) checks all required artifacts exist, (b) runs the verification script for each artifact, (c) runs external reproducibility checks, (d) produces a DemoGateResult with per-check pass/fail and an overall verdict.\n4. Implement a reproducibility harness: a script or binary that sets up a clean environment (using temp directories, no state leakage), runs the demo scenario, and captures output hashes for comparison. The harness MUST be runnable without root privileges.\n5. Implement a demo manifest: a machine-readable JSON document listing all demos, their gates, their status (NOT_STARTED, PASSED, FAILED), and the last evaluation timestamp. Store at artifacts/section_10_12/demo_manifest.json.\n6. Enforce that no frontier program (10.12) can be marked as complete unless its corresponding demo gate has PASSED.\n7. Unit tests: (a) gate evaluation with all artifacts passing, (b) gate evaluation with one artifact missing, (c) gate evaluation with reproducibility failure, (d) demo manifest update after evaluation.\n8. Integration test: run the VERIFIER_ECONOMY demo gate end-to-end using the SDK from bd-3c2 and sample artifacts from fixtures/verifier_sdk/.\n9. Verification: scripts/check_demo_gates.py --json, artifacts at artifacts/section_10_12/bd-n1w/.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:36:51.314668632Z","created_by":"ubuntu","updated_at":"2026-02-20T15:41:11.181915229Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-12","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-n1w","depends_on_id":"bd-2aj","type":"blocks","created_at":"2026-02-20T07:43:12.179734819Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-n71","title":"[PLAN 10.16] Adjacent Substrate Integration Execution Track (8.7)","description":"Section: 10.16 — Adjacent Substrate Integration Execution Track (8.7)\n\nStrategic Context:\nAdjacent substrate integration track to enforce deep composition with frankentui, frankensqlite, sqlmodel_rust, and fastapi_rust.\n\nExecution Requirements:\n- Preserve all scoped capabilities from the canonical plan.\n- Keep contracts self-contained so future contributors can execute without reopening the master plan.\n- Require explicit testing strategy (unit + integration/e2e) and structured logging/telemetry for every child bead.\n- Require artifact-backed validation for performance, security, and correctness claims.\n\nDependency Semantics:\n- This epic is blocked by its child implementation beads.\n- Cross-epic dependencies encode strategic sequencing and canonical ownership boundaries.\n\n## Success Criteria\n- All child beads for this section are completed with acceptance artifacts attached and no unresolved blockers.\n- Section-level verification gate for comprehensive unit tests, integration/e2e workflows, and detailed structured logging evidence is green.\n- Scope-to-plan traceability is explicit, with no feature loss versus the canonical plan section.\n\n## Optimization Notes\n- User-Outcome Lens: \"[PLAN 10.16] Adjacent Substrate Integration Execution Track (8.7)\" must improve operator confidence, safety posture, and deterministic recovery behavior under both normal and adversarial conditions.\n- Cross-Section Coordination: child beads must encode integration assumptions explicitly to avoid local optimizations that degrade system-wide correctness.\n- Verification Non-Negotiable: completion requires reproducible unit/integration/E2E evidence and structured logs suitable for independent replay.\n- Scope Protection: any simplification must preserve canonical-plan feature intent and be justified with explicit tradeoff documentation.","status":"open","priority":1,"issue_type":"epic","created_at":"2026-02-20T07:36:41.539920124Z","created_by":"ubuntu","updated_at":"2026-02-20T08:16:39.699401457Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-16"],"dependencies":[{"issue_id":"bd-n71","depends_on_id":"bd-10g0","type":"blocks","created_at":"2026-02-20T07:48:16.765575787Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-n71","depends_on_id":"bd-159q","type":"blocks","created_at":"2026-02-20T07:37:02.719637680Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-n71","depends_on_id":"bd-1719","type":"blocks","created_at":"2026-02-20T07:37:01.891414144Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-n71","depends_on_id":"bd-1a1j","type":"blocks","created_at":"2026-02-20T07:37:01.973617753Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-n71","depends_on_id":"bd-1ow","type":"blocks","created_at":"2026-02-20T07:37:11.163855654Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-n71","depends_on_id":"bd-1v65","type":"blocks","created_at":"2026-02-20T07:37:02.304645182Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-n71","depends_on_id":"bd-1xtf","type":"blocks","created_at":"2026-02-20T07:37:01.808199702Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-n71","depends_on_id":"bd-26ux","type":"blocks","created_at":"2026-02-20T07:37:02.140030738Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-n71","depends_on_id":"bd-28ld","type":"blocks","created_at":"2026-02-20T07:37:01.644950751Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-n71","depends_on_id":"bd-2f5l","type":"blocks","created_at":"2026-02-20T07:37:02.469218239Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-n71","depends_on_id":"bd-2ji2","type":"blocks","created_at":"2026-02-20T07:37:02.882954758Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-n71","depends_on_id":"bd-2owx","type":"blocks","created_at":"2026-02-20T07:37:01.563730614Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-n71","depends_on_id":"bd-2tua","type":"blocks","created_at":"2026-02-20T07:37:02.056631491Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-n71","depends_on_id":"bd-34ll","type":"blocks","created_at":"2026-02-20T07:37:01.726594778Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-n71","depends_on_id":"bd-35l5","type":"blocks","created_at":"2026-02-20T07:37:02.801132770Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-n71","depends_on_id":"bd-3ndj","type":"blocks","created_at":"2026-02-20T07:37:02.386653778Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-n71","depends_on_id":"bd-3qo","type":"blocks","created_at":"2026-02-20T07:37:11.205242795Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-n71","depends_on_id":"bd-3u2o","type":"blocks","created_at":"2026-02-20T07:37:02.638135137Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-n71","depends_on_id":"bd-8l9k","type":"blocks","created_at":"2026-02-20T07:37:02.552609009Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-n71","depends_on_id":"bd-bt82","type":"blocks","created_at":"2026-02-20T07:37:02.222768632Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-n71","depends_on_id":"bd-cda","type":"blocks","created_at":"2026-02-20T07:37:09.661776379Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-n9r","title":"Implement configuration system (franken_node.toml) with profile support","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md (Bootstrap bridge for Sections 10.0, 10.2, 10.3)\nSection: BOOTSTRAP (Configuration baseline bridge)\n\nTask Objective:\nImplement the foundational `franken_node.toml` configuration system with profile support and deterministic precedence resolution for CLI, env, and file inputs.\n\nIn Scope:\n- Typed config schema with profile blocks and validation rules.\n- Deterministic merge/precedence order (CLI overrides > env > profile > defaults).\n- Deterministic diagnostics for missing, invalid, and conflicting configuration.\n\nUser-Value Rationale:\nReliable configuration is required for reproducible migrations, predictable operator behavior, and low-friction adoption.\n\nAcceptance Criteria:\n- Profile selection and merge precedence produce deterministic resolved config snapshots.\n- Invalid configs fail with stable, actionable diagnostics and non-zero exit semantics.\n- Config resolution can be consumed cleanly by `init`/`doctor` command flows without duplicated parsing logic.\n\nExpected Artifacts:\n- Config contract/spec documenting schema, precedence, and failure semantics.\n- Example config fixtures for default/dev/prod or equivalent profile classes.\n- Machine-readable resolved-config artifact for CI validation.\n\n- Machine-readable verification artifact at `artifacts/section_bootstrap/bd-n9r/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_bootstrap/bd-n9r/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for parser/validator behavior, precedence rules, and edge/failure cases.\n- Integration tests covering config loading from file/env/CLI combinations.\n- E2E tests validating real command execution under multiple profile scenarios.\n- Structured logs capturing config source provenance, merge decisions, and validation outcomes.\n\nTask-Specific Clarification:\n- For \"Implement configuration system (franken_node.toml) with profile support\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"Implement configuration system (franken_node.toml) with profile support\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"Implement configuration system (franken_node.toml) with profile support\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"Implement configuration system (franken_node.toml) with profile support\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"Implement configuration system (franken_node.toml) with profile support\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","status":"in_progress","priority":1,"issue_type":"task","assignee":"CoralReef","created_at":"2026-02-20T07:29:19.182078063Z","created_by":"ubuntu","updated_at":"2026-02-20T08:46:43.830684199Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["config","foundation"],"dependencies":[{"issue_id":"bd-n9r","depends_on_id":"bd-3rp","type":"blocks","created_at":"2026-02-20T07:29:33.007345052Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-nbh7","title":"[16] Contribution: benchmark/verifier methodology publications","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 16\n\nTask Objective:\nPublish methodology for benchmark and verifier design.\n\nExecution Requirements:\n- Make this requirement machine-verifiable and release-gated where applicable.\n- Keep behavior self-documenting so future contributors do not need to re-open the master plan.\n\nTesting & Logging Requirements:\n- Unit tests for rule/contract logic and error conditions.\n- Integration/E2E tests for workflow-level enforcement.\n- Structured logs with stable codes and trace IDs.\n- Reproducible artifacts that prove contract satisfaction.\n\nAcceptance Criteria:\n- Success and failure invariants for [16] Contribution: benchmark/verifier methodology publications are explicitly quantified and machine-verifiable.\n- Determinism requirements for [16] Contribution: benchmark/verifier methodology publications are validated across repeated runs and adversarial perturbations.\n\n\nExpected Artifacts:\n- Machine-readable verification artifact with explicit canonical path under artifacts/section_16/bd-nbh7/verification_evidence.json, suitable for CI/release gating.\n- Human-readable verification summary with explicit canonical path under artifacts/section_16/bd-nbh7/verification_summary.md, linking implementation intent to measured validation outcomes.\n\nTask-Specific Clarification:\n- The implementation must deliver the exact capability named in the title, with no scope dilution and no silent feature omission.\n- Validation artifacts must include capability-specific thresholds, pass/fail criteria, and reproducible evidence bundles tied to this bead ID.\n- Program/section verification gates must be able to consume this bead's outputs without manual interpretation.\n\nWhy This Improves User Outcomes:\n- \"[16] Contribution: benchmark/verifier methodology publications\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[16] Contribution: benchmark/verifier methodology publications\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"1. Published methodology document for benchmark design: how metrics were selected, how workloads were designed, how scoring formulas were derived, and what validity threats were considered.\n2. Published methodology document for verifier design: what claims the verifier validates, how validation is performed, what evidence is required, and what limitations exist.\n3. Methodology documents follow academic standards: (a) related work section comparing to existing approaches, (b) threat-to-validity analysis, (c) reproducibility instructions.\n4. Methodologies are peer-reviewed: >= 2 external reviewers provide written feedback; feedback and responses are published.\n5. Methodology enables independent replication: a reader can build a comparable benchmark/verifier from the methodology document alone (validated by >= 1 external replication attempt).\n6. Methodologies are versioned and updated when benchmark/verifier design changes materially.\n7. Evidence: methodology_publication_registry.json with per-document: title, version, reviewer names, review status, and replication attempts.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:39:36.959551099Z","created_by":"ubuntu","updated_at":"2026-02-20T15:28:20.458041922Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-16","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-nbh7","depends_on_id":"bd-2ad0","type":"blocks","created_at":"2026-02-20T07:43:26.636344418Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-nbwo","title":"[10.17] Publish universal verifier SDK and replay capsule format.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.17 — Radical Expansion Execution Track (9K)\n\nWhy This Exists:\nRadical expansion track for proof-carrying speculation, Bayesian adversary control, time-travel replay, ZK attestations, and claim compiler systems.\n\nTask Objective:\nPublish universal verifier SDK and replay capsule format.\n\nAcceptance Criteria:\n- External verifiers can replay signed capsules and reproduce claim verdicts without privileged internal access; capsule schema and verification APIs are stable and versioned.\n\nExpected Artifacts:\n- `sdk/verifier/*`, `docs/specs/replay_capsule_format.md`, `tests/conformance/verifier_sdk_capsule_replay.rs`, `artifacts/10.17/verifier_sdk_certification_report.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_17/bd-nbwo/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_17/bd-nbwo/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.17] Publish universal verifier SDK and replay capsule format.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.17] Publish universal verifier SDK and replay capsule format.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.17] Publish universal verifier SDK and replay capsule format.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.17] Publish universal verifier SDK and replay capsule format.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.17] Publish universal verifier SDK and replay capsule format.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- External verifiers can replay signed capsules and reproduce claim verdicts without privileged internal access; capsule schema and verification APIs are stable and versioned.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:37:03.842488483Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:58.631738243Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-17","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-nbwo","depends_on_id":"bd-2iyk","type":"blocks","created_at":"2026-02-20T07:43:18.733727838Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-nglx","title":"[11] Contract field: rollback command","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 11\n\nTask Objective:\nRequire concrete rollback command/procedure for every major subsystem change.\n\nExecution Requirements:\n- Make this requirement machine-verifiable and release-gated where applicable.\n- Keep behavior self-documenting so future contributors do not need to re-open the master plan.\n\nTesting & Logging Requirements:\n- Unit tests for rule/contract logic and error conditions.\n- Integration/E2E tests for workflow-level enforcement.\n- Structured logs with stable codes and trace IDs.\n- Reproducible artifacts that prove contract satisfaction.\n\nAcceptance Criteria:\n- Success and failure invariants for [11] Contract field: rollback command are explicitly quantified and machine-verifiable.\n- Determinism requirements for [11] Contract field: rollback command are validated across repeated runs and adversarial perturbations.\n\n\nExpected Artifacts:\n- Machine-readable verification artifact with explicit canonical path under artifacts/section_11/bd-nglx/verification_evidence.json, suitable for CI/release gating.\n- Human-readable verification summary with explicit canonical path under artifacts/section_11/bd-nglx/verification_summary.md, linking implementation intent to measured validation outcomes.\n\nTask-Specific Clarification:\n- The implementation must deliver the exact capability named in the title, with no scope dilution and no silent feature omission.\n- Validation artifacts must include capability-specific thresholds, pass/fail criteria, and reproducible evidence bundles tied to this bead ID.\n- Program/section verification gates must be able to consume this bead's outputs without manual interpretation.\n\nWhy This Improves User Outcomes:\n- \"[11] Contract field: rollback command\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[11] Contract field: rollback command\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"1. Every evidence contract includes a rollback command: a single executable command or script that reverts the change completely.\n2. The rollback command must be: (a) copy-pasteable (no placeholders requiring manual substitution), (b) idempotent (safe to run multiple times), (c) tested in CI (the command is executed in a test environment and verified to restore prior state).\n3. The contract must specify rollback scope: what is reverted (config, binary, data) and what is NOT reverted (e.g., already-processed events).\n4. CI rejects contracts where rollback command is missing, contains unresolved placeholders, or is not tested.\n5. Unit test: a contract with tested, idempotent rollback command passes; one with placeholder variables or untested command fails.\n6. Rollback command execution time must be documented (estimated seconds/minutes).","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:39:32.988255014Z","created_by":"ubuntu","updated_at":"2026-02-20T15:16:48.817420566Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-11","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-nglx","depends_on_id":"bd-2ymp","type":"blocks","created_at":"2026-02-20T07:43:24.557214665Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-novi","title":"[10.13] Define stable error code namespace and machine-readable `retryable/retry_after/recovery_hint` contract.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.13 — FCP Deep-Mined Expansion Execution Track (9I)\n\nWhy This Exists:\nDeep connector/provider contract track: lifecycle FSMs, conformance harnesses, fencing, sandboxing, revocation freshness, and protocol hardening.\n\nTask Objective:\nDefine stable error code namespace and machine-readable `retryable/retry_after/recovery_hint` contract.\n\nAcceptance Criteria:\n- Error codes are unique and namespaced; machine-readable recovery fields are present for all non-fatal errors; compatibility tests catch breaking changes.\n\nExpected Artifacts:\n- `docs/specs/error_code_contract.md`, `tests/conformance/error_contract_stability.rs`, `artifacts/10.13/error_code_registry.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_13/bd-novi/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_13/bd-novi/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.13] Define stable error code namespace and machine-readable `retryable/retry_after/recovery_hint` contract.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.13] Define stable error code namespace and machine-readable `retryable/retry_after/recovery_hint` contract.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.13] Define stable error code namespace and machine-readable `retryable/retry_after/recovery_hint` contract.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.13] Define stable error code namespace and machine-readable `retryable/retry_after/recovery_hint` contract.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.13] Define stable error code namespace and machine-readable `retryable/retry_after/recovery_hint` contract.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","status":"closed","priority":1,"issue_type":"task","assignee":"CrimsonCrane","created_at":"2026-02-20T07:36:54.657859380Z","created_by":"ubuntu","updated_at":"2026-02-20T13:22:47.359794706Z","closed_at":"2026-02-20T13:22:47.359758960Z","close_reason":"done","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-13","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-novi","depends_on_id":"bd-1ugy","type":"blocks","created_at":"2026-02-20T07:43:13.937275412Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-nr4","title":"[10.8] Implement operator runbooks for high-severity trust incidents.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.8 — Operational Readiness\n\nWhy This Exists:\nOperational readiness and fleet safety posture: control APIs, observability contracts, safe-mode operations, and disaster drills.\n\nTask Objective:\nImplement operator runbooks for high-severity trust incidents.\n\nAcceptance Criteria:\n- Implement with explicit success/failure invariants and deterministic behavior under normal, edge, and fault scenarios.\n- Ensure outcomes are verifiable via automated tests and reproducible artifact outputs.\n\nExpected Artifacts:\n- Section-owned design/spec artifact at `docs/specs/section_10_8/bd-nr4_contract.md`, capturing decision rationale, invariants, and interface boundaries.\n- Machine-readable verification artifact at `artifacts/section_10_8/bd-nr4/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_8/bd-nr4/verification_summary.md` linking implementation intent to measured outcomes.\n\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.8] Implement operator runbooks for high-severity trust incidents.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.8] Implement operator runbooks for high-severity trust incidents.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.8] Implement operator runbooks for high-severity trust incidents.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.8] Implement operator runbooks for high-severity trust incidents.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.8] Implement operator runbooks for high-severity trust incidents.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"1. Runbooks cover at minimum: trust-anchor compromise, fleet-wide quarantine escalation, control-plane split-brain, key rotation emergency, and malicious-extension detection.\n2. Each runbook follows a standard template: trigger conditions, severity classification, step-by-step response procedure, verification checks, and rollback instructions.\n3. Runbooks are stored as Markdown under docs/runbooks/ and are indexed in a table-of-contents file.\n4. Each runbook includes estimated time-to-resolution and required operator privilege level.\n5. At least one runbook is exercised end-to-end in a test environment as part of the DR drill program (cross-reference bd-3m6).\n6. Runbooks reference specific CLI commands and API calls — no vague instructions like 'contact support'.\n7. Runbook review cadence is documented: each runbook has a last-reviewed date and must be re-validated at least once per release cycle.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:36:48.105511076Z","created_by":"ubuntu","updated_at":"2026-02-20T15:18:56.718991192Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-8","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-nr4","depends_on_id":"bd-f2y","type":"blocks","created_at":"2026-02-20T07:43:23.897763606Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-nupr","title":"[10.14] Define `EvidenceEntry` schema for product control decisions with deterministic field and candidate ordering.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.14 — FrankenSQLite Deep-Mined Expansion Execution Track (9J)\n\nWhy This Exists:\nFrankenSQLite deep-mined control integrity track: evidence ledgers, proofs, epochs, remote effects, markers/MMR, and deterministic fault labs.\n\nTask Objective:\nDefine `EvidenceEntry` schema for product control decisions with deterministic field and candidate ordering.\n\nAcceptance Criteria:\n- Schema covers decision kind, candidates, constraints, chosen action, and witness references; field ordering is canonical; schema validation is enforced in CI.\n\nExpected Artifacts:\n- `docs/specs/evidence_entry_schema.md`, `spec/evidence_entry_v1.json`, `artifacts/10.14/evidence_schema_validation_report.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_14/bd-nupr/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_14/bd-nupr/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.14] Define `EvidenceEntry` schema for product control decisions with deterministic field and candidate ordering.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.14] Define `EvidenceEntry` schema for product control decisions with deterministic field and candidate ordering.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.14] Define `EvidenceEntry` schema for product control decisions with deterministic field and candidate ordering.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.14] Define `EvidenceEntry` schema for product control decisions with deterministic field and candidate ordering.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.14] Define `EvidenceEntry` schema for product control decisions with deterministic field and candidate ordering.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"Schema covers decision kind, candidates, constraints, chosen action, and witness references; field ordering is canonical; schema validation is enforced in CI.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:36:55.140064103Z","created_by":"ubuntu","updated_at":"2026-02-20T15:44:12.748893732Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-14","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-nupr","depends_on_id":"bd-1ta","type":"blocks","created_at":"2026-02-20T07:46:32.911199206Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-nupr","depends_on_id":"bd-cda","type":"blocks","created_at":"2026-02-20T07:46:32.971880877Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-nwhn","title":"[10.14] Implement root pointer atomic publication protocol (`write temp -> fsync temp -> rename -> fsync dir`).","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.14 — FrankenSQLite Deep-Mined Expansion Execution Track (9J)\n\nWhy This Exists:\nFrankenSQLite deep-mined control integrity track: evidence ledgers, proofs, epochs, remote effects, markers/MMR, and deterministic fault labs.\n\nTask Objective:\nImplement root pointer atomic publication protocol (`write temp -> fsync temp -> rename -> fsync dir`).\n\nAcceptance Criteria:\n- Publication protocol survives crash-injection tests without ambiguous root; missing fsync steps are detected by tests; root switch is atomic.\n\nExpected Artifacts:\n- `docs/specs/root_publication_protocol.md`, `tests/integration/root_pointer_crash_safety.rs`, `artifacts/10.14/root_publication_crash_matrix.csv`.\n\n- Machine-readable verification artifact at `artifacts/section_10_14/bd-nwhn/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_14/bd-nwhn/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.14] Implement root pointer atomic publication protocol (`write temp -> fsync temp -> rename -> fsync dir`).\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.14] Implement root pointer atomic publication protocol (`write temp -> fsync temp -> rename -> fsync dir`).\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.14] Implement root pointer atomic publication protocol (`write temp -> fsync temp -> rename -> fsync dir`).\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.14] Implement root pointer atomic publication protocol (`write temp -> fsync temp -> rename -> fsync dir`).\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.14] Implement root pointer atomic publication protocol (`write temp -> fsync temp -> rename -> fsync dir`).\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"Publication protocol survives crash-injection tests without ambiguous root; missing fsync steps are detected by tests; root switch is atomic.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:36:58.874236996Z","created_by":"ubuntu","updated_at":"2026-02-20T15:44:03.058800465Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-14","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-nwhn","depends_on_id":"bd-1dar","type":"blocks","created_at":"2026-02-20T07:43:16.146533186Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-okqy","title":"[10.14] Implement L1/L2/L3 trust artifact storage abstraction with explicit source-of-truth designation.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.14 — FrankenSQLite Deep-Mined Expansion Execution Track (9J)\n\nWhy This Exists:\nFrankenSQLite deep-mined control integrity track: evidence ledgers, proofs, epochs, remote effects, markers/MMR, and deterministic fault labs.\n\nTask Objective:\nImplement L1/L2/L3 trust artifact storage abstraction with explicit source-of-truth designation.\n\nAcceptance Criteria:\n- Tier abstraction exposes clear authority boundaries; source-of-truth is explicit and immutable by class; recovery path reconstructs derived tiers.\n\nExpected Artifacts:\n- `docs/specs/tiered_trust_storage.md`, `tests/integration/tiered_storage_recovery.rs`, `artifacts/10.14/tiered_storage_authority_map.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_14/bd-okqy/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_14/bd-okqy/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.14] Implement L1/L2/L3 trust artifact storage abstraction with explicit source-of-truth designation.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.14] Implement L1/L2/L3 trust artifact storage abstraction with explicit source-of-truth designation.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.14] Implement L1/L2/L3 trust artifact storage abstraction with explicit source-of-truth designation.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.14] Implement L1/L2/L3 trust artifact storage abstraction with explicit source-of-truth designation.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.14] Implement L1/L2/L3 trust artifact storage abstraction with explicit source-of-truth designation.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"Tier abstraction exposes clear authority boundaries; source-of-truth is explicit and immutable by class; recovery path reconstructs derived tiers.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:36:57.303257262Z","created_by":"ubuntu","updated_at":"2026-02-20T15:44:07.102800764Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-14","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-okqy","depends_on_id":"bd-27o2","type":"blocks","created_at":"2026-02-20T07:43:15.316661085Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-oolt","title":"[10.14] Require evidence emission for policy-driven commit/abort/quarantine/release actions.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.14 — FrankenSQLite Deep-Mined Expansion Execution Track (9J)\n\nWhy This Exists:\nFrankenSQLite deep-mined control integrity track: evidence ledgers, proofs, epochs, remote effects, markers/MMR, and deterministic fault labs.\n\nTask Objective:\nRequire evidence emission for policy-driven commit/abort/quarantine/release actions.\n\nAcceptance Criteria:\n- All policy-driven control decisions emit mandatory evidence entries; missing entry causes conformance failure; evidence links to action IDs.\n\nExpected Artifacts:\n- `tests/conformance/policy_decision_evidence.rs`, `docs/specs/policy_evidence_requirements.md`, `artifacts/10.14/policy_decision_evidence_matrix.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_14/bd-oolt/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_14/bd-oolt/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.14] Require evidence emission for policy-driven commit/abort/quarantine/release actions.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.14] Require evidence emission for policy-driven commit/abort/quarantine/release actions.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.14] Require evidence emission for policy-driven commit/abort/quarantine/release actions.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.14] Require evidence emission for policy-driven commit/abort/quarantine/release actions.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.14] Require evidence emission for policy-driven commit/abort/quarantine/release actions.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"All policy-driven control decisions emit mandatory evidence entries; missing entry causes conformance failure; evidence links to action IDs.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:36:55.303257010Z","created_by":"ubuntu","updated_at":"2026-02-20T15:44:12.323964618Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-14","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-oolt","depends_on_id":"bd-2e73","type":"blocks","created_at":"2026-02-20T07:43:14.303523007Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-oty","title":"[10.10] Integrate canonical session-authenticated control channel + monotonic anti-replay framing (from `10.13`) across product control APIs.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.10 — FCP-Inspired Hardening + Interop Integration Track\n\nWhy This Exists:\nFCP-inspired hardening/interop contract for IDs, serialization, control-channel auth, revocation freshness, and publication gating.\n\nTask Objective:\nIntegrate canonical session-authenticated control channel + monotonic anti-replay framing (from `10.13`) across product control APIs.\n\nAcceptance Criteria:\n- Implement with explicit success/failure invariants and deterministic behavior under normal, edge, and fault scenarios.\n- Ensure outcomes are verifiable via automated tests and reproducible artifact outputs.\n\nExpected Artifacts:\n- Section-owned design/spec artifact at `docs/specs/section_10_10/bd-oty_contract.md`, capturing decision rationale, invariants, and interface boundaries.\n- Machine-readable verification artifact at `artifacts/section_10_10/bd-oty/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_10/bd-oty/verification_summary.md` linking implementation intent to measured outcomes.\n\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.10] Integrate canonical session-authenticated control channel + monotonic anti-replay framing (from `10.13`) across product control APIs.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.10] Integrate canonical session-authenticated control channel + monotonic anti-replay framing (from `10.13`) across product control APIs.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.10] Integrate canonical session-authenticated control channel + monotonic anti-replay framing (from `10.13`) across product control APIs.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.10] Integrate canonical session-authenticated control channel + monotonic anti-replay framing (from `10.13`) across product control APIs.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.10] Integrate canonical session-authenticated control channel + monotonic anti-replay framing (from `10.13`) across product control APIs.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"1. Integrate the canonical session-authenticated control channel from 10.13 (control_channel.rs) into all product control API endpoints. Every control API call MUST be dispatched through an authenticated session; unauthenticated control traffic is rejected with SESSION_REQUIRED error.\n2. Enforce monotonic anti-replay framing from 10.13 (frame_parser.rs): every control message carries a session-scoped monotonic sequence number. The receiver MUST reject any message whose sequence number is <= the highest previously accepted sequence number for that session. Return REPLAY_DETECTED error with the offending and expected sequence numbers.\n3. Implement a session lifecycle for control APIs: (a) session_open(client_id, auth_token) -> session_id, (b) session_send(session_id, message, seq) -> Result, (c) session_close(session_id). Sessions have a configurable max idle timeout (default 300s) and max lifetime (default 3600s).\n4. Implement session state tracking: maintain per-session high-water-mark for sequence numbers, last activity timestamp, and total message count.\n5. On session timeout (idle or lifetime), automatically close the session and reject further messages with SESSION_EXPIRED error.\n6. Integrate with the trace_context module from 10.13: every control message MUST propagate a trace context header. Log session open/close/replay-reject events with trace correlation IDs.\n7. Implement a control API inventory: maintain a list of all control endpoints and verify each is wrapped with session authentication. Provide an audit function list_unprotected_endpoints() that returns an empty list when fully integrated.\n8. Unit tests: (a) session open/send/close lifecycle, (b) replay rejection, (c) idle timeout expiry, (d) lifetime timeout expiry, (e) unauthenticated rejection, (f) trace context propagation.\n9. Integration test: send 100 messages with correct monotonic sequences, then replay message #50 and verify rejection.\n10. Verification: scripts/check_session_auth_channel.py --json, artifacts at artifacts/section_10_10/bd-oty/.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:36:49.247751565Z","created_by":"ubuntu","updated_at":"2026-02-20T15:37:40.482297511Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-10","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-oty","depends_on_id":"bd-364","type":"blocks","created_at":"2026-02-20T07:43:11.086819540Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-oty","depends_on_id":"bd-v97o","type":"blocks","created_at":"2026-02-20T14:59:51.922380476Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-p6v1","title":"Epic: Adjacent Substrate Integration [10.16]","description":"- type: epic","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-20T07:47:58.072163029Z","updated_at":"2026-02-20T07:49:21.278189660Z","closed_at":"2026-02-20T07:49:21.278169974Z","close_reason":"Superseded by canonical detailed master-plan graph (bd-33v) with full 10.N-10.21 and 11-16 coverage, explicit dependencies, and per-section verification gates.","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-p73r","title":"[10.18] Define canonical `ExecutionReceipt` schema and deterministic serialization rules.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.18 — Verifiable Execution Fabric Execution Track (9L)\n\nWhy This Exists:\nVEF track for proof-carrying runtime compliance: receipt chains, commitment checkpoints, proof generation/verification, and claim gating.\n\nTask Objective:\nDefine canonical `ExecutionReceipt` schema and deterministic serialization rules.\n\nAcceptance Criteria:\n- Receipt schema includes action type, capability context, actor/artifact identity, policy snapshot hash, timestamp/sequence, and witness references; serialization is canonical and hash-stable.\n\nExpected Artifacts:\n- `docs/specs/vef_execution_receipt.md`, `spec/vef_execution_receipt_v1.json`, `artifacts/10.18/vef_receipt_schema_vectors.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_18/bd-p73r/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_18/bd-p73r/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.18] Define canonical `ExecutionReceipt` schema and deterministic serialization rules.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.18] Define canonical `ExecutionReceipt` schema and deterministic serialization rules.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.18] Define canonical `ExecutionReceipt` schema and deterministic serialization rules.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.18] Define canonical `ExecutionReceipt` schema and deterministic serialization rules.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.18] Define canonical `ExecutionReceipt` schema and deterministic serialization rules.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- Receipt schema includes action type, capability context, actor/artifact identity, policy snapshot hash, timestamp/sequence, and witness references; serialization is canonical and hash-stable.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:37:04.289355524Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:57.368304226Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-18","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-p73r","depends_on_id":"bd-16fq","type":"blocks","created_at":"2026-02-20T07:43:18.965727430Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-paui","title":"[12] Risk control: topological choke-point false positives","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 12\n\nTask Objective:\nUse counterfactual simulation, expected-loss calibration, and staged barrier rollout with rollback receipts.\n\nExecution Requirements:\n- Make this requirement machine-verifiable and release-gated where applicable.\n- Keep behavior self-documenting so future contributors do not need to re-open the master plan.\n\nTesting & Logging Requirements:\n- Unit tests for rule/contract logic and error conditions.\n- Integration/E2E tests for workflow-level enforcement.\n- Structured logs with stable codes and trace IDs.\n- Reproducible artifacts that prove contract satisfaction.\n\nAcceptance Criteria:\n- Success and failure invariants for [12] Risk control: topological choke-point false positives are explicitly quantified and machine-verifiable.\n- Determinism requirements for [12] Risk control: topological choke-point false positives are validated across repeated runs and adversarial perturbations.\n\n\nExpected Artifacts:\n- Machine-readable verification artifact with explicit canonical path under artifacts/section_12/bd-paui/verification_evidence.json, suitable for CI/release gating.\n- Human-readable verification summary with explicit canonical path under artifacts/section_12/bd-paui/verification_summary.md, linking implementation intent to measured validation outcomes.\n\nTask-Specific Clarification:\n- The implementation must deliver the exact capability named in the title, with no scope dilution and no silent feature omission.\n- Validation artifacts must include capability-specific thresholds, pass/fail criteria, and reproducible evidence bundles tied to this bead ID.\n- Program/section verification gates must be able to consume this bead's outputs without manual interpretation.\n\nWhy This Improves User Outcomes:\n- \"[12] Risk control: topological choke-point false positives\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[12] Risk control: topological choke-point false positives\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"RISK: Over-hardening false positives — security hardening rules are too aggressive, blocking legitimate operations and creating alert fatigue.\nIMPACT: Developers disable hardening, legitimate extensions are rejected, operational overhead from investigating false positives.\nCOUNTERMEASURES:\n  (a) Counterfactual simulation: before deploying a new hardening rule, simulate it against historical traffic to measure false-positive rate.\n  (b) Expected-loss calibration: each hardening rule has an expected-loss threshold; rules whose false-positive cost exceeds blocked-threat cost are rejected or tuned.\n  (c) Staged rollout: new hardening rules deploy in audit-only mode first, then warn mode, then enforce mode.\nVERIFICATION:\n  1. Counterfactual simulation framework exists and can replay >= 1000 historical operations against a proposed rule.\n  2. False-positive rate for any enforced rule is <= 1% (measured on historical data).\n  3. Expected-loss calibration: every enforced rule has documented false-positive cost vs blocked-threat cost, with net positive expected value.\n  4. Staged rollout: every new rule goes through audit -> warn -> enforce stages with minimum 24h per stage.\nTEST SCENARIOS:\n  - Scenario A: Propose a rule that would block 5% of legitimate operations; verify counterfactual simulation catches this and rejects enforcement.\n  - Scenario B: Deploy a rule in audit mode; verify it logs violations without blocking.\n  - Scenario C: Promote a rule from warn to enforce; verify only rules with FP rate <= 1% are promotable.\n  - Scenario D: Verify expected-loss calculation: a rule blocking $100/day of legitimate ops to prevent $10/day of threats is flagged as net-negative.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:39:33.940100297Z","created_by":"ubuntu","updated_at":"2026-02-20T15:19:53.232640682Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-12","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-paui","depends_on_id":"bd-1n1t","type":"blocks","created_at":"2026-02-20T07:43:25.084668493Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-pga7","title":"[13] Success criterion: deterministic incident containment/explanation","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 13\n\nTask Objective:\nEnsure operator workflows can contain and explain high-severity incidents deterministically.\n\nExecution Requirements:\n- Make this requirement machine-verifiable and release-gated where applicable.\n- Keep behavior self-documenting so future contributors do not need to re-open the master plan.\n\nTesting & Logging Requirements:\n- Unit tests for rule/contract logic and error conditions.\n- Integration/E2E tests for workflow-level enforcement.\n- Structured logs with stable codes and trace IDs.\n- Reproducible artifacts that prove contract satisfaction.\n\nAcceptance Criteria:\n- Success and failure invariants for [13] Success criterion: deterministic incident containment/explanation are explicitly quantified and machine-verifiable.\n- Determinism requirements for [13] Success criterion: deterministic incident containment/explanation are validated across repeated runs and adversarial perturbations.\n\n\nExpected Artifacts:\n- Machine-readable verification artifact with explicit canonical path under artifacts/section_13/bd-pga7/verification_evidence.json, suitable for CI/release gating.\n- Human-readable verification summary with explicit canonical path under artifacts/section_13/bd-pga7/verification_summary.md, linking implementation intent to measured validation outcomes.\n\nTask-Specific Clarification:\n- The implementation must deliver the exact capability named in the title, with no scope dilution and no silent feature omission.\n- Validation artifacts must include capability-specific thresholds, pass/fail criteria, and reproducible evidence bundles tied to this bead ID.\n- Program/section verification gates must be able to consume this bead's outputs without manual interpretation.\n\nWhy This Improves User Outcomes:\n- \"[13] Success criterion: deterministic incident containment/explanation\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[13] Success criterion: deterministic incident containment/explanation\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"1. Every production incident of severity >= high produces a deterministic replay artifact within 24 hours of detection.\n2. Replay artifact enables full causal explanation: root cause, propagation path, blast radius, and containment timeline.\n3. Containment is deterministic: given the same incident inputs, the containment system produces identical isolation decisions every time.\n4. Incident explanation report is generated automatically from replay artifacts (no manual investigation required for initial triage).\n5. Containment latency target: from detection to isolation <= 30 seconds for automated containment, <= 5 minutes for human-in-the-loop.\n6. Post-incident verification: replay the incident with the fix applied and confirm the incident does not recur.\n7. Evidence: incident_containment_log.json with per-incident: detection time, containment time, replay artifact path, explanation completeness score.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:39:34.584488977Z","created_by":"ubuntu","updated_at":"2026-02-20T15:22:54.121598689Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-13","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-pga7","depends_on_id":"bd-2a4l","type":"blocks","created_at":"2026-02-20T07:43:25.400230188Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-phf","title":"[10.4] Implement ecosystem telemetry for trust and adoption metrics.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.4 — Extension Ecosystem + Registry\n\nWhy This Exists:\nExtension ecosystem and registry trust foundation: signed artifacts, provenance, trust cards, revocation, and quarantine flows.\n\nTask Objective:\nImplement ecosystem telemetry for trust and adoption metrics.\n\nAcceptance Criteria:\n(See structured acceptance_criteria field for domain-specific criteria.)\n\nExpected Artifacts:\n- Section-owned design/spec artifact at `docs/specs/section_10_4/bd-phf_contract.md`, capturing decision rationale, invariants, and interface boundaries.\n- Machine-readable verification artifact at `artifacts/section_10_4/bd-phf/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_4/bd-phf/verification_summary.md` linking implementation intent to measured outcomes.\n\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.4] Implement ecosystem telemetry for trust and adoption metrics.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.4] Implement ecosystem telemetry for trust and adoption metrics.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.4] Implement ecosystem telemetry for trust and adoption metrics.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.4] Implement ecosystem telemetry for trust and adoption metrics.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.4] Implement ecosystem telemetry for trust and adoption metrics.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"1. Define ecosystem telemetry schema with metric categories: trust metrics (certification level distribution, reputation score histogram, revocation rate, mean-time-to-quarantine), adoption metrics (install/uninstall counts, active extension count per node, capability usage frequency, extension retention rate at 7d/30d/90d), and health metrics (provenance verification failure rate, attestation chain gap rate, policy violation rate). 2. All telemetry metrics use a stable metric naming convention: 'franken.ecosystem.<category>.<metric_name>' with consistent label dimensions (ext_id, publisher_id, certification_level, safety_tier). 3. Metrics are emitted via OpenTelemetry-compatible interface: counters for event counts, gauges for current-state values, histograms for latency/distribution metrics. Export targets include Prometheus exposition format and OTLP gRPC. 4. Trust score aggregation: compute fleet-wide trust posture score as weighted average of per-extension trust card scores, with anomaly detection flagging sudden trust posture drops (>10% decline in rolling 1-hour window). 5. Adoption funnel tracking: measure conversion from discovery -> install -> active_use -> retention for each extension, with cohort analysis by certification level and publisher reputation tier. 6. Privacy controls: telemetry is aggregated at the fleet level before export; no per-user or per-session data leaves the node boundary. Node-level telemetry requires explicit operator opt-in. Per-extension telemetry is anonymized using k-anonymity (k>=5 nodes) before fleet aggregation. 7. Dashboard-ready data: telemetry API endpoint GET /api/v1/ecosystem/telemetry/summary returns a pre-computed summary suitable for rendering trust posture dashboards, updated at configurable interval (default 60s). 8. Alerting thresholds: configurable alert rules for: revocation_rate > threshold, mean_trust_score < threshold, quarantine_count > threshold within time window. Alert rules are defined in policy configuration alongside certification requirements. 9. Historical telemetry retention: raw metrics retained for 30 days, hourly aggregates for 365 days, daily aggregates indefinitely. Retention is configurable per deployment. 10. Structured log events: TELEMETRY_EXPORT_CYCLE with metrics_count, export_target, export_latency_ms; TRUST_POSTURE_ANOMALY with posture_score, delta, contributing_extensions[]; TELEMETRY_PRIVACY_REDACTION with redacted_fields_count, k_anonymity_threshold.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:36:45.982792949Z","created_by":"ubuntu","updated_at":"2026-02-20T15:18:42.167687287Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-4","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-phf","depends_on_id":"bd-273","type":"blocks","created_at":"2026-02-20T07:43:22.688795246Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-q5y7","title":"Epic: Testing Infrastructure Framework","description":"- type: task","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-20T07:47:58.072163029Z","updated_at":"2026-02-20T07:49:21.077495114Z","closed_at":"2026-02-20T07:49:21.077477812Z","close_reason":"Superseded by canonical detailed master-plan graph (bd-33v) with full 10.N-10.21 and 11-16 coverage, explicit dependencies, and per-section verification gates.","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-qlc6","title":"[10.14] Map remote/control tasks to lane-aware scheduler classes with priority policies.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.14 — FrankenSQLite Deep-Mined Expansion Execution Track (9J)\n\nWhy This Exists:\nFrankenSQLite deep-mined control integrity track: evidence ledgers, proofs, epochs, remote effects, markers/MMR, and deterministic fault labs.\n\nTask Objective:\nMap remote/control tasks to lane-aware scheduler classes with priority policies.\n\nAcceptance Criteria:\n- Task classes are mapped to lanes by policy; lane starvation and misclassification checks are enforced; lane telemetry is exposed.\n\nExpected Artifacts:\n- `docs/specs/lane_mapping_policy.md`, `tests/conformance/lane_mapping_enforcement.rs`, `artifacts/10.14/lane_mapping_metrics.csv`.\n\n- Machine-readable verification artifact at `artifacts/section_10_14/bd-qlc6/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_14/bd-qlc6/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.14] Map remote/control tasks to lane-aware scheduler classes with priority policies.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.14] Map remote/control tasks to lane-aware scheduler classes with priority policies.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.14] Map remote/control tasks to lane-aware scheduler classes with priority policies.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.14] Map remote/control tasks to lane-aware scheduler classes with priority policies.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.14] Map remote/control tasks to lane-aware scheduler classes with priority policies.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"Task classes are mapped to lanes by policy; lane starvation and misclassification checks are enforced; lane telemetry is exposed.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:36:58.061700429Z","created_by":"ubuntu","updated_at":"2026-02-20T15:44:05.186931120Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-14","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-qlc6","depends_on_id":"bd-v4l0","type":"blocks","created_at":"2026-02-20T07:43:15.698361701Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-r6i","title":"[PLAN 16] Scientific Contribution Output","description":"Section 16 research-output epic. Produce open specs, reproducible datasets, publishable methodology, external evaluations, and transparent failure/correction reports.\n\n## Success Criteria\n- All child beads for this section are completed with acceptance artifacts attached and no unresolved blockers.\n- Section-level verification gate for comprehensive unit tests, integration/e2e workflows, and detailed structured logging evidence is green.\n- Scope-to-plan traceability is explicit, with no feature loss versus the canonical plan section.\n\n## Optimization Notes\n- User-Outcome Lens: \"[PLAN 16] Scientific Contribution Output\" must improve real operator and end-user reliability, explainability, and time-to-safe-outcome under both normal and degraded conditions.\n- Cross-Section Coordination: this epic's child beads must explicitly encode integration expectations with neighboring sections to prevent local optimizations that break global behavior.\n- Verification Non-Negotiable: completion requires deterministic unit coverage, integration/E2E replay evidence, and structured logs sufficient for independent third-party reproduction and triage.\n- Scope Protection: any proposed simplification must prove feature parity against plan intent and document tradeoffs explicitly; silent scope reduction is forbidden.","status":"open","priority":2,"issue_type":"epic","created_at":"2026-02-20T07:36:42.403660417Z","created_by":"ubuntu","updated_at":"2026-02-20T08:12:48.507532518Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-16"],"dependencies":[{"issue_id":"bd-r6i","depends_on_id":"bd-10ee","type":"blocks","created_at":"2026-02-20T07:39:37.171008727Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-r6i","depends_on_id":"bd-1sgr","type":"blocks","created_at":"2026-02-20T07:39:37.257015480Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-r6i","depends_on_id":"bd-1wz","type":"blocks","created_at":"2026-02-20T07:38:36.701224981Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-r6i","depends_on_id":"bd-2ad0","type":"blocks","created_at":"2026-02-20T07:39:36.913292975Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-r6i","depends_on_id":"bd-2ke","type":"blocks","created_at":"2026-02-20T07:38:36.615754206Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-r6i","depends_on_id":"bd-32p","type":"blocks","created_at":"2026-02-20T07:38:36.745702849Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-r6i","depends_on_id":"bd-33u2","type":"blocks","created_at":"2026-02-20T07:39:37.428935502Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-r6i","depends_on_id":"bd-37i","type":"blocks","created_at":"2026-02-20T07:38:36.878486012Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-r6i","depends_on_id":"bd-39a","type":"blocks","created_at":"2026-02-20T07:38:36.788618076Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-r6i","depends_on_id":"bd-3id1","type":"blocks","created_at":"2026-02-20T07:39:37.085703220Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-r6i","depends_on_id":"bd-4ou","type":"blocks","created_at":"2026-02-20T07:38:36.574375200Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-r6i","depends_on_id":"bd-e5cz","type":"blocks","created_at":"2026-02-20T07:39:37.343195305Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-r6i","depends_on_id":"bd-f955","type":"blocks","created_at":"2026-02-20T07:39:36.824189704Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-r6i","depends_on_id":"bd-nbh7","type":"blocks","created_at":"2026-02-20T07:39:36.999379977Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-r6i","depends_on_id":"bd-t8m","type":"blocks","created_at":"2026-02-20T07:38:36.659507525Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-r6i","depends_on_id":"bd-unkm","type":"blocks","created_at":"2026-02-20T07:48:31.769111976Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-r6i","depends_on_id":"bd-ybe","type":"blocks","created_at":"2026-02-20T07:38:36.831764184Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-s4cu","title":"[12] Risk control: compatibility illusion","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 12 — Risk Register\nRisk: Compatibility Illusion (Risk #1 of 12)\n\nWhy This Exists:\nThe compatibility illusion risk is that franken_node appears compatible in testing but diverges in subtle, hard-to-detect ways under real-world conditions. This is the #1 risk because it directly undermines the core value proposition.\n\nTask Objective:\nImplement countermeasures for the compatibility illusion risk: lockstep oracle + divergence receipts. Ensure the risk is continuously monitored and the countermeasures are active.\n\nDetailed Acceptance Criteria:\n1. Lockstep oracle (from 10.0 Initiative #4) actively running on all compatibility bands with continuous divergence detection.\n2. Divergence receipts (from 10.0 Initiative #1) automatically generated for any detected behavioral difference.\n3. Compatibility corpus targets >= 95% pass rate (Success Criteria from Section 13).\n4. Monitoring dashboard shows real-time compatibility health per API family (from 10.2 regression dashboard).\n5. Alert system triggers when compatibility drops below threshold or new divergences appear.\n6. Risk mitigation documented with explicit evidence artifacts proving countermeasure effectiveness.\n\nKey Dependencies:\n- Depends on 10.2 (Compatibility Core) for lockstep runners and band definitions.\n- Depends on 10.0 (compatibility envelope, lockstep oracle) for countermeasure implementation.\n- Feeds into 13 (Success Criteria) for >= 95% compatibility corpus pass target.\n\nExpected Artifacts:\n- Risk mitigation report with evidence of countermeasure effectiveness.\n- Monitoring configuration for compatibility health.\n- artifacts/section_12/bd-s4cu/verification_evidence.json\n\nTesting and Logging Requirements:\n- Unit tests: risk threshold detection, alert triggering logic.\n- Integration tests: lockstep oracle -> divergence detection -> receipt generation -> alert pipeline.\n- E2E tests: simulated compatibility degradation triggering alert and risk escalation.\n- Structured logs: RISK_COMPATIBILITY_CHECKED, DIVERGENCE_DETECTED, RISK_THRESHOLD_BREACHED, COUNTERMEASURE_ACTIVE with risk level and trace IDs.","acceptance_criteria":"RISK: Compatibility illusion — passing compatibility tests while actual runtime behavior diverges, creating false confidence.\nIMPACT: Production failures in migrated workloads that passed all pre-migration checks; erosion of trust in compatibility claims.\nCOUNTERMEASURES:\n  (a) Lockstep oracle: run franken_node and reference Node.js side-by-side on identical inputs, compare outputs byte-for-byte.\n  (b) Divergence receipts: every oracle comparison produces a signed receipt recording inputs, outputs, and match/mismatch verdict.\n  (c) Receipt persistence: all divergence receipts are stored in artifacts/ with retention policy.\nVERIFICATION:\n  1. Lockstep oracle exists and runs on >= 500 representative API call sequences from the compatibility corpus.\n  2. Divergence receipts are generated for every comparison (both match and mismatch).\n  3. Any mismatch receipt triggers a blocking CI failure — no silent divergences.\n  4. Receipt format is machine-parseable (JSON) with fields: input_hash, expected_output_hash, actual_output_hash, verdict, timestamp.\nTEST SCENARIOS:\n  - Scenario A: Inject a subtle behavioral divergence (e.g., different error message format); verify oracle detects it and blocks merge.\n  - Scenario B: Run 100 matching comparisons; verify all produce match receipts and CI passes.\n  - Scenario C: Tamper with a receipt; verify integrity check catches the tampering.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:39:33.242758563Z","created_by":"ubuntu","updated_at":"2026-02-20T16:08:06.512489468Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-12","self-contained","test-obligations"]}
{"id":"bd-s6y","title":"[10.7] Adopt canonical trust protocol vectors from `10.13` + `10.14` and enforce release/publication gates on those vectors.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.7 — Conformance + Verification\n\nWhy This Exists:\nConformance and verification evidence stack for compatibility, trust protocols, fuzzing, and external reproducibility.\n\nTask Objective:\nAdopt canonical trust protocol vectors from `10.13` + `10.14` and enforce release/publication gates on those vectors.\n\nAcceptance Criteria:\n- Implement with explicit success/failure invariants and deterministic behavior under normal, edge, and fault scenarios.\n- Ensure outcomes are verifiable via automated tests and reproducible artifact outputs.\n\nExpected Artifacts:\n- Section-owned design/spec artifact at `docs/specs/section_10_7/bd-s6y_contract.md`, capturing decision rationale, invariants, and interface boundaries.\n- Machine-readable verification artifact at `artifacts/section_10_7/bd-s6y/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_7/bd-s6y/verification_summary.md` linking implementation intent to measured outcomes.\n\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.7] Adopt canonical trust protocol vectors from `10.13` + `10.14` and enforce release/publication gates on those vectors.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.7] Adopt canonical trust protocol vectors from `10.13` + `10.14` and enforce release/publication gates on those vectors.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.7] Adopt canonical trust protocol vectors from `10.13` + `10.14` and enforce release/publication gates on those vectors.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.7] Adopt canonical trust protocol vectors from `10.13` + `10.14` and enforce release/publication gates on those vectors.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.7] Adopt canonical trust protocol vectors from `10.13` + `10.14` and enforce release/publication gates on those vectors.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"1. All canonical trust protocol vectors from 10.13 (golden vectors, interop suites, fuzz corpus) and 10.14 are imported into the release verification pipeline.\n2. Release gate: CI blocks release if any canonical vector fails verification — no override without explicit exception.\n3. Publication gate: documentation or artifact publication is blocked if associated trust vectors have not passed in the current build.\n4. Vector adoption is traceable: each imported vector references its source bead ID and version.\n5. Gate produces a structured JSON report listing each vector set, its pass/fail status, and the timestamp of last verification.\n6. New vectors added in 10.13/10.14 are automatically picked up by the gate without manual integration (convention-based discovery).\n7. Per Section 3.2 capability #7 (compatibility lockstep oracle): vectors include cross-runtime comparison results where applicable.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:36:47.344215304Z","created_by":"ubuntu","updated_at":"2026-02-20T15:16:48.213341487Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-7","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-s6y","depends_on_id":"bd-2ja","type":"blocks","created_at":"2026-02-20T07:43:23.482001019Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-s6y","depends_on_id":"bd-3i6c","type":"blocks","created_at":"2026-02-20T15:00:23.289283159Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-s6y","depends_on_id":"bd-3n2u","type":"blocks","created_at":"2026-02-20T15:00:23.111978942Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-sddz","title":"[10.14] Define immutable correctness envelope that policy controllers are forbidden to modify.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.14 — FrankenSQLite Deep-Mined Expansion Execution Track (9J)\n\nWhy This Exists:\nFrankenSQLite deep-mined control integrity track: evidence ledgers, proofs, epochs, remote effects, markers/MMR, and deterministic fault labs.\n\nTask Objective:\nDefine immutable correctness envelope that policy controllers are forbidden to modify.\n\nAcceptance Criteria:\n- Envelope enumerates non-tunable invariants; controller API rejects writes outside allowed policy set; governance doc maps invariant ownership.\n\nExpected Artifacts:\n- `docs/specs/correctness_envelope.md`, `tests/security/controller_envelope_enforcement.rs`, `artifacts/10.14/correctness_envelope_manifest.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_14/bd-sddz/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_14/bd-sddz/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.14] Define immutable correctness envelope that policy controllers are forbidden to modify.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.14] Define immutable correctness envelope that policy controllers are forbidden to modify.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.14] Define immutable correctness envelope that policy controllers are forbidden to modify.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.14] Define immutable correctness envelope that policy controllers are forbidden to modify.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.14] Define immutable correctness envelope that policy controllers are forbidden to modify.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"Envelope enumerates non-tunable invariants; controller API rejects writes outside allowed policy set; governance doc maps invariant ownership.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:36:55.549959217Z","created_by":"ubuntu","updated_at":"2026-02-20T15:44:11.673642863Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-14","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-sddz","depends_on_id":"bd-2ona","type":"blocks","created_at":"2026-02-20T07:43:14.429325149Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-sh3","title":"[10.5] Implement policy change approval workflows with cryptographic audit trail.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.5 — Security + Policy Product Surfaces\n\nWhy This Exists:\nSecurity and policy product surfaces: decision receipts, incident replay, expected-loss policying, and auditable degraded-mode behavior.\n\nTask Objective:\nImplement policy change approval workflows with cryptographic audit trail.\n\nAcceptance Criteria:\n- Implement with explicit success/failure invariants and deterministic behavior under normal, edge, and fault scenarios.\n- Ensure outcomes are verifiable via automated tests and reproducible artifact outputs.\n\nExpected Artifacts:\n- Section-owned design/spec artifact at `docs/specs/section_10_5/bd-sh3_contract.md`, capturing decision rationale, invariants, and interface boundaries.\n- Machine-readable verification artifact at `artifacts/section_10_5/bd-sh3/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_5/bd-sh3/verification_summary.md` linking implementation intent to measured outcomes.\n\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.5] Implement policy change approval workflows with cryptographic audit trail.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.5] Implement policy change approval workflows with cryptographic audit trail.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.5] Implement policy change approval workflows with cryptographic audit trail.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.5] Implement policy change approval workflows with cryptographic audit trail.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.5] Implement policy change approval workflows with cryptographic audit trail.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"1. Define a PolicyChangeProposal struct containing: proposal_id (UUID v7), proposed_by (string, operator identity), proposed_at (RFC-3339), policy_diff (structured diff showing old and new values for each changed field), justification (string, minimum 20 characters), risk_assessment (enum: Low | Medium | High | Critical), and required_approvers (Vec<String>, minimum 1).\n2. Implement a multi-step approval workflow: Proposed -> UnderReview -> Approved | Rejected -> Applied | Rolled-back. Each state transition must produce a PolicyChangeAuditEntry containing: transition_from, transition_to, actor, timestamp, and signature (Ed25519 over canonical JSON of the entry).\n3. Approval requires signatures from all identities listed in required_approvers; the system must verify each signature before advancing to Approved state. Partial approval (some but not all signatures) keeps the proposal in UnderReview.\n4. Implement a cryptographic audit trail: an append-only log of PolicyChangeAuditEntry records where each entry includes a prev_hash field (SHA-256 of the preceding entry's canonical JSON), forming a hash chain. The first entry uses a well-known genesis hash (SHA-256 of the empty string).\n5. Provide verify_audit_chain(entries: &[PolicyChangeAuditEntry]) -> Result<bool> that walks the chain and confirms every prev_hash and signature is valid; any break returns Err with the index of the first invalid entry.\n6. Rollback: an applied policy change can be rolled back by creating a new proposal whose policy_diff is the inverse of the original; it must reference the original proposal_id via a rollback_of field and follow the same approval workflow.\n7. Verification: scripts/check_policy_approval.py --json exercises the full lifecycle (propose, review, approve with valid sigs, apply, rollback), verifies the audit chain, and tests rejection of a tampered entry; unit tests in tests/test_check_policy_approval.py cover partial approval, invalid signature rejection, chain verification with N=50 entries, and rollback linkage; evidence in artifacts/section_10_5/bd-sh3/.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:36:46.622383372Z","created_by":"ubuntu","updated_at":"2026-02-20T15:16:21.016541630Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-5","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-sh3","depends_on_id":"bd-3nr","type":"blocks","created_at":"2026-02-20T07:43:23.064370594Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-sxt5","title":"[15] Adoption target: deterministic migration validation on representative Node/Bun project cohorts","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 15 — Ecosystem Capture Strategy\n\nWhy This Exists:\nSection 15 defines 5 execution pillars and 3 adoption targets. This bead covers the adoption target requiring deterministic migration validation on representative Node/Bun project cohorts, ensuring that the migration autopilot and lockstep oracle produce reliable results on real-world projects.\n\nTask Objective:\nBuild and maintain a representative project cohort for deterministic migration validation. The cohort must include diverse Node and Bun project archetypes. Migration audit, rewrite, and lockstep validation must produce deterministic, reproducible results on every cohort member.\n\nAcceptance Criteria:\n- Define cohort of minimum 10 representative Node/Bun projects (covering Express, Fastify, Next.js, Remix, CLI tools, Bun workers, extension hosts, monorepos, etc.).\n- Migration audit produces identical findings on repeated runs for each cohort member.\n- Migration rewrite produces deterministic transforms with rollback artifacts.\n- Lockstep validation passes with documented divergence receipts for known edge cases.\n- Cohort is version-pinned and CI-reproducible.\n- Results are published as machine-readable validation evidence.\n\nExpected Artifacts:\n- tests/e2e/migration_cohort_validation.sh\n- docs/ecosystem/migration_cohort_definition.md\n- artifacts/15/migration_cohort_results.json\n\n- Machine-readable verification artifact at `artifacts/section_15/bd-sxt5/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_15/bd-sxt5/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- E2E test scripts exercising full migration pipeline on each cohort member.\n- Structured logging with stable codes and trace correlation IDs.\n- Deterministic replay fixtures for divergence analysis.\n\nTask-Specific Clarification:\n- For \"[15] Adoption target: deterministic migration validation on representative Node/Bun project cohorts\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[15] Adoption target: deterministic migration validation on representative Node/Bun project cohorts\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[15] Adoption target: deterministic migration validation on representative Node/Bun project cohorts\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[15] Adoption target: deterministic migration validation on representative Node/Bun project cohorts\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[15] Adoption target: deterministic migration validation on representative Node/Bun project cohorts\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"1. Representative project cohort defined: >= 10 real-world Node.js/Bun projects spanning all major archetypes (web server, SSR app, CLI, library, worker, monorepo, native addon project, TypeScript-heavy project, test-heavy project, minimal project).\n2. Each cohort project has: (a) pre-migration baseline (test suite results on original runtime), (b) migration executed using franken_node migration kit, (c) post-migration validation (same test suite on franken_node).\n3. Deterministic validation: post-migration test suite produces identical pass/fail results on repeated runs (flaky rate < 1%).\n4. Migration success criteria per project: >= 95% of original test suite passes on franken_node (or all failures are documented as known incompatibilities).\n5. Cohort-wide success: >= 80% of cohort projects meet the per-project success criteria.\n6. Cohort is refreshed at least once per major release to ensure continued relevance.\n7. Results are published with project descriptions (anonymized if needed) and per-project migration outcomes.\n8. Evidence: migration_cohort_results.json with per-project: archetype, test count, pass rate, known incompatibilities, and overall cohort success rate.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T08:01:45.235566011Z","created_by":"ubuntu","updated_at":"2026-02-20T16:08:49.083357999Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-15","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-sxt5","depends_on_id":"bd-elog","type":"blocks","created_at":"2026-02-20T08:03:58.137496018Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-t89w","title":"[10.20] Implement topological risk metric engine (fan-out, betweenness, articulation points, percolation thresholds, trust bottleneck scores).","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.20 — Dependency Graph Immune System Execution Track (9N)\n\nWhy This Exists:\nDGIS topological immune system track for dependency contagion modeling, choke-point immunization, and graph-aware containment economics.\n\nTask Objective:\nImplement topological risk metric engine (fan-out, betweenness, articulation points, percolation thresholds, trust bottleneck scores).\n\nAcceptance Criteria:\n- Metric computation is deterministic, versioned, and scalable for representative ecosystem graph sizes; output includes explainable feature attribution for each high-risk node.\n\nExpected Artifacts:\n- `src/security/dgis/topology_metrics.rs`, `tests/security/dgis_topology_metrics.rs`, `artifacts/10.20/dgis_topology_risk_snapshot.csv`.\n\n- Machine-readable verification artifact at `artifacts/section_10_20/bd-t89w/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_20/bd-t89w/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.20] Implement topological risk metric engine (fan-out, betweenness, articulation points, percolation thresholds, trust bottleneck scores).\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.20] Implement topological risk metric engine (fan-out, betweenness, articulation points, percolation thresholds, trust bottleneck scores).\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.20] Implement topological risk metric engine (fan-out, betweenness, articulation points, percolation thresholds, trust bottleneck scores).\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.20] Implement topological risk metric engine (fan-out, betweenness, articulation points, percolation thresholds, trust bottleneck scores).\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.20] Implement topological risk metric engine (fan-out, betweenness, articulation points, percolation thresholds, trust bottleneck scores).\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- Metric computation is deterministic, versioned, and scalable for representative ecosystem graph sizes; output includes explainable feature attribution for each high-risk node.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:37:06.583954630Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:27.089505092Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-20","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-t89w","depends_on_id":"bd-2bj4","type":"blocks","created_at":"2026-02-20T07:43:20.667455238Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-t8m","title":"[PLAN 15] Ecosystem Capture Execution","description":"Section 15 network-effect epic. Deliver signed registry, migration kits, governance integrations, reputation APIs, and lighthouse partner programs with measurable adoption outcomes.\n\n## Success Criteria\n- All child beads for this section are completed with acceptance artifacts attached and no unresolved blockers.\n- Section-level verification gate for comprehensive unit tests, integration/e2e workflows, and detailed structured logging evidence is green.\n- Scope-to-plan traceability is explicit, with no feature loss versus the canonical plan section.\n\n## Optimization Notes\n- User-Outcome Lens: \"[PLAN 15] Ecosystem Capture Execution\" must improve real operator and end-user reliability, explainability, and time-to-safe-outcome under both normal and degraded conditions.\n- Cross-Section Coordination: this epic's child beads must explicitly encode integration expectations with neighboring sections to prevent local optimizations that break global behavior.\n- Verification Non-Negotiable: completion requires deterministic unit coverage, integration/E2E replay evidence, and structured logs sufficient for independent third-party reproduction and triage.\n- Scope Protection: any proposed simplification must prove feature parity against plan intent and document tradeoffs explicitly; silent scope reduction is forbidden.","status":"open","priority":2,"issue_type":"epic","created_at":"2026-02-20T07:36:42.330234889Z","created_by":"ubuntu","updated_at":"2026-02-20T08:12:48.927337939Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-15"],"dependencies":[{"issue_id":"bd-t8m","depends_on_id":"bd-1961","type":"blocks","created_at":"2026-02-20T07:39:36.482360876Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-t8m","depends_on_id":"bd-1wz","type":"blocks","created_at":"2026-02-20T07:38:36.397618539Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-t8m","depends_on_id":"bd-1xg","type":"blocks","created_at":"2026-02-20T07:38:36.248042346Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-t8m","depends_on_id":"bd-209w","type":"blocks","created_at":"2026-02-20T07:39:36.200965196Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-t8m","depends_on_id":"bd-20a","type":"blocks","created_at":"2026-02-20T07:38:36.292697204Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-t8m","depends_on_id":"bd-26k","type":"blocks","created_at":"2026-02-20T07:38:36.350043742Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-t8m","depends_on_id":"bd-2nre","type":"blocks","created_at":"2026-02-20T07:48:31.095630640Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-t8m","depends_on_id":"bd-31tg","type":"blocks","created_at":"2026-02-20T07:39:36.567295722Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-t8m","depends_on_id":"bd-37i","type":"blocks","created_at":"2026-02-20T07:38:36.530530822Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-t8m","depends_on_id":"bd-39a","type":"blocks","created_at":"2026-02-20T07:38:36.442302170Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-t8m","depends_on_id":"bd-3mj9","type":"blocks","created_at":"2026-02-20T07:39:36.396474277Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-t8m","depends_on_id":"bd-cv49","type":"blocks","created_at":"2026-02-20T07:39:36.738279711Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-t8m","depends_on_id":"bd-elog","type":"blocks","created_at":"2026-02-20T07:39:36.651492344Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-t8m","depends_on_id":"bd-sxt5","type":"blocks","created_at":"2026-02-20T08:02:26.401305399Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-t8m","depends_on_id":"bd-wpck","type":"blocks","created_at":"2026-02-20T07:39:36.286472098Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-t8m","depends_on_id":"bd-ybe","type":"blocks","created_at":"2026-02-20T07:38:36.486762626Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-tg2","title":"[10.8] Implement fleet control API for quarantine/revocation operations.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.8 — Operational Readiness (Item 1 of 6)\n\nWhy This Exists:\nThe fleet control API is the programmatic interface that turns engine-level quarantine/revocation primitives into operator-accessible operations. It is the backbone of the fleet quarantine UX (10.0 Initiative #6) and supports all operational incident response workflows.\n\nTask Objective:\nImplement the fleet control API that enables quarantine and revocation operations with zone/tenant scoping, convergence tracking, and rollback capabilities.\n\nDetailed Acceptance Criteria:\n1. API endpoints: quarantine(extension_id, scope), revoke(extension_id, scope), release(incident_id), status(zone), reconcile().\n2. Scope control: operations scoped to zones/tenants with blast-radius metadata.\n3. Convergence tracking: API reports propagation progress and estimated completion time.\n4. Rollback: release command deterministically rolls back quarantine state with verification.\n5. All operations produce signed decision receipts (10.5).\n6. Canonical structured observability + stable error taxonomy contracts adopted from 10.13.\n7. Deterministic safe-mode startup: fleet control API starts in read-only mode and requires explicit activation.\n8. Integration with incident bundle system (10.5) for post-incident evidence collection.\n\nKey Dependencies:\n- Depends on 10.N (Normalization) for canonical ownership rules.\n- Consumed by fleet quarantine UX (10.0 Initiative #6).\n- Consumed by operator copilot (10.0 Initiative #8).\n- Consumes 10.13 error taxonomy and observability contracts.\n\nExpected Artifacts:\n- src/fleet/ module with fleet_api.rs, quarantine.rs, revocation.rs, reconcile.rs.\n- API documentation and OpenAPI/contract spec.\n- docs/specs/section_10_8/bd-tg2_contract.md\n- artifacts/section_10_8/bd-tg2/verification_evidence.json\n\nTesting and Logging Requirements:\n- Unit tests: quarantine/revocation/release logic, scope validation, convergence computation.\n- Integration tests: multi-zone quarantine propagation and convergence.\n- E2E tests: franken-node fleet status/release/reconcile CLI commands.\n- Fault injection: API behavior during partial fleet connectivity.\n- Structured logs: FLEET_QUARANTINE_INITIATED, FLEET_REVOCATION_ISSUED, CONVERGENCE_PROGRESS, FLEET_RELEASED with zone/scope metadata and trace IDs.","acceptance_criteria":"1. Fleet control API exposes endpoints for: quarantine-node, revoke-node, list-quarantined, promote-from-quarantine, and bulk-quarantine operations.\n2. Quarantine propagation meets bounded convergence guarantee per Section 9A.6: all fleet members acknowledge quarantine within a defined time ceiling (documented in spec).\n3. Anti-entropy reconciliation: nodes that were offline during a quarantine event converge to correct state upon reconnection without operator intervention.\n4. API supports idempotent operations: repeated quarantine/revocation of the same node produces identical state.\n5. Per Section 3.2 capability #5: quarantine propagation is verified with a multi-node integration test simulating network partitions and delayed joins.\n6. API returns structured JSON responses with operation ID, affected nodes, convergence status, and timestamp.\n7. Authorization: quarantine/revocation operations require explicit operator credentials — no unauthenticated fleet mutations are possible.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:36:47.750223438Z","created_by":"ubuntu","updated_at":"2026-02-20T15:18:01.860580048Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-8","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-tg2","depends_on_id":"bd-1hf","type":"blocks","created_at":"2026-02-20T07:46:37.454276130Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-tg2","depends_on_id":"bd-1ta","type":"blocks","created_at":"2026-02-20T07:46:37.498530696Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-tg2","depends_on_id":"bd-20a","type":"blocks","created_at":"2026-02-20T07:46:37.545926983Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-tg2","depends_on_id":"bd-cda","type":"blocks","created_at":"2026-02-20T07:46:37.589692968Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-tyr2","title":"[10.15] Integrate canonical evidence replay validator (from `10.14`) into control-plane decision gates.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.15 — Asupersync-First Integration Execution Track (8.4-8.6)\n\nWhy This Exists:\nAsupersync-first control-plane migration track enforcing Cx-first, region ownership, cancellation correctness, and protocol-grade verification gates.\n\nTask Objective:\nIntegrate canonical evidence replay validator (from `10.14`) into control-plane decision gates.\n\nAcceptance Criteria:\n- Given evidence + inputs, canonical replay validator reproduces chosen decision or emits minimal deterministic diff; control-plane gate consumes verdict.\n\nExpected Artifacts:\n- `tests/conformance/control_evidence_replay.rs`, `docs/integration/control_evidence_replay_adoption.md`, `artifacts/10.15/control_evidence_replay_report.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_15/bd-tyr2/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_15/bd-tyr2/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.15] Integrate canonical evidence replay validator (from `10.14`) into control-plane decision gates.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.15] Integrate canonical evidence replay validator (from `10.14`) into control-plane decision gates.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.15] Integrate canonical evidence replay validator (from `10.14`) into control-plane decision gates.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.15] Integrate canonical evidence replay validator (from `10.14`) into control-plane decision gates.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.15] Integrate canonical evidence replay validator (from `10.14`) into control-plane decision gates.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- Given evidence + inputs, canonical replay validator reproduces chosen decision or emits minimal deterministic diff; control-plane gate consumes verdict.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:37:00.628849179Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:51.022674716Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-15","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-tyr2","depends_on_id":"bd-15j6","type":"blocks","created_at":"2026-02-20T07:43:17.049342010Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-tyr2","depends_on_id":"bd-2ona","type":"blocks","created_at":"2026-02-20T14:59:37.389157207Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-ufk5","title":"[10.18] Add performance budget gates for VEF overhead in p95/p99 control and extension-host hot paths.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.18 — Verifiable Execution Fabric Execution Track (9L)\n\nWhy This Exists:\nVEF track for proof-carrying runtime compliance: receipt chains, commitment checkpoints, proof generation/verification, and claim gating.\n\nTask Objective:\nAdd performance budget gates for VEF overhead in p95/p99 control and extension-host hot paths.\n\nAcceptance Criteria:\n- VEF overhead remains within agreed budgets by mode; regressions fail CI with reproducible profiling evidence.\n\nExpected Artifacts:\n- `tests/perf/vef_overhead_budget_gate.rs`, `benchmarks/vef_overhead/*`, `artifacts/10.18/vef_overhead_report.csv`.\n\n- Machine-readable verification artifact at `artifacts/section_10_18/bd-ufk5/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_18/bd-ufk5/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.18] Add performance budget gates for VEF overhead in p95/p99 control and extension-host hot paths.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.18] Add performance budget gates for VEF overhead in p95/p99 control and extension-host hot paths.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.18] Add performance budget gates for VEF overhead in p95/p99 control and extension-host hot paths.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.18] Add performance budget gates for VEF overhead in p95/p99 control and extension-host hot paths.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.18] Add performance budget gates for VEF overhead in p95/p99 control and extension-host hot paths.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- VEF overhead remains within agreed budgets by mode; regressions fail CI with reproducible profiling evidence.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:37:05.118324759Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:54.899716208Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-18","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-ufk5","depends_on_id":"bd-3ptu","type":"blocks","created_at":"2026-02-20T07:43:19.388511182Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-uh9","title":"Implement franken-node CLI scaffold aligned with README command families","description":"Introduce command surface skeleton (init/migrate/verify/trust/incident/fleet/doctor) to reduce README-implementation mismatch.","status":"closed","priority":1,"issue_type":"feature","created_at":"2026-02-20T07:26:05.511034353Z","created_by":"ubuntu","updated_at":"2026-02-20T07:26:56.719179182Z","closed_at":"2026-02-20T07:26:56.719155639Z","close_reason":"Duplicate scope; superseded by active CLI beads bd-2lb/bd-3vk","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-ukh7","title":"[10.19] Implement privacy envelope layer: secure aggregation + differential-privacy budget enforcement.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.19 — Adversarial Trust Commons Execution Track (9M)\n\nWhy This Exists:\nATC federated intelligence track for privacy-preserving cross-deployment threat learning, robust aggregation, and verifier-backed trust metrics.\n\nTask Objective:\nImplement privacy envelope layer: secure aggregation + differential-privacy budget enforcement.\n\nAcceptance Criteria:\n- Participant contributions are aggregated without exposing per-participant raw values; privacy budget accounting is deterministic and policy-gated.\n\nExpected Artifacts:\n- `docs/specs/atc_privacy_envelope.md`, `src/federation/atc_secure_aggregation.rs`, `artifacts/10.19/atc_privacy_budget_report.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_19/bd-ukh7/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_19/bd-ukh7/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.19] Implement privacy envelope layer: secure aggregation + differential-privacy budget enforcement.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.19] Implement privacy envelope layer: secure aggregation + differential-privacy budget enforcement.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.19] Implement privacy envelope layer: secure aggregation + differential-privacy budget enforcement.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.19] Implement privacy envelope layer: secure aggregation + differential-privacy budget enforcement.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.19] Implement privacy envelope layer: secure aggregation + differential-privacy budget enforcement.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- Participant contributions are aggregated without exposing per-participant raw values; privacy budget accounting is deterministic and policy-gated.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:37:05.585135739Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:27.315820210Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-19","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-ukh7","depends_on_id":"bd-1hj3","type":"blocks","created_at":"2026-02-20T07:43:19.619311561Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-unkm","title":"[16] Section-wide verification gate: comprehensive unit+e2e+logging","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 16\n\nTask Objective:\nCreate a hard section completion gate that verifies all implemented behavior in this section with comprehensive unit tests, integration/e2e scripts, and detailed structured logging evidence.\n\nAcceptance Criteria:\n- Section test matrix covers happy-path, edge-case, and adversarial/error-path scenarios for all section deliverables.\n- E2E scripts execute representative end-user workflows and policy/control-plane transitions for this section.\n- Structured logs include stable event/error codes, trace correlation IDs, and enough context for deterministic replay triage.\n- Verification report is deterministic and machine-readable for CI/release gating.\n\nExpected Artifacts:\n- Section-level test matrix and coverage summary artifact.\n- E2E script suite with pass/fail outputs and reproducible fixtures/seeds.\n- Structured log validation report and traceability bundle.\n- Gate verdict artifact consumable by release automation.\n\n- Machine-readable verification artifact at `artifacts/section_16/bd-unkm/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_16/bd-unkm/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests must validate contracts, invariants, and failure semantics.\n- E2E tests must validate cross-component behavior from user/operator entrypoints to persisted effects.\n- Logging must support root-cause analysis without hidden context requirements.\n\nTask-Specific Clarification:\n- For \"[16] Section-wide verification gate: comprehensive unit+e2e+logging\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[16] Section-wide verification gate: comprehensive unit+e2e+logging\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[16] Section-wide verification gate: comprehensive unit+e2e+logging\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[16] Section-wide verification gate: comprehensive unit+e2e+logging\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[16] Section-wide verification gate: comprehensive unit+e2e+logging\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"1. Section 16 verification gate runs all scientific-contribution check scripts and confirms 100% pass rate.\n2. Gate validates: (a) open specs are published and versioned, (b) datasets are published with DOIs, (c) methodology documents are peer-reviewed, (d) external evaluations are completed, (e) transparent reports are published, (f) output contracts (reports, replications, tools) are met.\n3. Publication completeness: >= 3 reproducible reports, >= 2 external replications, >= 2 red-team engagements, >= 1 dataset with DOI.\n4. Gate produces section_16_verification_summary.md with per-contribution status and publication checklist.\n5. Any contribution below target is flagged with gap analysis and remediation timeline.\n6. The gate itself has a unit test verifying correct aggregation of sub-check results.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:48:31.265005180Z","created_by":"ubuntu","updated_at":"2026-02-20T15:29:36.513392656Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-16","test-obligations","verification-gate"],"dependencies":[{"issue_id":"bd-unkm","depends_on_id":"bd-10ee","type":"blocks","created_at":"2026-02-20T07:48:31.511640251Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-unkm","depends_on_id":"bd-1dpd","type":"blocks","created_at":"2026-02-20T08:24:23.472704262Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-unkm","depends_on_id":"bd-1sgr","type":"blocks","created_at":"2026-02-20T07:48:31.462746243Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-unkm","depends_on_id":"bd-2ad0","type":"blocks","created_at":"2026-02-20T07:48:31.660003045Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-unkm","depends_on_id":"bd-2twu","type":"blocks","created_at":"2026-02-20T08:20:48.805444370Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-unkm","depends_on_id":"bd-33u2","type":"blocks","created_at":"2026-02-20T07:48:31.363597834Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-unkm","depends_on_id":"bd-3id1","type":"blocks","created_at":"2026-02-20T07:48:31.560227107Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-unkm","depends_on_id":"bd-e5cz","type":"blocks","created_at":"2026-02-20T07:48:31.413078314Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-unkm","depends_on_id":"bd-f955","type":"blocks","created_at":"2026-02-20T07:48:31.708143710Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-unkm","depends_on_id":"bd-nbh7","type":"blocks","created_at":"2026-02-20T07:48:31.611242326Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-uo4","title":"[10.0] Deliver dual-layer lockstep oracle program (L1 product + L2 engine boundary + release-policy linkage).","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.0 — Top 10 Initiative Tracking (Initiative #4)\nCross-references: 9A.4, 9B.4, 9C.4, 9D.4\n\nWhy This Exists:\nThe dual-layer lockstep oracle is the #4 strategic initiative. It provides externally verifiable compatibility and runtime-integrity guarantees by running Node, Bun, and franken_node in synchronized scenarios at two layers: L1 (product-visible behavior) and L2 (engine-boundary runtime semantics).\n\nTask Objective:\nDeliver the dual-layer lockstep oracle program: L1 runs Node/Bun/franken_node against shared fixture suites for externally visible behavior equivalence; L2 runs franken_engine boundary corpora against reference semantics for runtime-integrity guardrails. Both layers must have release-policy linkage so no release ships without green oracle status.\n\nDetailed Acceptance Criteria:\n1. L1 oracle: runs identical test scenarios across Node, Bun, and franken_node; captures and normalizes outputs; reports divergences with causal trace equivalence reports (9C.4).\n2. L2 oracle: runs franken_engine boundary corpora against reference semantics; validates runtime invariants.\n3. Release-policy linkage: release gates require both L1 and L2 green status.\n4. Oracle delivery close condition: dual-layer oracle is only complete when L1 (10.2) + L2 (10.17) + release policy linkage (10.2) are all green.\n5. Deterministic simulation and delta-debugging reductions to converge quickly on minimal divergence fixtures (9B.4).\n6. Deterministic replay envelopes for each divergence decision (9C.4).\n7. Streaming normalization and parallel fixture evaluation to reduce differential harness cost (9D.4).\n8. Coverage spans all compatibility bands (core/high-value/edge/unsafe) with per-band pass/fail reporting.\n\nKey Dependencies:\n- L1 oracle canonical ownership: 10.2 (Compatibility Core).\n- L2 oracle canonical ownership: 10.17 (Radical Expansion — engine-boundary N-version oracle).\n- Release policy linkage: 10.2 release gates.\n- Depends on 10.1 (Charter) for split-governance contract defining engine vs product boundaries.\n\nExpected Artifacts:\n- src/conformance/lockstep_oracle.rs — L1 oracle harness.\n- Integration with franken_engine for L2 boundary oracle.\n- Release gate configuration linking both layers.\n- docs/specs/section_10_0/bd-uo4_contract.md\n- artifacts/section_10_0/bd-uo4/verification_evidence.json\n\nTesting and Logging Requirements:\n- Unit tests: output normalization, divergence detection, delta-debugging reduction, release gate evaluation.\n- Integration tests: L1 three-runtime comparison on fixture suites, L2 engine boundary corpus validation.\n- E2E tests: franken-node verify lockstep CLI producing divergence reports with per-band breakdown.\n- Performance tests: parallel fixture evaluation throughput and memory profile.\n- Structured logs: LOCKSTEP_L1_RUN, LOCKSTEP_L2_RUN, DIVERGENCE_DETECTED, DELTA_DEBUG_REDUCED, RELEASE_GATE_EVALUATED with trace IDs.","acceptance_criteria":"1. L1 (product boundary) oracle tracks: franken-node release versions, feature flags, API surface changes, deprecation schedule; emits compatibility matrix per release.\n2. L2 (engine boundary) oracle tracks: underlying engine versions (V8/JavaScriptCore/SpiderMonkey), ABI changes, embedding API deltas; emits engine-compatibility matrix.\n3. Release-policy linkage: each release decision references both L1 and L2 oracle outputs; policy gate blocks release if oracle detects unresolved breaking change.\n4. Lockstep verification: oracle detects version skew between L1 product and L2 engine within 1 CI cycle; alerts with specific incompatibility details.\n5. Oracle state is deterministic and reproducible: given same input versions, produces identical compatibility assessment.\n6. Oracle outputs machine-readable compatibility report (JSON): { l1_version, l2_version, compatibility_status, breaking_changes[], policy_disposition, release_recommendation }.\n7. Historical oracle decisions are append-only and auditable; queryable by version range and date range.\n8. Integration with compatibility envelope (bd-1qp): oracle consumes envelope scores as input signal for release readiness.\n9. Dual-layer coverage: oracle covers 100% of catalogued API surface in both L1 and L2 dimensions (Section 3 replay coverage target).\n10. Verification evidence includes: oracle decision log for at least 3 simulated release scenarios, lockstep violation detection test, policy-gate enforcement test.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:36:42.723311996Z","created_by":"ubuntu","updated_at":"2026-02-20T15:35:47.145504542Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-0","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-uo4","depends_on_id":"bd-al8i","type":"blocks","created_at":"2026-02-20T15:01:25.079028856Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-uo4","depends_on_id":"bd-y4g","type":"blocks","created_at":"2026-02-20T07:43:10.224402686Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-v4l0","title":"[10.14] Enforce global remote bulkhead with configurable `remote_max_in_flight` and overload backpressure.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.14 — FrankenSQLite Deep-Mined Expansion Execution Track (9J)\n\nWhy This Exists:\nFrankenSQLite deep-mined control integrity track: evidence ledgers, proofs, epochs, remote effects, markers/MMR, and deterministic fault labs.\n\nTask Objective:\nEnforce global remote bulkhead with configurable `remote_max_in_flight` and overload backpressure.\n\nAcceptance Criteria:\n- In-flight remote operations never exceed cap; overload applies deterministic backpressure policy; p99 foreground latency remains within target under degradation.\n\nExpected Artifacts:\n- `src/remote/remote_bulkhead.rs`, `tests/perf/remote_bulkhead_under_load.rs`, `artifacts/10.14/remote_bulkhead_latency_report.csv`.\n\n- Machine-readable verification artifact at `artifacts/section_10_14/bd-v4l0/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_14/bd-v4l0/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.14] Enforce global remote bulkhead with configurable `remote_max_in_flight` and overload backpressure.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.14] Enforce global remote bulkhead with configurable `remote_max_in_flight` and overload backpressure.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.14] Enforce global remote bulkhead with configurable `remote_max_in_flight` and overload backpressure.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.14] Enforce global remote bulkhead with configurable `remote_max_in_flight` and overload backpressure.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.14] Enforce global remote bulkhead with configurable `remote_max_in_flight` and overload backpressure.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"In-flight remote operations never exceed cap; overload applies deterministic backpressure policy; p99 foreground latency remains within target under degradation.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:36:57.976072853Z","created_by":"ubuntu","updated_at":"2026-02-20T15:44:05.402173177Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-14","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-v4l0","depends_on_id":"bd-206h","type":"blocks","created_at":"2026-02-20T07:43:15.656186360Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-v4ps","title":"[12] Risk control: temporal concept drift","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 12\n\nTask Objective:\nImplement recalibration windows, cohort drift audits, and threshold-update regression gates.\n\nExecution Requirements:\n- Make this requirement machine-verifiable and release-gated where applicable.\n- Keep behavior self-documenting so future contributors do not need to re-open the master plan.\n\nTesting & Logging Requirements:\n- Unit tests for rule/contract logic and error conditions.\n- Integration/E2E tests for workflow-level enforcement.\n- Structured logs with stable codes and trace IDs.\n- Reproducible artifacts that prove contract satisfaction.\n\nAcceptance Criteria:\n- Success and failure invariants for [12] Risk control: temporal concept drift are explicitly quantified and machine-verifiable.\n- Determinism requirements for [12] Risk control: temporal concept drift are validated across repeated runs and adversarial perturbations.\n\n\nExpected Artifacts:\n- Machine-readable verification artifact with explicit canonical path under artifacts/section_12/bd-v4ps/verification_evidence.json, suitable for CI/release gating.\n- Human-readable verification summary with explicit canonical path under artifacts/section_12/bd-v4ps/verification_summary.md, linking implementation intent to measured validation outcomes.\n\nTask-Specific Clarification:\n- The implementation must deliver the exact capability named in the title, with no scope dilution and no silent feature omission.\n- Validation artifacts must include capability-specific thresholds, pass/fail criteria, and reproducible evidence bundles tied to this bead ID.\n- Program/section verification gates must be able to consume this bead's outputs without manual interpretation.\n\nWhy This Improves User Outcomes:\n- \"[12] Risk control: temporal concept drift\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[12] Risk control: temporal concept drift\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"RISK: Temporal concept drift — trust models, compatibility baselines, and threat profiles become stale as the ecosystem evolves.\nIMPACT: Outdated models make incorrect trust decisions, compatibility claims based on stale data, missed new threat patterns.\nCOUNTERMEASURES:\n  (a) Continuous recalibration: trust and compatibility models are retrained/revalidated on a defined cadence (at least monthly).\n  (b) Cohort-specific drift audits: performance metrics are broken down by time cohort; degradation in recent cohorts triggers recalibration.\n  (c) Staleness alerts: models older than their defined TTL trigger mandatory review.\nVERIFICATION:\n  1. Every model has a defined TTL (time-to-live) and last-calibration timestamp.\n  2. Models exceeding TTL are flagged; CI blocks deployment of decisions based on stale models.\n  3. Drift detection: accuracy on most-recent-30-day cohort vs all-time accuracy; if delta > 5%, recalibration is triggered.\n  4. Recalibration pipeline runs end-to-end in CI (on synthetic data) to verify it completes without errors.\nTEST SCENARIOS:\n  - Scenario A: Set a model TTL to 1 day; advance clock by 2 days; verify staleness alert fires and CI blocks deployment.\n  - Scenario B: Inject concept drift (change test distribution); verify drift detection catches accuracy degradation > 5%.\n  - Scenario C: Run recalibration pipeline; verify updated model has improved accuracy on recent cohort.\n  - Scenario D: Verify cohort breakdown: model accuracy reported separately for each monthly cohort.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:39:34.025097700Z","created_by":"ubuntu","updated_at":"2026-02-20T15:20:07.998850770Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-12","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-v4ps","depends_on_id":"bd-paui","type":"blocks","created_at":"2026-02-20T07:43:25.127813720Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-v97o","title":"[10.13] Implement authenticated control channel with per-direction sequence monotonicity and replay-window checks.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.13 — FCP Deep-Mined Expansion Execution Track (9I)\n\nWhy This Exists:\nDeep connector/provider contract track: lifecycle FSMs, conformance harnesses, fencing, sandboxing, revocation freshness, and protocol hardening.\n\nTask Objective:\nImplement authenticated control channel with per-direction sequence monotonicity and replay-window checks.\n\nAcceptance Criteria:\n- Channel rejects out-of-window and non-monotonic frames; per-direction sequence state survives restart safely; replay attack fixtures are blocked.\n\nExpected Artifacts:\n- `src/protocol/control_channel.rs`, `tests/security/control_channel_replay_window.rs`, `artifacts/10.13/control_channel_security_trace.jsonl`.\n\n- Machine-readable verification artifact at `artifacts/section_10_13/bd-v97o/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_13/bd-v97o/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.13] Implement authenticated control channel with per-direction sequence monotonicity and replay-window checks.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.13] Implement authenticated control channel with per-direction sequence monotonicity and replay-window checks.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.13] Implement authenticated control channel with per-direction sequence monotonicity and replay-window checks.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.13] Implement authenticated control channel with per-direction sequence monotonicity and replay-window checks.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.13] Implement authenticated control channel with per-direction sequence monotonicity and replay-window checks.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","status":"closed","priority":1,"issue_type":"task","assignee":"CrimsonCrane","created_at":"2026-02-20T07:36:54.416231153Z","created_by":"ubuntu","updated_at":"2026-02-20T13:05:56.544150103Z","closed_at":"2026-02-20T13:05:56.544126589Z","close_reason":"done","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-13","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-v97o","depends_on_id":"bd-12h8","type":"blocks","created_at":"2026-02-20T07:43:13.812042961Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-vjq","title":"[10.1] Add explicit product charter document aligned to `/dp/franken_engine/PLAN_TO_CREATE_FRANKEN_ENGINE.md`.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.1 — Charter + Split Governance\n\nWhy This Exists:\nProgram charter and governance baseline: split contracts, reproducibility, and anti-regression rules for strategic integrity.\n\nTask Objective:\nRatify and harden the bootstrap charter output from `bd-2nd` into the canonical 10.1 product charter artifact aligned with `/dp/franken_engine/PLAN_TO_CREATE_FRANKEN_ENGINE.md` and section-level governance controls.\n\nScope Clarification:\n- `bd-2nd` creates the initial explicit charter document for immediate operational alignment.\n- This bead finalizes/ratifies that document as the canonical, policy-enforced 10.1 contract to avoid duplicate charter divergence.\n\nAcceptance Criteria:\n- Canonical charter supersedes bootstrap draft with explicit governance ownership, decision rights, and escalation contracts.\n- Split-boundary language is consistent with engine/product ownership and no duplicate-implementation policy.\n- Ratified charter is linked into CI/policy references used by dependent governance checks.\n\nExpected Artifacts:\n- Canonical charter document revision with ratification change log.\n- Governance cross-reference matrix showing alignment to related 10.1 controls.\n- Machine-readable evidence artifact proving dependent checks reference canonical charter.\n\n- Machine-readable verification artifact at `artifacts/section_10_1/bd-vjq/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_1/bd-vjq/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit-style validation for charter schema/template completeness (if automated).\n- E2E doc-navigation validation from README -> charter -> split-governance references.\n- Structured logs/validation outputs with stable finding categories and trace IDs.\n\nTask-Specific Clarification:\n- For \"[10.1] Add explicit product charter document aligned to `/dp/franken_engine/PLAN_TO_CREATE_FRANKEN_ENGINE.md`.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.1] Add explicit product charter document aligned to `/dp/franken_engine/PLAN_TO_CREATE_FRANKEN_ENGINE.md`.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.1] Add explicit product charter document aligned to `/dp/franken_engine/PLAN_TO_CREATE_FRANKEN_ENGINE.md`.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.1] Add explicit product charter document aligned to `/dp/franken_engine/PLAN_TO_CREATE_FRANKEN_ENGINE.md`.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.1] Add explicit product charter document aligned to `/dp/franken_engine/PLAN_TO_CREATE_FRANKEN_ENGINE.md`.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","status":"closed","priority":1,"issue_type":"task","assignee":"CrimsonCrane","created_at":"2026-02-20T07:36:43.289046058Z","created_by":"ubuntu","updated_at":"2026-02-20T09:03:58.249864497Z","closed_at":"2026-02-20T09:03:58.249824643Z","close_reason":"Charter ratified as v1.1 canonical 10.1 artifact. Engine plan alignment verified across 10 dimensions. Governance cross-reference matrix added with 4 CI/enforcement points. All 6/6 verification checks pass.","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-1","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-vjq","depends_on_id":"bd-2nd","type":"blocks","created_at":"2026-02-20T08:03:10.014293129Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-vjq","depends_on_id":"bd-cda","type":"blocks","created_at":"2026-02-20T07:46:30.960158137Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-vll","title":"[10.5] Implement deterministic incident replay bundle generation.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.5 — Security + Policy Product Surfaces (Item 3 of 8)\n\nWhy This Exists:\nDeterministic incident replay is a core safety guarantee. When a security incident occurs, the system must be able to produce a self-contained bundle that captures all relevant state, decisions, and effects — and replay them deterministically to verify what happened and enable counterfactual analysis.\n\nTask Objective:\nImplement deterministic incident replay bundle generation that captures full incident context and enables exact replay of decision sequences.\n\nDetailed Acceptance Criteria:\n1. Incident bundle captures: triggering event, evidence ledger entries, policy state at decision time, actions taken (with decision receipts), affected artifacts/extensions, timeline.\n2. Bundle is deterministic: given identical inputs, produces bit-identical bundle.\n3. Bundle is self-contained: includes all data needed for replay without external dependencies.\n4. Replay harness can re-execute the decision sequence and verify identical outcomes.\n5. Bundle format supports versioning (v1 per config.rs replay.bundle_version).\n6. Bundle integrity verified with cryptographic signatures.\n7. CLI surface: franken-node incident bundle {incident_id} produces the bundle; franken-node incident replay {bundle_path} replays it.\n\nKey Dependencies:\n- Depends on 10.14 (FrankenSQLite Deep-Mined) for evidence ledger and replay validator.\n- Consumed by 10.5 counterfactual replay mode.\n- Consumed by 10.8 (Operational Readiness) for incident bundle retention policy.\n- Consumed by 13 (Success Criteria) for 100% replay artifact coverage target.\n\nExpected Artifacts:\n- src/replay/ module with bundle_generator.rs, replay_harness.rs, bundle_format.rs.\n- CLI integration for incident bundle/replay commands.\n- docs/specs/section_10_5/bd-vll_contract.md\n- artifacts/section_10_5/bd-vll/verification_evidence.json\n\nTesting and Logging Requirements:\n- Unit tests: bundle generation determinism, self-containment verification, signature integrity, version compatibility.\n- Integration tests: incident -> bundle generation -> replay -> outcome verification pipeline.\n- E2E tests: full CLI workflow incident bundle -> incident replay producing matching results.\n- Determinism tests: multiple bundle generations from same incident produce identical outputs.\n- Structured logs: BUNDLE_GENERATED, BUNDLE_SIGNED, REPLAY_STARTED, REPLAY_VERIFIED, DETERMINISM_CHECK_PASSED with trace IDs and bundle version.","acceptance_criteria":"1. Define a ReplayBundle struct containing: bundle_id (UUID v7), incident_id (string), created_at (RFC-3339), timeline (Vec<TimelineEvent>), initial_state_snapshot (serialized system state), policy_version (semver), and integrity_hash (SHA-256 over canonical serialization of all preceding fields).\n2. Each TimelineEvent includes: sequence_number (u64, monotonic), timestamp (RFC-3339, microsecond precision), event_type (enum: StateChange | PolicyEval | ExternalSignal | OperatorAction), payload (serde_json::Value), and causal_parent (Option<u64> referencing a prior sequence_number).\n3. Bundle generation must be deterministic: given the same incident log inputs, two independent calls produce byte-identical bundles (canonical JSON, sorted keys, no floating-point ambiguity).\n4. Implement generate_replay_bundle(incident_id: &str, event_log: &[RawEvent]) -> Result<ReplayBundle> that filters, orders, and packages events.\n5. Bundle size must include a manifest listing event count, time span, and compressed size; bundles over 10 MB must be split into numbered chunks with a shared bundle_id and chunk index.\n6. Provide validate_bundle_integrity(bundle: &ReplayBundle) -> Result<bool> that recomputes and checks the integrity_hash.\n7. Verification: scripts/check_replay_bundle.py --json generates a sample bundle from fixture data in fixtures/interop/, validates integrity, and checks determinism by generating twice and comparing; unit tests in tests/test_check_replay_bundle.py; evidence in artifacts/section_10_5/bd-vll/.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:36:46.218994247Z","created_by":"ubuntu","updated_at":"2026-02-20T16:06:06.896959246Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-5","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-vll","depends_on_id":"bd-21z","type":"blocks","created_at":"2026-02-20T07:43:22.834533549Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-w0jq","title":"[10.13] Emit explicit degraded-mode audit events whenever stale revocation frontier overrides are used.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.13 — FCP Deep-Mined Expansion Execution Track (9I)\n\nWhy This Exists:\nDeep connector/provider contract track: lifecycle FSMs, conformance harnesses, fencing, sandboxing, revocation freshness, and protocol hardening.\n\nTask Objective:\nEmit explicit degraded-mode audit events whenever stale revocation frontier overrides are used.\n\nAcceptance Criteria:\n- Every degraded-mode override emits required audit schema fields; missing event is a hard failure in conformance tests; events correlate to action IDs.\n\nExpected Artifacts:\n- `tests/conformance/degraded_mode_audit_events.rs`, `docs/specs/degraded_mode_audit_schema.md`, `artifacts/10.13/degraded_mode_events.jsonl`.\n\n- Machine-readable verification artifact at `artifacts/section_10_13/bd-w0jq/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_13/bd-w0jq/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.13] Emit explicit degraded-mode audit events whenever stale revocation frontier overrides are used.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.13] Emit explicit degraded-mode audit events whenever stale revocation frontier overrides are used.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.13] Emit explicit degraded-mode audit events whenever stale revocation frontier overrides are used.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.13] Emit explicit degraded-mode audit events whenever stale revocation frontier overrides are used.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.13] Emit explicit degraded-mode audit events whenever stale revocation frontier overrides are used.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","status":"closed","priority":1,"issue_type":"task","assignee":"CrimsonCrane","created_at":"2026-02-20T07:36:53.194210248Z","created_by":"ubuntu","updated_at":"2026-02-20T12:07:54.663148458Z","closed_at":"2026-02-20T12:07:54.663123642Z","close_reason":"done","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-13","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-w0jq","depends_on_id":"bd-1m8r","type":"blocks","created_at":"2026-02-20T07:43:13.184802996Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-whxp","title":"[13] Concrete target gate: >=2 independent replications","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 13\n\nTask Objective:\nBuild KPI gate for at least two independent external reproductions of headline claims.\n\nExecution Requirements:\n- Make this requirement machine-verifiable and release-gated where applicable.\n- Keep behavior self-documenting so future contributors do not need to re-open the master plan.\n\nTesting & Logging Requirements:\n- Unit tests for rule/contract logic and error conditions.\n- Integration/E2E tests for workflow-level enforcement.\n- Structured logs with stable codes and trace IDs.\n- Reproducible artifacts that prove contract satisfaction.\n\nAcceptance Criteria:\n- Success and failure invariants for [13] Concrete target gate: >=2 independent replications are explicitly quantified and machine-verifiable.\n- Determinism requirements for [13] Concrete target gate: >=2 independent replications are validated across repeated runs and adversarial perturbations.\n\n\nExpected Artifacts:\n- Machine-readable verification artifact with explicit canonical path under artifacts/section_13/bd-whxp/verification_evidence.json, suitable for CI/release gating.\n- Human-readable verification summary with explicit canonical path under artifacts/section_13/bd-whxp/verification_summary.md, linking implementation intent to measured validation outcomes.\n\nTask-Specific Clarification:\n- The implementation must deliver the exact capability named in the title, with no scope dilution and no silent feature omission.\n- Validation artifacts must include capability-specific thresholds, pass/fail criteria, and reproducible evidence bundles tied to this bead ID.\n- Program/section verification gates must be able to consume this bead's outputs without manual interpretation.\n\nWhy This Improves User Outcomes:\n- \"[13] Concrete target gate: >=2 independent replications\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[13] Concrete target gate: >=2 independent replications\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"1. At least 2 independent external parties (universities, security firms, or open-source organizations) have reproduced key claims.\n2. Reproduced claims must include at least: (a) one compatibility claim (corpus pass rate), (b) one security claim (compromise reduction), (c) one performance claim (latency/throughput under hardening).\n3. Each reproduction is documented with: reproducer identity, date, methodology, results, and delta from original claims.\n4. Reproduction results are within 10% of original claims (allowing for environment differences).\n5. Reproduction reports are published alongside project documentation.\n6. Reproduction kit (instructions, data, scripts) is available in the public repository.\n7. Evidence artifact: replication_registry.json listing each replication with party, claim, result, and date.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:39:35.213287458Z","created_by":"ubuntu","updated_at":"2026-02-20T15:22:03.385726778Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-13","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-whxp","depends_on_id":"bd-2l1k","type":"blocks","created_at":"2026-02-20T07:43:25.707874868Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-wpck","title":"[15] Pillar: migration kit ecosystem","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 15\n\nTask Objective:\nBuild migration kit ecosystem for major Node/Bun archetypes.\n\nExecution Requirements:\n- Make this requirement machine-verifiable and release-gated where applicable.\n- Keep behavior self-documenting so future contributors do not need to re-open the master plan.\n\nTesting & Logging Requirements:\n- Unit tests for rule/contract logic and error conditions.\n- Integration/E2E tests for workflow-level enforcement.\n- Structured logs with stable codes and trace IDs.\n- Reproducible artifacts that prove contract satisfaction.\n\nAcceptance Criteria:\n- Success and failure invariants for [15] Pillar: migration kit ecosystem are explicitly quantified and machine-verifiable.\n- Determinism requirements for [15] Pillar: migration kit ecosystem are validated across repeated runs and adversarial perturbations.\n\n\nExpected Artifacts:\n- Machine-readable verification artifact with explicit canonical path under artifacts/section_15/bd-wpck/verification_evidence.json, suitable for CI/release gating.\n- Human-readable verification summary with explicit canonical path under artifacts/section_15/bd-wpck/verification_summary.md, linking implementation intent to measured validation outcomes.\n\nTask-Specific Clarification:\n- The implementation must deliver the exact capability named in the title, with no scope dilution and no silent feature omission.\n- Validation artifacts must include capability-specific thresholds, pass/fail criteria, and reproducible evidence bundles tied to this bead ID.\n- Program/section verification gates must be able to consume this bead's outputs without manual interpretation.\n\nWhy This Improves User Outcomes:\n- \"[15] Pillar: migration kit ecosystem\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[15] Pillar: migration kit ecosystem\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"1. Migration kits exist for >= 5 major Node.js/Bun archetypes: (a) Express.js/Fastify web server, (b) Next.js/Remix SSR app, (c) CLI tool (Commander/Yargs), (d) npm library package, (e) background worker (Bull/BullMQ queue processor).\n2. Each kit includes: (a) automated analyzer that scores migration readiness, (b) migration script that handles >= 80% of steps automatically, (c) manual intervention guide for remaining steps, (d) post-migration validation suite, (e) rollback script.\n3. Kits are published as npm packages installable via 'npx franken-migrate --kit <archetype>'.\n4. Each kit has been validated on >= 3 real-world projects of its archetype (documented in test matrix).\n5. Kit documentation includes: estimated migration time, known limitations, and compatibility exceptions.\n6. Bun-specific kits exist for >= 2 archetypes with documented Bun-specific compatibility delta.\n7. Evidence: migration_kit_matrix.json with per-archetype kit status, validated projects, and success rates.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:39:36.246627380Z","created_by":"ubuntu","updated_at":"2026-02-20T15:26:11.404944424Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-15","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-wpck","depends_on_id":"bd-209w","type":"blocks","created_at":"2026-02-20T07:43:26.255430105Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-wzjl","title":"[14] Include security and trust co-metrics","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 14\n\nTask Objective:\nExpand benchmark suite beyond speed-only metrics to include security and operational trust dimensions.\n\nExecution Requirements:\n- Make this requirement machine-verifiable and release-gated where applicable.\n- Keep behavior self-documenting so future contributors do not need to re-open the master plan.\n\nTesting & Logging Requirements:\n- Unit tests for rule/contract logic and error conditions.\n- Integration/E2E tests for workflow-level enforcement.\n- Structured logs with stable codes and trace IDs.\n- Reproducible artifacts that prove contract satisfaction.\n\nAcceptance Criteria:\n- Success and failure invariants for [14] Include security and trust co-metrics are explicitly quantified and machine-verifiable.\n- Determinism requirements for [14] Include security and trust co-metrics are validated across repeated runs and adversarial perturbations.\n\n\nExpected Artifacts:\n- Machine-readable verification artifact with explicit canonical path under artifacts/section_14/bd-wzjl/verification_evidence.json, suitable for CI/release gating.\n- Human-readable verification summary with explicit canonical path under artifacts/section_14/bd-wzjl/verification_summary.md, linking implementation intent to measured validation outcomes.\n\nTask-Specific Clarification:\n- The implementation must deliver the exact capability named in the title, with no scope dilution and no silent feature omission.\n- Validation artifacts must include capability-specific thresholds, pass/fail criteria, and reproducible evidence bundles tied to this bead ID.\n- Program/section verification gates must be able to consume this bead's outputs without manual interpretation.\n\nWhy This Improves User Outcomes:\n- \"[14] Include security and trust co-metrics\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[14] Include security and trust co-metrics\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"1. Benchmark suite includes security co-metrics alongside performance metrics: (a) attack surface area (number of exposed APIs under test profile), (b) containment latency under attack, (c) trust decision accuracy under adversarial load.\n2. Trust co-metrics include: (a) false positive rate of trust decisions, (b) false negative rate (malicious extensions passing trust checks), (c) trust decision latency p50/p95/p99.\n3. Security and trust metrics are reported in the same benchmark output as performance metrics (unified report).\n4. Co-metric baselines are established: each security/trust metric has a defined acceptable range.\n5. Trade-off analysis: report explicitly shows performance vs security trade-offs (e.g., 'strict profile: +20ms p99 latency, -90% attack surface').\n6. Co-metrics are measured under at least 2 hardening profiles (balanced, strict).\n7. Evidence: security_trust_cometrics.json with per-profile metric values and trade-off summary.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:39:35.385320210Z","created_by":"ubuntu","updated_at":"2026-02-20T15:23:52.906712131Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-14","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-wzjl","depends_on_id":"bd-3h1g","type":"blocks","created_at":"2026-02-20T07:43:25.805877406Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-xwk5","title":"[10.14] Implement fork/divergence detection via marker-id prefix comparison and binary search.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.14 — FrankenSQLite Deep-Mined Expansion Execution Track (9J)\n\nWhy This Exists:\nFrankenSQLite deep-mined control integrity track: evidence ledgers, proofs, epochs, remote effects, markers/MMR, and deterministic fault labs.\n\nTask Objective:\nImplement fork/divergence detection via marker-id prefix comparison and binary search.\n\nAcceptance Criteria:\n- Divergence finder returns greatest common prefix deterministically; fork detection scales logarithmically; mismatch evidence includes exact divergence point.\n\nExpected Artifacts:\n- `tests/integration/marker_divergence_detection.rs`, `docs/specs/divergence_detection.md`, `artifacts/10.14/divergence_detection_examples.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_14/bd-xwk5/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_14/bd-xwk5/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.14] Implement fork/divergence detection via marker-id prefix comparison and binary search.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.14] Implement fork/divergence detection via marker-id prefix comparison and binary search.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.14] Implement fork/divergence detection via marker-id prefix comparison and binary search.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.14] Implement fork/divergence detection via marker-id prefix comparison and binary search.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.14] Implement fork/divergence detection via marker-id prefix comparison and binary search.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"Divergence finder returns greatest common prefix deterministically; fork detection scales logarithmically; mismatch evidence includes exact divergence point.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:36:58.710125669Z","created_by":"ubuntu","updated_at":"2026-02-20T15:44:03.483608385Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-14","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-xwk5","depends_on_id":"bd-129f","type":"blocks","created_at":"2026-02-20T07:43:16.061741464Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-y0v","title":"[10.12] Implement operator intelligence recommendation engine with rollback proofs.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.12 — Frontier Programs Execution Track (9H)\n\nWhy This Exists:\nFrontier program execution turning migration singularity, trust fabric, verifier economy, and operator intelligence into production flow.\n\nTask Objective:\nImplement operator intelligence recommendation engine with rollback proofs.\n\nAcceptance Criteria:\n- Implement with explicit success/failure invariants and deterministic behavior under normal, edge, and fault scenarios.\n- Ensure outcomes are verifiable via automated tests and reproducible artifact outputs.\n\nExpected Artifacts:\n- Section-owned design/spec artifact at `docs/specs/section_10_12/bd-y0v_contract.md`, capturing decision rationale, invariants, and interface boundaries.\n- Machine-readable verification artifact at `artifacts/section_10_12/bd-y0v/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_12/bd-y0v/verification_summary.md` linking implementation intent to measured outcomes.\n\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.12] Implement operator intelligence recommendation engine with rollback proofs.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.12] Implement operator intelligence recommendation engine with rollback proofs.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.12] Implement operator intelligence recommendation engine with rollback proofs.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.12] Implement operator intelligence recommendation engine with rollback proofs.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.12] Implement operator intelligence recommendation engine with rollback proofs.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"1. Define a Recommendation struct: (a) recommendation_id (unique), (b) action (enum: MIGRATE, ROLLBACK, UPGRADE, HOLD, DECOMMISSION), (c) target (system/component identifier), (d) confidence_score (f64 in [0.0, 1.0]), (e) expected_loss (f64, estimated cost/impact if the recommendation is wrong), (f) expected_gain (f64, estimated benefit if the recommendation succeeds), (g) evidence (list of {factor_name, weight, value} contributing to the score), (h) rollback_proof (Option<RollbackReceipt> from bd-3hm, required for MIGRATE and UPGRADE actions).\n2. Implement a RecommendationEngine with: (a) evaluate(target, context) -> Recommendation that computes a recommendation based on system state, historical outcomes, and policy constraints, (b) explain(recommendation_id) -> ExplanationReport that produces a human-readable breakdown of the scoring factors.\n3. Enforce rollback-proof requirement: recommendations for MIGRATE or UPGRADE actions MUST include a valid rollback_proof. The engine MUST NOT emit a recommendation without one. Return MissingRollbackProof error if rollback receipt generation fails.\n4. Implement expected-loss-aware ranking: when multiple recommendations are possible, rank by expected_gain - expected_loss (net expected value). Expose the ranking function for testing.\n5. Implement a confidence threshold gate: recommendations with confidence_score < configurable minimum (default 0.6) are emitted with a LOW_CONFIDENCE flag and MUST NOT be auto-executed. They require explicit operator approval.\n6. Implement recommendation audit trail: every recommendation emitted is logged as a structured event with all Recommendation fields plus the operator action taken (ACCEPTED, REJECTED, DEFERRED) and the actual outcome (SUCCESS, FAILURE, PENDING).\n7. Implement outcome feedback loop: after a recommendation is executed, record the actual outcome. Provide a function update_model(recommendation_id, actual_outcome) that adjusts future scoring (at minimum, track hit/miss ratio per action type).\n8. Unit tests: (a) MIGRATE recommendation includes rollback proof, (b) missing rollback proof error, (c) net expected value ranking, (d) low confidence flag, (e) explanation report contains all factors, (f) audit trail logging, (g) outcome feedback updates hit ratio.\n9. Verification: scripts/check_recommendation_engine.py --json, artifacts at artifacts/section_10_12/bd-y0v/.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:36:51.154948985Z","created_by":"ubuntu","updated_at":"2026-02-20T15:40:31.709507627Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-12","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-y0v","depends_on_id":"bd-3c2","type":"blocks","created_at":"2026-02-20T07:43:12.097316347Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-y4g","title":"[10.0] Implement trust cards for extensions and publishers.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.0 — Top 10 Initiative Tracking (Initiative #3)\nCross-references: 9A.3, 9B.3, 9C.3, 9D.3\n\nWhy This Exists:\nTrust cards are the #3 strategic initiative. They surface provenance, behavioral telemetry, revocation status, and policy constraints in a single explainable trust model consumable by both humans and automation. Trust cards are the primary interface through which operators and tools understand the trustworthiness of extensions and publishers.\n\nTask Objective:\nImplement the trust card system for extensions and publishers — a structured, queryable trust profile that aggregates provenance data, behavioral evidence, revocation status, policy constraints, and reputation signals into an explainable, API-accessible trust assessment.\n\nDetailed Acceptance Criteria:\n1. Trust card schema captures: provenance attestations, behavioral telemetry summary, revocation status, policy constraint set, certification level, publisher reputation score, and risk tier.\n2. CLI surface: franken-node trust card {extension_id} displays full trust card in human-readable format.\n3. API surface: programmatic trust-card query returns structured JSON suitable for automation.\n4. Trust deltas decomposed into posterior components with counterfactual action impacts exposed (9C.3).\n5. Authenticated data structures and transparency-style append-only proofs for trust evidence lineage (9B.3).\n6. Trust-card materialization optimized with incremental updates and bounded recomputation (9D.3).\n7. Trust card integrates with extension certification levels (10.4), policy controls (10.5), and fleet quarantine (10.8).\n8. Publisher trust cards aggregate across all published extensions with explainable reputation transitions.\n\nKey Dependencies:\n- Depends on 10.4 (Extension Ecosystem) for manifest schema and provenance attestation.\n- Consumed by 10.5 (Security) for policy-visible trust decisions.\n- Consumed by 10.17 (Radical Expansion) for Bayesian adversary graph integration.\n- Consumed by 10.21 (BPET) for behavioral phenotype evidence.\n\nExpected Artifacts:\n- src/security/trust_card.rs — trust card schema, builder, query API.\n- src/security/trust_card_publisher.rs — publisher-level aggregation.\n- CLI integration in cli.rs for trust card/list/revoke commands.\n- docs/specs/section_10_0/bd-y4g_contract.md\n- artifacts/section_10_0/bd-y4g/verification_evidence.json\n\nTesting and Logging Requirements:\n- Unit tests: trust card construction, field validation, incremental update correctness, posterior decomposition.\n- Integration tests: trust card generation from mock extension manifests + behavioral data + revocation feeds.\n- E2E tests: franken-node trust card {extension_id} CLI workflow producing correct output.\n- Adversarial tests: malformed provenance data, stale revocation, conflicting signals.\n- Structured logs: TRUST_CARD_MATERIALIZED, TRUST_CARD_QUERIED, TRUST_DELTA_COMPUTED, REPUTATION_UPDATED with trace IDs.","acceptance_criteria":"1. Trust card schema includes: publisher identity, provenance chain (build source -> artifact), behavioral telemetry summary, revocation status, policy constraint set, trust score, last-audit timestamp.\n2. Provenance chain is cryptographically verifiable: each link signed, tamper-evident, traceable to source commit.\n3. Behavioral telemetry captures: permission usage (fs/net/child_process), resource consumption bounds, anomaly flags; updated on each publish cycle.\n4. Revocation status propagates within <= 60 seconds to all connected fleet nodes (real-time revocation channel).\n5. Policy constraints expressed as declarative rules (e.g., \"no net access\", \"fs read-only /app/**\"); enforced at runtime with deny-by-default semantics.\n6. Trust model is explainable: CLI command (`franken-node trust explain <extension>`) outputs human-readable rationale for current trust score decomposition.\n7. Compromise reduction target: trust card system contributes to >= 10x compromise reduction (Section 3) by blocking extensions that fail provenance or behavioral checks.\n8. Trust cards queryable via API and CLI in JSON format; support filtering by publisher, score range, revocation status.\n9. Integration with secure extension distribution network (bd-2ac): trust card is mandatory for registry publish; missing card blocks distribution.\n10. Verification evidence includes: sample trust cards for test extensions, revocation propagation latency measurement, policy constraint enforcement test results.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:36:42.642636403Z","created_by":"ubuntu","updated_at":"2026-02-20T16:06:11.059508909Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-0","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-y4g","depends_on_id":"bd-2de","type":"blocks","created_at":"2026-02-20T07:43:10.181037921Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-y7lu","title":"[10.13] Implement revocation registry with monotonic revocation-head checkpoints.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.13 — FCP Deep-Mined Expansion Execution Track (9I)\n\nWhy This Exists:\nDeep connector/provider contract track: lifecycle FSMs, conformance harnesses, fencing, sandboxing, revocation freshness, and protocol hardening.\n\nTask Objective:\nImplement revocation registry with monotonic revocation-head checkpoints.\n\nAcceptance Criteria:\n- Revocation heads are monotonic per zone/tenant; stale head updates are rejected; head state is recoverable from canonical storage.\n\nExpected Artifacts:\n- `docs/specs/revocation_registry.md`, `tests/conformance/revocation_head_monotonicity.rs`, `artifacts/10.13/revocation_head_history.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_13/bd-y7lu/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_13/bd-y7lu/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.13] Implement revocation registry with monotonic revocation-head checkpoints.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.13] Implement revocation registry with monotonic revocation-head checkpoints.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.13] Implement revocation registry with monotonic revocation-head checkpoints.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.13] Implement revocation registry with monotonic revocation-head checkpoints.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.13] Implement revocation registry with monotonic revocation-head checkpoints.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","status":"closed","priority":1,"issue_type":"task","assignee":"CrimsonCrane","created_at":"2026-02-20T07:36:53.031084487Z","created_by":"ubuntu","updated_at":"2026-02-20T12:00:29.376707201Z","closed_at":"2026-02-20T12:00:29.376681092Z","close_reason":"done","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-13","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-y7lu","depends_on_id":"bd-2yc4","type":"blocks","created_at":"2026-02-20T07:43:13.096265779Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-ybe","title":"[PLAN 10.20] Dependency Graph Immune System Execution Track (9N)","description":"Section: 10.20 — Dependency Graph Immune System Execution Track (9N)\n\nStrategic Context:\nDGIS topological immune system track for dependency contagion modeling, choke-point immunization, and graph-aware containment economics.\n\nExecution Requirements:\n- Preserve all scoped capabilities from the canonical plan.\n- Keep contracts self-contained so future contributors can execute without reopening the master plan.\n- Require explicit testing strategy (unit + integration/e2e) and structured logging/telemetry for every child bead.\n- Require artifact-backed validation for performance, security, and correctness claims.\n\nDependency Semantics:\n- This epic is blocked by its child implementation beads.\n- Cross-epic dependencies encode strategic sequencing and canonical ownership boundaries.\n\n## Success Criteria\n- All child beads for this section are completed with acceptance artifacts attached and no unresolved blockers.\n- Section-level verification gate for comprehensive unit tests, integration/e2e workflows, and detailed structured logging evidence is green.\n- Scope-to-plan traceability is explicit, with no feature loss versus the canonical plan section.\n\n## Optimization Notes\n- User-Outcome Lens: \"[PLAN 10.20] Dependency Graph Immune System Execution Track (9N)\" must improve operator confidence, safety posture, and deterministic recovery behavior under both normal and adversarial conditions.\n- Cross-Section Coordination: child beads must encode integration assumptions explicitly to avoid local optimizations that degrade system-wide correctness.\n- Verification Non-Negotiable: completion requires reproducible unit/integration/E2E evidence and structured logs suitable for independent replay.\n- Scope Protection: any simplification must preserve canonical-plan feature intent and be justified with explicit tradeoff documentation.","status":"open","priority":2,"issue_type":"epic","created_at":"2026-02-20T07:36:41.868695628Z","created_by":"ubuntu","updated_at":"2026-02-20T08:16:44.582810918Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-20"],"dependencies":[{"issue_id":"bd-ybe","depends_on_id":"bd-19k2","type":"blocks","created_at":"2026-02-20T07:37:07.314030839Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-ybe","depends_on_id":"bd-1f8v","type":"blocks","created_at":"2026-02-20T07:37:07.399259833Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-ybe","depends_on_id":"bd-1q38","type":"blocks","created_at":"2026-02-20T07:37:06.786535764Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-ybe","depends_on_id":"bd-1tnu","type":"blocks","created_at":"2026-02-20T07:37:06.952108563Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-ybe","depends_on_id":"bd-1wz","type":"blocks","created_at":"2026-02-20T07:37:11.674423749Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-ybe","depends_on_id":"bd-2bj4","type":"blocks","created_at":"2026-02-20T07:37:06.539505946Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-ybe","depends_on_id":"bd-2d17","type":"blocks","created_at":"2026-02-20T07:37:07.482271307Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-ybe","depends_on_id":"bd-2fid","type":"blocks","created_at":"2026-02-20T07:37:06.870182601Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-ybe","depends_on_id":"bd-2jns","type":"blocks","created_at":"2026-02-20T07:37:06.704903769Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-ybe","depends_on_id":"bd-2wod","type":"blocks","created_at":"2026-02-20T07:37:07.116148597Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-ybe","depends_on_id":"bd-351r","type":"blocks","created_at":"2026-02-20T07:37:07.199226465Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-ybe","depends_on_id":"bd-38yt","type":"blocks","created_at":"2026-02-20T07:37:07.647037444Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-ybe","depends_on_id":"bd-39a","type":"blocks","created_at":"2026-02-20T07:37:11.713144824Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-ybe","depends_on_id":"bd-3po7","type":"blocks","created_at":"2026-02-20T07:48:21.598558852Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-ybe","depends_on_id":"bd-b541","type":"blocks","created_at":"2026-02-20T07:37:06.456439910Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-ybe","depends_on_id":"bd-c97l","type":"blocks","created_at":"2026-02-20T07:37:07.034435652Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-ybe","depends_on_id":"bd-cclm","type":"blocks","created_at":"2026-02-20T07:37:07.565014060Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-ybe","depends_on_id":"bd-cda","type":"blocks","created_at":"2026-02-20T07:37:09.817479825Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-ybe","depends_on_id":"bd-t89w","type":"blocks","created_at":"2026-02-20T07:37:06.621423352Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-ye4m","title":"[10.21] Implement adversarial evaluation suite for slow-roll mimicry, staged camouflage, and dormant-then-burst mutation campaigns.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.21 — Behavioral Phenotype Evolution Tracker Execution Track (9O)\n\nWhy This Exists:\nBPET longitudinal phenotype intelligence track for pre-compromise trajectory detection and integration with DGIS/ATC/migration/economic policy.\n\nTask Objective:\nImplement adversarial evaluation suite for slow-roll mimicry, staged camouflage, and dormant-then-burst mutation campaigns.\n\nAcceptance Criteria:\n- Simulated adversaries test resilience to trajectory-gaming tactics; bypasses emit typed failure classes and trigger policy hardening recommendations.\n\nExpected Artifacts:\n- `tests/security/bpet_adversarial_evolution_suite.rs`, `docs/security/bpet_adversarial_playbook.md`, `artifacts/10.21/bpet_adversarial_results.json`.\n\n- Machine-readable verification artifact at `artifacts/section_10_21/bd-ye4m/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_21/bd-ye4m/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests for core logic, invariants, and error handling.\n- Integration/E2E tests for end-to-end control-flow behavior.\n- Detailed structured logs/telemetry with stable codes and trace correlation IDs.\n- Deterministic replay fixture or reproducible artifact for failure analysis.\n\nTask-Specific Clarification:\n- For \"[10.21] Implement adversarial evaluation suite for slow-roll mimicry, staged camouflage, and dormant-then-burst mutation campaigns.\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.21] Implement adversarial evaluation suite for slow-roll mimicry, staged camouflage, and dormant-then-burst mutation campaigns.\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.21] Implement adversarial evaluation suite for slow-roll mimicry, staged camouflage, and dormant-then-burst mutation campaigns.\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.21] Implement adversarial evaluation suite for slow-roll mimicry, staged camouflage, and dormant-then-burst mutation campaigns.\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.21] Implement adversarial evaluation suite for slow-roll mimicry, staged camouflage, and dormant-then-burst mutation campaigns.\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- Simulated adversaries test resilience to trajectory-gaming tactics; bypasses emit typed failure classes and trigger policy hardening recommendations.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:37:08.793889202Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:27.550662159Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-21","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-ye4m","depends_on_id":"bd-3cbi","type":"blocks","created_at":"2026-02-20T07:43:21.862625458Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-yqz","title":"[10.0] Implement fleet quarantine UX + control plane.","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.0 — Top 10 Initiative Tracking (Initiative #6)\nCross-references: 9A.6, 9B.6, 9C.6, 9D.6\n\nWhy This Exists:\nFleet quarantine UX + control plane is the #6 strategic initiative. It turns engine-level containment primitives into operator-grade workflows with global scope, blast-radius views, convergence indicators, and rollback controls. Without this, quarantine operations remain low-level and error-prone.\n\nTask Objective:\nBuild the fleet quarantine user experience and control plane that enables operators to manage quarantine/revocation operations across distributed deployments with clear visibility into scope, impact, convergence state, and rollback options.\n\nDetailed Acceptance Criteria:\n1. Fleet control API for quarantine/revocation operations with zone/tenant scoping.\n2. Blast-radius visualization showing affected extensions, publishers, and dependent workloads.\n3. Convergence indicators: real-time progress tracking of quarantine propagation across fleet.\n4. Rollback controls: deterministic rollback to pre-quarantine state with verification.\n5. Anti-entropy reconciliation and bounded degraded-mode semantics under network partition (9B.6).\n6. Probabilistic SLO proofs for containment latency and convergence quality (9C.6).\n7. Propagation path latency and conflict reconciliation fast paths optimized (9D.6).\n8. CLI surface: franken-node fleet status/release/reconcile commands.\n9. Convergence timeout configurable per profile (strict=60s, balanced=120s, legacy-risky=300s per config.rs).\n\nKey Dependencies:\n- Depends on engine-level containment primitives from franken_engine.\n- Consumed by 10.8 (Operational Readiness) for fleet control API.\n- Consumed by 10.5 (Security) for policy-driven quarantine decisions.\n- Integrates with 10.20 (DGIS) for topology-aware containment.\n\nExpected Artifacts:\n- src/fleet/ module with control_plane.rs, convergence.rs, blast_radius.rs, rollback.rs.\n- CLI integration for fleet commands in cli.rs.\n- docs/specs/section_10_0/bd-yqz_contract.md\n- artifacts/section_10_0/bd-yqz/verification_evidence.json\n\nTesting and Logging Requirements:\n- Unit tests: convergence calculation, blast radius computation, rollback state verification, anti-entropy reconciliation.\n- Integration tests: quarantine propagation across simulated multi-zone fleet.\n- E2E tests: franken-node fleet status/release/reconcile CLI workflows.\n- Fault injection tests: network partition during quarantine propagation, convergence under degraded mode.\n- Structured logs: QUARANTINE_INITIATED, PROPAGATION_PROGRESS, CONVERGENCE_REACHED, ROLLBACK_EXECUTED, DEGRADED_MODE_ENTERED with trace IDs and zone metadata.","acceptance_criteria":"1. Global scope: quarantine operations apply fleet-wide; single quarantine action propagates to all enrolled nodes within <= 120 seconds.\n2. Blast-radius views: CLI and API expose affected node count, affected workload count, estimated user impact percentage, and dependency graph of quarantined components.\n3. Convergence indicators: real-time dashboard data (JSON API) showing: quarantine propagation progress (% nodes confirmed), rollback progress, and time-to-convergence estimate.\n4. Rollback controls: deterministic single-command rollback (`franken-node quarantine rollback <id>`) that restores pre-quarantine state; rollback verified by post-rollback health check.\n5. Quarantine policies are declarative: trigger conditions (severity threshold, anomaly score, revocation event), scope (extension/version/publisher), and auto-escalation rules.\n6. Audit trail: every quarantine action (create/extend/rollback/expire) logged with timestamp, actor, justification, blast-radius snapshot; append-only and tamper-evident.\n7. Integration with trust cards (bd-y4g): revocation events automatically trigger quarantine evaluation; trust score drop below threshold triggers quarantine proposal.\n8. Compromise reduction contribution: quarantine system contributes to >= 10x compromise reduction target (Section 3) by containing blast radius within <= 60 seconds of detection.\n9. UX: quarantine status visible in `franken-node status` output; color-coded severity; actionable next-step suggestions.\n10. Verification evidence includes: propagation latency measurement, rollback success test, blast-radius calculation accuracy test, convergence indicator correctness test.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:36:42.883031172Z","created_by":"ubuntu","updated_at":"2026-02-20T15:36:06.178178085Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-0","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-yqz","depends_on_id":"bd-1vm","type":"blocks","created_at":"2026-02-20T15:01:23.957644953Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-yqz","depends_on_id":"bd-mwf","type":"blocks","created_at":"2026-02-20T07:43:10.310263860Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-yqz","depends_on_id":"bd-tg2","type":"blocks","created_at":"2026-02-20T15:01:24.143258180Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-yz3t","title":"[14] Publish verifier toolkit for independent validation","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 14\n\nTask Objective:\nDeliver verifier toolkit enabling independent claim validation.\n\nExecution Requirements:\n- Make this requirement machine-verifiable and release-gated where applicable.\n- Keep behavior self-documenting so future contributors do not need to re-open the master plan.\n\nTesting & Logging Requirements:\n- Unit tests for rule/contract logic and error conditions.\n- Integration/E2E tests for workflow-level enforcement.\n- Structured logs with stable codes and trace IDs.\n- Reproducible artifacts that prove contract satisfaction.\n\nAcceptance Criteria:\n- Success and failure invariants for [14] Publish verifier toolkit for independent validation are explicitly quantified and machine-verifiable.\n- Determinism requirements for [14] Publish verifier toolkit for independent validation are validated across repeated runs and adversarial perturbations.\n\n\nExpected Artifacts:\n- Machine-readable verification artifact with explicit canonical path under artifacts/section_14/bd-yz3t/verification_evidence.json, suitable for CI/release gating.\n- Human-readable verification summary with explicit canonical path under artifacts/section_14/bd-yz3t/verification_summary.md, linking implementation intent to measured validation outcomes.\n\nTask-Specific Clarification:\n- The implementation must deliver the exact capability named in the title, with no scope dilution and no silent feature omission.\n- Validation artifacts must include capability-specific thresholds, pass/fail criteria, and reproducible evidence bundles tied to this bead ID.\n- Program/section verification gates must be able to consume this bead's outputs without manual interpretation.\n\nWhy This Improves User Outcomes:\n- \"[14] Publish verifier toolkit for independent validation\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[14] Publish verifier toolkit for independent validation\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"1. Verifier toolkit is published as an independently installable package (npm, cargo crate, or standalone binary).\n2. Toolkit enables external parties to validate: (a) compatibility claims against the published corpus, (b) security claims via reproducible attack scenarios, (c) performance claims via standardized benchmark workloads.\n3. Toolkit requires no access to franken_node source code — operates on published artifacts and binary.\n4. Toolkit produces a validation report (JSON + Markdown) with per-claim verdict: confirmed/refuted/inconclusive.\n5. Documentation: getting-started guide enables first validation run in <= 15 minutes.\n6. Toolkit is versioned in lockstep with benchmark versions; version compatibility matrix is published.\n7. At least 1 external party has used the toolkit and provided feedback (tracked in feedback log).\n8. Evidence: verifier_toolkit_release.json with version, download URL, platform support, and external feedback summary.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-20T07:39:35.471414837Z","created_by":"ubuntu","updated_at":"2026-02-20T15:24:04.405317727Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-14","self-contained","test-obligations"],"dependencies":[{"issue_id":"bd-yz3t","depends_on_id":"bd-wzjl","type":"blocks","created_at":"2026-02-20T07:43:25.849846186Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-z7bt","title":"[13] Section-wide verification gate: comprehensive unit+e2e+logging","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 13\n\nTask Objective:\nCreate a hard section completion gate that verifies all implemented behavior in this section with comprehensive unit tests, integration/e2e scripts, and detailed structured logging evidence.\n\nAcceptance Criteria:\n- Section test matrix covers happy-path, edge-case, and adversarial/error-path scenarios for all section deliverables.\n- E2E scripts execute representative end-user workflows and policy/control-plane transitions for this section.\n- Structured logs include stable event/error codes, trace correlation IDs, and enough context for deterministic replay triage.\n- Verification report is deterministic and machine-readable for CI/release gating.\n\nExpected Artifacts:\n- Section-level test matrix and coverage summary artifact.\n- E2E script suite with pass/fail outputs and reproducible fixtures/seeds.\n- Structured log validation report and traceability bundle.\n- Gate verdict artifact consumable by release automation.\n\n- Machine-readable verification artifact at `artifacts/section_13/bd-z7bt/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_13/bd-z7bt/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests must validate contracts, invariants, and failure semantics.\n- E2E tests must validate cross-component behavior from user/operator entrypoints to persisted effects.\n- Logging must support root-cause analysis without hidden context requirements.\n\nTask-Specific Clarification:\n- For \"[13] Section-wide verification gate: comprehensive unit+e2e+logging\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[13] Section-wide verification gate: comprehensive unit+e2e+logging\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[13] Section-wide verification gate: comprehensive unit+e2e+logging\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[13] Section-wide verification gate: comprehensive unit+e2e+logging\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[13] Section-wide verification gate: comprehensive unit+e2e+logging\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"1. Section 13 verification gate runs all success-criteria check scripts and confirms 100% pass rate.\n2. Gate validates: (a) all quantitative targets have measurement infrastructure in place, (b) all success criteria have unit tests, (c) evidence artifacts exist for all measurable criteria.\n3. Quantitative summary: >= 95% compat pass, >= 3x migration velocity, >= 10x compromise reduction, 100% replay coverage, >= 2 replications — all measured and reported.\n4. Gate produces section_13_verification_summary.md with per-criterion measured value vs target.\n5. Any criterion below target is flagged with gap analysis and remediation plan.\n6. The gate itself has a unit test verifying correct aggregation and threshold comparison logic.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:48:29.034567608Z","created_by":"ubuntu","updated_at":"2026-02-20T15:23:28.617407767Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-13","test-obligations","verification-gate"],"dependencies":[{"issue_id":"bd-z7bt","depends_on_id":"bd-1dpd","type":"blocks","created_at":"2026-02-20T08:24:23.893583167Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-z7bt","depends_on_id":"bd-1w78","type":"blocks","created_at":"2026-02-20T07:48:29.583154761Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-z7bt","depends_on_id":"bd-1xao","type":"blocks","created_at":"2026-02-20T07:48:29.434802006Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-z7bt","depends_on_id":"bd-28sz","type":"blocks","created_at":"2026-02-20T07:48:29.336653099Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-z7bt","depends_on_id":"bd-2a4l","type":"blocks","created_at":"2026-02-20T07:48:29.534267146Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-z7bt","depends_on_id":"bd-2f43","type":"blocks","created_at":"2026-02-20T07:48:29.632150919Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-z7bt","depends_on_id":"bd-2l1k","type":"blocks","created_at":"2026-02-20T07:48:29.187313866Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-z7bt","depends_on_id":"bd-2twu","type":"blocks","created_at":"2026-02-20T08:20:49.302407217Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-z7bt","depends_on_id":"bd-34d5","type":"blocks","created_at":"2026-02-20T08:02:25.864726127Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-z7bt","depends_on_id":"bd-3agp","type":"blocks","created_at":"2026-02-20T07:48:29.287689802Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-z7bt","depends_on_id":"bd-3cpa","type":"blocks","created_at":"2026-02-20T07:48:29.238047871Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-z7bt","depends_on_id":"bd-3e74","type":"blocks","created_at":"2026-02-20T07:48:29.386053930Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-z7bt","depends_on_id":"bd-pga7","type":"blocks","created_at":"2026-02-20T07:48:29.484603013Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-z7bt","depends_on_id":"bd-whxp","type":"blocks","created_at":"2026-02-20T07:48:29.137567260Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-z7ix","title":"Epic: Extension Ecosystem + Registry [10.4]","description":"- type: epic","status":"closed","priority":2,"issue_type":"task","created_at":"2026-02-20T07:47:58.072163029Z","updated_at":"2026-02-20T07:49:21.107289257Z","closed_at":"2026-02-20T07:49:21.107270903Z","close_reason":"Superseded by canonical detailed master-plan graph (bd-33v) with full 10.N-10.21 and 11-16 coverage, explicit dependencies, and per-section verification gates.","source_repo":".","compaction_level":0,"original_size":0}
{"id":"bd-zm5b","title":"[10.21] Section-wide verification gate: comprehensive unit+e2e+logging","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.21\n\nTask Objective:\nCreate a hard section completion gate that verifies all implemented behavior in this section with comprehensive unit tests, integration/e2e scripts, and detailed structured logging evidence.\n\nAcceptance Criteria:\n- Section test matrix covers happy-path, edge-case, and adversarial/error-path scenarios for all section deliverables.\n- E2E scripts execute representative end-user workflows and policy/control-plane transitions for this section.\n- Structured logs include stable event/error codes, trace correlation IDs, and enough context for deterministic replay triage.\n- Verification report is deterministic and machine-readable for CI/release gating.\n\nExpected Artifacts:\n- Section-level test matrix and coverage summary artifact.\n- E2E script suite with pass/fail outputs and reproducible fixtures/seeds.\n- Structured log validation report and traceability bundle.\n- Gate verdict artifact consumable by release automation.\n\n- Machine-readable verification artifact at `artifacts/section_10_21/bd-zm5b/verification_evidence.json` for CI/release gating.\n- Human-readable verification summary at `artifacts/section_10_21/bd-zm5b/verification_summary.md` linking implementation intent to measured outcomes.\nTesting & Logging Requirements:\n- Unit tests must validate contracts, invariants, and failure semantics.\n- E2E tests must validate cross-component behavior from user/operator entrypoints to persisted effects.\n- Logging must support root-cause analysis without hidden context requirements.\n\nTask-Specific Clarification:\n- For \"[10.21] Section-wide verification gate: comprehensive unit+e2e+logging\", preserve full capability scope from the plan; no feature compression or silent omission is allowed.\n- Verification for \"[10.21] Section-wide verification gate: comprehensive unit+e2e+logging\" must include capability-specific thresholds and machine-readable pass/fail evidence artifacts.\n- Unit tests, integration/E2E scripts, and structured logs for \"[10.21] Section-wide verification gate: comprehensive unit+e2e+logging\" must support deterministic replay and root-cause triage without hidden context.\n\nWhy This Improves User Outcomes:\n- \"[10.21] Section-wide verification gate: comprehensive unit+e2e+logging\" is required to reduce operator error, increase deterministic safety guarantees, and improve time-to-diagnosis for failures in real-world workflows.\n- Explicit success/failure evidence for \"[10.21] Section-wide verification gate: comprehensive unit+e2e+logging\" prevents false confidence and improves trust in migration/compatibility/security outcomes.\n- Detailed unit + integration/E2E + structured logging requirements ensure reproducible quality and faster incident remediation for users.","acceptance_criteria":"- Section test matrix covers happy-path, edge-case, and adversarial/error-path scenarios for all section deliverables.\n- E2E scripts execute representative end-user workflows and policy/control-plane transitions for this section.\n- Structured logs include stable event/error codes, trace correlation IDs, and enough context for deterministic replay triage.\n- Verification report is deterministic and machine-readable for CI/release gating.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-20T07:48:21.762437314Z","created_by":"ubuntu","updated_at":"2026-02-20T15:45:28.124456449Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-21","test-obligations","verification-gate"],"dependencies":[{"issue_id":"bd-zm5b","depends_on_id":"bd-1b9x","type":"blocks","created_at":"2026-02-20T07:48:22.300226185Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-zm5b","depends_on_id":"bd-1dpd","type":"blocks","created_at":"2026-02-20T08:24:25.464208870Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-zm5b","depends_on_id":"bd-1ga5","type":"blocks","created_at":"2026-02-20T07:48:22.447989892Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-zm5b","depends_on_id":"bd-1jpc","type":"blocks","created_at":"2026-02-20T07:48:22.251792795Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-zm5b","depends_on_id":"bd-1naf","type":"blocks","created_at":"2026-02-20T07:48:21.911223176Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-zm5b","depends_on_id":"bd-232t","type":"blocks","created_at":"2026-02-20T07:48:22.202650104Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-zm5b","depends_on_id":"bd-2ao3","type":"blocks","created_at":"2026-02-20T07:48:22.399502893Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-zm5b","depends_on_id":"bd-2lll","type":"blocks","created_at":"2026-02-20T07:48:22.351386493Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-zm5b","depends_on_id":"bd-2twu","type":"blocks","created_at":"2026-02-20T08:20:51.133554194Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-zm5b","depends_on_id":"bd-2xgs","type":"blocks","created_at":"2026-02-20T07:48:22.545790912Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-zm5b","depends_on_id":"bd-2zo1","type":"blocks","created_at":"2026-02-20T07:48:22.103844453Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-zm5b","depends_on_id":"bd-39ga","type":"blocks","created_at":"2026-02-20T07:48:22.595406483Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-zm5b","depends_on_id":"bd-3cbi","type":"blocks","created_at":"2026-02-20T07:48:22.008292252Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-zm5b","depends_on_id":"bd-3rai","type":"blocks","created_at":"2026-02-20T07:48:22.495990636Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-zm5b","depends_on_id":"bd-3v9l","type":"blocks","created_at":"2026-02-20T07:48:21.859341734Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-zm5b","depends_on_id":"bd-aoq6","type":"blocks","created_at":"2026-02-20T07:48:22.056325276Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-zm5b","depends_on_id":"bd-kwwg","type":"blocks","created_at":"2026-02-20T07:48:22.152229884Z","created_by":"ubuntu","metadata":"{}","thread_id":""},{"issue_id":"bd-zm5b","depends_on_id":"bd-ye4m","type":"blocks","created_at":"2026-02-20T07:48:21.959993523Z","created_by":"ubuntu","metadata":"{}","thread_id":""}]}
{"id":"bd-zxk8","title":"[10.N] Publish canonical capability ownership registry","description":"Master Plan Source: PLAN_TO_CREATE_FRANKEN_NODE.md\nSection: 10.N — Execution Normalization Contract (No Duplicate Implementations)\n\nWhy This Exists:\nThe canonical ownership map prevents duplicate implementations of the same protocol semantics across parallel tracks. Without this, multiple tracks would independently implement the same capability, creating maintenance burden, divergence risk, and confusion about which version is authoritative.\n\nTask Objective:\nPublish and enforce a canonical ownership registry mapping each capability/protocol family to exactly one implementation owner track, with all other tracks constrained to integration/policy/adoption responsibilities.\n\nCANONICAL OWNERSHIP MAP (from Plan Section 10.N):\n- remote registry/idempotency/saga semantics: CANONICAL in 10.14, integrated and policy-gated in 10.15.\n- epoch validity + transition barriers: CANONICAL in 10.14, integrated into control workflows in 10.15.\n- evidence ledger + replay validator: CANONICAL in 10.14, mandatory adoption and release gating in 10.15.\n- fault harness/cancellation injection/DPOR exploration: CANONICAL harness in 10.14, control-plane enforcement gate in 10.15.\n- verifier SDK/replay capsules/claim compiler + trust scoreboard: CANONICAL in 10.17, ecosystem distribution/adoption in 10.9 + 10.12.\n- semantic oracle: L1 product oracle owned in 10.2, L2 engine-boundary oracle owned in 10.17.\n- authenticated control channel + anti-replay framing: CANONICAL protocol in 10.13, adoption and policy rollout in 10.10 + 10.15.\n- revocation freshness semantics: CANONICAL enforcement in 10.13, ecosystem/policy adoption in 10.4 + 10.10.\n- stable error taxonomy and recovery contract: CANONICAL definition in 10.13, operations/product-surface adoption in 10.8 + 10.10.\n- trust protocol vectors/golden fixtures: CANONICAL generation in 10.13 + 10.14, release and publication gates in 10.7 + 10.10.\n- verifiable execution fabric (policy-constraint compiler + receipt commitments + proof generation/verification): CANONICAL in 10.18, consumed by 10.17 verifier/claim surfaces and enforced through 10.15 control-plane gates.\n- adversarial trust commons federation (privacy-preserving signal sharing + global priors + incentive weighting): CANONICAL in 10.19, consumed by 10.17 adversary graph/reputation surfaces and enforced through 10.15 + 10.4 trust controls.\n- dependency graph immune system (topological risk model + contagion simulator + preemptive barrier planner): CANONICAL in 10.20, consumed by 10.17 adversary/economic scoring, 10.15 control-plane containment, and 10.19 federated threat-intelligence enrichment.\n- behavioral phenotype evolution tracker (longitudinal genome modeling + drift/regime-shift detection + hazard scoring): CANONICAL in 10.21, consumed by 10.17 adversary/trust scoring, 10.20 topological prioritization, 10.19 federated temporal intelligence, and 10.2/10.15 migration-control gating.\n- spec-first Node/Bun compatibility extraction and fixture-oracle baselining: CANONICAL in 10.2, consumed by 10.3 migration automation and 10.7 release verification.\n\nORACLE DELIVERY CLOSE CONDITION:\nDual-layer oracle is only complete when L1 (10.2) + L2 (10.17) + release policy linkage (10.2) are all green.\n\nAcceptance Criteria:\n- Ownership registry enumerates ALL capability domains listed above.\n- Each capability has one and only one canonical implementation owner.\n- Integration/adoption tracks reference owner capability IDs rather than re-defining implementation semantics.\n- Machine-readable registry format (JSON) queryable by CI gates and agents.\n- Registry is linked into all section epics as a dependency to ensure awareness.\n\nExpected Artifacts:\n- docs/capability_ownership_registry.json — machine-readable canonical map.\n- docs/CAPABILITY_OWNERSHIP_REGISTRY.md — human-readable reference.\n- CI integration for ownership validation.\n\nTesting and Logging Requirements:\n- Unit tests: ownership map schema validation, uniqueness constraints, no-orphan capability checks.\n- Integration tests: cross-track references resolve to canonical owners correctly.\n- E2E: CI gate blocks PRs that introduce duplicate implementations without waiver.\n- Structured logs: OWNERSHIP_VALIDATED, DUPLICATE_DETECTED, WAIVER_GRANTED with trace IDs.","status":"closed","priority":1,"issue_type":"task","assignee":"ubuntu","created_at":"2026-02-20T07:50:04.092016885Z","created_by":"ubuntu","updated_at":"2026-02-20T13:07:33.935321926Z","closed_at":"2026-02-20T08:13:12.040442327Z","source_repo":".","compaction_level":0,"original_size":0,"labels":["plan","section-10-N","self-contained","test-obligations"]}
